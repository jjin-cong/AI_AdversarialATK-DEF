{"cells":[{"cell_type":"markdown","source":["데이터셋 설정 관련\n","* for문으로 돌리려다가, 방어기법에서까지 하나하나 돌리는게 너무 오래 걸려서 코드로 나누고 계정별로 돌릴 수 있게 코드 변경했습니다\n","* 공격 종류 (FGSM, PGD), 공격 입실론 (0.02 등)을 목차 [Attack 수행 : 공격 데이터셋 만드는 코드] 부분에서 수정하고 코드 돌리면 됩니다\n","\n","1. 모든 train valid 데이터는 0~1사이로 정규화 되어있음.\n","2. 모든 test 데이터는 0~255로 정규화 안되어있음\n","3. target 값은 정규화하면 안됨."],"metadata":{"id":"05NggkxjGxlN"}},{"cell_type":"markdown","source":["# 기본 import"],"metadata":{"id":"H5r08xIXerXB"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"WgKss5hJBb5B","executionInfo":{"status":"ok","timestamp":1664034785100,"user_tz":-540,"elapsed":3332,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import time\n","import os\n","import pathlib\n","\n","import cv2 #영상처리에 사용하는 오픈소스 라이브러리, 컴퓨터가 사람 눈처럼 인식할 수 있게 처리\n","from PIL import Image # 파이썬 이미지 처리 pillow 라이브러리\n","from tensorflow.keras.preprocessing import image\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator #imagedatagenerater는 이미지를 학습시킬 때 학습 데이터의 양이 적을 경우 학습데이터를 조금씩 변형 시켜서 학습데이터의 양을 늘리는 방식중 하나\n","from tensorflow.keras.preprocessing.image import img_to_array, array_to_img, load_img\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n","from tensorflow.keras.models import Sequential\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","from tqdm.auto import tqdm\n","\n","#난수 랜덤성 고정\n","np.random.seed(42)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29902,"status":"ok","timestamp":1664034814997,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"},"user_tz":-540},"id":"Qn7HC1qiBnNE","outputId":"5c4a363b-fabf-488d-dfeb-b1585a13b4c9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2018,"status":"ok","timestamp":1664034817013,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"},"user_tz":-540},"id":"VwTVXhm7BoaE","outputId":"e22a3b9d-8354-48f1-9584-9565f640d978"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1WKEjdIyqtzI-NV5o0O_ixsHslngaSiQX/[한이음] 적대적 AI 공격에 대한 인공지능 보안기술 연구/3. 소스코드/GTSRB\n"]}],"source":["cd drive/MyDrive/[한이음] 적대적 AI 공격에 대한 인공지능 보안기술 연구/3. 소스코드/GTSRB"]},{"cell_type":"markdown","source":["# Train & Test 데이터 불러오기"],"metadata":{"id":"FhnfS-0MH1sa"}},{"cell_type":"markdown","metadata":{"id":"JjBcm524Fams"},"source":["Train Data 불러오기"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"kZnmTWHIBo_E","executionInfo":{"status":"ok","timestamp":1664034817014,"user_tz":-540,"elapsed":4,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"outputs":[],"source":["import numpy as np\n","import os\n","import gzip\n","import urllib.request\n","\n","from keras.models import load_model\n","\n","def ordered_onehotencoding(labels):\n","    labels_ordered = []\n","    for i in range(len(labels)):\n","        if labels[i] == 3:\n","            labels_ordered.append(0)\n","        elif labels[i] == 7:\n","            labels_ordered.append(1)\n","        elif labels[i] == 9:\n","            labels_ordered.append(2)\n","        elif labels[i] == 10:\n","            labels_ordered.append(3)\n","        elif labels[i] == 11:\n","            labels_ordered.append(4)\n","        elif labels[i] == 12:\n","            labels_ordered.append(5)\n","        elif labels[i] == 13:\n","            labels_ordered.append(6)\n","        elif labels[i] == 17:\n","            labels_ordered.append(7)\n","        elif labels[i] == 18:\n","            labels_ordered.append(8)\n","        elif labels[i] == 25:\n","            labels_ordered.append(9)\n","        elif labels[i] == 35:\n","            labels_ordered.append(10)\n","        elif labels[i] == 38:\n","            labels_ordered.append(11)\n","    \n","    return np.array(labels_ordered)\n","\n","class GTSRB:\n","    def __init__(self):\n","        imgs_path = \"Train\"\n","        data_list = []\n","        labels_list = []\n","\n","        result_class = [3,7, 9, 10, 11, 12, 13, 17, 18, 25, 35, 38]\n","\n","        for i in result_class:\n","            i_path = os.path.join(imgs_path, str(i)) # 3, 7, 9, 10, 11, 12,13, 17, 18, 25, 35, 38\n","            num = 0\n","            for img in os.listdir(i_path):\n","          \n","                im = Image.open(i_path +'/'+ img)\n","                im = im.resize((32,32))\n","                im = np.array(im)\n","\n","                data_list.append(im)\n","                labels_list.append(i)\n","                num = num + 1\n","                if num == 1000:\n","                    break;\n","\n","        data = np.array(data_list)\n","        labels = ordered_onehotencoding(labels_list)\n","\n","        labels = to_categorical(labels)\n","\n","        VALIDATION_SIZE = 5000\n","        \n","        self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(np.array(data), labels, test_size=0.4)    \n","\n","    @staticmethod\n","    def print():\n","        return \"GTSRB\""]},{"cell_type":"code","execution_count":5,"metadata":{"id":"lWo9BzndEm67","executionInfo":{"status":"ok","timestamp":1664035158027,"user_tz":-540,"elapsed":341016,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"outputs":[],"source":["data = GTSRB()"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"Zc5Q_EXiEppb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664035158027,"user_tz":-540,"elapsed":40,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}},"outputId":"af2adda1-ffa4-4e90-ef6e-7d2eecc04e90"},"outputs":[{"output_type":"stream","name":"stdout","text":["(7200, 32, 32, 3)\n","(4800, 32, 32, 3)\n","(7200, 12)\n","(4800, 12)\n"]}],"source":["print(data.x_train.shape) # 0~255\n","print(data.x_test.shape) # 0~255\n","print(data.y_train.shape) # 0~11 원핫 인코딩\n","print(data.y_test.shape) # 0~11 원핫 인코딩"]},{"cell_type":"code","source":["print(np.min(data.x_train))\n","print(np.max(data.x_train))\n","print(np.min(data.x_test))\n","print(np.max(data.x_test))"],"metadata":{"id":"JtM8GsuYfDFc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664035158031,"user_tz":-540,"elapsed":36,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}},"outputId":"8ccd42e5-7586-43b5-d3eb-98150eb579d5"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","255\n","0\n","255\n"]}]},{"cell_type":"code","source":["data.x_train, data.y_train, data.x_test, data.y_test =data.x_train/255, data.y_train, data.x_test/255, data.y_test #0~1로 찐 train만 정규화"],"metadata":{"id":"L88pCixpf4wC","executionInfo":{"status":"ok","timestamp":1664035158032,"user_tz":-540,"elapsed":31,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["print(np.min(data.x_train))\n","print(np.max(data.x_train))\n","print(np.min(data.x_test))\n","print(np.max(data.x_test))"],"metadata":{"id":"YoKSRN2ef-n0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664035158032,"user_tz":-540,"elapsed":31,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}},"outputId":"f9cacdc3-dbd8-4938-86a1-f6333e01ec95"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["0.0\n","1.0\n","0.0\n","1.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"P2uSEM66FdVa"},"source":["Test Data 불러오기"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"_shX58HHFisj","executionInfo":{"status":"ok","timestamp":1664035160234,"user_tz":-540,"elapsed":2211,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"outputs":[],"source":["metainfo = pd.read_csv(\"Meta.csv\")\n","traininfo = pd.read_csv(\"Train.csv\")\n","testinfo = pd.read_csv(\"Test.csv\")"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"z9HPAPg2FZ9L","executionInfo":{"status":"ok","timestamp":1664035160234,"user_tz":-540,"elapsed":3,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"outputs":[],"source":["import natsort\n","\n","class GTSRB_test:\n","    def __init__(self):\n","        imgs_path = \"Test\"\n","        data_list = []\n","        labels_list = []\n","        \n","        for img in natsort.natsorted(os.listdir(imgs_path)):\n","            im = Image.open(imgs_path +'/'+ img)\n","            im = im.resize((32,32))\n","            im = np.array(im)\n","            data_list.append(im)\n","        data_test = np.array(data_list)\n","        \n","        for i in range(len(testinfo.ClassId)):\n","            labels_list.append(testinfo.ClassId[i])\n","        \n","        labels_test = np.array(labels_list)\n","\n","        labels_test_index = []\n","        for i in range(len(labels_test)):\n","            if (labels_test[i] == 3) | (labels_test[i] == 7) | (labels_test[i] == 9) | (labels_test[i] == 10) | (labels_test[i] == 11) | (labels_test[i] == 12) | (labels_test[i] == 13) | (labels_test[i] == 17) | (labels_test[i] == 18) | (labels_test[i] == 25) | (labels_test[i] == 35) | (labels_test[i] == 38):\n","                labels_test_index.append(i)\n","\n","        test_data = []\n","        test_label = []\n","        for i in labels_test_index:\n","            test_data.append(data_test[i])\n","            test_label.append(labels_test[i])\n","\n","        data_test = np.array(test_data)\n","\n","        labels_test =ordered_onehotencoding(test_label)\n","\n","        labels_test = to_categorical(labels_test)\n","        \n","        self.x_test = data_test\n","        self.y_test = labels_test    \n","\n","    @staticmethod\n","    def print():\n","        return \"GTSRB_test\""]},{"cell_type":"code","execution_count":12,"metadata":{"id":"CcWfJaa6Ft7z","executionInfo":{"status":"ok","timestamp":1664035370549,"user_tz":-540,"elapsed":210317,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"outputs":[],"source":["data_test = GTSRB_test()"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"VE9NTZrAFv7e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664035370550,"user_tz":-540,"elapsed":20,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}},"outputId":"e9a69074-c7b9-459a-ba67-f154d747903a"},"outputs":[{"output_type":"stream","name":"stdout","text":["(6180, 32, 32, 3)\n","(6180, 12)\n"]}],"source":["print(data_test.x_test.shape) # 0~255\n","print(data_test.y_test.shape) # 12개 원핫 인코딩"]},{"cell_type":"code","source":["print(np.min(data_test.x_test))\n","print(np.max(data_test.x_test))"],"metadata":{"id":"phupmxLufTsN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664035370550,"user_tz":-540,"elapsed":16,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}},"outputId":"08bd64ec-5699-41d7-b19b-f6a1e82b34e4"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","255\n"]}]},{"cell_type":"markdown","metadata":{"id":"XWfrLWt3EtSN"},"source":["# 분류기 : CNN"]},{"cell_type":"code","source":["print(np.min(data.x_train))\n","print(np.max(data.x_train))\n","print(np.min(data.x_test))\n","print(np.max(data.x_test))"],"metadata":{"id":"-Ll78wYPewyM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664035370551,"user_tz":-540,"elapsed":10,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}},"outputId":"9ab3ad48-5e6a-4cf9-8967-be49c86d1482"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["0.0\n","1.0\n","0.0\n","1.0\n"]}]},{"cell_type":"code","execution_count":16,"metadata":{"id":"gI5nIfEQE0Dt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664035422986,"user_tz":-540,"elapsed":52442,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}},"outputId":"e7bca796-91c3-42ac-cb98-29b9eeb8597d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 30, 30, 96)        2688      \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 15, 15, 96)       0         \n"," )                                                               \n","                                                                 \n"," dropout (Dropout)           (None, 15, 15, 96)        0         \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 13, 13, 192)       166080    \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 6, 6, 192)        0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_1 (Dropout)         (None, 6, 6, 192)         0         \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 4, 4, 192)         331968    \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 64)                196672    \n","                                                                 \n"," dense_1 (Dense)             (None, 12)                780       \n","                                                                 \n","=================================================================\n","Total params: 698,188\n","Trainable params: 698,188\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/30\n","60/60 [==============================] - 13s 23ms/step - loss: 0.3204 - accuracy: 0.1303 - val_loss: 0.2574 - val_accuracy: 0.2760\n","Epoch 2/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.1892 - accuracy: 0.5074 - val_loss: 0.1229 - val_accuracy: 0.7329\n","Epoch 3/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0904 - accuracy: 0.8169 - val_loss: 0.0656 - val_accuracy: 0.9004\n","Epoch 4/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0500 - accuracy: 0.9224 - val_loss: 0.0364 - val_accuracy: 0.9590\n","Epoch 5/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0312 - accuracy: 0.9606 - val_loss: 0.0264 - val_accuracy: 0.9712\n","Epoch 6/30\n","60/60 [==============================] - 1s 19ms/step - loss: 0.0203 - accuracy: 0.9764 - val_loss: 0.0180 - val_accuracy: 0.9831\n","Epoch 7/30\n","60/60 [==============================] - 1s 24ms/step - loss: 0.0145 - accuracy: 0.9847 - val_loss: 0.0148 - val_accuracy: 0.9842\n","Epoch 8/30\n","60/60 [==============================] - 1s 24ms/step - loss: 0.0112 - accuracy: 0.9899 - val_loss: 0.0118 - val_accuracy: 0.9883\n","Epoch 9/30\n","60/60 [==============================] - 1s 19ms/step - loss: 0.0095 - accuracy: 0.9929 - val_loss: 0.0096 - val_accuracy: 0.9908\n","Epoch 10/30\n","60/60 [==============================] - 1s 24ms/step - loss: 0.0075 - accuracy: 0.9931 - val_loss: 0.0090 - val_accuracy: 0.9915\n","Epoch 11/30\n","60/60 [==============================] - 1s 24ms/step - loss: 0.0063 - accuracy: 0.9951 - val_loss: 0.0090 - val_accuracy: 0.9896\n","Epoch 12/30\n","60/60 [==============================] - 1s 24ms/step - loss: 0.0052 - accuracy: 0.9960 - val_loss: 0.0071 - val_accuracy: 0.9933\n","Epoch 13/30\n","60/60 [==============================] - 1s 19ms/step - loss: 0.0043 - accuracy: 0.9964 - val_loss: 0.0071 - val_accuracy: 0.9929\n","Epoch 14/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0039 - accuracy: 0.9974 - val_loss: 0.0072 - val_accuracy: 0.9935\n","Epoch 15/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0031 - accuracy: 0.9975 - val_loss: 0.0061 - val_accuracy: 0.9944\n","Epoch 16/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.9985 - val_loss: 0.0058 - val_accuracy: 0.9950\n","Epoch 17/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0024 - accuracy: 0.9986 - val_loss: 0.0057 - val_accuracy: 0.9952\n","Epoch 18/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0025 - accuracy: 0.9981 - val_loss: 0.0054 - val_accuracy: 0.9956\n","Epoch 19/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0021 - accuracy: 0.9985 - val_loss: 0.0052 - val_accuracy: 0.9965\n","Epoch 20/30\n","60/60 [==============================] - 1s 19ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0055 - val_accuracy: 0.9952\n","Epoch 21/30\n","60/60 [==============================] - 1s 24ms/step - loss: 0.0021 - accuracy: 0.9982 - val_loss: 0.0063 - val_accuracy: 0.9952\n","Epoch 22/30\n","60/60 [==============================] - 1s 19ms/step - loss: 0.0018 - accuracy: 0.9992 - val_loss: 0.0048 - val_accuracy: 0.9962\n","Epoch 23/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0011 - accuracy: 0.9989 - val_loss: 0.0050 - val_accuracy: 0.9956\n","Epoch 24/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0048 - val_accuracy: 0.9962\n","Epoch 25/30\n","60/60 [==============================] - 1s 19ms/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 0.0052 - val_accuracy: 0.9962\n","Epoch 26/30\n","60/60 [==============================] - 1s 24ms/step - loss: 9.2871e-04 - accuracy: 0.9993 - val_loss: 0.0049 - val_accuracy: 0.9962\n","Epoch 27/30\n","60/60 [==============================] - 1s 18ms/step - loss: 8.7845e-04 - accuracy: 0.9997 - val_loss: 0.0057 - val_accuracy: 0.9952\n","Epoch 28/30\n","60/60 [==============================] - 1s 19ms/step - loss: 8.0725e-04 - accuracy: 0.9997 - val_loss: 0.0051 - val_accuracy: 0.9967\n","Epoch 29/30\n","60/60 [==============================] - 1s 24ms/step - loss: 5.3601e-04 - accuracy: 0.9999 - val_loss: 0.0059 - val_accuracy: 0.9958\n","Epoch 30/30\n","60/60 [==============================] - 1s 18ms/step - loss: 8.4717e-04 - accuracy: 0.9999 - val_loss: 0.0048 - val_accuracy: 0.9969\n"]}],"source":["from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D,GlobalAveragePooling2D\n","from tensorflow.keras.optimizers import SGD\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","import tensorflow as tf\n","import os\n","\n","\n","def train(data, file_name, num_epochs=50, batch_size=128):\n","    \"\"\"\n","    Standard neural network training procedure.\n","    \"\"\"\n","    model = Sequential()\n","\n","    IMG_HEIGHT = 32\n","    IMG_WIDTH = 32\n","\n","    # 첫번째 Convolutional Layer : 입력 데이터로부터 특징을 추출\n","    model.add(Conv2D(filters=96, kernel_size=3, activation='relu', input_shape=data.x_train.shape[1:]))\n","    model.add(MaxPool2D(pool_size=(2, 2)))\n","    model.add(Dropout(rate=0.25))\n","\n","    # 두번째 Convolutional Layer\n","    model.add(Conv2D(filters=192, kernel_size=3, activation='relu'))\n","    model.add(MaxPool2D(pool_size=(2, 2)))\n","    model.add(Dropout(rate=0.25)) # 인풋데이터의 25%를 무작위로 0으로 만듦\n","\n","    # 세번째 Convolutional Layer\n","    model.add(Conv2D(filters=192, kernel_size=3, activation='relu')) # 특징을 추출하는 기능을 하는 필터, 비선형 값으로 바꿔주는 activation 함수->relu\n","    # model.add(GlobalAveragePooling2D())\n","    model.add(Flatten())\n","\n","    model.add(Dense(units=64, activation='relu'))\n","    model.add(Dense(12, activation='softmax'))\n","\n","\n","    # 모델 컴파일 하기\n","    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    model.summary()\n","\n","    # 모델 핏하기\n","    EPOCHS = num_epochs\n","    model.fit(data.x_train, data.y_train,\n","              validation_data = (data.x_test, data.y_test), \n","              epochs=EPOCHS, steps_per_epoch=60\n","              )\n","\n","    if file_name != None:\n","        model.save(file_name)\n","\n","    return model\n","\n","\n","if not os.path.isdir('models'):\n","    os.makedirs('models')\n","\n","model = train(data, None, num_epochs=30)"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"Ez-W2phKFLws","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664035423672,"user_tz":-540,"elapsed":695,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}},"outputId":"de28edd1-2d40-445c-89d7-8d120494c0e9"},"outputs":[{"output_type":"stream","name":"stdout","text":["225/225 [==============================] - 1s 3ms/step - loss: 2.0184e-04 - accuracy: 1.0000\n","train set accuracy:  100.0\n","150/150 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 0.9969\n","valid set accuracy:  99.6874988079071\n"]}],"source":["loss, accuracy = model.evaluate(data.x_train, data.y_train)\n","\n","print('train set accuracy: ', accuracy * 100) #train 성능\n","\n","loss, accuracy = model.evaluate(data.x_test, data.y_test)\n","\n","print('valid set accuracy: ', accuracy * 100) #val 성능"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"xbYmfSHYHOIa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664035426144,"user_tz":-540,"elapsed":2476,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}},"outputId":"c1f15481-bec3-4a27-9fe0-c0825be4e91d"},"outputs":[{"output_type":"stream","name":"stdout","text":["194/194 [==============================] - 1s 4ms/step - loss: 0.0327 - accuracy: 0.9694\n","test set accuracy with nomalization:  96.94174528121948\n"]}],"source":["loss, accuracy = model.evaluate(data_test.x_test/255, data_test.y_test)\n","\n","print('test set accuracy with nomalization: ', accuracy * 100) #찐 test"]},{"cell_type":"markdown","source":["# 공격 데이터셋 : FGSM & PGD"],"metadata":{"id":"QNRCIvO3-8lf"}},{"cell_type":"code","source":["def tf_preprocess(image):\n","  image = tf.cast(image, tf.float32)\n","  image = image/255\n","  image = tf.image.resize(image, (32, 32))\n","  image = image[None, ...]\n","  return image\n","\n","# 확률 벡터에서 레이블을 추출해주는 헬퍼 메서드\n","def get_tf_label(labels):\n","    label = tf.cast(labels, tf.int32)\n","    label = tf.reshape(label,[1,12])\n","    return label\n","\n","loss_object = tf.keras.losses.CategoricalCrossentropy()\n","\n","def create_adversarial_pattern(input_image, input_label):\n","  with tf.GradientTape() as tape:\n","    tape.watch(input_image)\n","    input_img = tf.reshape(input_image,[1,32,32,3])\n","    prediction = model(input_img)\n","    loss = loss_object(input_label, prediction)\n","\n","  # 입력 이미지에 대한 손실 함수의 기울기를 구합니다.\n","  gradient = tape.gradient(loss, input_image)\n","  # 왜곡을 생성하기 위해 그래디언트의 부호를 구합니다.\n","  signed_grad = tf.sign(gradient)\n","  return signed_grad"],"metadata":{"id":"Dn9x64obA9UB","executionInfo":{"status":"ok","timestamp":1664035426145,"user_tz":-540,"elapsed":6,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4SUb6-MoJtay"},"source":["### FGSM & PGD define"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"DGBdi7tWJT1K","executionInfo":{"status":"ok","timestamp":1664035426145,"user_tz":-540,"elapsed":6,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"outputs":[],"source":["def fgsm_attack(model,test_x,test_y,eps):\n","    \n","    correct = 0\n","    adv_examples = []\n","    save_adv_examples = [] # 공격받은 이미지들이 저장될 리스트\n","    save_original_output = [] # 공격받은 이미지들의 정답 라벨 값이 저장될 리스트\n","    \n","    for i in range(len(test_x)):\n","        # 1장의 이미지와 그 label\n","        data = test_x[i]\n","        target_onehot = test_y[i] # one-hot 형태\n","        target_label = int(np.argmax(target_onehot)) # label 형태\n","\n","        # model이 정상 데이터를 분류한 결과 (각각 one-hot 형태, int label 형태)\n","        result_onehot = model.predict(data.reshape(1,32,32,3) / 255) # one-hot 형태\n","        result_label = int(np.argmax(result_onehot))\n","\n","        # 모델이 정상 데이터인데도 잘못 분류했다면 사용하지 않는다 (아래 코드 실행하지 않고 다음 이미지로 넘어감)\n","        if target_label != result_label:\n","            continue\n","\n","        # 이미지 전처리\n","        img =  tf_preprocess(data) # 텐서플로 전처리\n","        label = get_tf_label(target_onehot) # 확률벡터에서 레이블 추출\n","        \n","        # FGSM 공격 수행\n","        perturbations = create_adversarial_pattern(img, label)\n","        adv_x = img + eps * perturbations\n","        adv_x = tf.clip_by_value(adv_x, 0, 1) # 공격받은 이미지\n","\n","        # 공격 이미지를 분류기에 넣은 결과; 잘못 분류되어야 할 것 \n","        atkresult_onehot = model.predict(adv_x) # one-hot 형태\n","        atkresult_label = int(np.argmax(atkresult_onehot)) # label 형태\n","\n","        # 만약 공격 받아도 제대로 분류된다면 correct로 count\n","        if atkresult_label == target_label:\n","            correct += 1\n","        # ####################################################################################\n","        # ################ 여기 코드는 필요 없지 않나?\n","        #     if (eps == 0) and (len(adv_examples) < 5):\n","        #         adv_ex = adv_x\n","        #         adv_examples.append((init_output,final_pred,adv_x))\n","        # else:\n","        #     if len(adv_examples) < 5:\n","        #         adv_ex = adv_x\n","        #         adv_examples.append((init_output,final_pred,adv_x))\n","        # ####################################################################################\n","        \n","        # 공격 적용된 이미지, 그 공격 받은 이미지의 원래 정답 label을 각각 리스트에 저장합니다\n","        save_adv_examples.append(tf.reshape(adv_x,[32,32,3]))\n","        save_original_output.append(target_label)\n","\n","    # 해당 엡실론에서의 최종 정확도를 계산합니다\n","    final_acc = correct/float(len(test_x))\n","    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(eps, correct, len(test_x), final_acc))\n","\n","    # 정확도와 적대적 예제를 리턴합니다\n","    return final_acc, adv_examples, save_adv_examples, save_original_output"]},{"cell_type":"code","source":["def pgd_attack(model,test_x,test_y,eps,step_size=2,num_steps=7): \n","    \"\"\"\n","    FGSM 코드와 차이점\n","    - step_size, num_steps 파라미터 추가됨\n","    - unifrom distribution 코드 추가\n","    - FGSM 공격 수행 -> PGD 공격 수행\n","    ** 모든 return 형식은 동일함\n","    \n","    default 값\n","    - step_size = 2 (alpha 값)\n","    - num_steps = 7 (iterations 값)\n","\n","    \"\"\"\n","\n","    prog = 0 # 진행상황 확인용 변수\n","\n","    correct = 0\n","    adv_examples = []\n","    save_adv_examples = [] # 공격받은 이미지들이 저장될 리스트\n","    save_original_output = [] # 공격받은 이미지들의 정답 라벨 값이 저장될 리스트\n","    \n","    for i in range(len(test_x)):\n","        # 1장의 이미지와 그 label\n","        data = test_x[i]\n","        target_onehot = test_y[i] # one-hot 형태\n","        target_label = int(np.argmax(target_onehot)) # label 형태\n","\n","        # model이 정상 데이터를 분류한 결과 (각각 one-hot 형태, int label 형태)\n","        result_onehot = model.predict(data.reshape(1,32,32,3) / 255) # one-hot 형태\n","        result_label = int(np.argmax(result_onehot))\n","\n","        # 모델이 정상 데이터인데도 잘못 분류했다면 사용하지 않는다 (아래 코드 실행하지 않고 다음 이미지로 넘어감)\n","        if target_label != result_label:\n","            continue\n","\n","        # PGD uniform distribution 코드\n","        data = data + np.random.uniform(-eps,eps,data.shape)\n","        data = np.clip(data,0,255)\n","\n","        # 이미지 전처리\n","        img =  tf_preprocess(data) # 텐서플로 전처리 -> 0~1사이로 정규화 함.\n","        label = get_tf_label(target_onehot) # 확률벡터에서 레이블 추출\n","        \n","        # PGD 공격 수행\n","        adv_x = img # 공격받은 이미지 (for문으로 업데이트)\n","        for num_step in range(num_steps):\n","          perturbations = create_adversarial_pattern(adv_x,label) # signed_grad를 리턴한 값\n","          adv_x += step_size * perturbations\n","          adv_x = tf.clip_by_value(adv_x,img-eps,img+eps)\n","          adv_x = tf.clip_by_value(adv_x,0,1)\n","\n","        # 공격 이미지를 분류기에 넣은 결과; 잘못 분류되어야 할 것 \n","        atkresult_onehot = model.predict(adv_x) # one-hot 형태\n","        atkresult_label = int(np.argmax(atkresult_onehot)) # label 형태\n","\n","        # 만약 공격 받아도 제대로 분류된다면 correct로 count\n","        if atkresult_label == target_label:\n","            correct += 1\n","        # ####################################################################################\n","        # ################ 여기 코드는 필요 없지 않나?\n","        #     if (eps == 0) and (len(adv_examples) < 5):\n","        #         adv_ex = adv_x\n","        #         adv_examples.append((init_output,final_pred,adv_x))\n","        # else:\n","        #     if len(adv_examples) < 5:\n","        #         adv_ex = adv_x\n","        #         adv_examples.append((init_output,final_pred,adv_x))\n","        # ####################################################################################\n","        \n","        # 공격 적용된 이미지, 그 공격 받은 이미지의 원래 정답 label을 각각 리스트에 저장합니다\n","        save_adv_examples.append(tf.reshape(adv_x,[32,32,3]))\n","        save_original_output.append(target_label) #공격 받은 이미지에 원래 타겟 값을 저장합니다 ! \n","\n","        prog += 1\n","\n","        if prog%500 == 0:\n","          print(\"prog :\", prog)\n","\n","    # 해당 엡실론에서의 최종 정확도를 계산합니다\n","    final_acc = correct/float(len(test_x))\n","    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(eps, correct, len(test_x), final_acc))\n","\n","    # 정확도와 적대적 예제를 리턴합니다\n","    return final_acc, adv_examples, save_adv_examples, save_original_output"],"metadata":{"id":"GmiLgFduVhR0","executionInfo":{"status":"ok","timestamp":1664035426146,"user_tz":-540,"elapsed":6,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["### Attack 수행 : 공격 데이터셋 만드는 코드\n","\n","**여기에서 [attack_type]과 [eps] 설정하면 됩니다!!!**\n","\n","* attack_type : FGSM, PGD\n","* eps = 0.02, 0.03, 8/255, 0.05, 0.08, 0.10\n","* 정상 이미지에 대한 분류기 정확도 -> 위에 있음 (분류기:CNN; 약 97%)"],"metadata":{"id":"AVs5AnagBdTK"}},{"cell_type":"code","source":["################################################################################\n","# 공격 데이터 설정 #################################################################\n","attack_type = \"FGSM\" # FGSM, PGD\n","eps = 0.1 # 0.02, 0.03, 0.04, 0.05, 0.08, 0.10\n","################################################################################\n","################################################################################\n","\n","if attack_type == \"FGSM\":\n","  acc, ex, ad_examples, orig_labels = fgsm_attack(model, data_test.x_test, data_test.y_test, eps) #x 공격데이터 : 0~1 정규화 완료, y 데이터 : 12개 라벨\n","elif attack_type == \"PGD\":\n","  acc, ex, ad_examples, orig_labels = pgd_attack(model, data_test.x_test, data_test.y_test, eps) #x 공격데이터 : 0~1 정규화 완료, y 데이터 : 12개 라벨\n","\n","print(\"Attack Data 생성 완료\")"],"metadata":{"id":"ZE2wZtfAEOBh","colab":{"base_uri":"https://localhost:8080/","height":470},"executionInfo":{"status":"error","timestamp":1664035523138,"user_tz":-540,"elapsed":96998,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}},"outputId":"55a79d2e-bb60-4775-e813-9c463eef6624"},"execution_count":22,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-c7dc73da3e28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mattack_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"FGSM\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mad_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfgsm_attack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#x 공격데이터 : 0~1 정규화 완료, y 데이터 : 12개 라벨\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0mattack_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"PGD\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mad_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpgd_attack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#x 공격데이터 : 0~1 정규화 완료, y 데이터 : 12개 라벨\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-20-bd0e95358264>\u001b[0m in \u001b[0;36mfgsm_attack\u001b[0;34m(model, test_x, test_y, eps)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# 공격 이미지를 분류기에 넣은 결과; 잘못 분류되어야 할 것\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0matkresult_onehot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv_x\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# one-hot 형태\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0matkresult_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matkresult_onehot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# label 형태\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1976\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1977\u001b[0m       \u001b[0mbatch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1978\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Single epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1979\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1980\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1188\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1190\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m       \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_truncate_execution_to_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1203\u001b[0m     should_truncate = (\n\u001b[1;32m   1204\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inferred_steps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1205\u001b[0;31m         self._steps_per_execution.numpy().item() > self._inferred_steps)\n\u001b[0m\u001b[1;32m   1206\u001b[0m     \u001b[0moriginal_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m     raise NotImplementedError(\n\u001b[1;32m    676\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \"\"\"\n\u001b[1;32m   1222\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1224\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1187\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["print(orig_labels[0])\n","plt.figure()\n","plt.imshow(data_test.x_test[0])\n","plt.show();"],"metadata":{"id":"NohgITryaLHv","executionInfo":{"status":"aborted","timestamp":1664035523139,"user_tz":-540,"elapsed":20,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(orig_labels[0])\n","plt.figure()\n","plt.imshow(ad_examples[0])\n","plt.show();"],"metadata":{"id":"Fjghmlv4kRKa","executionInfo":{"status":"aborted","timestamp":1664035523140,"user_tz":-540,"elapsed":21,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 방어모델 : MagNet, Defense-GAN, PCA"],"metadata":{"id":"6DfDZcE5_GGB"}},{"cell_type":"markdown","source":["## MagNet"],"metadata":{"id":"Lb-doZmmIFqj"}},{"cell_type":"markdown","source":["### MagNet - def (utils, worker, Defensive Model)"],"metadata":{"id":"-Yc-yrW7ktMW"}},{"cell_type":"markdown","source":["#### MagNet - utils"],"metadata":{"id":"bt4nIJ5xg73T"}},{"cell_type":"code","source":["## utils.py -- utility functions\n","##\n","## Copyright (C) 2017, Dongyu Meng <zbshfmmm@gmail.com>.\n","##\n","## This program is licenced under the BSD 2-Clause licence,\n","## contained in the LICENCE file in this directory.\n","\n","import pickle\n","import os\n","import numpy as np\n","\n","\n","def prepare_data(dataset, idx):\n","    \"\"\"\n","    Extract data from index.\n","\n","    dataset: Full, working dataset. Such as MNIST().\n","    idx: Index of test examples that we care about.\n","    return: X, targets, Y\n","    \"\"\"\n","    return dataset.x_test[idx], dataset.y_test[idx], np.argmax(dataset.y_test[idx], axis=1)\n","\n","\n","def save_obj(obj, name, directory='./attack_data/'):\n","    with open(os.path.join(directory, name + '.pkl'), 'wb') as f:\n","        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n","\n","\n","def load_obj(name, directory='./attack_data/'):\n","    if name.endswith(\".pkl\"): name = name[:-4]\n","    with open(os.path.join(directory, name + '.pkl'), 'rb') as f:\n","        return pickle.load(f)"],"metadata":{"id":"hAvlahKmMFdO","executionInfo":{"status":"aborted","timestamp":1664035523140,"user_tz":-540,"elapsed":21,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### MagNet - worker"],"metadata":{"id":"EhncucofhEvv"}},{"cell_type":"code","source":["## setup_mnist.py -- mnist data and model loading code\n","##\n","## Copyright (C) 2016, Nicholas Carlini <nicholas@carlini.com>.\n","##\n","## This program is licenced under the BSD 2-Clause licence,\n","## contained in the LICENCE file in this directory.\n","\n","## Modified for MagNet's use.\n","\n","## worker.py -- evaluation code\n","##\n","## Copyright (C) 2017, Dongyu Meng <zbshfmmm@gmail.com>.\n","##\n","## This program is licenced under the BSD 2-Clause licence,\n","## contained in the LICENCE file in this directory.\n","\n","import matplotlib\n","matplotlib.use('Agg')\n","from scipy.stats import entropy\n","from numpy.linalg import norm\n","from matplotlib.ticker import FuncFormatter\n","from keras.models import Sequential, load_model\n","from keras.activations import softmax\n","from keras.layers import Lambda\n","import numpy as np\n","import pylab\n","import os\n","import matplotlib.pyplot as plt\n","\n","\n","class AEDetector:\n","    def __init__(self, path, p=1):\n","        \"\"\"\n","        Error based detector.\n","        Marks examples for filtering decisions.\n","\n","        path: Path to the autoencoder used.\n","        p: Distance measure to use.\n","        \"\"\"\n","\n","        self.model = load_model(path)\n","        self.path = path\n","        self.p = p\n","\n","    def mark(self, X):\n","        diff = np.abs(X - self.model.predict(X)) # input X와 예측값 X'(autoencoder를 통해 노이즈가 더해진 값) 의 오차 값\n","        marks = np.mean(np.power(diff, self.p), axis=(1,2,3)) # 오차값의 분산\n","        return marks\n","\n","    def print(self):\n","        return \"AEDetector:\" + self.path.split(\"/\")[-1]\n","\n","\n","class IdReformer:\n","    def __init__(self, path=\"IdentityFunction\"):\n","        \"\"\"\n","        Identity reformer.\n","        Reforms an example to itself.\n","        \"\"\"\n","        self.path = path\n","        self.heal = lambda X: X\n","\n","    def print(self):\n","        return \"IdReformer:\" + self.path\n","\n","\n","class SimpleReformer:\n","    def __init__(self, path):\n","        \"\"\"\n","        Reformer.\n","        Reforms examples with autoencoder. Action of reforming is called heal.\n","\n","        path: Path to the autoencoder used.\n","        \"\"\"\n","        self.model = load_model(path)\n","        self.path = path\n","\n","    def heal(self, X):\n","        X = self.model.predict(X) # autoencoder로 X값 재구성\n","        return np.clip(X, 0.0, 1.0)\n","\n","    def print(self):\n","        return \"SimpleReformer:\" + self.path.split(\"/\")[-1]\n","\n","\n","def JSD(P, Q):\n","    _P = P / norm(P, ord=1)\n","    _Q = Q / norm(Q, ord=1)\n","    _M = 0.5 * (_P + _Q)\n","    return 0.5 * (entropy(_P, _M) + entropy(_Q, _M)) # Xp와 Xr의 분포의 entropy \n","    # KL divergence: Q(one autoencoder)를 기반으로 했을 때의 cross entropy와 P(magnet)를 기반으로 했을 때의 entropy의 차이\n","\n","\n","\n","class DBDetector:\n","    def __init__(self, reconstructor, prober, classifier, option=\"jsd\", T=1):\n","        \"\"\"\n","        Divergence-Based Detector.\n","\n","        reconstructor: One autoencoder.\n","        prober: Another autoencoder.\n","        classifier: Classifier object.\n","        option: Measure of distance, jsd as default.\n","        T: Temperature to soften the classification decision.\n","        \"\"\"\n","        self.prober = prober\n","        self.reconstructor = reconstructor\n","        self.classifier = classifier\n","        self.option = option\n","        self.T = T\n","\n","    def mark(self, X):\n","        return self.mark_jsd(X)\n","\n","    def mark_jsd(self, X):\n","        Xp = self.prober.heal(X) # 1번 autoencoder로 생성한 이미지 \n","        Xr = self.reconstructor.heal(X) #2번 autoencoder로 생성한 이미지 \n","        Pp = self.classifier.classify(Xp, option=\"prob\", T=self.T) # Xp의 확률\n","        Pr = self.classifier.classify(Xr, option=\"prob\", T=self.T) # Xr의 확률\n","\n","        marks = [(JSD(Pp[i], Pr[i])) for i in range(len(Pr))]\n","        return np.array(marks)\n","\n","    def print(self):\n","        return \"Divergence-Based Detector\"\n","\n","\n","class Classifier:\n","    def __init__(self, classifier_path):\n","        \"\"\"\n","        Keras classifier wrapper.\n","        Note that the wrapped classifier should spit logits as output.\n","\n","        classifier_path: Path to Keras classifier file.\n","        \"\"\"\n","        self.path = classifier_path\n","        self.model = load_model(classifier_path)\n","        self.softmax = Sequential()\n","        self.softmax.add(Lambda(lambda X: softmax(X, axis=1)))\n","\n","    def classify(self, X, option=\"logit\", T=1):\n","        if option == \"logit\":\n","            return self.model.predict(X)\n","        if option == \"prob\":\n","            logits = self.model.predict(X)/T\n","            return self.softmax.predict(logits)\n","\n","    def print(self):\n","        return \"Classifier:\"+self.path.split(\"/\")[-1]\n","\n","\n","class Operator:\n","    def __init__(self, data, classifier, det_dict, reformer):\n","        \"\"\"\n","        Operator.\n","        Describes the classification problem and defense.\n","\n","        data: Standard problem dataset. Including train, test, and validation.\n","        classifier: Target classifier.\n","        reformer: Reformer of defense.\n","        det_dict: Detector(s) of defense.\n","        \"\"\"\n","\n","        self.data = data\n","        self.classifier = classifier\n","        self.det_dict = det_dict \n","        self.reformer = reformer\n","        self.normal = self.operate(AttackData(data.x_train, np.argmax(data.y_train, axis=1), \"Normal\"))\n","        \n","\n","    def get_thrs(self, drop_rate):\n","        \"\"\"\n","        Get filtering threshold by marking validation set.\n","        \"\"\"\n","        thrs = dict()\n","        for name, detector in self.det_dict.items():\n","            num = int(len(data.x_test) * drop_rate[name])\n","            marks = detector.mark(data.x_test)\n","            marks = np.sort(marks)\n","            thrs[name] = marks[-num]\n","        return thrs\n","\n","    def operate(self, untrusted_obj):\n","        \"\"\"\n","        For untrusted input(normal or adversarial), classify original input and\n","        reformed input. Classifier is unaware of the source of input.\n","\n","        untrusted_obj: Input data.\n","        \"\"\"\n","\n","        X = untrusted_obj.data\n","        Y_true = untrusted_obj.labels\n","\n","\n","        X_prime = self.reformer.heal(X) # autoencoder 값으로 재구성\n","        Y = np.argmax(self.classifier.classify(X), axis=1) # 원본 input X 분류\n","        Y_judgement = (Y == Y_true[:len(X_prime)]) # 실제 label과 X 분류 label 비교\n","        Y_prime = np.argmax(self.classifier.classify(X_prime), axis=1)  # autoencoder로 재구성한 X' 분류\n","        Y_prime_judgement = (Y_prime == Y_true[:len(X_prime)])  # 실제 label과 X' 분류 label 비교\n","        return np.array(list(zip(Y_judgement, Y_prime_judgement)))\n","\n","    def filter(self, X, thrs):\n","        \"\"\"\n","        untrusted_obj: Untrusted input to test against.\n","        thrs: Thresholds.\n","\n","        return:\n","        all_pass: Index of examples that passed all detectors.\n","        collector: Number of examples that escaped each detector.\n","        \"\"\"\n","        collector = dict()\n","        all_pass = np.array(range(10000)) #Index\n","        for name, detector in self.det_dict.items():\n","            marks = detector.mark(X) #  KL divergnece: Xp와 Xr의 분포의 entropy \n","            idx_pass = np.argwhere(marks < thrs[name]) # KL divergnece가 thershold보다 작을 경우 pass, 클 경우 reject\n","            collector[name] = len(idx_pass) # pass가 된 수\n","            all_pass = np.intersect1d(all_pass, idx_pass) # 전체 index array와 pass된 array의 교집합\n","        return all_pass, collector\n","\n","    def print(self):\n","        components = [self.reformer, self.classifier]\n","        return \" \".join(map(lambda obj: getattr(obj, \"print\")(), components))\n","\n","\n","class AttackData:\n","    def __init__(self, examples, labels, name=\"\"):\n","        \"\"\"\n","        Input data wrapper. May be normal or adversarial.\n","\n","        examples: Path or object of input examples.\n","        labels: Ground truth labels.\n","        \"\"\"\n","        # if isinstance(examples, str): \n","        #   self.data = load_obj(examples)\n","        # else: \n","\n","        self.data = examples\n","        self.labels = labels\n","        self.name = name\n","\n","    def print(self):\n","        return \"Attack:\"+self.name\n","\n","\n","class Evaluator:\n","    def __init__(self, operator, untrusted_data, graph_dir=\"./graph\"):\n","        \"\"\"\n","        Evaluator.\n","        For strategy described by operator, conducts tests on untrusted input.\n","        Mainly stats and plotting code. Most methods omitted for clarity.\n","\n","        operator: Operator object.\n","        untrusted_data: Input data to test against.\n","        graph_dir: Where to spit the graphs.\n","        \"\"\"\n","        self.operator = operator\n","        self.untrusted_data = untrusted_data # attacked data\n","        self.graph_dir = graph_dir\n","        self.data_package = operator.operate(untrusted_data)\n","\n","    def bind_operator(self, operator):\n","        self.operator = operator\n","        self.data_package = operator.operate(self.untrusted_data)\n","\n","    def load_data(self, data):\n","        self.untrusted_data = data\n","        self.data_package = self.operator.operate(self.untrusted_data)\n","\n","    def get_normal_acc(self, normal_all_pass):\n","        \"\"\"\n","        traning data에 대한 정확도\n","\n","        Break down of who does what in defense. Accuracy of defense on normal\n","        input.\n","\n","        both: Both detectors and reformer take effect\n","        det_only: detector(s) take effect\n","        ref_only: Only reformer takes effect\n","        none: Attack effect with no defense\n","        \"\"\"\n","        normal_tups = self.operator.normal\n","        num_normal = len(normal_tups)\n","        filtered_normal_tups = normal_tups[normal_all_pass]\n","\n","        both_acc = sum(1 for _, XpC in filtered_normal_tups if XpC)/num_normal # detector and refomer\n","        det_only_acc = sum(1 for XC, XpC in filtered_normal_tups if XC)/num_normal # only detector\n","        ref_only_acc = sum([1 for _, XpC in normal_tups if XpC])/num_normal # only reformer\n","        none_acc = sum([1 for XC, _ in normal_tups if XC])/num_normal # no defense\n","\n","        return both_acc, det_only_acc, ref_only_acc, none_acc\n","\n","    def get_attack_acc(self, attack_pass):\n","        \"\"\"\n","        attacked data에 대한 정확도 \n","        \"\"\"\n","        attack_tups = self.data_package\n","        num_untrusted = len(attack_tups)\n","        filtered_attack_tups = attack_tups[attack_pass]\n","\n","\n","        both_acc = 1 - sum(1 for _, XpC in filtered_attack_tups if not XpC)/num_untrusted # detector and refomer\n","        det_only_acc = 1 - sum(1 for XC, XpC in filtered_attack_tups if not XC)/num_untrusted # only detector\n","        ref_only_acc = sum([1 for _, XpC in attack_tups if XpC])/num_untrusted # only reformer\n","        none_acc = sum([1 for XC, _ in attack_tups if XC])/num_untrusted # no defense\n","        \n","        return both_acc, det_only_acc, ref_only_acc, none_acc\n","\n","    def plot_various_confidences(self, graph_name, drop_rate,\n","                                 idx_file=\"example_idx\",\n","                                 confs=(0.0, 10.0),\n","                                 get_attack_data_name=lambda c: \"example_carlini_\"+str(c)):\n","        \"\"\"\n","        Test defense performance against Carlini L2 attack of various confidences.\n","\n","        graph_name: Name of graph file.\n","        drop_rate: How many normal examples should each detector drops?\n","        idx_file: Index of adversarial examples in standard test set.\n","        confs: A series of confidence to test against.\n","        get_attack_data_name: Function mapping confidence to corresponding file.\n","        \"\"\"\n","        pylab.rcParams['figure.figsize'] = 6, 4\n","        fig = plt.figure(1, (6, 4))\n","        ax = fig.add_subplot(1, 1, 1)\n","\n","        idx = orig_labels\n","        # idx = original_labels_list\n","        X, _, Y = prepare_data(self.operator.data, idx)\n","\n","\n","        det_only = []\n","        ref_only = []\n","        both = []\n","        none = []\n","\n","        print(\"\\n==========================================================\")\n","        print(\"Drop Rate:\", drop_rate)\n","        thrs = self.operator.get_thrs(drop_rate)\n","\n","        all_pass, _ = self.operator.filter(self.operator.data.x_train, thrs)\n","        all_on_acc, _, _, _ = self.get_normal_acc(all_pass)\n","\n","        print(\"Classification accuracy with all defense on:\", all_on_acc)\n","\n","        for confidence in confs:\n","            # f = get_attack_data_name(confidence)\n","            self.load_data(AttackData(ad_examples1, orig_labels, \"GTSRB FSGM\"))\n","\n","            print(\"----------------------------------------------------------\")\n","            print(\"Confidence:\", confidence)\n","            all_pass, detector_breakdown = self.operator.filter(self.untrusted_data.data, thrs)\n","            both_acc, det_only_acc, ref_only_acc, none_acc = self.get_attack_acc(all_pass)\n","            print(detector_breakdown)\n","            both.append(both_acc)\n","            det_only.append(det_only_acc)\n","            ref_only.append(ref_only_acc)\n","            none.append(none_acc)\n","\n","        size = 2.5\n","\n","        print(\"With detector & reformer: \", both_acc)\n","        print(\"With detector: \",det_only_acc)\n","        print(\"With reformer: \", ref_only_acc)\n","        print(\"No Defense: \",none_acc)\n","\n","        # print(\"With detector & reformer: \", both)\n","        # print(\"With detector: \",det_only)\n","        # print(\"With reformer: \", ref_only)\n","        # print(\"No Defense: \",none)\n","\n","        plt.plot(confs, none, c=\"green\", label=\"No Defense\", marker=\"x\", markersize=size,alpha=0.5)\n","        # plt.plot(confs, det_only, c=\"orange\", label=\"With detector\", marker=\"o\", markersize=size,alpha=0.5)\n","        # plt.plot(confs, ref_only, c=\"blue\", label=\"With reformer\", marker=\"^\", markersize=size,alpha=0.5)\n","        plt.plot(confs, both, c=\"red\", label=\"With detector & reformer\", marker=\"s\", markersize=size,alpha=0.5)\n","\n","        pylab.legend(loc='lower left', bbox_to_anchor=(0.02, 0.1), prop={'size':8})\n","        plt.grid(linestyle='dotted')\n","        plt.xlabel(r\"Confidence in Carlini $L^2$ attack\")\n","        plt.ylabel(\"Classification accuracy\")\n","        plt.xlim(min(confs)-1.0, max(confs)+1.0)\n","        plt.ylim(-0.05, 1.05)\n","        ax.yaxis.set_major_formatter(FuncFormatter('{0:.0%}'.format))\n","\n","        save_path = os.path.join(self.graph_dir, graph_name+\".pdf\")\n","        plt.savefig(save_path)\n","        plt.clf()\n","\n","    def print(self):\n","        return \" \".join([self.operator.print(), self.untrusted_data.print()])"],"metadata":{"id":"ZRv7EXuShHMK","executionInfo":{"status":"aborted","timestamp":1664035523141,"user_tz":-540,"elapsed":22,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### MagNet - Defensive Model"],"metadata":{"id":"4e-GBUowhNUQ"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import os\n","import numpy as np\n","from keras.layers.core import Lambda\n","from keras.layers.merge import Average, add\n","from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, AveragePooling2D\n","from keras.models import Model\n","import keras.regularizers as regs\n","\n","\n","class DenoisingAutoEncoder:\n","    def __init__(self, image_shape,\n","                 structure,\n","                 v_noise=0.0,\n","                 activation=\"relu\",\n","                 model_dir=\"./defensive_models/\",\n","                 reg_strength=0.0):\n","        \"\"\"\n","        Denoising Autoencoder(DAE)\n","        training data에 nosie를 추가하여 인코더에 넣어서 학습된 결과가 \n","        noise를 붙이기 전 데이터와의 error을 최소화하는 목적을 가진 Autoencoder\n","\n","        image_shape: Shape of input image. e.g. 28, 28, 1.\n","        structure: Structure of autoencoder.\n","        v_noise: Volume of noise while training.\n","        activation: What activation function to use.\n","        model_dir: Where to save / load model from.\n","        reg_strength: Strength of L2 regularization.\n","        \"\"\"\n","        h, w, c = image_shape\n","        self.image_shape = image_shape # shape of input image (32,32,3)\n","        self.model_dir = model_dir \n","        self.v_noise = v_noise\n","\n","        input_img = Input(shape=self.image_shape)\n","        x = input_img\n","\n","        # encoder 정의 \n","        for layer in structure: \n","            if isinstance(layer, int):\n","                x = Conv2D(layer, (3, 3), activation=activation, padding=\"same\",\n","                           activity_regularizer=regs.l2(reg_strength))(x)\n","            elif layer == \"max\":\n","                x = MaxPooling2D((2, 2), padding=\"same\")(x)\n","            elif layer == \"average\":\n","                x = AveragePooling2D((2, 2), padding=\"same\")(x)\n","            else:\n","                print(layer, \"is not recognized!\")\n","                exit(0)\n","        \n","        for layer in reversed(structure):\n","            if isinstance(layer, int):\n","                x = Conv2D(layer, (3, 3), activation=activation, padding=\"same\",\n","                           activity_regularizer=regs.l2(reg_strength))(x)\n","            elif layer == \"max\" or layer == \"average\":\n","                x = UpSampling2D((2, 2))(x)\n","\n","        # decoder 정의 \n","        decoded = Conv2D(c, (3, 3), activation='sigmoid', padding='same',\n","                         activity_regularizer=regs.l2(reg_strength))(x)\n","\n","        self.model = Model(input_img, decoded) # autoencoder 모델\n","\n","    def train(self, data, archive_name, num_epochs=100, batch_size=32):\n","        self.model.compile(loss='mean_squared_error',\n","                           metrics=['mean_squared_error'],\n","                           optimizer='adam')\n","        \n","        noise = self.v_noise * np.random.normal(size=np.shape(data.x_train)) # 랜덤 노이즈 \n","        noisy_train_data = data.x_train + noise # Input Data에 랜덤 노이즈 추가 \n","        noisy_train_data = np.clip(noisy_train_data, 0.0, 1.0) # [0,1] 범위로 재구성\n","\n","        self.model.fit(noisy_train_data, data.x_train,\n","                       batch_size=batch_size,\n","                       validation_data=(data.x_test, data.x_test),\n","                       epochs=num_epochs,\n","                       shuffle=True)\n","\n","        print(os.path.join(self.model_dir, archive_name))        \n","        self.model.save(os.path.join(self.model_dir, archive_name))\n","\n","    def load(self, archive_name, model_dir=None):\n","        if model_dir is None: model_dir = self.model_dir\n","        self.model.load_weights(os.path.join(model_dir, archive_name))\n","\n","\n","class PackedAutoEncoder:\n","    def __init__(self, image_shape, structure, data,\n","                 v_noise=0.1, n_pack=2, pre_epochs=3, activation=\"relu\",\n","                 model_dir=\"./defensive_models/\"):\n","        \"\"\"\n","        Train different autoencoders.\n","        Demo code for graybox scenario.\n","\n","        pre_epochs: How many epochs do we train before fine-tuning.\n","        n_pack: Number of autoencoders we want to train at once.\n","        \"\"\"\n","        self.v_noise = v_noise\n","        self.n_pack = n_pack\n","        self.model_dir = model_dir\n","        pack = []\n","\n","\n","\n","        for i in range(n_pack):\n","            dae = DenoisingAutoEncoder(image_shape, structure, v_noise=v_noise,\n","                                       activation=activation, model_dir=model_dir)\n","            dae.train(data, \"\", num_epochs=pre_epochs)\n","            pack.append(dae.model)\n","\n","\n","        shared_input = Input(shape=image_shape, name=\"shared_input\")\n","        outputs = [dae(shared_input) for dae in pack]\n","        avg_output = Average()(outputs)\n","        delta_outputs = [add([avg_output, Lambda(lambda x: -x)(output)])\n","                         for output in outputs]\n","\n","        self.model = Model(inputs=shared_input, outputs=outputs+delta_outputs)\n","\n","    def train(self, data, archive_name, alpha, num_epochs=10, batch_size=32):\n","        noise = self.v_noise * np.random.normal(size=np.shape(data.x_train))\n","        noisy_train_data = data.x_train + noise\n","        noisy_train_data = np.clip(noisy_train_data, 0.0, 1.0)\n","\n","        train_zeros = [np.zeros_like(data.x_train)] * self.n_pack\n","        val_zeros = [np.zeros_like(data.x_test)] * self.n_pack\n","\n","        self.model.compile(loss=\"mean_squared_error\", optimizer=\"adam\",\n","                           loss_weights=[1.0]*self.n_pack + [-alpha]*self.n_pack)\n","\n","        self.model.fit(noisy_train_data,\n","                       [data.x_train]*self.n_pack + train_zeros,\n","                       batch_size=batch_size,\n","                       validation_data=(data.x_test,\n","                            [data.x_test]*self.n_pack+val_zeros),\n","                       epochs=num_epochs,\n","                       shuffle=True)\n","\n","        for i in range(self.n_pack):\n","            model = Model(self.model.input, self.model.outputs[i])\n","            self.model.save(\"\")\n","            print(os.path.join(self.model_dir, archive_name+\"_\"+str(i)))\n","            self.model.save(os.path.join(self.model_dir, archive_name+\"_\"+str(i)))\n","\n","    def load(self, archive_name, model_dir=None):\n","        if model_dir is None: model_dir = self.model_dir\n","        self.model.load_weights(os.path.join(model_dir, archive_name))"],"metadata":{"id":"HyIrYmBIhPRc","executionInfo":{"status":"aborted","timestamp":1664035523141,"user_tz":-540,"elapsed":21,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### MagNet - Train Defensive Model"],"metadata":{"id":"ukxjkHWahV8B"}},{"cell_type":"code","source":["DAE = DenoisingAutoEncoder\n","PAE = PackedAutoEncoder\n","\n","shape = [32, 32, 3]\n","combination_I = [3, \"average\", 3]\n","combination_II = [3]\n","activation = \"sigmoid\"\n","reg_strength = 1e-9\n","epochs = 350\n","\n","# data = GTSRB()\n","\n","# AE_II = PAE(shape, combination_II, data, v_noise=0.025, activation=activation, n_pack=8)\n","# AE_II.train(data, \"_8_PAE_GTSRB_II\", alpha=.2, num_epochs=epochs)\n","\n","# AE_II = PAE(shape, combination_II, data, v_noise=0.025, activation=activation)\n","# AE_II.train(data, \"_PAE_GTSRB_II\", alpha=.2, num_epochs=epochs)    \n","\n","# AE_II = PAE(shape, combination_II, data, v_noise=0.025, activation=activation, n_pack=32)\n","# AE_II.train(data, \"O32_PAE_GTSRB_II\", alpha=.2, num_epochs=epochs)  \n","\n","AE_I = DAE(shape, combination_I, v_noise=0.1, activation=activation, reg_strength=reg_strength)\n","#AE_I.train(data, \"350_0918_DAE_GTSRB_I\", num_epochs=epochs)\n","\n","AE_II = DAE(shape, combination_II, v_noise=0.1, activation=activation,  reg_strength=reg_strength)\n","#AE_II.train(data, \"350_0918_DAE_GTSRB_II\", num_epochs=epochs)"],"metadata":{"id":"C5S8s9wxhanJ","executionInfo":{"status":"aborted","timestamp":1664035523142,"user_tz":-540,"elapsed":22,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### MagNet - 1"],"metadata":{"id":"mzltzwx8he_N"}},{"cell_type":"code","source":["ad_examples1 = np.array(ad_examples)\n","orig_labels1 = to_categorical(orig_labels)"],"metadata":{"id":"BZXZc5yXGbHR","executionInfo":{"status":"aborted","timestamp":1664035523142,"user_tz":-540,"elapsed":22,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ad_examples1.shape"],"metadata":{"id":"jNeNPwhcwXgR","executionInfo":{"status":"aborted","timestamp":1664035523142,"user_tz":-540,"elapsed":22,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(np.min(ad_examples1[0]))\n","print(np.max(ad_examples1[0]))"],"metadata":{"id":"n88gOua2r0cF","executionInfo":{"status":"aborted","timestamp":1664035523143,"user_tz":-540,"elapsed":23,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["orig_labels1[0]"],"metadata":{"id":"S6TVgUZer8GA","executionInfo":{"status":"aborted","timestamp":1664035523143,"user_tz":-540,"elapsed":23,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" data_test.y_test"],"metadata":{"id":"W0UMav8hwSJ0","executionInfo":{"status":"aborted","timestamp":1664035523143,"user_tz":-540,"elapsed":23,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 원본 이미지\n","classifier = Classifier(\"./models/gtsrb_classifier\")\n","loss, accuracy = classifier.model.evaluate(data_test.x_test/255, data_test.y_test)\n","\n","print('test set accuracy (original) : ', accuracy * 100)"],"metadata":{"id":"0vMxKPzjhhAy","executionInfo":{"status":"aborted","timestamp":1664035523144,"user_tz":-540,"elapsed":23,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 공격받은 이미지\n","classifier = Classifier(\"./models/gtsrb_classifier\")\n","loss, accuracy = classifier.model.evaluate(ad_examples1, orig_labels1)\n","\n","print('test set accuracy (attacked) : ', accuracy * 100)"],"metadata":{"id":"ca5TN0fGhrgk","executionInfo":{"status":"aborted","timestamp":1664035523144,"user_tz":-540,"elapsed":23,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["DAE_detector_I = AEDetector(\"./defensive_models/350_0918_DAE_GTSRB_I\", p=2)\n","DAE_detector_II = AEDetector(\"./defensive_models/350_0918_DAE_GTSRB_II\", p=1)\n","DAE_reformer = SimpleReformer(\"./defensive_models/350_0918_DAE_GTSRB_I\")\n","\n","\n","DAE_id_reformer = IdReformer()\n","DAE_classifier = Classifier(\"./models/gtsrb_classifier\")"],"metadata":{"id":"L6gv49XOhtCl","executionInfo":{"status":"aborted","timestamp":1664035523144,"user_tz":-540,"elapsed":23,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["detector_JSD1 = DBDetector(DAE_id_reformer, DAE_reformer, DAE_classifier, T=10)\n","detector_JSD2 = DBDetector(DAE_id_reformer, DAE_reformer, DAE_classifier, T=40)\n","\n","\n","DAE_detector_dict = dict()\n","DAE_detector_dict[\"I\"] = DAE_detector_I\n","DAE_detector_dict[\"II\"] = DAE_detector_II\n","DAE_detector_dict[\"JSD1\"] = detector_JSD1\n","DAE_detector_dict[\"JSD2\"] = detector_JSD2"],"metadata":{"id":"qRcUtasdhuRN","executionInfo":{"status":"aborted","timestamp":1664035523145,"user_tz":-540,"elapsed":24,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["DAE_operator = Operator(data, DAE_classifier, DAE_detector_dict, DAE_reformer)\n","DAE_testAttack = AttackData(ad_examples1, orig_labels, \"GTSRB FSGM\")"],"metadata":{"id":"36Yx1eqahvso","executionInfo":{"status":"aborted","timestamp":1664035523145,"user_tz":-540,"elapsed":24,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["DAE_evaluator = Evaluator(DAE_operator, DAE_testAttack)\n","\n","DAE_evaluator.plot_various_confidences(\"defense_performance\", drop_rate={\"I\": 0.001, \"II\": 0.001,\"JSD1\": 0.001,\"JSD2\": 0.001})"],"metadata":{"id":"C3MbM1HDhwv0","executionInfo":{"status":"aborted","timestamp":1664035523146,"user_tz":-540,"elapsed":25,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('with reformer')\n","start = time.time()\n","predict = np.array((DAE_reformer.model.predict(ad_examples1))).reshape(-1,32,32,3)\n","activ_time = time.time() - start\n","meantime = activ_time / len(ad_examples1)\n","predicted1 = np.argmax(classifier.model.predict(predict),axis=1)\n","\n","print(np.mean(predicted1[:len(orig_labels)] == orig_labels[:len(orig_labels)]))\n","# print(.sum(predicted==orig_labels))#,predicted)\n","print(meantime)"],"metadata":{"id":"gBi_uO4Dhx6D","executionInfo":{"status":"aborted","timestamp":1664035523147,"user_tz":-540,"elapsed":26,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(type(data.x_train))\n","print(type(ad_examples))"],"metadata":{"id":"AmEhY0bFhzJd","executionInfo":{"status":"aborted","timestamp":1664035523148,"user_tz":-540,"elapsed":26,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Defense-GAN"],"metadata":{"id":"vIK9wb4vIIlv"}},{"cell_type":"markdown","metadata":{"id":"P9v5DhrcQTi_"},"source":["###  Defense Model 1 : DefenseGAN"]},{"cell_type":"markdown","source":["### DefenseGAN 구현\n"],"metadata":{"id":"2TtBNBJxn2Db"}},{"cell_type":"code","source":["ad_examples1 = np.array(ad_examples)\n","orig_labels1 = to_categorical(orig_labels)"],"metadata":{"id":"oDv8n7tn6Hep","executionInfo":{"status":"aborted","timestamp":1664035523149,"user_tz":-540,"elapsed":27,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(ad_examples1.shape)\n","print(orig_labels1.shape)"],"metadata":{"id":"fhZ-PyFGn3lz","executionInfo":{"status":"aborted","timestamp":1664035523149,"user_tz":-540,"elapsed":27,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# GAN 모델 저장\n","from keras.models import load_model\n","\n","generator_base = load_model('baseGAN_Generator_attacked0.02.h5')"],"metadata":{"id":"lZngn6VduEUE","executionInfo":{"status":"aborted","timestamp":1664035523150,"user_tz":-540,"elapsed":28,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.imshow(generator_base.predict(np.random.normal(0, 1, (1, 100))).reshape(32,32,3))"],"metadata":{"id":"P4m8Jituudng","executionInfo":{"status":"aborted","timestamp":1664035523150,"user_tz":-540,"elapsed":28,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%matplotlib inline\n","import matplotlib.pyplot as plt"],"metadata":{"id":"g5GA13HB7okG","executionInfo":{"status":"aborted","timestamp":1664035523152,"user_tz":-540,"elapsed":30,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def DefenseGAN(img_at,L,R):\n","    z_list = []\n","    img = img_at.reshape(32,32,3)\n","    img_st = (img - np.mean(img)) / np.std(img) \n","    img_var = tf.Variable(img_st,dtype = float)\n","    opt = tf.keras.optimizers.SGD(learning_rate=0.1,momentum = 0.7)\n","\n","    def compute():\n","        z_hats_recs = generator_base(z_var)\n","        z_hats_recs = tf.reshape(z_hats_recs, [32,32,3])\n","        num_dim = len(z_hats_recs.get_shape())\n","        axes = range(1, num_dim)\n","        image_rec_loss = tf.reduce_mean(tf.square(z_hats_recs - img_var),axis=axes)\n","        rec_loss = tf.reduce_sum(image_rec_loss)\n","        return rec_loss\n","\n","    for r in range(R):\n","        z = np.random.normal(0, 1, (1, 100))\n","        z_var = tf.Variable(z,dtype = float)\n","    \n","        for l in range(L):\n","            opt.minimize(compute,[z_var])\n","        z_list.append(z_var)\n","\n","    def compute_10(z):\n","        #generator_base.trainable = False #아직 더해야하는지 뺴야하는지 판단 x\n","        z_hats_recs = generator_base(z)\n","        z_hats_recs = tf.reshape(z_hats_recs, [32,32,3])\n","        num_dim = len(z_hats_recs.get_shape())\n","        axes = range(1, num_dim)\n","        image_rec_loss = tf.reduce_mean(tf.square(z_hats_recs - img_var),axis=axes)\n","        rec_loss = tf.reduce_sum(image_rec_loss)\n","        return rec_loss\n","    \n","\n","    loss_list = []\n","    \n","    for i in range(len(z_list)):\n","        loss = compute_10(z_list[i])\n","        loss_list.append(loss)\n","    \n","    index_min = np.argmin(loss_list)\n","\n","    z_min = np.array(z_list[index_min])\n","\n","    generated_images = 0.5 * generator_base.predict(z_min)+ 0.5\n","\n","    generated_images = generated_images.reshape(32,32,3)\n","\n","    return generated_images"],"metadata":{"id":"2Zppe2W6n3n9","executionInfo":{"status":"aborted","timestamp":1664035523152,"user_tz":-540,"elapsed":30,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## predict_output에 한개씩 넣는 것부터 구현해야한다. (전체가 들어가는 것만 정상 작동함)\n","\n","def test(classifier, ad_example_data, orig_label_data):\n","\n","    # 정확도 카운터\n","    correct = 0\n","    defense_correct = 0\n","    df_examples = []\n","    alltime = []\n","    # 테스트 셋의 모든 예제에 대해 루프를 돕니다\n","\n","    loss, accuracy = classifier.evaluate(ad_example_data, orig_label_data)\n","\n","    print('방어 전 모델 정확도 : ',accuracy * 100)\n","\n","    for i in range(len(ad_example_data)):\n","        data = ad_example_data[i].reshape(-1,32,32,3)\n","        target = orig_label_data[i]\n","        \n","        data_plot = data.reshape(32,32,3)\n","        print('원본 label : ',np.argmax(target))\n","        plt.figure()\n","        plt.imshow(data_plot)\n","        plt.show();\n","\n","        start = time.time()\n","\n","        generated_img = DefenseGAN(data.reshape(32,32,3),200,10).reshape(-1,32,32,3)\n","\n","        activ_time = time.time() - start \n","\n","        generated_img_plot = generated_img.reshape(32,32,3)\n","\n","\n","        defense_output = classifier.predict(generated_img.reshape(1,32,32,3))\n","\n","        defense_pred= int(np.argmax(defense_output))\n","\n","        print('방어 라벨 : ',defense_pred)\n","        plt.figure()\n","        plt.imshow(generated_img_plot)\n","        plt.show();\n","\n","        if defense_pred == int(np.argmax(target)):\n","            defense_correct += 1\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","        else:\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","\n","        print('Working...!')\n","\n","        alltime.append(activ_time)\n","\n","    meantime = sum(alltime) / len(alltime)\n","\n","    defense_acc = defense_correct / float(len(ad_example_data))\n","    print(\"Defense Accuracy = {} / {} = {}\".format(defense_correct, len(ad_example_data), defense_acc))\n","    # 정확도와 적대적 예제를 리턴합니다\n","    return defense_acc, df_examples, meantime"],"metadata":{"id":"HsGI-NY4n3qe","executionInfo":{"status":"aborted","timestamp":1664035523152,"user_tz":-540,"elapsed":30,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["accuracies_df = []\n","examples_df = []\n","\n","acc_df, ex_df, meantime = test(model, ad_examples1[:100], orig_labels1[:100])\n","\n","accuracies_df.append(acc_df)\n","examples_df.append(ex_df)"],"metadata":{"id":"qnYmHP5Bn3tC","executionInfo":{"status":"aborted","timestamp":1664035523153,"user_tz":-540,"elapsed":30,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["meantime"],"metadata":{"id":"PBdm3k8iA2kP","executionInfo":{"status":"aborted","timestamp":1664035523153,"user_tz":-540,"elapsed":30,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## predict_output에 한개씩 넣는 것부터 구현해야한다. (전체가 들어가는 것만 정상 작동함)\n","\n","def saveimg(classifier, ad_example_data, orig_label_data):\n","\n","    data_at = []\n","    data_dgan = []\n","    # 정확도 카운터\n","    correct = 0\n","    defense_correct = 0\n","    df_examples = []\n","    alltime = []\n","    # 테스트 셋의 모든 예제에 대해 루프를 돕니다\n","\n","    loss, accuracy = classifier.evaluate(ad_example_data, orig_label_data)\n","\n","    print('방어 전 모델 정확도 : ',accuracy * 100)\n","\n","    for i in range(len(ad_example_data)):\n","        data = ad_example_data[i].reshape(-1,32,32,3)\n","        target = orig_label_data[i]\n","        \n","        data_plot = data.reshape(32,32,3)\n","        data_at.append(data_plot)\n","        print('원본 label : ',np.argmax(target))\n","        plt.figure()\n","        plt.imshow(data_plot)\n","        plt.show();\n","\n","        start = time.time()\n","\n","        generated_img = DefenseGAN(data.reshape(32,32,3),200,10).reshape(-1,32,32,3)\n","\n","        activ_time = time.time() - start \n","\n","        generated_img_plot = generated_img.reshape(32,32,3)\n","        data_dgan.append(generated_img_plot)\n","\n","        defense_output = classifier.predict(generated_img.reshape(1,32,32,3))\n","\n","        defense_pred= int(np.argmax(defense_output))\n","\n","        print('방어 라벨 : ',defense_pred)\n","        plt.figure()\n","        plt.imshow(generated_img_plot)\n","        plt.show();\n","\n","        if defense_pred == int(np.argmax(target)):\n","            defense_correct += 1\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","        else:\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","\n","        print('Working...!')\n","\n","        alltime.append(activ_time)\n","\n","    meantime = sum(alltime) / len(alltime)\n","\n","    defense_acc = defense_correct / float(len(ad_example_data))\n","    print(\"Defense Accuracy = {} / {} = {}\".format(defense_correct, len(ad_example_data), defense_acc))\n","    # 정확도와 적대적 예제를 리턴합니다\n","    return data_at, data_dgan"],"metadata":{"id":"2H7joCLxallR","executionInfo":{"status":"aborted","timestamp":1664035523154,"user_tz":-540,"elapsed":31,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_at, data_dgan= test(model, ad_examples1[:1], orig_labels1[:1])"],"metadata":{"id":"VpZUjdhVa54W","executionInfo":{"status":"aborted","timestamp":1664035523154,"user_tz":-540,"elapsed":31,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"evLKdiPEa-hQ","executionInfo":{"status":"aborted","timestamp":1664035523154,"user_tz":-540,"elapsed":31,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## PCA"],"metadata":{"id":"63SBpYd-IL2u"}},{"cell_type":"markdown","metadata":{"id":"1ywsHS3sfPxD"},"source":["### Defense 2 : PCA (Components = 5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KuoOeVKxsyvD","executionInfo":{"status":"aborted","timestamp":1664035523155,"user_tz":-540,"elapsed":32,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"outputs":[],"source":["ad_examples1 = np.array(ad_examples)\n","orig_labels1 = to_categorical(orig_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rAB3avuSbB3q","executionInfo":{"status":"aborted","timestamp":1664035523155,"user_tz":-540,"elapsed":32,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"outputs":[],"source":["from sklearn.decomposition import PCA\n","\n","# data shape이 32,32,3이어야한다.\n","def defense_PCA(data,component):\n","    #r,g,b를 각각 나눠준다\n","    data = data.reshape(32,32,3)\n","    r = data[:,:,0]\n","    g = data[:,:,1]\n","    b = data[:,:,2]\n","\n","    pca_r = PCA(n_components=component)\n","    pca_r_trans = pca_r.fit_transform(r)\n","\n","    pca_g = PCA(n_components=component)\n","    pca_g_trans = pca_g.fit_transform(g)\n","\n","    pca_b = PCA(n_components=component)\n","    pca_b_trans = pca_b.fit_transform(b)\n","\n","    pca_r_org = pca_r.inverse_transform(pca_r_trans)\n","    pca_g_org = pca_g.inverse_transform(pca_g_trans)\n","    pca_b_org = pca_b.inverse_transform(pca_b_trans)\n","\n","    img_compressed = np.stack((pca_r_org, pca_g_org, pca_b_org),axis = 2)\n","\n","    return img_compressed.reshape((-1,32,32,3))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j2uWTxjIf-a-","executionInfo":{"status":"aborted","timestamp":1664035523156,"user_tz":-540,"elapsed":32,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"outputs":[],"source":["## predict_output에 한개씩 넣는 것부터 구현해야한다. (전체가 들어가는 것만 정상 작동함)\n","\n","def test(classifier, ad_example_data, orig_label_data):\n","\n","    # 정확도 카운터\n","    correct = 0\n","    defense_correct = 0\n","    df_examples = []\n","    alltime = []\n","    # 테스트 셋의 모든 예제에 대해 루프를 돕니다\n","\n","    loss, accuracy = classifier.evaluate(ad_examples1, orig_labels1)\n","\n","    print('방어 전 모델 정확도 : ',accuracy * 100)\n","\n","    for i in range(len(ad_example_data)):\n","        data = ad_example_data[i].reshape(-1,32,32,3)\n","        target = orig_label_data[i]\n","        \n","        data_plot = data.reshape(32,32,3)\n","        print('원본 label : ',np.argmax(target))\n","        plt.figure()\n","        plt.imshow(data_plot)\n","        plt.show();\n","\n","        start = time.time()\n","        generated_img = defense_PCA(data,5)\n","        activ_time = time.time() - start \n","\n","        generated_img_plot = generated_img.reshape(32,32,3)\n","\n","        defense_output = classifier.predict(generated_img.reshape(1,32,32,3))\n","\n","        defense_pred= int(np.argmax(defense_output))\n","\n","        print('방어 라벨 : ',defense_pred)\n","        plt.figure()\n","        plt.imshow(generated_img_plot)\n","        plt.show();\n","\n","        if defense_pred == int(np.argmax(target)):\n","            defense_correct += 1\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","        else:\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","\n","        print('Working...!')\n","\n","        alltime.append(activ_time)\n","\n","    meantime = sum(alltime) / len(alltime)\n","    defense_acc = defense_correct / float(len(ad_example_data))\n","    print(\"Defense Accuracy = {} / {} = {}\".format(defense_correct, len(ad_example_data), defense_acc))\n","    # 정확도와 적대적 예제를 리턴합니다\n","    return defense_acc, df_examples, meantime"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TGm6ObXDhR2V","executionInfo":{"status":"aborted","timestamp":1664035523156,"user_tz":-540,"elapsed":32,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"outputs":[],"source":["accuracies_df = []\n","examples_df = []\n","\n","acc_df, ex_df,meantime = test(model, ad_examples1[:2000], orig_labels1[:2000])\n","\n","accuracies_df.append(acc_df)\n","examples_df.append(ex_df)\n","meantime"]},{"cell_type":"markdown","metadata":{"id":"9Y_-9xiJiAeC"},"source":["### Defense 2 : PCA (Components = 10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZOiE-bIgsz6w","executionInfo":{"status":"aborted","timestamp":1664035523156,"user_tz":-540,"elapsed":32,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"outputs":[],"source":["ad_examples1 = np.array(ad_examples)\n","orig_labels1 = to_categorical(orig_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EyLQ-kGQwqEZ","executionInfo":{"status":"aborted","timestamp":1664035523157,"user_tz":-540,"elapsed":33,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"outputs":[],"source":["from sklearn.decomposition import PCA\n","\n","# data shape이 32,32,3이어야한다.\n","def defense_PCA(data,component):\n","    #r,g,b를 각각 나눠준다\n","    data = data.reshape(32,32,3)\n","    r = data[:,:,0]\n","    g = data[:,:,1]\n","    b = data[:,:,2]\n","\n","    pca_r = PCA(n_components=component)\n","    pca_r_trans = pca_r.fit_transform(r)\n","\n","    pca_g = PCA(n_components=component)\n","    pca_g_trans = pca_g.fit_transform(g)\n","\n","    pca_b = PCA(n_components=component)\n","    pca_b_trans = pca_b.fit_transform(b)\n","\n","    pca_r_org = pca_r.inverse_transform(pca_r_trans)\n","    pca_g_org = pca_g.inverse_transform(pca_g_trans)\n","    pca_b_org = pca_b.inverse_transform(pca_b_trans)\n","\n","    img_compressed = np.stack((pca_r_org, pca_g_org, pca_b_org),axis = 2)\n","\n","    return img_compressed.reshape((-1,32,32,3))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lWXuP7V4iPO0","executionInfo":{"status":"aborted","timestamp":1664035523157,"user_tz":-540,"elapsed":33,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"outputs":[],"source":["## predict_output에 한개씩 넣는 것부터 구현해야한다. (전체가 들어가는 것만 정상 작동함)\n","\n","def test(classifier, ad_example_data, orig_label_data):\n","\n","    # 정확도 카운터\n","    correct = 0\n","    defense_correct = 0\n","    df_examples = []\n","    alltime = []\n","    # 테스트 셋의 모든 예제에 대해 루프를 돕니다\n","\n","    loss, accuracy = classifier.evaluate(ad_examples1, orig_labels1)\n","\n","    print('방어 전 모델 정확도 : ',accuracy * 100)\n","\n","    for i in range(len(ad_example_data)):\n","        data = ad_example_data[i].reshape(-1,32,32,3)\n","        target = orig_label_data[i]\n","        \n","        data_plot = data.reshape(32,32,3)\n","        print('원본 label : ',np.argmax(target))\n","        plt.figure()\n","        plt.imshow(data_plot)\n","        plt.show();\n","\n","        start = time.time()\n","        generated_img = defense_PCA(data,10)\n","        activ_time = time.time() - start \n","\n","        generated_img_plot = generated_img.reshape(32,32,3)\n","\n","        defense_output = classifier.predict(generated_img.reshape(1,32,32,3))\n","\n","        defense_pred= int(np.argmax(defense_output))\n","\n","        print('방어 라벨 : ',defense_pred)\n","        plt.figure()\n","        plt.imshow(generated_img_plot)\n","        plt.show();\n","\n","        if defense_pred == int(np.argmax(target)):\n","            defense_correct += 1\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","        else:\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","\n","        print('Working...!')\n","\n","        alltime.append(activ_time)\n","\n","    meantime = sum(alltime) / len(alltime)\n","    defense_acc = defense_correct / float(len(ad_example_data))\n","    print(\"Defense Accuracy = {} / {} = {}\".format(defense_correct, len(ad_example_data), defense_acc))\n","    # 정확도와 적대적 예제를 리턴합니다\n","    return defense_acc, df_examples, meantime"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HP7_KoXqiWhf","executionInfo":{"status":"aborted","timestamp":1664035523158,"user_tz":-540,"elapsed":34,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"outputs":[],"source":["accuracies_df = []\n","examples_df = []\n","\n","acc_df, ex_df,meantime = test(model, ad_examples1[:2000], orig_labels1[:2000])\n","\n","accuracies_df.append(acc_df)\n","examples_df.append(ex_df)\n","meantime"]},{"cell_type":"code","source":["## predict_output에 한개씩 넣는 것부터 구현해야한다. (전체가 들어가는 것만 정상 작동함)\n","\n","def saveimg(classifier, ad_example_data, orig_label_data):\n","\n","    data_at = []\n","    data_pca = []\n","    # 정확도 카운터\n","    correct = 0\n","    defense_correct = 0\n","    df_examples = []\n","    alltime = []\n","    # 테스트 셋의 모든 예제에 대해 루프를 돕니다\n","\n","    loss, accuracy = classifier.evaluate(ad_examples1, orig_labels1)\n","\n","    print('방어 전 모델 정확도 : ',accuracy * 100)\n","\n","    for i in range(len(ad_example_data)):\n","        data = ad_example_data[i].reshape(-1,32,32,3)\n","        target = orig_label_data[i]\n","        \n","        data_plot = data.reshape(32,32,3)\n","        data_at.append(data_plot)\n","        print('원본 label : ',np.argmax(target))\n","        plt.figure()\n","        plt.imshow(data_plot)\n","        plt.show();\n","\n","        start = time.time()\n","        generated_img = defense_PCA(data,10)\n","        activ_time = time.time() - start \n","\n","        generated_img_plot = generated_img.reshape(32,32,3)\n","        data_pca.append(generated_img_plot)\n","\n","        defense_output = classifier.predict(generated_img.reshape(1,32,32,3))\n","\n","        defense_pred= int(np.argmax(defense_output))\n","\n","        print('방어 라벨 : ',defense_pred)\n","        plt.figure()\n","        plt.imshow(generated_img_plot)\n","        plt.show();\n","\n","        if defense_pred == int(np.argmax(target)):\n","            defense_correct += 1\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","        else:\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","\n","        print('Working...!')\n","\n","        alltime.append(activ_time)\n","\n","    meantime = sum(alltime) / len(alltime)\n","    defense_acc = defense_correct / float(len(ad_example_data))\n","    print(\"Defense Accuracy = {} / {} = {}\".format(defense_correct, len(ad_example_data), defense_acc))\n","    # 정확도와 적대적 예제를 리턴합니다\n","    return data_at, data_pca"],"metadata":{"id":"NPiPNsFNXQHm","executionInfo":{"status":"aborted","timestamp":1664035523158,"user_tz":-540,"elapsed":34,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_at, data_pca = saveimg(model, ad_examples1[:1], orig_labels1[:1])"],"metadata":{"id":"bh4nORYcYBbU","executionInfo":{"status":"aborted","timestamp":1664035523159,"user_tz":-540,"elapsed":35,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.imshow(data_at[0])"],"metadata":{"id":"1pOypd9HYFSI","executionInfo":{"status":"aborted","timestamp":1664035523159,"user_tz":-540,"elapsed":35,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.imshow(data_at[0])"],"metadata":{"id":"RxH5RN5uY1Tf","executionInfo":{"status":"aborted","timestamp":1664035523160,"user_tz":-540,"elapsed":36,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["i = 0\n","#len(saved_original_output)\n","for num in range(len(save_original_output)):\n","    img_name = str(num) + '.png'\n","    img = save_original_examples[num].transpose(1,2,0)\n","    clip_img = np.clip(img, 0, 255)\n","    integer_img = clip_img.astype('uint8')\n","    img_2 = Image.fromarray(integer_img)\n","    img_2.save(img_name, 'png')\n","    i = i + 1"],"metadata":{"id":"6qq50d_dZWUQ","executionInfo":{"status":"aborted","timestamp":1664035523160,"user_tz":-540,"elapsed":35,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img = data_at[0] * 255\n","clip_img = np.clip(img, 0, 255)\n","integer_img = clip_img.astype('uint8')\n","img_2 = Image.fromarray(integer_img)\n","img_2.save('PCA', 'png')"],"metadata":{"id":"n9Og5jC0ZYbS","executionInfo":{"status":"aborted","timestamp":1664035523161,"user_tz":-540,"elapsed":36,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xkZbk27-Zlog","executionInfo":{"status":"aborted","timestamp":1664035523161,"user_tz":-540,"elapsed":36,"user":{"displayName":"진규코랩3","userId":"15317755441765680267"}}},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"collapsed_sections":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}