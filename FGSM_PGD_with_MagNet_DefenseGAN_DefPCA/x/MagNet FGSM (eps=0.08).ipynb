{"cells":[{"cell_type":"markdown","source":["데이터셋 설정 관련\n","* for문으로 돌리려다가, 하나하나 돌리는게 너무 오래 걸려서 코드로 나누고 계정별로 돌릴 수 있게 코드 변경했습니다\n","* 공격 종류 (FGSM, PGD), 공격 입실론 (0.02 등)을 목차 [Attack 수행 : 공격 데이터셋 만드는 코드] 부분에서 수정하고 코드 돌리면 됩니다"],"metadata":{"id":"05NggkxjGxlN"}},{"cell_type":"markdown","source":["# 기본 import"],"metadata":{"id":"H5r08xIXerXB"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"WgKss5hJBb5B","executionInfo":{"status":"ok","timestamp":1663416666679,"user_tz":-540,"elapsed":3236,"user":{"displayName":"김채현코랩3","userId":"12600322500441715060"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","import os\n","import pathlib\n","\n","import cv2 #영상처리에 사용하는 오픈소스 라이브러리, 컴퓨터가 사람 눈처럼 인식할 수 있게 처리\n","from PIL import Image # 파이썬 이미지 처리 pillow 라이브러리\n","from tensorflow.keras.preprocessing import image\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator #imagedatagenerater는 이미지를 학습시킬 때 학습 데이터의 양이 적을 경우 학습데이터를 조금씩 변형 시켜서 학습데이터의 양을 늘리는 방식중 하나\n","from tensorflow.keras.preprocessing.image import img_to_array, array_to_img, load_img\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n","from tensorflow.keras.models import Sequential\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","import matplotlib.pyplot as plt\n","\n","from tqdm.auto import tqdm\n","\n","#난수 랜덤성 고정\n","np.random.seed(42)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14872,"status":"ok","timestamp":1663416681548,"user":{"displayName":"김채현코랩3","userId":"12600322500441715060"},"user_tz":-540},"id":"Qn7HC1qiBnNE","outputId":"11a79034-a938-42a7-fb0a-f24454364a7e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":498,"status":"ok","timestamp":1663416682044,"user":{"displayName":"김채현코랩3","userId":"12600322500441715060"},"user_tz":-540},"id":"VwTVXhm7BoaE","outputId":"5ed3a3f9-121d-4f30-d76d-f64c7e731aac"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1WKEjdIyqtzI-NV5o0O_ixsHslngaSiQX/[한이음] 적대적 AI 공격에 대한 인공지능 보안기술 연구/3. 소스코드/GTSRB\n"]}],"source":["cd drive/MyDrive/[한이음] 적대적 AI 공격에 대한 인공지능 보안기술 연구/3. 소스코드/GTSRB"]},{"cell_type":"markdown","source":["# Train & Test 데이터 불러오기"],"metadata":{"id":"FhnfS-0MH1sa"}},{"cell_type":"markdown","metadata":{"id":"JjBcm524Fams"},"source":["Train Data 불러오기"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"kZnmTWHIBo_E","executionInfo":{"status":"ok","timestamp":1663416682044,"user_tz":-540,"elapsed":4,"user":{"displayName":"김채현코랩3","userId":"12600322500441715060"}}},"outputs":[],"source":["import numpy as np\n","import os\n","import gzip\n","import urllib.request\n","\n","from keras.models import load_model\n","\n","def ordered_onehotencoding(labels):\n","    labels_ordered = []\n","    for i in range(len(labels)):\n","        if labels[i] == 3:\n","            labels_ordered.append(0)\n","        elif labels[i] == 7:\n","            labels_ordered.append(1)\n","        elif labels[i] == 9:\n","            labels_ordered.append(2)\n","        elif labels[i] == 10:\n","            labels_ordered.append(3)\n","        elif labels[i] == 11:\n","            labels_ordered.append(4)\n","        elif labels[i] == 12:\n","            labels_ordered.append(5)\n","        elif labels[i] == 13:\n","            labels_ordered.append(6)\n","        elif labels[i] == 17:\n","            labels_ordered.append(7)\n","        elif labels[i] == 18:\n","            labels_ordered.append(8)\n","        elif labels[i] == 25:\n","            labels_ordered.append(9)\n","        elif labels[i] == 35:\n","            labels_ordered.append(10)\n","        elif labels[i] == 38:\n","            labels_ordered.append(11)\n","    \n","    return np.array(labels_ordered)\n","\n","class GTSRB:\n","    def __init__(self):\n","        imgs_path = \"Train\"\n","        data_list = []\n","        labels_list = []\n","\n","        result_class = [3,7, 9, 10, 11, 12, 13, 17, 18, 25, 35, 38]\n","\n","        for i in result_class:\n","            i_path = os.path.join(imgs_path, str(i)) # 3, 7, 9, 10, 11, 12,13, 17, 18, 25, 35, 38\n","            num = 0\n","            for img in os.listdir(i_path):\n","          \n","                im = Image.open(i_path +'/'+ img)\n","                im = im.resize((32,32))\n","                im = np.array(im)\n","\n","                data_list.append(im)\n","                labels_list.append(i)\n","                num = num + 1\n","                if num == 1000:\n","                    break;\n","\n","        data = np.array(data_list)\n","        labels = ordered_onehotencoding(labels_list)\n","\n","        labels = to_categorical(labels)\n","\n","        VALIDATION_SIZE = 5000\n","        \n","        self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(np.array(data), labels, test_size=0.4)    \n","\n","    @staticmethod\n","    def print():\n","        return \"GTSRB\""]},{"cell_type":"code","execution_count":5,"metadata":{"id":"lWo9BzndEm67","executionInfo":{"status":"ok","timestamp":1663416917051,"user_tz":-540,"elapsed":235010,"user":{"displayName":"김채현코랩3","userId":"12600322500441715060"}}},"outputs":[],"source":["data = GTSRB()"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1663416917054,"user":{"displayName":"김채현코랩3","userId":"12600322500441715060"},"user_tz":-540},"id":"Zc5Q_EXiEppb","outputId":"732324a6-ae3b-4e88-d690-c1facc4df266"},"outputs":[{"output_type":"stream","name":"stdout","text":["(7200, 32, 32, 3)\n","(4800, 32, 32, 3)\n","(7200, 12)\n","(4800, 12)\n"]}],"source":["print(data.x_train.shape)\n","print(data.x_test.shape)\n","print(data.y_train.shape)\n","print(data.y_test.shape)"]},{"cell_type":"markdown","metadata":{"id":"P2uSEM66FdVa"},"source":["Test Data 불러오기"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"_shX58HHFisj","executionInfo":{"status":"ok","timestamp":1663416917550,"user_tz":-540,"elapsed":501,"user":{"displayName":"김채현코랩3","userId":"12600322500441715060"}}},"outputs":[],"source":["metainfo = pd.read_csv(\"Meta.csv\")\n","traininfo = pd.read_csv(\"Train.csv\")\n","testinfo = pd.read_csv(\"Test.csv\")"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"z9HPAPg2FZ9L","executionInfo":{"status":"ok","timestamp":1663416917849,"user_tz":-540,"elapsed":302,"user":{"displayName":"김채현코랩3","userId":"12600322500441715060"}}},"outputs":[],"source":["import natsort\n","\n","class GTSRB_test:\n","    def __init__(self):\n","        imgs_path = \"Test\"\n","        data_list = []\n","        labels_list = []\n","        \n","        for img in natsort.natsorted(os.listdir(imgs_path)):\n","            im = Image.open(imgs_path +'/'+ img)\n","            im = im.resize((32,32))\n","            im = np.array(im)\n","            data_list.append(im)\n","        data_test = np.array(data_list)\n","        \n","        for i in range(len(testinfo.ClassId)):\n","            labels_list.append(testinfo.ClassId[i])\n","        \n","        labels_test = np.array(labels_list)\n","\n","        labels_test_index = []\n","        for i in range(len(labels_test)):\n","            if (labels_test[i] == 3) | (labels_test[i] == 7) | (labels_test[i] == 9) | (labels_test[i] == 10) | (labels_test[i] == 11) | (labels_test[i] == 12) | (labels_test[i] == 13) | (labels_test[i] == 17) | (labels_test[i] == 18) | (labels_test[i] == 25) | (labels_test[i] == 35) | (labels_test[i] == 38):\n","                labels_test_index.append(i)\n","\n","        test_data = []\n","        test_label = []\n","        for i in labels_test_index:\n","            test_data.append(data_test[i])\n","            test_label.append(labels_test[i])\n","\n","        data_test = np.array(test_data)\n","\n","        labels_test =ordered_onehotencoding(test_label)\n","\n","        labels_test = to_categorical(labels_test)\n","        \n","        self.x_test = data_test\n","        self.y_test = labels_test    \n","\n","    @staticmethod\n","    def print():\n","        return \"GTSRB_test\""]},{"cell_type":"code","execution_count":9,"metadata":{"id":"CcWfJaa6Ft7z","executionInfo":{"status":"ok","timestamp":1663417037318,"user_tz":-540,"elapsed":119473,"user":{"displayName":"김채현코랩3","userId":"12600322500441715060"}}},"outputs":[],"source":["data_test = GTSRB_test()"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1663417037318,"user":{"displayName":"김채현코랩3","userId":"12600322500441715060"},"user_tz":-540},"id":"VE9NTZrAFv7e","outputId":"c254b5ad-f844-4020-ba65-4c2caed5e781"},"outputs":[{"output_type":"stream","name":"stdout","text":["(6180, 32, 32, 3)\n","(6180, 12)\n"]}],"source":["print(data_test.x_test.shape)\n","print(data_test.y_test.shape)"]},{"cell_type":"markdown","metadata":{"id":"XWfrLWt3EtSN"},"source":["# 분류기 : CNN"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"TqQDIy-WEwQz","executionInfo":{"status":"ok","timestamp":1663417037797,"user_tz":-540,"elapsed":498,"user":{"displayName":"김채현코랩3","userId":"12600322500441715060"}}},"outputs":[],"source":["data.x_train, data.y_train, data.x_test, data.y_test =data.x_train/255, data.y_train/255, data.x_test/255, data.y_test/255"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":55244,"status":"ok","timestamp":1663417093036,"user":{"displayName":"김채현코랩3","userId":"12600322500441715060"},"user_tz":-540},"id":"gI5nIfEQE0Dt","outputId":"52da4541-e325-4ec8-a6dc-05b0adbdbc42"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 30, 30, 96)        2688      \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 15, 15, 96)       0         \n"," )                                                               \n","                                                                 \n"," dropout (Dropout)           (None, 15, 15, 96)        0         \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 13, 13, 192)       166080    \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 6, 6, 192)        0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_1 (Dropout)         (None, 6, 6, 192)         0         \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 4, 4, 192)         331968    \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 64)                196672    \n","                                                                 \n"," dense_1 (Dense)             (None, 12)                780       \n","                                                                 \n","=================================================================\n","Total params: 698,188\n","Trainable params: 698,188\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/30\n","60/60 [==============================] - 13s 23ms/step - loss: 0.0422 - accuracy: 0.0861 - val_loss: 0.0057 - val_accuracy: 0.0842\n","Epoch 2/30\n","60/60 [==============================] - 1s 23ms/step - loss: 0.0040 - accuracy: 0.0897 - val_loss: 0.0044 - val_accuracy: 0.0965\n","Epoch 3/30\n","60/60 [==============================] - 1s 23ms/step - loss: 0.0031 - accuracy: 0.1047 - val_loss: 0.0043 - val_accuracy: 0.1281\n","Epoch 4/30\n","60/60 [==============================] - 1s 24ms/step - loss: 0.0030 - accuracy: 0.1306 - val_loss: 0.0040 - val_accuracy: 0.1529\n","Epoch 5/30\n","60/60 [==============================] - 1s 23ms/step - loss: 0.0030 - accuracy: 0.1732 - val_loss: 0.0037 - val_accuracy: 0.2315\n","Epoch 6/30\n","60/60 [==============================] - 1s 23ms/step - loss: 0.0029 - accuracy: 0.1990 - val_loss: 0.0036 - val_accuracy: 0.2075\n","Epoch 7/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0029 - accuracy: 0.2485 - val_loss: 0.0034 - val_accuracy: 0.3179\n","Epoch 8/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0029 - accuracy: 0.3001 - val_loss: 0.0033 - val_accuracy: 0.3640\n","Epoch 9/30\n","60/60 [==============================] - 1s 23ms/step - loss: 0.0028 - accuracy: 0.4150 - val_loss: 0.0031 - val_accuracy: 0.5208\n","Epoch 10/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.5400 - val_loss: 0.0032 - val_accuracy: 0.6417\n","Epoch 11/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.6506 - val_loss: 0.0028 - val_accuracy: 0.7369\n","Epoch 12/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0025 - accuracy: 0.7189 - val_loss: 0.0028 - val_accuracy: 0.7708\n","Epoch 13/30\n","60/60 [==============================] - 1s 23ms/step - loss: 0.0025 - accuracy: 0.7533 - val_loss: 0.0026 - val_accuracy: 0.8127\n","Epoch 14/30\n","60/60 [==============================] - 1s 23ms/step - loss: 0.0025 - accuracy: 0.7896 - val_loss: 0.0026 - val_accuracy: 0.8442\n","Epoch 15/30\n","60/60 [==============================] - 1s 23ms/step - loss: 0.0024 - accuracy: 0.8112 - val_loss: 0.0027 - val_accuracy: 0.8560\n","Epoch 16/30\n","60/60 [==============================] - 1s 24ms/step - loss: 0.0024 - accuracy: 0.8281 - val_loss: 0.0025 - val_accuracy: 0.8604\n","Epoch 17/30\n","60/60 [==============================] - 1s 23ms/step - loss: 0.0024 - accuracy: 0.8482 - val_loss: 0.0025 - val_accuracy: 0.8967\n","Epoch 18/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0024 - accuracy: 0.8683 - val_loss: 0.0025 - val_accuracy: 0.9067\n","Epoch 19/30\n","60/60 [==============================] - 1s 24ms/step - loss: 0.0024 - accuracy: 0.8901 - val_loss: 0.0026 - val_accuracy: 0.9242\n","Epoch 20/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0023 - accuracy: 0.9021 - val_loss: 0.0025 - val_accuracy: 0.9304\n","Epoch 21/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0023 - accuracy: 0.9128 - val_loss: 0.0025 - val_accuracy: 0.9354\n","Epoch 22/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0023 - accuracy: 0.9185 - val_loss: 0.0025 - val_accuracy: 0.9433\n","Epoch 23/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0023 - accuracy: 0.9310 - val_loss: 0.0026 - val_accuracy: 0.9417\n","Epoch 24/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0023 - accuracy: 0.9293 - val_loss: 0.0025 - val_accuracy: 0.9469\n","Epoch 25/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0023 - accuracy: 0.9369 - val_loss: 0.0025 - val_accuracy: 0.9525\n","Epoch 26/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0023 - accuracy: 0.9415 - val_loss: 0.0025 - val_accuracy: 0.9558\n","Epoch 27/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0023 - accuracy: 0.9436 - val_loss: 0.0024 - val_accuracy: 0.9592\n","Epoch 28/30\n","60/60 [==============================] - 1s 23ms/step - loss: 0.0023 - accuracy: 0.9486 - val_loss: 0.0023 - val_accuracy: 0.9638\n","Epoch 29/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0023 - accuracy: 0.9494 - val_loss: 0.0024 - val_accuracy: 0.9675\n","Epoch 30/30\n","60/60 [==============================] - 1s 23ms/step - loss: 0.0023 - accuracy: 0.9543 - val_loss: 0.0024 - val_accuracy: 0.9638\n"]}],"source":["from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D,GlobalAveragePooling2D\n","from tensorflow.keras.optimizers import SGD\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","import tensorflow as tf\n","import os\n","\n","\n","def train(data, file_name, num_epochs=50, batch_size=128):\n","    \"\"\"\n","    Standard neural network training procedure.\n","    \"\"\"\n","    model = Sequential()\n","\n","    IMG_HEIGHT = 32\n","    IMG_WIDTH = 32\n","\n","    # 첫번째 Convolutional Layer : 입력 데이터로부터 특징을 추출\n","    model.add(Conv2D(filters=96, kernel_size=3, activation='relu', input_shape=data.x_train.shape[1:]))\n","    model.add(MaxPool2D(pool_size=(2, 2)))\n","    model.add(Dropout(rate=0.25))\n","\n","    # 두번째 Convolutional Layer\n","    model.add(Conv2D(filters=192, kernel_size=3, activation='relu'))\n","    model.add(MaxPool2D(pool_size=(2, 2)))\n","    model.add(Dropout(rate=0.25)) # 인풋데이터의 25%를 무작위로 0으로 만듦\n","\n","    # 세번째 Convolutional Layer\n","    model.add(Conv2D(filters=192, kernel_size=3, activation='relu')) # 특징을 추출하는 기능을 하는 필터, 비선형 값으로 바꿔주는 activation 함수->relu\n","    # model.add(GlobalAveragePooling2D())\n","    model.add(Flatten())\n","\n","    model.add(Dense(units=64, activation='relu'))\n","    model.add(Dense(12, activation='softmax'))\n","\n","\n","    # 모델 컴파일 하기\n","    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    model.summary()\n","\n","    # 모델 핏하기\n","    EPOCHS = num_epochs\n","    model.fit(data.x_train, data.y_train,\n","              validation_data = (data.x_test, data.y_test), \n","              epochs=EPOCHS, steps_per_epoch=60\n","              )\n","\n","    if file_name != None:\n","        model.save(file_name)\n","\n","    return model\n","\n","\n","if not os.path.isdir('models'):\n","    os.makedirs('models')\n","\n","model = train(data, \"models/gtsrb_classifier\", num_epochs=30)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1837,"status":"ok","timestamp":1663417094846,"user":{"displayName":"김채현코랩3","userId":"12600322500441715060"},"user_tz":-540},"id":"Ez-W2phKFLws","outputId":"dbcd1bb5-a4c0-44b5-db0b-dda7d038ef00"},"outputs":[{"output_type":"stream","name":"stdout","text":["225/225 [==============================] - 1s 3ms/step - loss: 0.0024 - accuracy: 0.9674\n","test set accuracy:  96.73610925674438\n","150/150 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.9638\n","test set accuracy:  96.37500047683716\n"]}],"source":["loss, accuracy = model.evaluate(data.x_train, data.y_train)\n","\n","print('test set accuracy: ', accuracy * 100)\n","\n","loss, accuracy = model.evaluate(data.x_test, data.y_test)\n","\n","print('test set accuracy: ', accuracy * 100)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2187,"status":"ok","timestamp":1663417097031,"user":{"displayName":"김채현코랩3","userId":"12600322500441715060"},"user_tz":-540},"id":"xbYmfSHYHOIa","outputId":"878564ce-d8a8-439d-e88f-518ca85924fd"},"outputs":[{"output_type":"stream","name":"stdout","text":["194/194 [==============================] - 1s 4ms/step - loss: 25.6343 - accuracy: 0.8558\n","test set accuracy:  85.58252453804016\n","194/194 [==============================] - 1s 4ms/step - loss: 0.0024 - accuracy: 0.9154\n","test set accuracy with nomalization:  91.53721928596497\n"]}],"source":["# test data set\n","loss, accuracy = model.evaluate(data_test.x_test, data_test.y_test)\n","\n","print('test set accuracy: ', accuracy * 100)\n","\n","# --> 애초에 오버피팅 되어있음을 확인할 수 있다.\n","\n","loss, accuracy = model.evaluate(data_test.x_test/255, data_test.y_test/255)\n","\n","print('test set accuracy with nomalization: ', accuracy * 100)\n","\n","# --> /255로 정규화 시켜준다면 어느정도 성능 회복 "]},{"cell_type":"markdown","source":["# 공격 데이터셋 : FGSM & PGD"],"metadata":{"id":"QNRCIvO3-8lf"}},{"cell_type":"code","source":["def tf_preprocess(image):\n","  image = tf.cast(image, tf.float32)\n","  image = image/255\n","  image = tf.image.resize(image, (32, 32))\n","  image = image[None, ...]\n","  return image\n","\n","# 확률 벡터에서 레이블을 추출해주는 헬퍼 메서드\n","def get_tf_label(labels):\n","    label = tf.cast(labels, tf.int32)\n","    label = tf.reshape(label,[1,12])\n","    return label\n","\n","loss_object = tf.keras.losses.CategoricalCrossentropy()\n","\n","def create_adversarial_pattern(input_image, input_label):\n","  with tf.GradientTape() as tape:\n","    tape.watch(input_image)\n","    input_img = tf.reshape(input_image,[1,32,32,3])\n","    prediction = model(input_img)\n","    loss = loss_object(input_label, prediction)\n","\n","  # 입력 이미지에 대한 손실 함수의 기울기를 구합니다.\n","  gradient = tape.gradient(loss, input_image)\n","  # 왜곡을 생성하기 위해 그래디언트의 부호를 구합니다.\n","  signed_grad = tf.sign(gradient)\n","  return signed_grad"],"metadata":{"id":"Dn9x64obA9UB","executionInfo":{"status":"ok","timestamp":1663417097031,"user_tz":-540,"elapsed":3,"user":{"displayName":"김채현코랩3","userId":"12600322500441715060"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4SUb6-MoJtay"},"source":["### FGSM & PGD define"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"DGBdi7tWJT1K","executionInfo":{"status":"ok","timestamp":1663417097032,"user_tz":-540,"elapsed":4,"user":{"displayName":"김채현코랩3","userId":"12600322500441715060"}}},"outputs":[],"source":["def fgsm_attack(model,test_x,test_y,eps):\n","    \n","    correct = 0\n","    adv_examples = []\n","    save_adv_examples = [] # 공격받은 이미지들이 저장될 리스트\n","    save_original_output = [] # 공격받은 이미지들의 정답 라벨 값이 저장될 리스트\n","    \n","    for i in range(len(test_x)):\n","        # 1장의 이미지와 그 label\n","        data = test_x[i]\n","        target_onehot = test_y[i] # one-hot 형태\n","        target_label = int(np.argmax(target_onehot)) # label 형태\n","\n","        # model이 정상 데이터를 분류한 결과 (각각 one-hot 형태, int label 형태)\n","        result_onehot = model.predict(data.reshape(1,32,32,3) / 255) # one-hot 형태\n","        result_label = int(np.argmax(result_onehot))\n","\n","        # 모델이 정상 데이터인데도 잘못 분류했다면 사용하지 않는다 (아래 코드 실행하지 않고 다음 이미지로 넘어감)\n","        if target_label != result_label:\n","            continue\n","\n","        # 이미지 전처리\n","        img =  tf_preprocess(data) # 텐서플로 전처리\n","        label = get_tf_label(target_onehot) # 확률벡터에서 레이블 추출\n","        \n","        # FGSM 공격 수행\n","        perturbations = create_adversarial_pattern(img, label)\n","        adv_x = img + eps * perturbations\n","        adv_x = tf.clip_by_value(adv_x, 0, 1) # 공격받은 이미지\n","\n","        # 공격 이미지를 분류기에 넣은 결과; 잘못 분류되어야 할 것 \n","        atkresult_onehot = model.predict(adv_x) # one-hot 형태\n","        atkresult_label = int(np.argmax(atkresult_onehot)) # label 형태\n","\n","        # 만약 공격 받아도 제대로 분류된다면 correct로 count\n","        if atkresult_label == target_label:\n","            correct += 1\n","        # ####################################################################################\n","        # ################ 여기 코드는 필요 없지 않나?\n","        #     if (eps == 0) and (len(adv_examples) < 5):\n","        #         adv_ex = adv_x\n","        #         adv_examples.append((init_output,final_pred,adv_x))\n","        # else:\n","        #     if len(adv_examples) < 5:\n","        #         adv_ex = adv_x\n","        #         adv_examples.append((init_output,final_pred,adv_x))\n","        # ####################################################################################\n","        \n","        # 공격 적용된 이미지, 그 공격 받은 이미지의 원래 정답 label을 각각 리스트에 저장합니다\n","        save_adv_examples.append(tf.reshape(adv_x,[32,32,3]))\n","        save_original_output.append(atkresult_label)\n","\n","    # 해당 엡실론에서의 최종 정확도를 계산합니다\n","    final_acc = correct/float(len(test_x))\n","    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(eps, correct, len(test_x), final_acc))\n","\n","    # 정확도와 적대적 예제를 리턴합니다\n","    return final_acc, adv_examples, save_adv_examples, save_original_output"]},{"cell_type":"code","source":["def pgd_attack(model,test_x,test_y,eps,step_size=2,num_steps=7): \n","    \"\"\"\n","    FGSM 코드와 차이점\n","    - step_size, num_steps 파라미터 추가됨\n","    - unifrom distribution 코드 추가\n","    - FGSM 공격 수행 -> PGD 공격 수행\n","    ** 모든 return 형식은 동일함\n","    \n","    default 값\n","    - step_size = 2 (alpha 값)\n","    - num_steps = 7 (iterations 값)\n","\n","    \"\"\"\n","\n","    prog = 0 # 진행상황 확인용 변수\n","\n","    correct = 0\n","    adv_examples = []\n","    save_adv_examples = [] # 공격받은 이미지들이 저장될 리스트\n","    save_original_output = [] # 공격받은 이미지들의 정답 라벨 값이 저장될 리스트\n","    \n","    for i in range(len(test_x)):\n","        # 1장의 이미지와 그 label\n","        data = test_x[i]\n","        target_onehot = test_y[i] # one-hot 형태\n","        target_label = int(np.argmax(target_onehot)) # label 형태\n","\n","        # model이 정상 데이터를 분류한 결과 (각각 one-hot 형태, int label 형태)\n","        result_onehot = model.predict(data.reshape(1,32,32,3) / 255) # one-hot 형태\n","        result_label = int(np.argmax(result_onehot))\n","\n","        # 모델이 정상 데이터인데도 잘못 분류했다면 사용하지 않는다 (아래 코드 실행하지 않고 다음 이미지로 넘어감)\n","        if target_label != result_label:\n","            continue\n","\n","        # PGD uniform distribution 코드\n","        data = data + np.random.uniform(-eps,eps,data.shape)\n","        data = np.clip(data,0,255)\n","\n","        # 이미지 전처리\n","        img =  tf_preprocess(data) # 텐서플로 전처리\n","        label = get_tf_label(target_onehot) # 확률벡터에서 레이블 추출\n","        \n","        # PGD 공격 수행\n","        adv_x = img # 공격받은 이미지 (for문으로 업데이트)\n","        for num_step in range(num_steps):\n","          perturbations = create_adversarial_pattern(adv_x,label) # signed_grad를 리턴한 값\n","          adv_x += step_size * perturbations\n","          adv_x = tf.clip_by_value(adv_x,img-eps,img+eps)\n","          adv_x = tf.clip_by_value(adv_x,0,1)\n","\n","        # 공격 이미지를 분류기에 넣은 결과; 잘못 분류되어야 할 것 \n","        atkresult_onehot = model.predict(adv_x) # one-hot 형태\n","        atkresult_label = int(np.argmax(atkresult_onehot)) # label 형태\n","\n","        # 만약 공격 받아도 제대로 분류된다면 correct로 count\n","        if atkresult_label == target_label:\n","            correct += 1\n","        # ####################################################################################\n","        # ################ 여기 코드는 필요 없지 않나?\n","        #     if (eps == 0) and (len(adv_examples) < 5):\n","        #         adv_ex = adv_x\n","        #         adv_examples.append((init_output,final_pred,adv_x))\n","        # else:\n","        #     if len(adv_examples) < 5:\n","        #         adv_ex = adv_x\n","        #         adv_examples.append((init_output,final_pred,adv_x))\n","        # ####################################################################################\n","        \n","        # 공격 적용된 이미지, 그 공격 받은 이미지의 원래 정답 label을 각각 리스트에 저장합니다\n","        save_adv_examples.append(tf.reshape(adv_x,[32,32,3]))\n","        save_original_output.append(atkresult_label)\n","\n","        prog += 1\n","        if prog%3000 == 0:\n","          print(\"prog :\", prog)\n","\n","    # 해당 엡실론에서의 최종 정확도를 계산합니다\n","    final_acc = correct/float(len(test_x))\n","    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(eps, correct, len(test_x), final_acc))\n","\n","    # 정확도와 적대적 예제를 리턴합니다\n","    return final_acc, adv_examples, save_adv_examples, save_original_output"],"metadata":{"id":"GmiLgFduVhR0","executionInfo":{"status":"ok","timestamp":1663417097032,"user_tz":-540,"elapsed":3,"user":{"displayName":"김채현코랩3","userId":"12600322500441715060"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["### Attack 수행 : 공격 데이터셋 만드는 코드\n","\n","**여기에서 [attack_type]과 [eps] 설정하면 됩니다!!!**\n","\n","* attack_type : FGSM, PGD\n","* eps = 0.02, 0.03, 8/255, 0.05, 0.08, 0.10\n","* 정상 이미지에 대한 분류기 정확도 -> 위에 있음 (분류기:CNN; 약 91%)"],"metadata":{"id":"AVs5AnagBdTK"}},{"cell_type":"code","source":["################################################################################\n","# 공격 데이터 설정 #################################################################\n","attack_type = \"FGSM\" # FGSM, PGD\n","eps = 0.08 # 0.02, 0.03, 8/255, 0.05, 0.08, 0.10\n","################################################################################\n","################################################################################\n","\n","if attack_type == \"FGSM\":\n","  acc, ex, ad_examples, orig_labels = fgsm_attack(model, data_test.x_test, data_test.y_test, eps)\n","elif attack_type == \"PGD\":\n","  acc, ex, ad_examples, orig_labels = pgd_attack(model, data_test.x_test, data_test.y_test, eps)\n","\n","print(\"Attack Data 생성 완료\")"],"metadata":{"id":"ZE2wZtfAEOBh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663417602556,"user_tz":-540,"elapsed":505527,"user":{"displayName":"김채현코랩3","userId":"12600322500441715060"}},"outputId":"e95e33ea-32dc-400f-934e-fa14550d89d4"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Epsilon: 0.08\tTest Accuracy = 831 / 6180 = 0.13446601941747574\n","Attack Data 생성 완료\n"]}]},{"cell_type":"markdown","source":["# 방어모델 : MagNet, Defense-GAN, PCA"],"metadata":{"id":"6DfDZcE5_GGB"}},{"cell_type":"markdown","source":["## MagNet"],"metadata":{"id":"Lb-doZmmIFqj"}},{"cell_type":"markdown","source":["### MagNet - def (utils, worker, Defensive Model)"],"metadata":{"id":"-Yc-yrW7ktMW"}},{"cell_type":"markdown","source":["#### MagNet - utils"],"metadata":{"id":"bt4nIJ5xg73T"}},{"cell_type":"code","source":["## utils.py -- utility functions\n","##\n","## Copyright (C) 2017, Dongyu Meng <zbshfmmm@gmail.com>.\n","##\n","## This program is licenced under the BSD 2-Clause licence,\n","## contained in the LICENCE file in this directory.\n","\n","import pickle\n","import os\n","import numpy as np\n","\n","\n","def prepare_data(dataset, idx):\n","    \"\"\"\n","    Extract data from index.\n","\n","    dataset: Full, working dataset. Such as MNIST().\n","    idx: Index of test examples that we care about.\n","    return: X, targets, Y\n","    \"\"\"\n","    return dataset.x_test[idx], dataset.y_test[idx], np.argmax(dataset.y_test[idx], axis=1)\n","\n","\n","def save_obj(obj, name, directory='./attack_data/'):\n","    with open(os.path.join(directory, name + '.pkl'), 'wb') as f:\n","        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n","\n","\n","def load_obj(name, directory='./attack_data/'):\n","    if name.endswith(\".pkl\"): name = name[:-4]\n","    with open(os.path.join(directory, name + '.pkl'), 'rb') as f:\n","        return pickle.load(f)"],"metadata":{"id":"hAvlahKmMFdO","executionInfo":{"status":"ok","timestamp":1663417602557,"user_tz":-540,"elapsed":9,"user":{"displayName":"김채현코랩3","userId":"12600322500441715060"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["#### MagNet - worker"],"metadata":{"id":"EhncucofhEvv"}},{"cell_type":"code","source":["## setup_mnist.py -- mnist data and model loading code\n","##\n","## Copyright (C) 2016, Nicholas Carlini <nicholas@carlini.com>.\n","##\n","## This program is licenced under the BSD 2-Clause licence,\n","## contained in the LICENCE file in this directory.\n","\n","## Modified for MagNet's use.\n","\n","## worker.py -- evaluation code\n","##\n","## Copyright (C) 2017, Dongyu Meng <zbshfmmm@gmail.com>.\n","##\n","## This program is licenced under the BSD 2-Clause licence,\n","## contained in the LICENCE file in this directory.\n","\n","import matplotlib\n","matplotlib.use('Agg')\n","from scipy.stats import entropy\n","from numpy.linalg import norm\n","from matplotlib.ticker import FuncFormatter\n","from keras.models import Sequential, load_model\n","from keras.activations import softmax\n","from keras.layers import Lambda\n","import numpy as np\n","import pylab\n","import os\n","import matplotlib.pyplot as plt\n","\n","\n","class AEDetector:\n","    def __init__(self, path, p=1):\n","        \"\"\"\n","        Error based detector.\n","        Marks examples for filtering decisions.\n","\n","        path: Path to the autoencoder used.\n","        p: Distance measure to use.\n","        \"\"\"\n","\n","        self.model = load_model(path)\n","        self.path = path\n","        self.p = p\n","\n","    def mark(self, X):\n","        diff = np.abs(X - self.model.predict(X)) # input X와 예측값 X'(autoencoder를 통해 노이즈가 더해진 값) 의 오차 값\n","        marks = np.mean(np.power(diff, self.p), axis=(1,2,3)) # 오차값의 분산\n","        return marks\n","\n","    def print(self):\n","        return \"AEDetector:\" + self.path.split(\"/\")[-1]\n","\n","\n","class IdReformer:\n","    def __init__(self, path=\"IdentityFunction\"):\n","        \"\"\"\n","        Identity reformer.\n","        Reforms an example to itself.\n","        \"\"\"\n","        self.path = path\n","        self.heal = lambda X: X\n","\n","    def print(self):\n","        return \"IdReformer:\" + self.path\n","\n","\n","class SimpleReformer:\n","    def __init__(self, path):\n","        \"\"\"\n","        Reformer.\n","        Reforms examples with autoencoder. Action of reforming is called heal.\n","\n","        path: Path to the autoencoder used.\n","        \"\"\"\n","        self.model = load_model(path)\n","        self.path = path\n","\n","    def heal(self, X):\n","        X = self.model.predict(X) # autoencoder로 X값 재구성\n","        return np.clip(X, 0.0, 1.0)\n","\n","    def print(self):\n","        return \"SimpleReformer:\" + self.path.split(\"/\")[-1]\n","\n","\n","def JSD(P, Q):\n","    _P = P / norm(P, ord=1)\n","    _Q = Q / norm(Q, ord=1)\n","    _M = 0.5 * (_P + _Q)\n","    return 0.5 * (entropy(_P, _M) + entropy(_Q, _M)) # Xp와 Xr의 분포의 entropy \n","    # KL divergence: Q(one autoencoder)를 기반으로 했을 때의 cross entropy와 P(magnet)를 기반으로 했을 때의 entropy의 차이\n","\n","\n","\n","class DBDetector:\n","    def __init__(self, reconstructor, prober, classifier, option=\"jsd\", T=1):\n","        \"\"\"\n","        Divergence-Based Detector.\n","\n","        reconstructor: One autoencoder.\n","        prober: Another autoencoder.\n","        classifier: Classifier object.\n","        option: Measure of distance, jsd as default.\n","        T: Temperature to soften the classification decision.\n","        \"\"\"\n","        self.prober = prober\n","        self.reconstructor = reconstructor\n","        self.classifier = classifier\n","        self.option = option\n","        self.T = T\n","\n","    def mark(self, X):\n","        return self.mark_jsd(X)\n","\n","    def mark_jsd(self, X):\n","        Xp = self.prober.heal(X) # 1번 autoencoder로 생성한 이미지 \n","        Xr = self.reconstructor.heal(X) #2번 autoencoder로 생성한 이미지 \n","        Pp = self.classifier.classify(Xp, option=\"prob\", T=self.T) # Xp의 확률\n","        Pr = self.classifier.classify(Xr, option=\"prob\", T=self.T) # Xr의 확률\n","\n","        marks = [(JSD(Pp[i], Pr[i])) for i in range(len(Pr))]\n","        return np.array(marks)\n","\n","    def print(self):\n","        return \"Divergence-Based Detector\"\n","\n","\n","class Classifier:\n","    def __init__(self, classifier_path):\n","        \"\"\"\n","        Keras classifier wrapper.\n","        Note that the wrapped classifier should spit logits as output.\n","\n","        classifier_path: Path to Keras classifier file.\n","        \"\"\"\n","        self.path = classifier_path\n","        self.model = load_model(classifier_path)\n","        self.softmax = Sequential()\n","        self.softmax.add(Lambda(lambda X: softmax(X, axis=1)))\n","\n","    def classify(self, X, option=\"logit\", T=1):\n","        if option == \"logit\":\n","            return self.model.predict(X)\n","        if option == \"prob\":\n","            logits = self.model.predict(X)/T\n","            return self.softmax.predict(logits)\n","\n","    def print(self):\n","        return \"Classifier:\"+self.path.split(\"/\")[-1]\n","\n","\n","class Operator:\n","    def __init__(self, data, classifier, det_dict, reformer):\n","        \"\"\"\n","        Operator.\n","        Describes the classification problem and defense.\n","\n","        data: Standard problem dataset. Including train, test, and validation.\n","        classifier: Target classifier.\n","        reformer: Reformer of defense.\n","        det_dict: Detector(s) of defense.\n","        \"\"\"\n","\n","        self.data = data\n","        self.classifier = classifier\n","        self.det_dict = det_dict \n","        self.reformer = reformer\n","        self.normal = self.operate(AttackData(data.x_train, np.argmax(data.y_train, axis=1), \"Normal\"))\n","        \n","\n","    def get_thrs(self, drop_rate):\n","        \"\"\"\n","        Get filtering threshold by marking validation set.\n","        \"\"\"\n","        thrs = dict()\n","        for name, detector in self.det_dict.items():\n","            num = int(len(data.x_test) * drop_rate[name])\n","            marks = detector.mark(data.x_test)\n","            marks = np.sort(marks)\n","            thrs[name] = marks[-num]\n","        return thrs\n","\n","    def operate(self, untrusted_obj):\n","        \"\"\"\n","        For untrusted input(normal or adversarial), classify original input and\n","        reformed input. Classifier is unaware of the source of input.\n","\n","        untrusted_obj: Input data.\n","        \"\"\"\n","\n","        X = untrusted_obj.data\n","        Y_true = untrusted_obj.labels\n","\n","\n","        X_prime = self.reformer.heal(X) # autoencoder 값으로 재구성\n","        Y = np.argmax(self.classifier.classify(X), axis=1) # 원본 input X 분류\n","        Y_judgement = (Y == Y_true[:len(X_prime)]) # 실제 label과 X 분류 label 비교\n","        Y_prime = np.argmax(self.classifier.classify(X_prime), axis=1)  # autoencoder로 재구성한 X' 분류\n","        Y_prime_judgement = (Y_prime == Y_true[:len(X_prime)])  # 실제 label과 X' 분류 label 비교\n","        return np.array(list(zip(Y_judgement, Y_prime_judgement)))\n","\n","    def filter(self, X, thrs):\n","        \"\"\"\n","        untrusted_obj: Untrusted input to test against.\n","        thrs: Thresholds.\n","\n","        return:\n","        all_pass: Index of examples that passed all detectors.\n","        collector: Number of examples that escaped each detector.\n","        \"\"\"\n","        collector = dict()\n","        all_pass = np.array(range(10000)) #Index\n","        for name, detector in self.det_dict.items():\n","            marks = detector.mark(X) #  KL divergnece: Xp와 Xr의 분포의 entropy \n","            idx_pass = np.argwhere(marks < thrs[name]) # KL divergnece가 thershold보다 작을 경우 pass, 클 경우 reject\n","            collector[name] = len(idx_pass) # pass가 된 수\n","            all_pass = np.intersect1d(all_pass, idx_pass) # 전체 index array와 pass된 array의 교집합\n","        return all_pass, collector\n","\n","    def print(self):\n","        components = [self.reformer, self.classifier]\n","        return \" \".join(map(lambda obj: getattr(obj, \"print\")(), components))\n","\n","\n","class AttackData:\n","    def __init__(self, examples, labels, name=\"\"):\n","        \"\"\"\n","        Input data wrapper. May be normal or adversarial.\n","\n","        examples: Path or object of input examples.\n","        labels: Ground truth labels.\n","        \"\"\"\n","        # if isinstance(examples, str): \n","        #   self.data = load_obj(examples)\n","        # else: \n","\n","        self.data = examples\n","        self.labels = labels\n","        self.name = name\n","\n","    def print(self):\n","        return \"Attack:\"+self.name\n","\n","\n","class Evaluator:\n","    def __init__(self, operator, untrusted_data, graph_dir=\"./graph\"):\n","        \"\"\"\n","        Evaluator.\n","        For strategy described by operator, conducts tests on untrusted input.\n","        Mainly stats and plotting code. Most methods omitted for clarity.\n","\n","        operator: Operator object.\n","        untrusted_data: Input data to test against.\n","        graph_dir: Where to spit the graphs.\n","        \"\"\"\n","        self.operator = operator\n","        self.untrusted_data = untrusted_data # attacked data\n","        self.graph_dir = graph_dir\n","        self.data_package = operator.operate(untrusted_data)\n","\n","    def bind_operator(self, operator):\n","        self.operator = operator\n","        self.data_package = operator.operate(self.untrusted_data)\n","\n","    def load_data(self, data):\n","        self.untrusted_data = data\n","        self.data_package = self.operator.operate(self.untrusted_data)\n","\n","    def get_normal_acc(self, normal_all_pass):\n","        \"\"\"\n","        traning data에 대한 정확도\n","\n","        Break down of who does what in defense. Accuracy of defense on normal\n","        input.\n","\n","        both: Both detectors and reformer take effect\n","        det_only: detector(s) take effect\n","        ref_only: Only reformer takes effect\n","        none: Attack effect with no defense\n","        \"\"\"\n","        normal_tups = self.operator.normal\n","        num_normal = len(normal_tups)\n","        filtered_normal_tups = normal_tups[normal_all_pass]\n","\n","        both_acc = sum(1 for _, XpC in filtered_normal_tups if XpC)/num_normal # detector and refomer\n","        det_only_acc = sum(1 for XC, XpC in filtered_normal_tups if XC)/num_normal # only detector\n","        ref_only_acc = sum([1 for _, XpC in normal_tups if XpC])/num_normal # only reformer\n","        none_acc = sum([1 for XC, _ in normal_tups if XC])/num_normal # no defense\n","\n","        return both_acc, det_only_acc, ref_only_acc, none_acc\n","\n","    def get_attack_acc(self, attack_pass):\n","        \"\"\"\n","        attacked data에 대한 정확도 \n","        \"\"\"\n","        attack_tups = self.data_package\n","        num_untrusted = len(attack_tups)\n","        filtered_attack_tups = attack_tups[attack_pass]\n","\n","\n","        both_acc = 1 - sum(1 for _, XpC in filtered_attack_tups if not XpC)/num_untrusted # detector and refomer\n","        det_only_acc = 1 - sum(1 for XC, XpC in filtered_attack_tups if not XC)/num_untrusted # only detector\n","        ref_only_acc = sum([1 for _, XpC in attack_tups if XpC])/num_untrusted # only reformer\n","        none_acc = sum([1 for XC, _ in attack_tups if XC])/num_untrusted # no defense\n","        \n","        return both_acc, det_only_acc, ref_only_acc, none_acc\n","\n","    def plot_various_confidences(self, graph_name, drop_rate,\n","                                 idx_file=\"example_idx\",\n","                                 confs=(0.0, 10.0),\n","                                 get_attack_data_name=lambda c: \"example_carlini_\"+str(c)):\n","        \"\"\"\n","        Test defense performance against Carlini L2 attack of various confidences.\n","\n","        graph_name: Name of graph file.\n","        drop_rate: How many normal examples should each detector drops?\n","        idx_file: Index of adversarial examples in standard test set.\n","        confs: A series of confidence to test against.\n","        get_attack_data_name: Function mapping confidence to corresponding file.\n","        \"\"\"\n","        pylab.rcParams['figure.figsize'] = 6, 4\n","        fig = plt.figure(1, (6, 4))\n","        ax = fig.add_subplot(1, 1, 1)\n","\n","        idx = orig_labels\n","        # idx = original_labels_list\n","        X, _, Y = prepare_data(self.operator.data, idx)\n","\n","\n","        det_only = []\n","        ref_only = []\n","        both = []\n","        none = []\n","\n","        print(\"\\n==========================================================\")\n","        print(\"Drop Rate:\", drop_rate)\n","        thrs = self.operator.get_thrs(drop_rate)\n","\n","        all_pass, _ = self.operator.filter(self.operator.data.x_train, thrs)\n","        all_on_acc, _, _, _ = self.get_normal_acc(all_pass)\n","\n","        print(\"Classification accuracy with all defense on:\", all_on_acc)\n","\n","        for confidence in confs:\n","            # f = get_attack_data_name(confidence)\n","            self.load_data(AttackData(ad_examples1, orig_labels, \"GTSRB FSGM\"))\n","\n","            print(\"----------------------------------------------------------\")\n","            print(\"Confidence:\", confidence)\n","            all_pass, detector_breakdown = self.operator.filter(self.untrusted_data.data, thrs)\n","            both_acc, det_only_acc, ref_only_acc, none_acc = self.get_attack_acc(all_pass)\n","            print(detector_breakdown)\n","            both.append(both_acc)\n","            det_only.append(det_only_acc)\n","            ref_only.append(ref_only_acc)\n","            none.append(none_acc)\n","\n","        size = 2.5\n","\n","        print(\"With detector & reformer: \", both_acc)\n","        print(\"With detector: \",det_only_acc)\n","        print(\"With reformer: \", ref_only_acc)\n","        print(\"No Defense: \",none_acc)\n","\n","        # print(\"With detector & reformer: \", both)\n","        # print(\"With detector: \",det_only)\n","        # print(\"With reformer: \", ref_only)\n","        # print(\"No Defense: \",none)\n","\n","        plt.plot(confs, none, c=\"green\", label=\"No Defense\", marker=\"x\", markersize=size,alpha=0.5)\n","        # plt.plot(confs, det_only, c=\"orange\", label=\"With detector\", marker=\"o\", markersize=size,alpha=0.5)\n","        # plt.plot(confs, ref_only, c=\"blue\", label=\"With reformer\", marker=\"^\", markersize=size,alpha=0.5)\n","        plt.plot(confs, both, c=\"red\", label=\"With detector & reformer\", marker=\"s\", markersize=size,alpha=0.5)\n","\n","        pylab.legend(loc='lower left', bbox_to_anchor=(0.02, 0.1), prop={'size':8})\n","        plt.grid(linestyle='dotted')\n","        plt.xlabel(r\"Confidence in Carlini $L^2$ attack\")\n","        plt.ylabel(\"Classification accuracy\")\n","        plt.xlim(min(confs)-1.0, max(confs)+1.0)\n","        plt.ylim(-0.05, 1.05)\n","        ax.yaxis.set_major_formatter(FuncFormatter('{0:.0%}'.format))\n","\n","        save_path = os.path.join(self.graph_dir, graph_name+\".pdf\")\n","        plt.savefig(save_path)\n","        plt.clf()\n","\n","    def print(self):\n","        return \" \".join([self.operator.print(), self.untrusted_data.print()])"],"metadata":{"id":"ZRv7EXuShHMK","executionInfo":{"status":"ok","timestamp":1663417602557,"user_tz":-540,"elapsed":6,"user":{"displayName":"김채현코랩3","userId":"12600322500441715060"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["#### MagNet - Defensive Model"],"metadata":{"id":"4e-GBUowhNUQ"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import os\n","import numpy as np\n","from keras.layers.core import Lambda\n","from keras.layers.merge import Average, add\n","from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, AveragePooling2D\n","from keras.models import Model\n","import keras.regularizers as regs\n","\n","\n","class DenoisingAutoEncoder:\n","    def __init__(self, image_shape,\n","                 structure,\n","                 v_noise=0.0,\n","                 activation=\"relu\",\n","                 model_dir=\"./defensive_models/\",\n","                 reg_strength=0.0):\n","        \"\"\"\n","        Denoising Autoencoder(DAE)\n","        training data에 nosie를 추가하여 인코더에 넣어서 학습된 결과가 \n","        noise를 붙이기 전 데이터와의 error을 최소화하는 목적을 가진 Autoencoder\n","\n","        image_shape: Shape of input image. e.g. 28, 28, 1.\n","        structure: Structure of autoencoder.\n","        v_noise: Volume of noise while training.\n","        activation: What activation function to use.\n","        model_dir: Where to save / load model from.\n","        reg_strength: Strength of L2 regularization.\n","        \"\"\"\n","        h, w, c = image_shape\n","        self.image_shape = image_shape # shape of input image (32,32,3)\n","        self.model_dir = model_dir \n","        self.v_noise = v_noise\n","\n","        input_img = Input(shape=self.image_shape)\n","        x = input_img\n","\n","        # encoder 정의 \n","        for layer in structure: \n","            if isinstance(layer, int):\n","                x = Conv2D(layer, (3, 3), activation=activation, padding=\"same\",\n","                           activity_regularizer=regs.l2(reg_strength))(x)\n","            elif layer == \"max\":\n","                x = MaxPooling2D((2, 2), padding=\"same\")(x)\n","            elif layer == \"average\":\n","                x = AveragePooling2D((2, 2), padding=\"same\")(x)\n","            else:\n","                print(layer, \"is not recognized!\")\n","                exit(0)\n","        \n","        for layer in reversed(structure):\n","            if isinstance(layer, int):\n","                x = Conv2D(layer, (3, 3), activation=activation, padding=\"same\",\n","                           activity_regularizer=regs.l2(reg_strength))(x)\n","            elif layer == \"max\" or layer == \"average\":\n","                x = UpSampling2D((2, 2))(x)\n","\n","        # decoder 정의 \n","        decoded = Conv2D(c, (3, 3), activation='sigmoid', padding='same',\n","                         activity_regularizer=regs.l2(reg_strength))(x)\n","\n","        self.model = Model(input_img, decoded) # autoencoder 모델\n","\n","    def train(self, data, archive_name, num_epochs=100, batch_size=32):\n","        self.model.compile(loss='mean_squared_error',\n","                           metrics=['mean_squared_error'],\n","                           optimizer='adam')\n","        \n","        noise = self.v_noise * np.random.normal(size=np.shape(data.x_train)) # 랜덤 노이즈 \n","        noisy_train_data = data.x_train + noise # Input Data에 랜덤 노이즈 추가 \n","        noisy_train_data = np.clip(noisy_train_data, 0.0, 1.0) # [0,1] 범위로 재구성\n","\n","        self.model.fit(noisy_train_data, data.x_train,\n","                       batch_size=batch_size,\n","                       validation_data=(data.x_test, data.x_test),\n","                       epochs=num_epochs,\n","                       shuffle=True)\n","\n","        print(os.path.join(self.model_dir, archive_name))        \n","        self.model.save(os.path.join(self.model_dir, archive_name))\n","\n","    def load(self, archive_name, model_dir=None):\n","        if model_dir is None: model_dir = self.model_dir\n","        self.model.load_weights(os.path.join(model_dir, archive_name))\n","\n","\n","class PackedAutoEncoder:\n","    def __init__(self, image_shape, structure, data,\n","                 v_noise=0.1, n_pack=2, pre_epochs=3, activation=\"relu\",\n","                 model_dir=\"./defensive_models/\"):\n","        \"\"\"\n","        Train different autoencoders.\n","        Demo code for graybox scenario.\n","\n","        pre_epochs: How many epochs do we train before fine-tuning.\n","        n_pack: Number of autoencoders we want to train at once.\n","        \"\"\"\n","        self.v_noise = v_noise\n","        self.n_pack = n_pack\n","        self.model_dir = model_dir\n","        pack = []\n","\n","\n","\n","        for i in range(n_pack):\n","            dae = DenoisingAutoEncoder(image_shape, structure, v_noise=v_noise,\n","                                       activation=activation, model_dir=model_dir)\n","            dae.train(data, \"\", num_epochs=pre_epochs)\n","            pack.append(dae.model)\n","\n","\n","        shared_input = Input(shape=image_shape, name=\"shared_input\")\n","        outputs = [dae(shared_input) for dae in pack]\n","        avg_output = Average()(outputs)\n","        delta_outputs = [add([avg_output, Lambda(lambda x: -x)(output)])\n","                         for output in outputs]\n","\n","        self.model = Model(inputs=shared_input, outputs=outputs+delta_outputs)\n","\n","    def train(self, data, archive_name, alpha, num_epochs=10, batch_size=32):\n","        noise = self.v_noise * np.random.normal(size=np.shape(data.x_train))\n","        noisy_train_data = data.x_train + noise\n","        noisy_train_data = np.clip(noisy_train_data, 0.0, 1.0)\n","\n","        train_zeros = [np.zeros_like(data.x_train)] * self.n_pack\n","        val_zeros = [np.zeros_like(data.x_test)] * self.n_pack\n","\n","        self.model.compile(loss=\"mean_squared_error\", optimizer=\"adam\",\n","                           loss_weights=[1.0]*self.n_pack + [-alpha]*self.n_pack)\n","\n","        self.model.fit(noisy_train_data,\n","                       [data.x_train]*self.n_pack + train_zeros,\n","                       batch_size=batch_size,\n","                       validation_data=(data.x_test,\n","                            [data.x_test]*self.n_pack+val_zeros),\n","                       epochs=num_epochs,\n","                       shuffle=True)\n","\n","        for i in range(self.n_pack):\n","            model = Model(self.model.input, self.model.outputs[i])\n","            self.model.save(\"\")\n","            print(os.path.join(self.model_dir, archive_name+\"_\"+str(i)))\n","            self.model.save(os.path.join(self.model_dir, archive_name+\"_\"+str(i)))\n","\n","    def load(self, archive_name, model_dir=None):\n","        if model_dir is None: model_dir = self.model_dir\n","        self.model.load_weights(os.path.join(model_dir, archive_name))"],"metadata":{"id":"HyIrYmBIhPRc","executionInfo":{"status":"ok","timestamp":1663417604673,"user_tz":-540,"elapsed":2120,"user":{"displayName":"김채현코랩3","userId":"12600322500441715060"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["### MagNet - Train Defensive Model"],"metadata":{"id":"ukxjkHWahV8B"}},{"cell_type":"code","source":["data.x_train, data.y_train, data.x_test, data.y_test =data.x_train/255, data.y_train/255, data.x_test/255, data.y_test/255"],"metadata":{"id":"Y-CppiQYhYQp","executionInfo":{"status":"ok","timestamp":1663417604674,"user_tz":-540,"elapsed":5,"user":{"displayName":"김채현코랩3","userId":"12600322500441715060"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["DAE = DenoisingAutoEncoder\n","PAE = PackedAutoEncoder\n","\n","shape = [32, 32, 3]\n","combination_I = [3, \"average\", 3]\n","combination_II = [3]\n","activation = \"sigmoid\"\n","reg_strength = 1e-9\n","epochs = 350\n","\n","# data = GTSRB()\n","\n","# AE_II = PAE(shape, combination_II, data, v_noise=0.025, activation=activation, n_pack=8)\n","# AE_II.train(data, \"_8_PAE_GTSRB_II\", alpha=.2, num_epochs=epochs)\n","\n","# AE_II = PAE(shape, combination_II, data, v_noise=0.025, activation=activation)\n","# AE_II.train(data, \"_PAE_GTSRB_II\", alpha=.2, num_epochs=epochs)    \n","\n","# AE_II = PAE(shape, combination_II, data, v_noise=0.025, activation=activation, n_pack=32)\n","# AE_II.train(data, \"O32_PAE_GTSRB_II\", alpha=.2, num_epochs=epochs)  \n","\n","AE_I = DAE(shape, combination_I, v_noise=0.1, activation=activation, reg_strength=reg_strength)\n","AE_I.train(data, \"350_0903_DAE_GTSRB_I\", num_epochs=epochs)\n","\n","AE_II = DAE(shape, combination_II, v_noise=0.1, activation=activation,  reg_strength=reg_strength)\n","AE_II.train(data, \"350_0903_DAE_GTSRB_II\", num_epochs=epochs)"],"metadata":{"id":"C5S8s9wxhanJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663418629563,"user_tz":-540,"elapsed":1024892,"user":{"displayName":"김채현코랩3","userId":"12600322500441715060"}},"outputId":"b701288b-d373-4318-e455-d90f4b924e85"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0628 - mean_squared_error: 0.0628 - val_loss: 0.0065 - val_mean_squared_error: 0.0065\n","Epoch 2/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n","Epoch 3/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n","Epoch 4/350\n","225/225 [==============================] - 2s 7ms/step - loss: 8.8416e-04 - mean_squared_error: 8.7909e-04 - val_loss: 7.0493e-04 - val_mean_squared_error: 6.9998e-04\n","Epoch 5/350\n","225/225 [==============================] - 1s 6ms/step - loss: 5.8756e-04 - mean_squared_error: 5.8239e-04 - val_loss: 4.9092e-04 - val_mean_squared_error: 4.8590e-04\n","Epoch 6/350\n","225/225 [==============================] - 2s 7ms/step - loss: 4.2173e-04 - mean_squared_error: 4.1649e-04 - val_loss: 3.6289e-04 - val_mean_squared_error: 3.5782e-04\n","Epoch 7/350\n","225/225 [==============================] - 2s 7ms/step - loss: 3.1826e-04 - mean_squared_error: 3.1298e-04 - val_loss: 2.7943e-04 - val_mean_squared_error: 2.7432e-04\n","Epoch 8/350\n","225/225 [==============================] - 1s 6ms/step - loss: 2.4882e-04 - mean_squared_error: 2.4350e-04 - val_loss: 2.2170e-04 - val_mean_squared_error: 2.1656e-04\n","Epoch 9/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.9970e-04 - mean_squared_error: 1.9435e-04 - val_loss: 1.7993e-04 - val_mean_squared_error: 1.7477e-04\n","Epoch 10/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.6358e-04 - mean_squared_error: 1.5820e-04 - val_loss: 1.4868e-04 - val_mean_squared_error: 1.4350e-04\n","Epoch 11/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3618e-04 - mean_squared_error: 1.3079e-04 - val_loss: 1.2464e-04 - val_mean_squared_error: 1.1944e-04\n","Epoch 12/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1489e-04 - mean_squared_error: 1.0948e-04 - val_loss: 1.0577e-04 - val_mean_squared_error: 1.0055e-04\n","Epoch 13/350\n","225/225 [==============================] - 1s 6ms/step - loss: 9.8013e-05 - mean_squared_error: 9.2596e-05 - val_loss: 9.0666e-05 - val_mean_squared_error: 8.5441e-05\n","Epoch 14/350\n","225/225 [==============================] - 1s 6ms/step - loss: 8.4414e-05 - mean_squared_error: 7.8991e-05 - val_loss: 7.8409e-05 - val_mean_squared_error: 7.3176e-05\n","Epoch 15/350\n","225/225 [==============================] - 1s 6ms/step - loss: 7.3304e-05 - mean_squared_error: 6.7879e-05 - val_loss: 6.8333e-05 - val_mean_squared_error: 6.3094e-05\n","Epoch 16/350\n","225/225 [==============================] - 1s 6ms/step - loss: 6.4121e-05 - mean_squared_error: 5.8697e-05 - val_loss: 5.9957e-05 - val_mean_squared_error: 5.4716e-05\n","Epoch 17/350\n","225/225 [==============================] - 1s 5ms/step - loss: 5.6455e-05 - mean_squared_error: 5.1034e-05 - val_loss: 5.2938e-05 - val_mean_squared_error: 4.7696e-05\n","Epoch 18/350\n","225/225 [==============================] - 2s 7ms/step - loss: 5.0001e-05 - mean_squared_error: 4.4586e-05 - val_loss: 4.7007e-05 - val_mean_squared_error: 4.1767e-05\n","Epoch 19/350\n","225/225 [==============================] - 1s 6ms/step - loss: 4.4525e-05 - mean_squared_error: 3.9121e-05 - val_loss: 4.1957e-05 - val_mean_squared_error: 3.6720e-05\n","Epoch 20/350\n","225/225 [==============================] - 2s 7ms/step - loss: 3.9850e-05 - mean_squared_error: 3.4458e-05 - val_loss: 3.7635e-05 - val_mean_squared_error: 3.2405e-05\n","Epoch 21/350\n","225/225 [==============================] - 1s 6ms/step - loss: 3.5836e-05 - mean_squared_error: 3.0460e-05 - val_loss: 3.3916e-05 - val_mean_squared_error: 2.8693e-05\n","Epoch 22/350\n","225/225 [==============================] - 1s 6ms/step - loss: 3.2372e-05 - mean_squared_error: 2.7015e-05 - val_loss: 3.0701e-05 - val_mean_squared_error: 2.5490e-05\n","Epoch 23/350\n","225/225 [==============================] - 2s 7ms/step - loss: 2.9369e-05 - mean_squared_error: 2.4035e-05 - val_loss: 2.7909e-05 - val_mean_squared_error: 2.2711e-05\n","Epoch 24/350\n","225/225 [==============================] - 1s 6ms/step - loss: 2.6755e-05 - mean_squared_error: 2.1446e-05 - val_loss: 2.5477e-05 - val_mean_squared_error: 2.0295e-05\n","Epoch 25/350\n","225/225 [==============================] - 1s 6ms/step - loss: 2.4472e-05 - mean_squared_error: 1.9192e-05 - val_loss: 2.3352e-05 - val_mean_squared_error: 1.8188e-05\n","Epoch 26/350\n","225/225 [==============================] - 2s 7ms/step - loss: 2.2471e-05 - mean_squared_error: 1.7222e-05 - val_loss: 2.1487e-05 - val_mean_squared_error: 1.6344e-05\n","Epoch 27/350\n","225/225 [==============================] - 2s 7ms/step - loss: 2.0712e-05 - mean_squared_error: 1.5498e-05 - val_loss: 1.9847e-05 - val_mean_squared_error: 1.4728e-05\n","Epoch 28/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.9161e-05 - mean_squared_error: 1.3985e-05 - val_loss: 1.8402e-05 - val_mean_squared_error: 1.3309e-05\n","Epoch 29/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.7791e-05 - mean_squared_error: 1.2655e-05 - val_loss: 1.7124e-05 - val_mean_squared_error: 1.2060e-05\n","Epoch 30/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.6577e-05 - mean_squared_error: 1.1485e-05 - val_loss: 1.5994e-05 - val_mean_squared_error: 1.0961e-05\n","Epoch 31/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.5500e-05 - mean_squared_error: 1.0454e-05 - val_loss: 1.4991e-05 - val_mean_squared_error: 9.9911e-06\n","Epoch 32/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.4542e-05 - mean_squared_error: 9.5433e-06 - val_loss: 1.4098e-05 - val_mean_squared_error: 9.1346e-06\n","Epoch 33/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.3688e-05 - mean_squared_error: 8.7392e-06 - val_loss: 1.3304e-05 - val_mean_squared_error: 8.3779e-06\n","Epoch 34/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2926e-05 - mean_squared_error: 8.0283e-06 - val_loss: 1.2595e-05 - val_mean_squared_error: 7.7087e-06\n","Epoch 35/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2246e-05 - mean_squared_error: 7.3997e-06 - val_loss: 1.1961e-05 - val_mean_squared_error: 7.1171e-06\n","Epoch 36/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1636e-05 - mean_squared_error: 6.8434e-06 - val_loss: 1.1394e-05 - val_mean_squared_error: 6.5929e-06\n","Epoch 37/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1090e-05 - mean_squared_error: 6.3509e-06 - val_loss: 1.0885e-05 - val_mean_squared_error: 6.1289e-06\n","Epoch 38/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.0600e-05 - mean_squared_error: 5.9147e-06 - val_loss: 1.0428e-05 - val_mean_squared_error: 5.7179e-06\n","Epoch 39/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.0159e-05 - mean_squared_error: 5.5283e-06 - val_loss: 1.0017e-05 - val_mean_squared_error: 5.3539e-06\n","Epoch 40/350\n","225/225 [==============================] - 1s 5ms/step - loss: 9.7630e-06 - mean_squared_error: 5.1861e-06 - val_loss: 9.6467e-06 - val_mean_squared_error: 5.0316e-06\n","Epoch 41/350\n","225/225 [==============================] - 1s 6ms/step - loss: 9.4062e-06 - mean_squared_error: 4.8829e-06 - val_loss: 9.3125e-06 - val_mean_squared_error: 4.7460e-06\n","Epoch 42/350\n","225/225 [==============================] - 2s 7ms/step - loss: 9.0847e-06 - mean_squared_error: 4.6143e-06 - val_loss: 9.0106e-06 - val_mean_squared_error: 4.4932e-06\n","Epoch 43/350\n","225/225 [==============================] - 1s 6ms/step - loss: 8.7947e-06 - mean_squared_error: 4.3765e-06 - val_loss: 8.7373e-06 - val_mean_squared_error: 4.2693e-06\n","Epoch 44/350\n","225/225 [==============================] - 1s 6ms/step - loss: 8.5329e-06 - mean_squared_error: 4.1660e-06 - val_loss: 8.4899e-06 - val_mean_squared_error: 4.0715e-06\n","Epoch 45/350\n","225/225 [==============================] - 1s 6ms/step - loss: 8.2961e-06 - mean_squared_error: 3.9797e-06 - val_loss: 8.2652e-06 - val_mean_squared_error: 3.8964e-06\n","Epoch 46/350\n","225/225 [==============================] - 2s 7ms/step - loss: 8.0818e-06 - mean_squared_error: 3.8149e-06 - val_loss: 8.0604e-06 - val_mean_squared_error: 3.7415e-06\n","Epoch 47/350\n","225/225 [==============================] - 1s 6ms/step - loss: 7.8874e-06 - mean_squared_error: 3.6693e-06 - val_loss: 7.8736e-06 - val_mean_squared_error: 3.6048e-06\n","Epoch 48/350\n","225/225 [==============================] - 1s 6ms/step - loss: 7.7107e-06 - mean_squared_error: 3.5407e-06 - val_loss: 7.7030e-06 - val_mean_squared_error: 3.4844e-06\n","Epoch 49/350\n","225/225 [==============================] - 1s 6ms/step - loss: 7.5495e-06 - mean_squared_error: 3.4272e-06 - val_loss: 7.5462e-06 - val_mean_squared_error: 3.3783e-06\n","Epoch 50/350\n","225/225 [==============================] - 1s 6ms/step - loss: 7.4021e-06 - mean_squared_error: 3.3271e-06 - val_loss: 7.4017e-06 - val_mean_squared_error: 3.2849e-06\n","Epoch 51/350\n","225/225 [==============================] - 1s 6ms/step - loss: 7.2667e-06 - mean_squared_error: 3.2390e-06 - val_loss: 7.2680e-06 - val_mean_squared_error: 3.2026e-06\n","Epoch 52/350\n","225/225 [==============================] - 2s 7ms/step - loss: 7.1421e-06 - mean_squared_error: 3.1616e-06 - val_loss: 7.1441e-06 - val_mean_squared_error: 3.1305e-06\n","Epoch 53/350\n","225/225 [==============================] - 2s 7ms/step - loss: 7.0270e-06 - mean_squared_error: 3.0935e-06 - val_loss: 7.0291e-06 - val_mean_squared_error: 3.0670e-06\n","Epoch 54/350\n","225/225 [==============================] - 1s 6ms/step - loss: 6.9207e-06 - mean_squared_error: 3.0337e-06 - val_loss: 6.9226e-06 - val_mean_squared_error: 3.0113e-06\n","Epoch 55/350\n","225/225 [==============================] - 1s 6ms/step - loss: 6.8226e-06 - mean_squared_error: 2.9811e-06 - val_loss: 6.8243e-06 - val_mean_squared_error: 2.9626e-06\n","Epoch 56/350\n","225/225 [==============================] - 1s 6ms/step - loss: 6.7323e-06 - mean_squared_error: 2.9350e-06 - val_loss: 6.7337e-06 - val_mean_squared_error: 2.9197e-06\n","Epoch 57/350\n","225/225 [==============================] - 2s 7ms/step - loss: 6.6492e-06 - mean_squared_error: 2.8945e-06 - val_loss: 6.6505e-06 - val_mean_squared_error: 2.8822e-06\n","Epoch 58/350\n","225/225 [==============================] - 1s 6ms/step - loss: 6.5729e-06 - mean_squared_error: 2.8589e-06 - val_loss: 6.5739e-06 - val_mean_squared_error: 2.8491e-06\n","Epoch 59/350\n","225/225 [==============================] - 1s 6ms/step - loss: 6.5027e-06 - mean_squared_error: 2.8277e-06 - val_loss: 6.5032e-06 - val_mean_squared_error: 2.8202e-06\n","Epoch 60/350\n","225/225 [==============================] - 1s 6ms/step - loss: 6.4376e-06 - mean_squared_error: 2.8004e-06 - val_loss: 6.4376e-06 - val_mean_squared_error: 2.7949e-06\n","Epoch 61/350\n","225/225 [==============================] - 1s 6ms/step - loss: 6.3770e-06 - mean_squared_error: 2.7767e-06 - val_loss: 6.3762e-06 - val_mean_squared_error: 2.7730e-06\n","Epoch 62/350\n","225/225 [==============================] - 2s 7ms/step - loss: 6.3198e-06 - mean_squared_error: 2.7560e-06 - val_loss: 6.3183e-06 - val_mean_squared_error: 2.7538e-06\n","Epoch 63/350\n","225/225 [==============================] - 2s 7ms/step - loss: 6.2656e-06 - mean_squared_error: 2.7381e-06 - val_loss: 6.2631e-06 - val_mean_squared_error: 2.7373e-06\n","Epoch 64/350\n","225/225 [==============================] - 1s 6ms/step - loss: 6.2135e-06 - mean_squared_error: 2.7227e-06 - val_loss: 6.2100e-06 - val_mean_squared_error: 2.7232e-06\n","Epoch 65/350\n","225/225 [==============================] - 2s 7ms/step - loss: 6.1629e-06 - mean_squared_error: 2.7096e-06 - val_loss: 6.1583e-06 - val_mean_squared_error: 2.7111e-06\n","Epoch 66/350\n","225/225 [==============================] - 1s 6ms/step - loss: 6.1130e-06 - mean_squared_error: 2.6984e-06 - val_loss: 6.1074e-06 - val_mean_squared_error: 2.7009e-06\n","Epoch 67/350\n","225/225 [==============================] - 1s 6ms/step - loss: 6.0630e-06 - mean_squared_error: 2.6891e-06 - val_loss: 6.0561e-06 - val_mean_squared_error: 2.6925e-06\n","Epoch 68/350\n","225/225 [==============================] - 2s 7ms/step - loss: 6.0117e-06 - mean_squared_error: 2.6817e-06 - val_loss: 6.0029e-06 - val_mean_squared_error: 2.6858e-06\n","Epoch 69/350\n","225/225 [==============================] - 1s 6ms/step - loss: 5.9571e-06 - mean_squared_error: 2.6761e-06 - val_loss: 5.9456e-06 - val_mean_squared_error: 2.6809e-06\n","Epoch 70/350\n","225/225 [==============================] - 1s 6ms/step - loss: 5.8959e-06 - mean_squared_error: 2.6721e-06 - val_loss: 5.8798e-06 - val_mean_squared_error: 2.6780e-06\n","Epoch 71/350\n","225/225 [==============================] - 1s 6ms/step - loss: 5.8219e-06 - mean_squared_error: 2.6704e-06 - val_loss: 5.7969e-06 - val_mean_squared_error: 2.6776e-06\n","Epoch 72/350\n","225/225 [==============================] - 1s 6ms/step - loss: 5.7220e-06 - mean_squared_error: 2.6717e-06 - val_loss: 5.6790e-06 - val_mean_squared_error: 2.6804e-06\n","Epoch 73/350\n","225/225 [==============================] - 1s 6ms/step - loss: 5.5671e-06 - mean_squared_error: 2.6760e-06 - val_loss: 5.4843e-06 - val_mean_squared_error: 2.6872e-06\n","Epoch 74/350\n","225/225 [==============================] - 1s 6ms/step - loss: 5.2922e-06 - mean_squared_error: 2.6803e-06 - val_loss: 5.1249e-06 - val_mean_squared_error: 2.6858e-06\n","Epoch 75/350\n","225/225 [==============================] - 2s 7ms/step - loss: 4.8038e-06 - mean_squared_error: 2.6414e-06 - val_loss: 4.5247e-06 - val_mean_squared_error: 2.5752e-06\n","Epoch 76/350\n","225/225 [==============================] - 1s 6ms/step - loss: 4.1678e-06 - mean_squared_error: 2.4229e-06 - val_loss: 3.9055e-06 - val_mean_squared_error: 2.2705e-06\n","Epoch 77/350\n","225/225 [==============================] - 1s 6ms/step - loss: 3.6499e-06 - mean_squared_error: 2.1178e-06 - val_loss: 3.4708e-06 - val_mean_squared_error: 1.9995e-06\n","Epoch 78/350\n","225/225 [==============================] - 2s 7ms/step - loss: 3.2893e-06 - mean_squared_error: 1.8790e-06 - val_loss: 3.1590e-06 - val_mean_squared_error: 1.7771e-06\n","Epoch 79/350\n","225/225 [==============================] - 2s 7ms/step - loss: 3.0198e-06 - mean_squared_error: 1.6916e-06 - val_loss: 2.9233e-06 - val_mean_squared_error: 1.6200e-06\n","Epoch 80/350\n","225/225 [==============================] - 2s 9ms/step - loss: 2.8192e-06 - mean_squared_error: 1.5569e-06 - val_loss: 2.7546e-06 - val_mean_squared_error: 1.5177e-06\n","Epoch 81/350\n","225/225 [==============================] - 1s 6ms/step - loss: 2.6782e-06 - mean_squared_error: 1.4729e-06 - val_loss: 2.6368e-06 - val_mean_squared_error: 1.4454e-06\n","Epoch 82/350\n","225/225 [==============================] - 2s 7ms/step - loss: 2.5789e-06 - mean_squared_error: 1.4230e-06 - val_loss: 2.5514e-06 - val_mean_squared_error: 1.4135e-06\n","Epoch 83/350\n","225/225 [==============================] - 2s 7ms/step - loss: 2.5032e-06 - mean_squared_error: 1.3968e-06 - val_loss: 2.4827e-06 - val_mean_squared_error: 1.3955e-06\n","Epoch 84/350\n","225/225 [==============================] - 1s 6ms/step - loss: 2.4399e-06 - mean_squared_error: 1.3822e-06 - val_loss: 2.4250e-06 - val_mean_squared_error: 1.3707e-06\n","Epoch 85/350\n","225/225 [==============================] - 2s 7ms/step - loss: 2.3826e-06 - mean_squared_error: 1.3692e-06 - val_loss: 2.3674e-06 - val_mean_squared_error: 1.3731e-06\n","Epoch 86/350\n","225/225 [==============================] - 1s 6ms/step - loss: 2.3296e-06 - mean_squared_error: 1.3624e-06 - val_loss: 2.3164e-06 - val_mean_squared_error: 1.3588e-06\n","Epoch 87/350\n","225/225 [==============================] - 2s 7ms/step - loss: 2.2806e-06 - mean_squared_error: 1.3548e-06 - val_loss: 2.2682e-06 - val_mean_squared_error: 1.3568e-06\n","Epoch 88/350\n","225/225 [==============================] - 2s 7ms/step - loss: 2.2342e-06 - mean_squared_error: 1.3493e-06 - val_loss: 2.2240e-06 - val_mean_squared_error: 1.3562e-06\n","Epoch 89/350\n","225/225 [==============================] - 2s 7ms/step - loss: 2.1911e-06 - mean_squared_error: 1.3452e-06 - val_loss: 2.1805e-06 - val_mean_squared_error: 1.3468e-06\n","Epoch 90/350\n","225/225 [==============================] - 2s 7ms/step - loss: 2.1506e-06 - mean_squared_error: 1.3415e-06 - val_loss: 2.1405e-06 - val_mean_squared_error: 1.3403e-06\n","Epoch 91/350\n","225/225 [==============================] - 1s 6ms/step - loss: 2.1113e-06 - mean_squared_error: 1.3367e-06 - val_loss: 2.1024e-06 - val_mean_squared_error: 1.3366e-06\n","Epoch 92/350\n","225/225 [==============================] - 2s 7ms/step - loss: 2.0743e-06 - mean_squared_error: 1.3325e-06 - val_loss: 2.0664e-06 - val_mean_squared_error: 1.3324e-06\n","Epoch 93/350\n","225/225 [==============================] - 1s 6ms/step - loss: 2.0397e-06 - mean_squared_error: 1.3291e-06 - val_loss: 2.0320e-06 - val_mean_squared_error: 1.3291e-06\n","Epoch 94/350\n","225/225 [==============================] - 2s 7ms/step - loss: 2.0064e-06 - mean_squared_error: 1.3255e-06 - val_loss: 2.0002e-06 - val_mean_squared_error: 1.3239e-06\n","Epoch 95/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.9746e-06 - mean_squared_error: 1.3218e-06 - val_loss: 1.9686e-06 - val_mean_squared_error: 1.3212e-06\n","Epoch 96/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.9449e-06 - mean_squared_error: 1.3191e-06 - val_loss: 1.9392e-06 - val_mean_squared_error: 1.3173e-06\n","Epoch 97/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.9161e-06 - mean_squared_error: 1.3152e-06 - val_loss: 1.9117e-06 - val_mean_squared_error: 1.3138e-06\n","Epoch 98/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.8883e-06 - mean_squared_error: 1.3114e-06 - val_loss: 1.8836e-06 - val_mean_squared_error: 1.3142e-06\n","Epoch 99/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.8628e-06 - mean_squared_error: 1.3090e-06 - val_loss: 1.8622e-06 - val_mean_squared_error: 1.3074e-06\n","Epoch 100/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.8380e-06 - mean_squared_error: 1.3055e-06 - val_loss: 1.8369e-06 - val_mean_squared_error: 1.3041e-06\n","Epoch 101/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.8142e-06 - mean_squared_error: 1.3021e-06 - val_loss: 1.8106e-06 - val_mean_squared_error: 1.3008e-06\n","Epoch 102/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.7926e-06 - mean_squared_error: 1.3002e-06 - val_loss: 1.7896e-06 - val_mean_squared_error: 1.2972e-06\n","Epoch 103/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.7698e-06 - mean_squared_error: 1.2953e-06 - val_loss: 1.7687e-06 - val_mean_squared_error: 1.2940e-06\n","Epoch 104/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.7492e-06 - mean_squared_error: 1.2918e-06 - val_loss: 1.7479e-06 - val_mean_squared_error: 1.2906e-06\n","Epoch 105/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.7290e-06 - mean_squared_error: 1.2884e-06 - val_loss: 1.7266e-06 - val_mean_squared_error: 1.2873e-06\n","Epoch 106/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.7105e-06 - mean_squared_error: 1.2858e-06 - val_loss: 1.7086e-06 - val_mean_squared_error: 1.2837e-06\n","Epoch 107/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.6920e-06 - mean_squared_error: 1.2819e-06 - val_loss: 1.6992e-06 - val_mean_squared_error: 1.2843e-06\n","Epoch 108/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.6753e-06 - mean_squared_error: 1.2785e-06 - val_loss: 1.6752e-06 - val_mean_squared_error: 1.2773e-06\n","Epoch 109/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.6581e-06 - mean_squared_error: 1.2749e-06 - val_loss: 1.6602e-06 - val_mean_squared_error: 1.2745e-06\n","Epoch 110/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.6418e-06 - mean_squared_error: 1.2711e-06 - val_loss: 1.6460e-06 - val_mean_squared_error: 1.2719e-06\n","Epoch 111/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.6271e-06 - mean_squared_error: 1.2681e-06 - val_loss: 1.6301e-06 - val_mean_squared_error: 1.2681e-06\n","Epoch 112/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.6125e-06 - mean_squared_error: 1.2648e-06 - val_loss: 1.6143e-06 - val_mean_squared_error: 1.2640e-06\n","Epoch 113/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.5983e-06 - mean_squared_error: 1.2613e-06 - val_loss: 1.6007e-06 - val_mean_squared_error: 1.2607e-06\n","Epoch 114/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.5846e-06 - mean_squared_error: 1.2574e-06 - val_loss: 1.5871e-06 - val_mean_squared_error: 1.2572e-06\n","Epoch 115/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.5708e-06 - mean_squared_error: 1.2534e-06 - val_loss: 1.5827e-06 - val_mean_squared_error: 1.2594e-06\n","Epoch 116/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.5592e-06 - mean_squared_error: 1.2509e-06 - val_loss: 1.5612e-06 - val_mean_squared_error: 1.2502e-06\n","Epoch 117/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.5468e-06 - mean_squared_error: 1.2474e-06 - val_loss: 1.5513e-06 - val_mean_squared_error: 1.2480e-06\n","Epoch 118/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.5351e-06 - mean_squared_error: 1.2440e-06 - val_loss: 1.5424e-06 - val_mean_squared_error: 1.2465e-06\n","Epoch 119/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.5241e-06 - mean_squared_error: 1.2409e-06 - val_loss: 1.5323e-06 - val_mean_squared_error: 1.2440e-06\n","Epoch 120/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.5135e-06 - mean_squared_error: 1.2376e-06 - val_loss: 1.5161e-06 - val_mean_squared_error: 1.2373e-06\n","Epoch 121/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.5026e-06 - mean_squared_error: 1.2339e-06 - val_loss: 1.5056e-06 - val_mean_squared_error: 1.2342e-06\n","Epoch 122/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.4940e-06 - mean_squared_error: 1.2323e-06 - val_loss: 1.4974e-06 - val_mean_squared_error: 1.2320e-06\n","Epoch 123/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.4840e-06 - mean_squared_error: 1.2287e-06 - val_loss: 1.4865e-06 - val_mean_squared_error: 1.2284e-06\n","Epoch 124/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.4747e-06 - mean_squared_error: 1.2256e-06 - val_loss: 1.4781e-06 - val_mean_squared_error: 1.2260e-06\n","Epoch 125/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.4658e-06 - mean_squared_error: 1.2229e-06 - val_loss: 1.4738e-06 - val_mean_squared_error: 1.2260e-06\n","Epoch 126/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.4584e-06 - mean_squared_error: 1.2210e-06 - val_loss: 1.4625e-06 - val_mean_squared_error: 1.2217e-06\n","Epoch 127/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.4505e-06 - mean_squared_error: 1.2185e-06 - val_loss: 1.4573e-06 - val_mean_squared_error: 1.2210e-06\n","Epoch 128/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.4428e-06 - mean_squared_error: 1.2160e-06 - val_loss: 1.4514e-06 - val_mean_squared_error: 1.2198e-06\n","Epoch 129/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.4366e-06 - mean_squared_error: 1.2148e-06 - val_loss: 1.4426e-06 - val_mean_squared_error: 1.2167e-06\n","Epoch 130/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.4304e-06 - mean_squared_error: 1.2132e-06 - val_loss: 1.4337e-06 - val_mean_squared_error: 1.2137e-06\n","Epoch 131/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.4234e-06 - mean_squared_error: 1.2109e-06 - val_loss: 1.4269e-06 - val_mean_squared_error: 1.2123e-06\n","Epoch 132/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.4178e-06 - mean_squared_error: 1.2095e-06 - val_loss: 1.4230e-06 - val_mean_squared_error: 1.2113e-06\n","Epoch 133/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.4122e-06 - mean_squared_error: 1.2079e-06 - val_loss: 1.4162e-06 - val_mean_squared_error: 1.2099e-06\n","Epoch 134/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.4071e-06 - mean_squared_error: 1.2071e-06 - val_loss: 1.4169e-06 - val_mean_squared_error: 1.2116e-06\n","Epoch 135/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.4024e-06 - mean_squared_error: 1.2060e-06 - val_loss: 1.4092e-06 - val_mean_squared_error: 1.2086e-06\n","Epoch 136/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3971e-06 - mean_squared_error: 1.2042e-06 - val_loss: 1.4021e-06 - val_mean_squared_error: 1.2067e-06\n","Epoch 137/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3927e-06 - mean_squared_error: 1.2036e-06 - val_loss: 1.3981e-06 - val_mean_squared_error: 1.2058e-06\n","Epoch 138/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.3882e-06 - mean_squared_error: 1.2023e-06 - val_loss: 1.3942e-06 - val_mean_squared_error: 1.2051e-06\n","Epoch 139/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3852e-06 - mean_squared_error: 1.2027e-06 - val_loss: 1.3897e-06 - val_mean_squared_error: 1.2043e-06\n","Epoch 140/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.3808e-06 - mean_squared_error: 1.2014e-06 - val_loss: 1.3857e-06 - val_mean_squared_error: 1.2036e-06\n","Epoch 141/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.3765e-06 - mean_squared_error: 1.2002e-06 - val_loss: 1.3824e-06 - val_mean_squared_error: 1.2028e-06\n","Epoch 142/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.3728e-06 - mean_squared_error: 1.1993e-06 - val_loss: 1.3782e-06 - val_mean_squared_error: 1.2024e-06\n","Epoch 143/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.3694e-06 - mean_squared_error: 1.1990e-06 - val_loss: 1.3748e-06 - val_mean_squared_error: 1.2015e-06\n","Epoch 144/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.3655e-06 - mean_squared_error: 1.1976e-06 - val_loss: 1.3715e-06 - val_mean_squared_error: 1.2017e-06\n","Epoch 145/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3625e-06 - mean_squared_error: 1.1976e-06 - val_loss: 1.3705e-06 - val_mean_squared_error: 1.2010e-06\n","Epoch 146/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.3591e-06 - mean_squared_error: 1.1965e-06 - val_loss: 1.3650e-06 - val_mean_squared_error: 1.2003e-06\n","Epoch 147/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.3556e-06 - mean_squared_error: 1.1955e-06 - val_loss: 1.3624e-06 - val_mean_squared_error: 1.2006e-06\n","Epoch 148/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3535e-06 - mean_squared_error: 1.1960e-06 - val_loss: 1.3590e-06 - val_mean_squared_error: 1.1982e-06\n","Epoch 149/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.3495e-06 - mean_squared_error: 1.1944e-06 - val_loss: 1.3600e-06 - val_mean_squared_error: 1.1998e-06\n","Epoch 150/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3472e-06 - mean_squared_error: 1.1942e-06 - val_loss: 1.3556e-06 - val_mean_squared_error: 1.1981e-06\n","Epoch 151/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3440e-06 - mean_squared_error: 1.1931e-06 - val_loss: 1.3511e-06 - val_mean_squared_error: 1.1966e-06\n","Epoch 152/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.3412e-06 - mean_squared_error: 1.1926e-06 - val_loss: 1.3475e-06 - val_mean_squared_error: 1.1959e-06\n","Epoch 153/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3386e-06 - mean_squared_error: 1.1922e-06 - val_loss: 1.3457e-06 - val_mean_squared_error: 1.1955e-06\n","Epoch 154/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3363e-06 - mean_squared_error: 1.1919e-06 - val_loss: 1.3422e-06 - val_mean_squared_error: 1.1947e-06\n","Epoch 155/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.3334e-06 - mean_squared_error: 1.1910e-06 - val_loss: 1.3396e-06 - val_mean_squared_error: 1.1942e-06\n","Epoch 156/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.3309e-06 - mean_squared_error: 1.1906e-06 - val_loss: 1.3375e-06 - val_mean_squared_error: 1.1935e-06\n","Epoch 157/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3288e-06 - mean_squared_error: 1.1903e-06 - val_loss: 1.3355e-06 - val_mean_squared_error: 1.1932e-06\n","Epoch 158/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3265e-06 - mean_squared_error: 1.1898e-06 - val_loss: 1.3334e-06 - val_mean_squared_error: 1.1928e-06\n","Epoch 159/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3238e-06 - mean_squared_error: 1.1889e-06 - val_loss: 1.3311e-06 - val_mean_squared_error: 1.1923e-06\n","Epoch 160/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.3217e-06 - mean_squared_error: 1.1885e-06 - val_loss: 1.3275e-06 - val_mean_squared_error: 1.1914e-06\n","Epoch 161/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.3189e-06 - mean_squared_error: 1.1877e-06 - val_loss: 1.3253e-06 - val_mean_squared_error: 1.1908e-06\n","Epoch 162/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.3165e-06 - mean_squared_error: 1.1870e-06 - val_loss: 1.3255e-06 - val_mean_squared_error: 1.1914e-06\n","Epoch 163/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.3143e-06 - mean_squared_error: 1.1861e-06 - val_loss: 1.3219e-06 - val_mean_squared_error: 1.1920e-06\n","Epoch 164/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.3129e-06 - mean_squared_error: 1.1866e-06 - val_loss: 1.3187e-06 - val_mean_squared_error: 1.1896e-06\n","Epoch 165/350\n","225/225 [==============================] - 2s 8ms/step - loss: 1.3105e-06 - mean_squared_error: 1.1858e-06 - val_loss: 1.3169e-06 - val_mean_squared_error: 1.1887e-06\n","Epoch 166/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3080e-06 - mean_squared_error: 1.1847e-06 - val_loss: 1.3167e-06 - val_mean_squared_error: 1.1918e-06\n","Epoch 167/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3062e-06 - mean_squared_error: 1.1845e-06 - val_loss: 1.3125e-06 - val_mean_squared_error: 1.1879e-06\n","Epoch 168/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3040e-06 - mean_squared_error: 1.1838e-06 - val_loss: 1.3105e-06 - val_mean_squared_error: 1.1873e-06\n","Epoch 169/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.3023e-06 - mean_squared_error: 1.1834e-06 - val_loss: 1.3086e-06 - val_mean_squared_error: 1.1868e-06\n","Epoch 170/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3006e-06 - mean_squared_error: 1.1832e-06 - val_loss: 1.3071e-06 - val_mean_squared_error: 1.1862e-06\n","Epoch 171/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2984e-06 - mean_squared_error: 1.1823e-06 - val_loss: 1.3051e-06 - val_mean_squared_error: 1.1857e-06\n","Epoch 172/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2967e-06 - mean_squared_error: 1.1820e-06 - val_loss: 1.3032e-06 - val_mean_squared_error: 1.1852e-06\n","Epoch 173/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2949e-06 - mean_squared_error: 1.1815e-06 - val_loss: 1.3012e-06 - val_mean_squared_error: 1.1849e-06\n","Epoch 174/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2931e-06 - mean_squared_error: 1.1810e-06 - val_loss: 1.2994e-06 - val_mean_squared_error: 1.1845e-06\n","Epoch 175/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2918e-06 - mean_squared_error: 1.1809e-06 - val_loss: 1.2979e-06 - val_mean_squared_error: 1.1846e-06\n","Epoch 176/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2895e-06 - mean_squared_error: 1.1799e-06 - val_loss: 1.2963e-06 - val_mean_squared_error: 1.1833e-06\n","Epoch 177/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2880e-06 - mean_squared_error: 1.1795e-06 - val_loss: 1.2944e-06 - val_mean_squared_error: 1.1833e-06\n","Epoch 178/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2867e-06 - mean_squared_error: 1.1794e-06 - val_loss: 1.2935e-06 - val_mean_squared_error: 1.1827e-06\n","Epoch 179/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2844e-06 - mean_squared_error: 1.1784e-06 - val_loss: 1.2934e-06 - val_mean_squared_error: 1.1832e-06\n","Epoch 180/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2831e-06 - mean_squared_error: 1.1781e-06 - val_loss: 1.2897e-06 - val_mean_squared_error: 1.1816e-06\n","Epoch 181/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2817e-06 - mean_squared_error: 1.1778e-06 - val_loss: 1.2879e-06 - val_mean_squared_error: 1.1813e-06\n","Epoch 182/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2803e-06 - mean_squared_error: 1.1777e-06 - val_loss: 1.2867e-06 - val_mean_squared_error: 1.1807e-06\n","Epoch 183/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2787e-06 - mean_squared_error: 1.1770e-06 - val_loss: 1.2869e-06 - val_mean_squared_error: 1.1813e-06\n","Epoch 184/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2769e-06 - mean_squared_error: 1.1762e-06 - val_loss: 1.2837e-06 - val_mean_squared_error: 1.1807e-06\n","Epoch 185/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2755e-06 - mean_squared_error: 1.1760e-06 - val_loss: 1.2820e-06 - val_mean_squared_error: 1.1795e-06\n","Epoch 186/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2741e-06 - mean_squared_error: 1.1755e-06 - val_loss: 1.2815e-06 - val_mean_squared_error: 1.1810e-06\n","Epoch 187/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2729e-06 - mean_squared_error: 1.1755e-06 - val_loss: 1.2798e-06 - val_mean_squared_error: 1.1789e-06\n","Epoch 188/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2715e-06 - mean_squared_error: 1.1748e-06 - val_loss: 1.2777e-06 - val_mean_squared_error: 1.1783e-06\n","Epoch 189/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2698e-06 - mean_squared_error: 1.1743e-06 - val_loss: 1.2775e-06 - val_mean_squared_error: 1.1784e-06\n","Epoch 190/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2686e-06 - mean_squared_error: 1.1740e-06 - val_loss: 1.2752e-06 - val_mean_squared_error: 1.1775e-06\n","Epoch 191/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2672e-06 - mean_squared_error: 1.1734e-06 - val_loss: 1.2758e-06 - val_mean_squared_error: 1.1805e-06\n","Epoch 192/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2661e-06 - mean_squared_error: 1.1734e-06 - val_loss: 1.2732e-06 - val_mean_squared_error: 1.1770e-06\n","Epoch 193/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2644e-06 - mean_squared_error: 1.1724e-06 - val_loss: 1.2724e-06 - val_mean_squared_error: 1.1787e-06\n","Epoch 194/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2632e-06 - mean_squared_error: 1.1723e-06 - val_loss: 1.2705e-06 - val_mean_squared_error: 1.1762e-06\n","Epoch 195/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2619e-06 - mean_squared_error: 1.1718e-06 - val_loss: 1.2685e-06 - val_mean_squared_error: 1.1756e-06\n","Epoch 196/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2617e-06 - mean_squared_error: 1.1725e-06 - val_loss: 1.2681e-06 - val_mean_squared_error: 1.1756e-06\n","Epoch 197/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2597e-06 - mean_squared_error: 1.1712e-06 - val_loss: 1.2662e-06 - val_mean_squared_error: 1.1754e-06\n","Epoch 198/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2590e-06 - mean_squared_error: 1.1715e-06 - val_loss: 1.2652e-06 - val_mean_squared_error: 1.1746e-06\n","Epoch 199/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2568e-06 - mean_squared_error: 1.1700e-06 - val_loss: 1.2640e-06 - val_mean_squared_error: 1.1742e-06\n","Epoch 200/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2561e-06 - mean_squared_error: 1.1701e-06 - val_loss: 1.2635e-06 - val_mean_squared_error: 1.1756e-06\n","Epoch 201/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2551e-06 - mean_squared_error: 1.1699e-06 - val_loss: 1.2614e-06 - val_mean_squared_error: 1.1738e-06\n","Epoch 202/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2540e-06 - mean_squared_error: 1.1696e-06 - val_loss: 1.2606e-06 - val_mean_squared_error: 1.1732e-06\n","Epoch 203/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2533e-06 - mean_squared_error: 1.1696e-06 - val_loss: 1.2592e-06 - val_mean_squared_error: 1.1729e-06\n","Epoch 204/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2514e-06 - mean_squared_error: 1.1685e-06 - val_loss: 1.2590e-06 - val_mean_squared_error: 1.1742e-06\n","Epoch 205/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2504e-06 - mean_squared_error: 1.1683e-06 - val_loss: 1.2575e-06 - val_mean_squared_error: 1.1733e-06\n","Epoch 206/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2491e-06 - mean_squared_error: 1.1677e-06 - val_loss: 1.2559e-06 - val_mean_squared_error: 1.1720e-06\n","Epoch 207/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2482e-06 - mean_squared_error: 1.1676e-06 - val_loss: 1.2550e-06 - val_mean_squared_error: 1.1720e-06\n","Epoch 208/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2476e-06 - mean_squared_error: 1.1677e-06 - val_loss: 1.2539e-06 - val_mean_squared_error: 1.1716e-06\n","Epoch 209/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2464e-06 - mean_squared_error: 1.1671e-06 - val_loss: 1.2527e-06 - val_mean_squared_error: 1.1710e-06\n","Epoch 210/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2454e-06 - mean_squared_error: 1.1668e-06 - val_loss: 1.2517e-06 - val_mean_squared_error: 1.1707e-06\n","Epoch 211/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2447e-06 - mean_squared_error: 1.1669e-06 - val_loss: 1.2508e-06 - val_mean_squared_error: 1.1703e-06\n","Epoch 212/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2433e-06 - mean_squared_error: 1.1662e-06 - val_loss: 1.2508e-06 - val_mean_squared_error: 1.1705e-06\n","Epoch 213/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2429e-06 - mean_squared_error: 1.1663e-06 - val_loss: 1.2489e-06 - val_mean_squared_error: 1.1697e-06\n","Epoch 214/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2415e-06 - mean_squared_error: 1.1655e-06 - val_loss: 1.2479e-06 - val_mean_squared_error: 1.1694e-06\n","Epoch 215/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2404e-06 - mean_squared_error: 1.1651e-06 - val_loss: 1.2472e-06 - val_mean_squared_error: 1.1698e-06\n","Epoch 216/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2396e-06 - mean_squared_error: 1.1650e-06 - val_loss: 1.2472e-06 - val_mean_squared_error: 1.1695e-06\n","Epoch 217/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2386e-06 - mean_squared_error: 1.1646e-06 - val_loss: 1.2452e-06 - val_mean_squared_error: 1.1686e-06\n","Epoch 218/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2382e-06 - mean_squared_error: 1.1649e-06 - val_loss: 1.2447e-06 - val_mean_squared_error: 1.1685e-06\n","Epoch 219/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2369e-06 - mean_squared_error: 1.1640e-06 - val_loss: 1.2432e-06 - val_mean_squared_error: 1.1681e-06\n","Epoch 220/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2357e-06 - mean_squared_error: 1.1635e-06 - val_loss: 1.2433e-06 - val_mean_squared_error: 1.1694e-06\n","Epoch 221/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2352e-06 - mean_squared_error: 1.1636e-06 - val_loss: 1.2418e-06 - val_mean_squared_error: 1.1682e-06\n","Epoch 222/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2340e-06 - mean_squared_error: 1.1630e-06 - val_loss: 1.2411e-06 - val_mean_squared_error: 1.1682e-06\n","Epoch 223/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2333e-06 - mean_squared_error: 1.1629e-06 - val_loss: 1.2398e-06 - val_mean_squared_error: 1.1672e-06\n","Epoch 224/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2325e-06 - mean_squared_error: 1.1626e-06 - val_loss: 1.2406e-06 - val_mean_squared_error: 1.1691e-06\n","Epoch 225/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2319e-06 - mean_squared_error: 1.1626e-06 - val_loss: 1.2383e-06 - val_mean_squared_error: 1.1670e-06\n","Epoch 226/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2307e-06 - mean_squared_error: 1.1621e-06 - val_loss: 1.2375e-06 - val_mean_squared_error: 1.1662e-06\n","Epoch 227/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2300e-06 - mean_squared_error: 1.1618e-06 - val_loss: 1.2365e-06 - val_mean_squared_error: 1.1662e-06\n","Epoch 228/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2292e-06 - mean_squared_error: 1.1615e-06 - val_loss: 1.2384e-06 - val_mean_squared_error: 1.1694e-06\n","Epoch 229/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2287e-06 - mean_squared_error: 1.1616e-06 - val_loss: 1.2349e-06 - val_mean_squared_error: 1.1654e-06\n","Epoch 230/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2273e-06 - mean_squared_error: 1.1607e-06 - val_loss: 1.2345e-06 - val_mean_squared_error: 1.1653e-06\n","Epoch 231/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2273e-06 - mean_squared_error: 1.1612e-06 - val_loss: 1.2338e-06 - val_mean_squared_error: 1.1659e-06\n","Epoch 232/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2262e-06 - mean_squared_error: 1.1607e-06 - val_loss: 1.2329e-06 - val_mean_squared_error: 1.1655e-06\n","Epoch 233/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2255e-06 - mean_squared_error: 1.1604e-06 - val_loss: 1.2319e-06 - val_mean_squared_error: 1.1649e-06\n","Epoch 234/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2247e-06 - mean_squared_error: 1.1602e-06 - val_loss: 1.2316e-06 - val_mean_squared_error: 1.1644e-06\n","Epoch 235/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2242e-06 - mean_squared_error: 1.1601e-06 - val_loss: 1.2303e-06 - val_mean_squared_error: 1.1640e-06\n","Epoch 236/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2236e-06 - mean_squared_error: 1.1600e-06 - val_loss: 1.2301e-06 - val_mean_squared_error: 1.1640e-06\n","Epoch 237/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2230e-06 - mean_squared_error: 1.1599e-06 - val_loss: 1.2291e-06 - val_mean_squared_error: 1.1636e-06\n","Epoch 238/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2218e-06 - mean_squared_error: 1.1592e-06 - val_loss: 1.2282e-06 - val_mean_squared_error: 1.1635e-06\n","Epoch 239/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2211e-06 - mean_squared_error: 1.1589e-06 - val_loss: 1.2274e-06 - val_mean_squared_error: 1.1631e-06\n","Epoch 240/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2202e-06 - mean_squared_error: 1.1585e-06 - val_loss: 1.2268e-06 - val_mean_squared_error: 1.1629e-06\n","Epoch 241/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2196e-06 - mean_squared_error: 1.1585e-06 - val_loss: 1.2265e-06 - val_mean_squared_error: 1.1628e-06\n","Epoch 242/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2192e-06 - mean_squared_error: 1.1584e-06 - val_loss: 1.2275e-06 - val_mean_squared_error: 1.1639e-06\n","Epoch 243/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2187e-06 - mean_squared_error: 1.1583e-06 - val_loss: 1.2254e-06 - val_mean_squared_error: 1.1634e-06\n","Epoch 244/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2176e-06 - mean_squared_error: 1.1577e-06 - val_loss: 1.2240e-06 - val_mean_squared_error: 1.1621e-06\n","Epoch 245/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2169e-06 - mean_squared_error: 1.1575e-06 - val_loss: 1.2236e-06 - val_mean_squared_error: 1.1619e-06\n","Epoch 246/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2166e-06 - mean_squared_error: 1.1575e-06 - val_loss: 1.2230e-06 - val_mean_squared_error: 1.1621e-06\n","Epoch 247/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2157e-06 - mean_squared_error: 1.1571e-06 - val_loss: 1.2235e-06 - val_mean_squared_error: 1.1634e-06\n","Epoch 248/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2155e-06 - mean_squared_error: 1.1574e-06 - val_loss: 1.2221e-06 - val_mean_squared_error: 1.1623e-06\n","Epoch 249/350\n","225/225 [==============================] - 2s 8ms/step - loss: 1.2148e-06 - mean_squared_error: 1.1571e-06 - val_loss: 1.2220e-06 - val_mean_squared_error: 1.1628e-06\n","Epoch 250/350\n","225/225 [==============================] - 2s 8ms/step - loss: 1.2141e-06 - mean_squared_error: 1.1568e-06 - val_loss: 1.2203e-06 - val_mean_squared_error: 1.1608e-06\n","Epoch 251/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2134e-06 - mean_squared_error: 1.1565e-06 - val_loss: 1.2196e-06 - val_mean_squared_error: 1.1608e-06\n","Epoch 252/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2131e-06 - mean_squared_error: 1.1564e-06 - val_loss: 1.2250e-06 - val_mean_squared_error: 1.1676e-06\n","Epoch 253/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2122e-06 - mean_squared_error: 1.1562e-06 - val_loss: 1.2186e-06 - val_mean_squared_error: 1.1606e-06\n","Epoch 254/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2117e-06 - mean_squared_error: 1.1559e-06 - val_loss: 1.2184e-06 - val_mean_squared_error: 1.1610e-06\n","Epoch 255/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2111e-06 - mean_squared_error: 1.1557e-06 - val_loss: 1.2173e-06 - val_mean_squared_error: 1.1600e-06\n","Epoch 256/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2104e-06 - mean_squared_error: 1.1554e-06 - val_loss: 1.2180e-06 - val_mean_squared_error: 1.1616e-06\n","Epoch 257/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2098e-06 - mean_squared_error: 1.1553e-06 - val_loss: 1.2166e-06 - val_mean_squared_error: 1.1598e-06\n","Epoch 258/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2096e-06 - mean_squared_error: 1.1553e-06 - val_loss: 1.2158e-06 - val_mean_squared_error: 1.1598e-06\n","Epoch 259/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2089e-06 - mean_squared_error: 1.1551e-06 - val_loss: 1.2150e-06 - val_mean_squared_error: 1.1593e-06\n","Epoch 260/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2082e-06 - mean_squared_error: 1.1547e-06 - val_loss: 1.2148e-06 - val_mean_squared_error: 1.1597e-06\n","Epoch 261/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2075e-06 - mean_squared_error: 1.1544e-06 - val_loss: 1.2151e-06 - val_mean_squared_error: 1.1596e-06\n","Epoch 262/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2077e-06 - mean_squared_error: 1.1549e-06 - val_loss: 1.2134e-06 - val_mean_squared_error: 1.1587e-06\n","Epoch 263/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2066e-06 - mean_squared_error: 1.1542e-06 - val_loss: 1.2139e-06 - val_mean_squared_error: 1.1600e-06\n","Epoch 264/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2060e-06 - mean_squared_error: 1.1540e-06 - val_loss: 1.2125e-06 - val_mean_squared_error: 1.1587e-06\n","Epoch 265/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2058e-06 - mean_squared_error: 1.1541e-06 - val_loss: 1.2121e-06 - val_mean_squared_error: 1.1583e-06\n","Epoch 266/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2051e-06 - mean_squared_error: 1.1538e-06 - val_loss: 1.2114e-06 - val_mean_squared_error: 1.1581e-06\n","Epoch 267/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2047e-06 - mean_squared_error: 1.1537e-06 - val_loss: 1.2108e-06 - val_mean_squared_error: 1.1579e-06\n","Epoch 268/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2038e-06 - mean_squared_error: 1.1531e-06 - val_loss: 1.2115e-06 - val_mean_squared_error: 1.1594e-06\n","Epoch 269/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2036e-06 - mean_squared_error: 1.1533e-06 - val_loss: 1.2098e-06 - val_mean_squared_error: 1.1576e-06\n","Epoch 270/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2035e-06 - mean_squared_error: 1.1535e-06 - val_loss: 1.2094e-06 - val_mean_squared_error: 1.1576e-06\n","Epoch 271/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2026e-06 - mean_squared_error: 1.1529e-06 - val_loss: 1.2088e-06 - val_mean_squared_error: 1.1574e-06\n","Epoch 272/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2020e-06 - mean_squared_error: 1.1526e-06 - val_loss: 1.2084e-06 - val_mean_squared_error: 1.1572e-06\n","Epoch 273/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2018e-06 - mean_squared_error: 1.1527e-06 - val_loss: 1.2080e-06 - val_mean_squared_error: 1.1570e-06\n","Epoch 274/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2015e-06 - mean_squared_error: 1.1527e-06 - val_loss: 1.2075e-06 - val_mean_squared_error: 1.1570e-06\n","Epoch 275/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2009e-06 - mean_squared_error: 1.1525e-06 - val_loss: 1.2071e-06 - val_mean_squared_error: 1.1571e-06\n","Epoch 276/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2001e-06 - mean_squared_error: 1.1520e-06 - val_loss: 1.2067e-06 - val_mean_squared_error: 1.1570e-06\n","Epoch 277/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1999e-06 - mean_squared_error: 1.1522e-06 - val_loss: 1.2064e-06 - val_mean_squared_error: 1.1565e-06\n","Epoch 278/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1993e-06 - mean_squared_error: 1.1517e-06 - val_loss: 1.2060e-06 - val_mean_squared_error: 1.1570e-06\n","Epoch 279/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1990e-06 - mean_squared_error: 1.1518e-06 - val_loss: 1.2051e-06 - val_mean_squared_error: 1.1562e-06\n","Epoch 280/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1986e-06 - mean_squared_error: 1.1516e-06 - val_loss: 1.2063e-06 - val_mean_squared_error: 1.1581e-06\n","Epoch 281/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1981e-06 - mean_squared_error: 1.1515e-06 - val_loss: 1.2043e-06 - val_mean_squared_error: 1.1560e-06\n","Epoch 282/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1977e-06 - mean_squared_error: 1.1513e-06 - val_loss: 1.2050e-06 - val_mean_squared_error: 1.1573e-06\n","Epoch 283/350\n","225/225 [==============================] - 2s 8ms/step - loss: 1.1974e-06 - mean_squared_error: 1.1514e-06 - val_loss: 1.2040e-06 - val_mean_squared_error: 1.1565e-06\n","Epoch 284/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1965e-06 - mean_squared_error: 1.1508e-06 - val_loss: 1.2034e-06 - val_mean_squared_error: 1.1557e-06\n","Epoch 285/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1966e-06 - mean_squared_error: 1.1511e-06 - val_loss: 1.2026e-06 - val_mean_squared_error: 1.1554e-06\n","Epoch 286/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1961e-06 - mean_squared_error: 1.1508e-06 - val_loss: 1.2036e-06 - val_mean_squared_error: 1.1571e-06\n","Epoch 287/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1956e-06 - mean_squared_error: 1.1508e-06 - val_loss: 1.2020e-06 - val_mean_squared_error: 1.1552e-06\n","Epoch 288/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1951e-06 - mean_squared_error: 1.1504e-06 - val_loss: 1.2020e-06 - val_mean_squared_error: 1.1560e-06\n","Epoch 289/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1950e-06 - mean_squared_error: 1.1505e-06 - val_loss: 1.2021e-06 - val_mean_squared_error: 1.1564e-06\n","Epoch 290/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1945e-06 - mean_squared_error: 1.1504e-06 - val_loss: 1.2005e-06 - val_mean_squared_error: 1.1547e-06\n","Epoch 291/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1942e-06 - mean_squared_error: 1.1503e-06 - val_loss: 1.2007e-06 - val_mean_squared_error: 1.1555e-06\n","Epoch 292/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1941e-06 - mean_squared_error: 1.1505e-06 - val_loss: 1.1997e-06 - val_mean_squared_error: 1.1545e-06\n","Epoch 293/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1929e-06 - mean_squared_error: 1.1495e-06 - val_loss: 1.2003e-06 - val_mean_squared_error: 1.1556e-06\n","Epoch 294/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1927e-06 - mean_squared_error: 1.1497e-06 - val_loss: 1.1991e-06 - val_mean_squared_error: 1.1543e-06\n","Epoch 295/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1925e-06 - mean_squared_error: 1.1497e-06 - val_loss: 1.1993e-06 - val_mean_squared_error: 1.1545e-06\n","Epoch 296/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1921e-06 - mean_squared_error: 1.1494e-06 - val_loss: 1.1992e-06 - val_mean_squared_error: 1.1553e-06\n","Epoch 297/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1915e-06 - mean_squared_error: 1.1492e-06 - val_loss: 1.1978e-06 - val_mean_squared_error: 1.1539e-06\n","Epoch 298/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1912e-06 - mean_squared_error: 1.1491e-06 - val_loss: 1.1979e-06 - val_mean_squared_error: 1.1540e-06\n","Epoch 299/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1910e-06 - mean_squared_error: 1.1491e-06 - val_loss: 1.1977e-06 - val_mean_squared_error: 1.1545e-06\n","Epoch 300/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1910e-06 - mean_squared_error: 1.1494e-06 - val_loss: 1.1968e-06 - val_mean_squared_error: 1.1537e-06\n","Epoch 301/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1904e-06 - mean_squared_error: 1.1491e-06 - val_loss: 1.1970e-06 - val_mean_squared_error: 1.1543e-06\n","Epoch 302/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1899e-06 - mean_squared_error: 1.1489e-06 - val_loss: 1.1960e-06 - val_mean_squared_error: 1.1534e-06\n","Epoch 303/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1896e-06 - mean_squared_error: 1.1488e-06 - val_loss: 1.1957e-06 - val_mean_squared_error: 1.1532e-06\n","Epoch 304/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1891e-06 - mean_squared_error: 1.1485e-06 - val_loss: 1.1956e-06 - val_mean_squared_error: 1.1532e-06\n","Epoch 305/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1888e-06 - mean_squared_error: 1.1483e-06 - val_loss: 1.1951e-06 - val_mean_squared_error: 1.1532e-06\n","Epoch 306/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1885e-06 - mean_squared_error: 1.1483e-06 - val_loss: 1.1948e-06 - val_mean_squared_error: 1.1533e-06\n","Epoch 307/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1883e-06 - mean_squared_error: 1.1483e-06 - val_loss: 1.1943e-06 - val_mean_squared_error: 1.1528e-06\n","Epoch 308/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1878e-06 - mean_squared_error: 1.1481e-06 - val_loss: 1.1940e-06 - val_mean_squared_error: 1.1527e-06\n","Epoch 309/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1872e-06 - mean_squared_error: 1.1477e-06 - val_loss: 1.1936e-06 - val_mean_squared_error: 1.1526e-06\n","Epoch 310/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1871e-06 - mean_squared_error: 1.1478e-06 - val_loss: 1.1936e-06 - val_mean_squared_error: 1.1530e-06\n","Epoch 311/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1869e-06 - mean_squared_error: 1.1479e-06 - val_loss: 1.1930e-06 - val_mean_squared_error: 1.1525e-06\n","Epoch 312/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1866e-06 - mean_squared_error: 1.1478e-06 - val_loss: 1.1926e-06 - val_mean_squared_error: 1.1523e-06\n","Epoch 313/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1864e-06 - mean_squared_error: 1.1478e-06 - val_loss: 1.1923e-06 - val_mean_squared_error: 1.1522e-06\n","Epoch 314/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1863e-06 - mean_squared_error: 1.1479e-06 - val_loss: 1.1928e-06 - val_mean_squared_error: 1.1532e-06\n","Epoch 315/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1854e-06 - mean_squared_error: 1.1472e-06 - val_loss: 1.1925e-06 - val_mean_squared_error: 1.1532e-06\n","Epoch 316/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1856e-06 - mean_squared_error: 1.1476e-06 - val_loss: 1.1918e-06 - val_mean_squared_error: 1.1526e-06\n","Epoch 317/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1850e-06 - mean_squared_error: 1.1472e-06 - val_loss: 1.1910e-06 - val_mean_squared_error: 1.1519e-06\n","Epoch 318/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1842e-06 - mean_squared_error: 1.1467e-06 - val_loss: 1.1909e-06 - val_mean_squared_error: 1.1520e-06\n","Epoch 319/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1843e-06 - mean_squared_error: 1.1470e-06 - val_loss: 1.1904e-06 - val_mean_squared_error: 1.1516e-06\n","Epoch 320/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1839e-06 - mean_squared_error: 1.1467e-06 - val_loss: 1.1908e-06 - val_mean_squared_error: 1.1525e-06\n","Epoch 321/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1840e-06 - mean_squared_error: 1.1471e-06 - val_loss: 1.1902e-06 - val_mean_squared_error: 1.1521e-06\n","Epoch 322/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1835e-06 - mean_squared_error: 1.1467e-06 - val_loss: 1.1898e-06 - val_mean_squared_error: 1.1518e-06\n","Epoch 323/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1832e-06 - mean_squared_error: 1.1467e-06 - val_loss: 1.1896e-06 - val_mean_squared_error: 1.1518e-06\n","Epoch 324/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1830e-06 - mean_squared_error: 1.1468e-06 - val_loss: 1.1899e-06 - val_mean_squared_error: 1.1519e-06\n","Epoch 325/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1823e-06 - mean_squared_error: 1.1460e-06 - val_loss: 1.1909e-06 - val_mean_squared_error: 1.1538e-06\n","Epoch 326/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1825e-06 - mean_squared_error: 1.1467e-06 - val_loss: 1.1888e-06 - val_mean_squared_error: 1.1513e-06\n","Epoch 327/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1823e-06 - mean_squared_error: 1.1465e-06 - val_loss: 1.1882e-06 - val_mean_squared_error: 1.1509e-06\n","Epoch 328/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1819e-06 - mean_squared_error: 1.1463e-06 - val_loss: 1.1880e-06 - val_mean_squared_error: 1.1511e-06\n","Epoch 329/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1816e-06 - mean_squared_error: 1.1462e-06 - val_loss: 1.1876e-06 - val_mean_squared_error: 1.1510e-06\n","Epoch 330/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1812e-06 - mean_squared_error: 1.1461e-06 - val_loss: 1.1873e-06 - val_mean_squared_error: 1.1507e-06\n","Epoch 331/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1809e-06 - mean_squared_error: 1.1459e-06 - val_loss: 1.1871e-06 - val_mean_squared_error: 1.1507e-06\n","Epoch 332/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1809e-06 - mean_squared_error: 1.1461e-06 - val_loss: 1.1868e-06 - val_mean_squared_error: 1.1508e-06\n","Epoch 333/350\n","225/225 [==============================] - 2s 9ms/step - loss: 1.1804e-06 - mean_squared_error: 1.1458e-06 - val_loss: 1.1866e-06 - val_mean_squared_error: 1.1505e-06\n","Epoch 334/350\n","225/225 [==============================] - 2s 8ms/step - loss: 1.1801e-06 - mean_squared_error: 1.1456e-06 - val_loss: 1.1865e-06 - val_mean_squared_error: 1.1509e-06\n","Epoch 335/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1800e-06 - mean_squared_error: 1.1457e-06 - val_loss: 1.1867e-06 - val_mean_squared_error: 1.1513e-06\n","Epoch 336/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1797e-06 - mean_squared_error: 1.1456e-06 - val_loss: 1.1858e-06 - val_mean_squared_error: 1.1504e-06\n","Epoch 337/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1795e-06 - mean_squared_error: 1.1456e-06 - val_loss: 1.1854e-06 - val_mean_squared_error: 1.1502e-06\n","Epoch 338/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1791e-06 - mean_squared_error: 1.1454e-06 - val_loss: 1.1856e-06 - val_mean_squared_error: 1.1507e-06\n","Epoch 339/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1788e-06 - mean_squared_error: 1.1452e-06 - val_loss: 1.1864e-06 - val_mean_squared_error: 1.1519e-06\n","Epoch 340/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1788e-06 - mean_squared_error: 1.1455e-06 - val_loss: 1.1847e-06 - val_mean_squared_error: 1.1500e-06\n","Epoch 341/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1784e-06 - mean_squared_error: 1.1452e-06 - val_loss: 1.1845e-06 - val_mean_squared_error: 1.1500e-06\n","Epoch 342/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1783e-06 - mean_squared_error: 1.1452e-06 - val_loss: 1.1842e-06 - val_mean_squared_error: 1.1498e-06\n","Epoch 343/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1777e-06 - mean_squared_error: 1.1448e-06 - val_loss: 1.1840e-06 - val_mean_squared_error: 1.1498e-06\n","Epoch 344/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1776e-06 - mean_squared_error: 1.1449e-06 - val_loss: 1.1839e-06 - val_mean_squared_error: 1.1497e-06\n","Epoch 345/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1773e-06 - mean_squared_error: 1.1448e-06 - val_loss: 1.1835e-06 - val_mean_squared_error: 1.1497e-06\n","Epoch 346/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1774e-06 - mean_squared_error: 1.1450e-06 - val_loss: 1.1834e-06 - val_mean_squared_error: 1.1499e-06\n","Epoch 347/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1772e-06 - mean_squared_error: 1.1450e-06 - val_loss: 1.1831e-06 - val_mean_squared_error: 1.1496e-06\n","Epoch 348/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1766e-06 - mean_squared_error: 1.1445e-06 - val_loss: 1.1831e-06 - val_mean_squared_error: 1.1499e-06\n","Epoch 349/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1766e-06 - mean_squared_error: 1.1447e-06 - val_loss: 1.1825e-06 - val_mean_squared_error: 1.1494e-06\n","Epoch 350/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1763e-06 - mean_squared_error: 1.1445e-06 - val_loss: 1.1831e-06 - val_mean_squared_error: 1.1503e-06\n","./defensive_models/350_0903_DAE_GTSRB_I\n","Epoch 1/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0857 - mean_squared_error: 0.0857 - val_loss: 0.0070 - val_mean_squared_error: 0.0070\n","Epoch 2/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n","Epoch 3/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n","Epoch 4/350\n","225/225 [==============================] - 1s 5ms/step - loss: 8.1247e-04 - mean_squared_error: 8.0858e-04 - val_loss: 7.2040e-04 - val_mean_squared_error: 7.1681e-04\n","Epoch 5/350\n","225/225 [==============================] - 1s 5ms/step - loss: 5.4298e-04 - mean_squared_error: 5.3899e-04 - val_loss: 5.0620e-04 - val_mean_squared_error: 5.0254e-04\n","Epoch 6/350\n","225/225 [==============================] - 1s 5ms/step - loss: 3.9226e-04 - mean_squared_error: 3.8819e-04 - val_loss: 3.7713e-04 - val_mean_squared_error: 3.7342e-04\n","Epoch 7/350\n","225/225 [==============================] - 1s 5ms/step - loss: 2.9782e-04 - mean_squared_error: 2.9370e-04 - val_loss: 2.9234e-04 - val_mean_squared_error: 2.8858e-04\n","Epoch 8/350\n","225/225 [==============================] - 1s 5ms/step - loss: 2.3409e-04 - mean_squared_error: 2.2991e-04 - val_loss: 2.3320e-04 - val_mean_squared_error: 2.2940e-04\n","Epoch 9/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.8875e-04 - mean_squared_error: 1.8453e-04 - val_loss: 1.9011e-04 - val_mean_squared_error: 1.8628e-04\n","Epoch 10/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.5522e-04 - mean_squared_error: 1.5097e-04 - val_loss: 1.5762e-04 - val_mean_squared_error: 1.5377e-04\n","Epoch 11/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.2966e-04 - mean_squared_error: 1.2537e-04 - val_loss: 1.3250e-04 - val_mean_squared_error: 1.2862e-04\n","Epoch 12/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.0970e-04 - mean_squared_error: 1.0539e-04 - val_loss: 1.1265e-04 - val_mean_squared_error: 1.0875e-04\n","Epoch 13/350\n","225/225 [==============================] - 1s 5ms/step - loss: 9.3808e-05 - mean_squared_error: 8.9469e-05 - val_loss: 9.6684e-05 - val_mean_squared_error: 9.2764e-05\n","Epoch 14/350\n","225/225 [==============================] - 1s 5ms/step - loss: 8.0953e-05 - mean_squared_error: 7.6590e-05 - val_loss: 8.3662e-05 - val_mean_squared_error: 7.9723e-05\n","Epoch 15/350\n","225/225 [==============================] - 1s 5ms/step - loss: 7.0413e-05 - mean_squared_error: 6.6028e-05 - val_loss: 7.2909e-05 - val_mean_squared_error: 6.8953e-05\n","Epoch 16/350\n","225/225 [==============================] - 1s 6ms/step - loss: 6.1673e-05 - mean_squared_error: 5.7268e-05 - val_loss: 6.3941e-05 - val_mean_squared_error: 5.9969e-05\n","Epoch 17/350\n","225/225 [==============================] - 1s 5ms/step - loss: 5.4357e-05 - mean_squared_error: 4.9933e-05 - val_loss: 5.6395e-05 - val_mean_squared_error: 5.2408e-05\n","Epoch 18/350\n","225/225 [==============================] - 1s 5ms/step - loss: 4.8181e-05 - mean_squared_error: 4.3739e-05 - val_loss: 4.9997e-05 - val_mean_squared_error: 4.5995e-05\n","Epoch 19/350\n","225/225 [==============================] - 1s 5ms/step - loss: 4.2932e-05 - mean_squared_error: 3.8473e-05 - val_loss: 4.4537e-05 - val_mean_squared_error: 4.0522e-05\n","Epoch 20/350\n","225/225 [==============================] - 1s 5ms/step - loss: 3.8443e-05 - mean_squared_error: 3.3969e-05 - val_loss: 3.9849e-05 - val_mean_squared_error: 3.5821e-05\n","Epoch 21/350\n","225/225 [==============================] - 1s 5ms/step - loss: 3.4584e-05 - mean_squared_error: 3.0095e-05 - val_loss: 3.5810e-05 - val_mean_squared_error: 3.1769e-05\n","Epoch 22/350\n","225/225 [==============================] - 1s 5ms/step - loss: 3.1252e-05 - mean_squared_error: 2.6748e-05 - val_loss: 3.2312e-05 - val_mean_squared_error: 2.8260e-05\n","Epoch 23/350\n","225/225 [==============================] - 1s 5ms/step - loss: 2.8362e-05 - mean_squared_error: 2.3845e-05 - val_loss: 2.9271e-05 - val_mean_squared_error: 2.5208e-05\n","Epoch 24/350\n","225/225 [==============================] - 1s 5ms/step - loss: 2.5848e-05 - mean_squared_error: 2.1318e-05 - val_loss: 2.6621e-05 - val_mean_squared_error: 2.2547e-05\n","Epoch 25/350\n","225/225 [==============================] - 1s 5ms/step - loss: 2.3654e-05 - mean_squared_error: 1.9112e-05 - val_loss: 2.4302e-05 - val_mean_squared_error: 2.0219e-05\n","Epoch 26/350\n","225/225 [==============================] - 1s 5ms/step - loss: 2.1735e-05 - mean_squared_error: 1.7181e-05 - val_loss: 2.2270e-05 - val_mean_squared_error: 1.8177e-05\n","Epoch 27/350\n","225/225 [==============================] - 2s 7ms/step - loss: 2.0052e-05 - mean_squared_error: 1.5488e-05 - val_loss: 2.0486e-05 - val_mean_squared_error: 1.6384e-05\n","Epoch 28/350\n","225/225 [==============================] - 2s 8ms/step - loss: 1.8573e-05 - mean_squared_error: 1.3999e-05 - val_loss: 1.8915e-05 - val_mean_squared_error: 1.4804e-05\n","Epoch 29/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.7270e-05 - mean_squared_error: 1.2687e-05 - val_loss: 1.7532e-05 - val_mean_squared_error: 1.3413e-05\n","Epoch 30/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.6123e-05 - mean_squared_error: 1.1531e-05 - val_loss: 1.6309e-05 - val_mean_squared_error: 1.2183e-05\n","Epoch 31/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.5109e-05 - mean_squared_error: 1.0509e-05 - val_loss: 1.5230e-05 - val_mean_squared_error: 1.1097e-05\n","Epoch 32/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.4214e-05 - mean_squared_error: 9.6068e-06 - val_loss: 1.4276e-05 - val_mean_squared_error: 1.0136e-05\n","Epoch 33/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.3422e-05 - mean_squared_error: 8.8083e-06 - val_loss: 1.3431e-05 - val_mean_squared_error: 9.2842e-06\n","Epoch 34/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.2721e-05 - mean_squared_error: 8.1012e-06 - val_loss: 1.2682e-05 - val_mean_squared_error: 8.5293e-06\n","Epoch 35/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.2099e-05 - mean_squared_error: 7.4747e-06 - val_loss: 1.2018e-05 - val_mean_squared_error: 7.8609e-06\n","Epoch 36/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.1548e-05 - mean_squared_error: 6.9195e-06 - val_loss: 1.1429e-05 - val_mean_squared_error: 7.2675e-06\n","Epoch 37/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.1058e-05 - mean_squared_error: 6.4272e-06 - val_loss: 1.0906e-05 - val_mean_squared_error: 6.7407e-06\n","Epoch 38/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.0624e-05 - mean_squared_error: 5.9905e-06 - val_loss: 1.0442e-05 - val_mean_squared_error: 6.2735e-06\n","Epoch 39/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.0237e-05 - mean_squared_error: 5.6032e-06 - val_loss: 1.0030e-05 - val_mean_squared_error: 5.8589e-06\n","Epoch 40/350\n","225/225 [==============================] - 1s 6ms/step - loss: 9.8936e-06 - mean_squared_error: 5.2596e-06 - val_loss: 9.6632e-06 - val_mean_squared_error: 5.4904e-06\n","Epoch 41/350\n","225/225 [==============================] - 1s 6ms/step - loss: 9.5873e-06 - mean_squared_error: 4.9548e-06 - val_loss: 9.3369e-06 - val_mean_squared_error: 5.1634e-06\n","Epoch 42/350\n","225/225 [==============================] - 1s 5ms/step - loss: 9.3140e-06 - mean_squared_error: 4.6845e-06 - val_loss: 9.0467e-06 - val_mean_squared_error: 4.8736e-06\n","Epoch 43/350\n","225/225 [==============================] - 1s 5ms/step - loss: 9.0700e-06 - mean_squared_error: 4.4448e-06 - val_loss: 8.7878e-06 - val_mean_squared_error: 4.6159e-06\n","Epoch 44/350\n","225/225 [==============================] - 1s 5ms/step - loss: 8.8515e-06 - mean_squared_error: 4.2324e-06 - val_loss: 8.5570e-06 - val_mean_squared_error: 4.3877e-06\n","Epoch 45/350\n","225/225 [==============================] - 1s 5ms/step - loss: 8.6556e-06 - mean_squared_error: 4.0442e-06 - val_loss: 8.3510e-06 - val_mean_squared_error: 4.1854e-06\n","Epoch 46/350\n","225/225 [==============================] - 1s 5ms/step - loss: 8.4792e-06 - mean_squared_error: 3.8775e-06 - val_loss: 8.1665e-06 - val_mean_squared_error: 4.0062e-06\n","Epoch 47/350\n","225/225 [==============================] - 1s 5ms/step - loss: 8.3199e-06 - mean_squared_error: 3.7300e-06 - val_loss: 8.0007e-06 - val_mean_squared_error: 3.8472e-06\n","Epoch 48/350\n","225/225 [==============================] - 1s 5ms/step - loss: 8.1754e-06 - mean_squared_error: 3.5996e-06 - val_loss: 7.8517e-06 - val_mean_squared_error: 3.7068e-06\n","Epoch 49/350\n","225/225 [==============================] - 1s 5ms/step - loss: 8.0436e-06 - mean_squared_error: 3.4844e-06 - val_loss: 7.7169e-06 - val_mean_squared_error: 3.5824e-06\n","Epoch 50/350\n","225/225 [==============================] - 1s 6ms/step - loss: 7.9226e-06 - mean_squared_error: 3.3828e-06 - val_loss: 7.5946e-06 - val_mean_squared_error: 3.4728e-06\n","Epoch 51/350\n","225/225 [==============================] - 1s 5ms/step - loss: 7.8107e-06 - mean_squared_error: 3.2932e-06 - val_loss: 7.4827e-06 - val_mean_squared_error: 3.3760e-06\n","Epoch 52/350\n","225/225 [==============================] - 1s 5ms/step - loss: 7.7062e-06 - mean_squared_error: 3.2144e-06 - val_loss: 7.3799e-06 - val_mean_squared_error: 3.2909e-06\n","Epoch 53/350\n","225/225 [==============================] - 1s 5ms/step - loss: 7.6079e-06 - mean_squared_error: 3.1452e-06 - val_loss: 7.2844e-06 - val_mean_squared_error: 3.2159e-06\n","Epoch 54/350\n","225/225 [==============================] - 1s 5ms/step - loss: 7.5141e-06 - mean_squared_error: 3.0845e-06 - val_loss: 7.1949e-06 - val_mean_squared_error: 3.1502e-06\n","Epoch 55/350\n","225/225 [==============================] - 1s 5ms/step - loss: 7.4239e-06 - mean_squared_error: 3.0315e-06 - val_loss: 7.1101e-06 - val_mean_squared_error: 3.0928e-06\n","Epoch 56/350\n","225/225 [==============================] - 1s 5ms/step - loss: 7.3358e-06 - mean_squared_error: 2.9852e-06 - val_loss: 7.0288e-06 - val_mean_squared_error: 3.0427e-06\n","Epoch 57/350\n","225/225 [==============================] - 2s 7ms/step - loss: 7.2491e-06 - mean_squared_error: 2.9451e-06 - val_loss: 6.9499e-06 - val_mean_squared_error: 2.9991e-06\n","Epoch 58/350\n","225/225 [==============================] - 1s 5ms/step - loss: 7.1626e-06 - mean_squared_error: 2.9105e-06 - val_loss: 6.8723e-06 - val_mean_squared_error: 2.9614e-06\n","Epoch 59/350\n","225/225 [==============================] - 1s 5ms/step - loss: 7.0755e-06 - mean_squared_error: 2.8808e-06 - val_loss: 6.7953e-06 - val_mean_squared_error: 2.9290e-06\n","Epoch 60/350\n","225/225 [==============================] - 1s 5ms/step - loss: 6.9871e-06 - mean_squared_error: 2.8556e-06 - val_loss: 6.7180e-06 - val_mean_squared_error: 2.9015e-06\n","Epoch 61/350\n","225/225 [==============================] - 1s 5ms/step - loss: 6.8966e-06 - mean_squared_error: 2.8344e-06 - val_loss: 6.6397e-06 - val_mean_squared_error: 2.8782e-06\n","Epoch 62/350\n","225/225 [==============================] - 1s 6ms/step - loss: 6.8037e-06 - mean_squared_error: 2.8168e-06 - val_loss: 6.5597e-06 - val_mean_squared_error: 2.8588e-06\n","Epoch 63/350\n","225/225 [==============================] - 1s 6ms/step - loss: 6.7078e-06 - mean_squared_error: 2.8027e-06 - val_loss: 6.4775e-06 - val_mean_squared_error: 2.8430e-06\n","Epoch 64/350\n","225/225 [==============================] - 1s 5ms/step - loss: 6.6087e-06 - mean_squared_error: 2.7914e-06 - val_loss: 6.3925e-06 - val_mean_squared_error: 2.8303e-06\n","Epoch 65/350\n","225/225 [==============================] - 1s 5ms/step - loss: 6.5059e-06 - mean_squared_error: 2.7831e-06 - val_loss: 6.3041e-06 - val_mean_squared_error: 2.8205e-06\n","Epoch 66/350\n","225/225 [==============================] - 1s 6ms/step - loss: 6.3992e-06 - mean_squared_error: 2.7775e-06 - val_loss: 6.2118e-06 - val_mean_squared_error: 2.8134e-06\n","Epoch 67/350\n","225/225 [==============================] - 1s 5ms/step - loss: 6.2879e-06 - mean_squared_error: 2.7742e-06 - val_loss: 6.1146e-06 - val_mean_squared_error: 2.8088e-06\n","Epoch 68/350\n","225/225 [==============================] - 1s 5ms/step - loss: 6.1711e-06 - mean_squared_error: 2.7735e-06 - val_loss: 6.0114e-06 - val_mean_squared_error: 2.8065e-06\n","Epoch 69/350\n","225/225 [==============================] - 1s 6ms/step - loss: 6.0475e-06 - mean_squared_error: 2.7748e-06 - val_loss: 5.9008e-06 - val_mean_squared_error: 2.8061e-06\n","Epoch 70/350\n","225/225 [==============================] - 1s 5ms/step - loss: 5.9156e-06 - mean_squared_error: 2.7784e-06 - val_loss: 5.7811e-06 - val_mean_squared_error: 2.8072e-06\n","Epoch 71/350\n","225/225 [==============================] - 1s 5ms/step - loss: 5.7737e-06 - mean_squared_error: 2.7833e-06 - val_loss: 5.6512e-06 - val_mean_squared_error: 2.8086e-06\n","Epoch 72/350\n","225/225 [==============================] - 1s 5ms/step - loss: 5.6213e-06 - mean_squared_error: 2.7881e-06 - val_loss: 5.5104e-06 - val_mean_squared_error: 2.8083e-06\n","Epoch 73/350\n","225/225 [==============================] - 1s 5ms/step - loss: 5.4586e-06 - mean_squared_error: 2.7910e-06 - val_loss: 5.3595e-06 - val_mean_squared_error: 2.8055e-06\n","Epoch 74/350\n","225/225 [==============================] - 1s 5ms/step - loss: 5.2879e-06 - mean_squared_error: 2.7904e-06 - val_loss: 5.2004e-06 - val_mean_squared_error: 2.7970e-06\n","Epoch 75/350\n","225/225 [==============================] - 2s 7ms/step - loss: 5.1122e-06 - mean_squared_error: 2.7845e-06 - val_loss: 5.0361e-06 - val_mean_squared_error: 2.7820e-06\n","Epoch 76/350\n","225/225 [==============================] - 1s 5ms/step - loss: 4.9350e-06 - mean_squared_error: 2.7696e-06 - val_loss: 4.8698e-06 - val_mean_squared_error: 2.7622e-06\n","Epoch 77/350\n","225/225 [==============================] - 1s 5ms/step - loss: 4.7596e-06 - mean_squared_error: 2.7500e-06 - val_loss: 4.7044e-06 - val_mean_squared_error: 2.7374e-06\n","Epoch 78/350\n","225/225 [==============================] - 1s 5ms/step - loss: 4.5888e-06 - mean_squared_error: 2.7248e-06 - val_loss: 4.5422e-06 - val_mean_squared_error: 2.7091e-06\n","Epoch 79/350\n","225/225 [==============================] - 1s 5ms/step - loss: 4.4242e-06 - mean_squared_error: 2.6951e-06 - val_loss: 4.3845e-06 - val_mean_squared_error: 2.6783e-06\n","Epoch 80/350\n","225/225 [==============================] - 1s 5ms/step - loss: 4.2665e-06 - mean_squared_error: 2.6615e-06 - val_loss: 4.2316e-06 - val_mean_squared_error: 2.6456e-06\n","Epoch 81/350\n","225/225 [==============================] - 1s 5ms/step - loss: 4.1153e-06 - mean_squared_error: 2.6265e-06 - val_loss: 4.0831e-06 - val_mean_squared_error: 2.6086e-06\n","Epoch 82/350\n","225/225 [==============================] - 1s 5ms/step - loss: 3.9695e-06 - mean_squared_error: 2.5862e-06 - val_loss: 3.9372e-06 - val_mean_squared_error: 2.5687e-06\n","Epoch 83/350\n","225/225 [==============================] - 1s 5ms/step - loss: 3.8268e-06 - mean_squared_error: 2.5419e-06 - val_loss: 3.7916e-06 - val_mean_squared_error: 2.5235e-06\n","Epoch 84/350\n","225/225 [==============================] - 1s 5ms/step - loss: 3.6843e-06 - mean_squared_error: 2.4932e-06 - val_loss: 3.6431e-06 - val_mean_squared_error: 2.4672e-06\n","Epoch 85/350\n","225/225 [==============================] - 1s 5ms/step - loss: 3.5377e-06 - mean_squared_error: 2.4318e-06 - val_loss: 3.4857e-06 - val_mean_squared_error: 2.4018e-06\n","Epoch 86/350\n","225/225 [==============================] - 1s 5ms/step - loss: 3.3813e-06 - mean_squared_error: 2.3602e-06 - val_loss: 3.3118e-06 - val_mean_squared_error: 2.3158e-06\n","Epoch 87/350\n","225/225 [==============================] - 1s 5ms/step - loss: 3.2065e-06 - mean_squared_error: 2.2665e-06 - val_loss: 3.1105e-06 - val_mean_squared_error: 2.2005e-06\n","Epoch 88/350\n","225/225 [==============================] - 1s 5ms/step - loss: 3.0015e-06 - mean_squared_error: 2.1397e-06 - val_loss: 2.8699e-06 - val_mean_squared_error: 2.0467e-06\n","Epoch 89/350\n","225/225 [==============================] - 1s 5ms/step - loss: 2.7538e-06 - mean_squared_error: 1.9697e-06 - val_loss: 2.5934e-06 - val_mean_squared_error: 1.8552e-06\n","Epoch 90/350\n","225/225 [==============================] - 1s 6ms/step - loss: 2.4714e-06 - mean_squared_error: 1.7571e-06 - val_loss: 2.3312e-06 - val_mean_squared_error: 1.6607e-06\n","Epoch 91/350\n","225/225 [==============================] - 1s 5ms/step - loss: 2.2110e-06 - mean_squared_error: 1.5513e-06 - val_loss: 2.1496e-06 - val_mean_squared_error: 1.5260e-06\n","Epoch 92/350\n","225/225 [==============================] - 1s 5ms/step - loss: 2.0240e-06 - mean_squared_error: 1.4023e-06 - val_loss: 2.0987e-06 - val_mean_squared_error: 1.5134e-06\n","Epoch 93/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.9072e-06 - mean_squared_error: 1.3141e-06 - val_loss: 2.0464e-06 - val_mean_squared_error: 1.4858e-06\n","Epoch 94/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.8339e-06 - mean_squared_error: 1.2649e-06 - val_loss: 1.9701e-06 - val_mean_squared_error: 1.4277e-06\n","Epoch 95/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.7863e-06 - mean_squared_error: 1.2384e-06 - val_loss: 1.9819e-06 - val_mean_squared_error: 1.4623e-06\n","Epoch 96/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.7499e-06 - mean_squared_error: 1.2214e-06 - val_loss: 1.9666e-06 - val_mean_squared_error: 1.4658e-06\n","Epoch 97/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.7203e-06 - mean_squared_error: 1.2106e-06 - val_loss: 1.9805e-06 - val_mean_squared_error: 1.4990e-06\n","Epoch 98/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.6962e-06 - mean_squared_error: 1.2037e-06 - val_loss: 1.9673e-06 - val_mean_squared_error: 1.5024e-06\n","Epoch 99/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.6760e-06 - mean_squared_error: 1.2001e-06 - val_loss: 1.9381e-06 - val_mean_squared_error: 1.4879e-06\n","Epoch 100/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.6563e-06 - mean_squared_error: 1.1957e-06 - val_loss: 1.8961e-06 - val_mean_squared_error: 1.4593e-06\n","Epoch 101/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.6404e-06 - mean_squared_error: 1.1942e-06 - val_loss: 1.9902e-06 - val_mean_squared_error: 1.5721e-06\n","Epoch 102/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.6250e-06 - mean_squared_error: 1.1931e-06 - val_loss: 1.8626e-06 - val_mean_squared_error: 1.4526e-06\n","Epoch 103/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.6112e-06 - mean_squared_error: 1.1923e-06 - val_loss: 1.9383e-06 - val_mean_squared_error: 1.5446e-06\n","Epoch 104/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.5974e-06 - mean_squared_error: 1.1911e-06 - val_loss: 1.7826e-06 - val_mean_squared_error: 1.3943e-06\n","Epoch 105/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.5855e-06 - mean_squared_error: 1.1906e-06 - val_loss: 1.8171e-06 - val_mean_squared_error: 1.4425e-06\n","Epoch 106/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.5729e-06 - mean_squared_error: 1.1894e-06 - val_loss: 1.8577e-06 - val_mean_squared_error: 1.4960e-06\n","Epoch 107/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.5613e-06 - mean_squared_error: 1.1886e-06 - val_loss: 1.8203e-06 - val_mean_squared_error: 1.4678e-06\n","Epoch 108/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.5508e-06 - mean_squared_error: 1.1884e-06 - val_loss: 1.7075e-06 - val_mean_squared_error: 1.3601e-06\n","Epoch 109/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.5418e-06 - mean_squared_error: 1.1888e-06 - val_loss: 1.7954e-06 - val_mean_squared_error: 1.4618e-06\n","Epoch 110/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.5308e-06 - mean_squared_error: 1.1872e-06 - val_loss: 1.7530e-06 - val_mean_squared_error: 1.4269e-06\n","Epoch 111/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.5230e-06 - mean_squared_error: 1.1882e-06 - val_loss: 1.7265e-06 - val_mean_squared_error: 1.4082e-06\n","Epoch 112/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.5135e-06 - mean_squared_error: 1.1870e-06 - val_loss: 1.6877e-06 - val_mean_squared_error: 1.3762e-06\n","Epoch 113/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.5050e-06 - mean_squared_error: 1.1863e-06 - val_loss: 1.6919e-06 - val_mean_squared_error: 1.3886e-06\n","Epoch 114/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.4963e-06 - mean_squared_error: 1.1854e-06 - val_loss: 1.6797e-06 - val_mean_squared_error: 1.3835e-06\n","Epoch 115/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.4888e-06 - mean_squared_error: 1.1849e-06 - val_loss: 1.6770e-06 - val_mean_squared_error: 1.3879e-06\n","Epoch 116/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.4817e-06 - mean_squared_error: 1.1846e-06 - val_loss: 1.7085e-06 - val_mean_squared_error: 1.4276e-06\n","Epoch 117/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.4749e-06 - mean_squared_error: 1.1846e-06 - val_loss: 1.6463e-06 - val_mean_squared_error: 1.3697e-06\n","Epoch 118/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.4674e-06 - mean_squared_error: 1.1831e-06 - val_loss: 1.6673e-06 - val_mean_squared_error: 1.3979e-06\n","Epoch 119/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.4614e-06 - mean_squared_error: 1.1835e-06 - val_loss: 1.6287e-06 - val_mean_squared_error: 1.3639e-06\n","Epoch 120/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.4557e-06 - mean_squared_error: 1.1835e-06 - val_loss: 1.5949e-06 - val_mean_squared_error: 1.3347e-06\n","Epoch 121/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.4488e-06 - mean_squared_error: 1.1821e-06 - val_loss: 1.5582e-06 - val_mean_squared_error: 1.3020e-06\n","Epoch 122/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.4430e-06 - mean_squared_error: 1.1819e-06 - val_loss: 1.4991e-06 - val_mean_squared_error: 1.2446e-06\n","Epoch 123/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.4384e-06 - mean_squared_error: 1.1820e-06 - val_loss: 1.5476e-06 - val_mean_squared_error: 1.3017e-06\n","Epoch 124/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.4320e-06 - mean_squared_error: 1.1808e-06 - val_loss: 1.5069e-06 - val_mean_squared_error: 1.2638e-06\n","Epoch 125/350\n","225/225 [==============================] - 2s 8ms/step - loss: 1.4274e-06 - mean_squared_error: 1.1808e-06 - val_loss: 1.5280e-06 - val_mean_squared_error: 1.2912e-06\n","Epoch 126/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.4219e-06 - mean_squared_error: 1.1799e-06 - val_loss: 1.5060e-06 - val_mean_squared_error: 1.2728e-06\n","Epoch 127/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.4175e-06 - mean_squared_error: 1.1799e-06 - val_loss: 1.5023e-06 - val_mean_squared_error: 1.2736e-06\n","Epoch 128/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.4122e-06 - mean_squared_error: 1.1790e-06 - val_loss: 1.4847e-06 - val_mean_squared_error: 1.2594e-06\n","Epoch 129/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.4079e-06 - mean_squared_error: 1.1785e-06 - val_loss: 1.5043e-06 - val_mean_squared_error: 1.2845e-06\n","Epoch 130/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.4033e-06 - mean_squared_error: 1.1782e-06 - val_loss: 1.4848e-06 - val_mean_squared_error: 1.2681e-06\n","Epoch 131/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3989e-06 - mean_squared_error: 1.1775e-06 - val_loss: 1.4713e-06 - val_mean_squared_error: 1.2579e-06\n","Epoch 132/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3956e-06 - mean_squared_error: 1.1779e-06 - val_loss: 1.4571e-06 - val_mean_squared_error: 1.2467e-06\n","Epoch 133/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3905e-06 - mean_squared_error: 1.1765e-06 - val_loss: 1.4405e-06 - val_mean_squared_error: 1.2328e-06\n","Epoch 134/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.3870e-06 - mean_squared_error: 1.1763e-06 - val_loss: 1.4198e-06 - val_mean_squared_error: 1.2142e-06\n","Epoch 135/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.3835e-06 - mean_squared_error: 1.1761e-06 - val_loss: 1.4303e-06 - val_mean_squared_error: 1.2293e-06\n","Epoch 136/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3788e-06 - mean_squared_error: 1.1748e-06 - val_loss: 1.4265e-06 - val_mean_squared_error: 1.2287e-06\n","Epoch 137/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3769e-06 - mean_squared_error: 1.1761e-06 - val_loss: 1.4026e-06 - val_mean_squared_error: 1.2062e-06\n","Epoch 138/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.3723e-06 - mean_squared_error: 1.1744e-06 - val_loss: 1.4007e-06 - val_mean_squared_error: 1.2075e-06\n","Epoch 139/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.3697e-06 - mean_squared_error: 1.1748e-06 - val_loss: 1.3914e-06 - val_mean_squared_error: 1.2005e-06\n","Epoch 140/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.3658e-06 - mean_squared_error: 1.1736e-06 - val_loss: 1.3917e-06 - val_mean_squared_error: 1.2040e-06\n","Epoch 141/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3631e-06 - mean_squared_error: 1.1737e-06 - val_loss: 1.3992e-06 - val_mean_squared_error: 1.2153e-06\n","Epoch 142/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3595e-06 - mean_squared_error: 1.1728e-06 - val_loss: 1.3778e-06 - val_mean_squared_error: 1.1946e-06\n","Epoch 143/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.3564e-06 - mean_squared_error: 1.1724e-06 - val_loss: 1.3706e-06 - val_mean_squared_error: 1.1895e-06\n","Epoch 144/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.3537e-06 - mean_squared_error: 1.1721e-06 - val_loss: 1.3646e-06 - val_mean_squared_error: 1.1853e-06\n","Epoch 145/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.3512e-06 - mean_squared_error: 1.1720e-06 - val_loss: 1.3713e-06 - val_mean_squared_error: 1.1961e-06\n","Epoch 146/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.3477e-06 - mean_squared_error: 1.1711e-06 - val_loss: 1.3601e-06 - val_mean_squared_error: 1.1860e-06\n","Epoch 147/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.3456e-06 - mean_squared_error: 1.1712e-06 - val_loss: 1.3544e-06 - val_mean_squared_error: 1.1821e-06\n","Epoch 148/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3430e-06 - mean_squared_error: 1.1708e-06 - val_loss: 1.3586e-06 - val_mean_squared_error: 1.1900e-06\n","Epoch 149/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.3401e-06 - mean_squared_error: 1.1703e-06 - val_loss: 1.3515e-06 - val_mean_squared_error: 1.1843e-06\n","Epoch 150/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3377e-06 - mean_squared_error: 1.1700e-06 - val_loss: 1.3435e-06 - val_mean_squared_error: 1.1766e-06\n","Epoch 151/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.3352e-06 - mean_squared_error: 1.1696e-06 - val_loss: 1.3427e-06 - val_mean_squared_error: 1.1791e-06\n","Epoch 152/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.3325e-06 - mean_squared_error: 1.1688e-06 - val_loss: 1.3519e-06 - val_mean_squared_error: 1.1923e-06\n","Epoch 153/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.3303e-06 - mean_squared_error: 1.1688e-06 - val_loss: 1.3381e-06 - val_mean_squared_error: 1.1787e-06\n","Epoch 154/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.3277e-06 - mean_squared_error: 1.1682e-06 - val_loss: 1.3337e-06 - val_mean_squared_error: 1.1757e-06\n","Epoch 155/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.3258e-06 - mean_squared_error: 1.1682e-06 - val_loss: 1.3308e-06 - val_mean_squared_error: 1.1744e-06\n","Epoch 156/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.3234e-06 - mean_squared_error: 1.1678e-06 - val_loss: 1.3283e-06 - val_mean_squared_error: 1.1734e-06\n","Epoch 157/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.3212e-06 - mean_squared_error: 1.1673e-06 - val_loss: 1.3269e-06 - val_mean_squared_error: 1.1748e-06\n","Epoch 158/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3195e-06 - mean_squared_error: 1.1675e-06 - val_loss: 1.3240e-06 - val_mean_squared_error: 1.1735e-06\n","Epoch 159/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3169e-06 - mean_squared_error: 1.1666e-06 - val_loss: 1.3229e-06 - val_mean_squared_error: 1.1745e-06\n","Epoch 160/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.3145e-06 - mean_squared_error: 1.1660e-06 - val_loss: 1.3194e-06 - val_mean_squared_error: 1.1714e-06\n","Epoch 161/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3129e-06 - mean_squared_error: 1.1661e-06 - val_loss: 1.3172e-06 - val_mean_squared_error: 1.1710e-06\n","Epoch 162/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3115e-06 - mean_squared_error: 1.1663e-06 - val_loss: 1.3159e-06 - val_mean_squared_error: 1.1725e-06\n","Epoch 163/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.3093e-06 - mean_squared_error: 1.1659e-06 - val_loss: 1.3131e-06 - val_mean_squared_error: 1.1711e-06\n","Epoch 164/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3073e-06 - mean_squared_error: 1.1655e-06 - val_loss: 1.3109e-06 - val_mean_squared_error: 1.1697e-06\n","Epoch 165/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3052e-06 - mean_squared_error: 1.1648e-06 - val_loss: 1.3088e-06 - val_mean_squared_error: 1.1697e-06\n","Epoch 166/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3038e-06 - mean_squared_error: 1.1651e-06 - val_loss: 1.3110e-06 - val_mean_squared_error: 1.1715e-06\n","Epoch 167/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.3018e-06 - mean_squared_error: 1.1645e-06 - val_loss: 1.3048e-06 - val_mean_squared_error: 1.1685e-06\n","Epoch 168/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.3002e-06 - mean_squared_error: 1.1644e-06 - val_loss: 1.3030e-06 - val_mean_squared_error: 1.1680e-06\n","Epoch 169/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2987e-06 - mean_squared_error: 1.1644e-06 - val_loss: 1.3013e-06 - val_mean_squared_error: 1.1676e-06\n","Epoch 170/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2965e-06 - mean_squared_error: 1.1638e-06 - val_loss: 1.3037e-06 - val_mean_squared_error: 1.1702e-06\n","Epoch 171/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2949e-06 - mean_squared_error: 1.1634e-06 - val_loss: 1.2975e-06 - val_mean_squared_error: 1.1669e-06\n","Epoch 172/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.2937e-06 - mean_squared_error: 1.1637e-06 - val_loss: 1.2962e-06 - val_mean_squared_error: 1.1666e-06\n","Epoch 173/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2915e-06 - mean_squared_error: 1.1629e-06 - val_loss: 1.3018e-06 - val_mean_squared_error: 1.1719e-06\n","Epoch 174/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2901e-06 - mean_squared_error: 1.1627e-06 - val_loss: 1.2953e-06 - val_mean_squared_error: 1.1676e-06\n","Epoch 175/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.2885e-06 - mean_squared_error: 1.1623e-06 - val_loss: 1.2909e-06 - val_mean_squared_error: 1.1654e-06\n","Epoch 176/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.2869e-06 - mean_squared_error: 1.1620e-06 - val_loss: 1.2916e-06 - val_mean_squared_error: 1.1666e-06\n","Epoch 177/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.2858e-06 - mean_squared_error: 1.1622e-06 - val_loss: 1.2967e-06 - val_mean_squared_error: 1.1718e-06\n","Epoch 178/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2850e-06 - mean_squared_error: 1.1626e-06 - val_loss: 1.2914e-06 - val_mean_squared_error: 1.1682e-06\n","Epoch 179/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2820e-06 - mean_squared_error: 1.1607e-06 - val_loss: 1.2899e-06 - val_mean_squared_error: 1.1680e-06\n","Epoch 180/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2811e-06 - mean_squared_error: 1.1610e-06 - val_loss: 1.2839e-06 - val_mean_squared_error: 1.1642e-06\n","Epoch 181/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.2799e-06 - mean_squared_error: 1.1610e-06 - val_loss: 1.2816e-06 - val_mean_squared_error: 1.1634e-06\n","Epoch 182/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2791e-06 - mean_squared_error: 1.1614e-06 - val_loss: 1.2858e-06 - val_mean_squared_error: 1.1673e-06\n","Epoch 183/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.2771e-06 - mean_squared_error: 1.1606e-06 - val_loss: 1.2837e-06 - val_mean_squared_error: 1.1665e-06\n","Epoch 184/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.2763e-06 - mean_squared_error: 1.1606e-06 - val_loss: 1.2776e-06 - val_mean_squared_error: 1.1626e-06\n","Epoch 185/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2747e-06 - mean_squared_error: 1.1604e-06 - val_loss: 1.2890e-06 - val_mean_squared_error: 1.1729e-06\n","Epoch 186/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.2735e-06 - mean_squared_error: 1.1599e-06 - val_loss: 1.2756e-06 - val_mean_squared_error: 1.1624e-06\n","Epoch 187/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.2718e-06 - mean_squared_error: 1.1595e-06 - val_loss: 1.2761e-06 - val_mean_squared_error: 1.1636e-06\n","Epoch 188/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2704e-06 - mean_squared_error: 1.1591e-06 - val_loss: 1.2809e-06 - val_mean_squared_error: 1.1685e-06\n","Epoch 189/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.2697e-06 - mean_squared_error: 1.1593e-06 - val_loss: 1.2758e-06 - val_mean_squared_error: 1.1649e-06\n","Epoch 190/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2685e-06 - mean_squared_error: 1.1592e-06 - val_loss: 1.2737e-06 - val_mean_squared_error: 1.1639e-06\n","Epoch 191/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.2669e-06 - mean_squared_error: 1.1586e-06 - val_loss: 1.2786e-06 - val_mean_squared_error: 1.1690e-06\n","Epoch 192/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.2661e-06 - mean_squared_error: 1.1587e-06 - val_loss: 1.2729e-06 - val_mean_squared_error: 1.1649e-06\n","Epoch 193/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2648e-06 - mean_squared_error: 1.1584e-06 - val_loss: 1.2689e-06 - val_mean_squared_error: 1.1623e-06\n","Epoch 194/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2636e-06 - mean_squared_error: 1.1581e-06 - val_loss: 1.2763e-06 - val_mean_squared_error: 1.1695e-06\n","Epoch 195/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2624e-06 - mean_squared_error: 1.1578e-06 - val_loss: 1.2675e-06 - val_mean_squared_error: 1.1626e-06\n","Epoch 196/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2616e-06 - mean_squared_error: 1.1580e-06 - val_loss: 1.2667e-06 - val_mean_squared_error: 1.1627e-06\n","Epoch 197/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2598e-06 - mean_squared_error: 1.1571e-06 - val_loss: 1.2659e-06 - val_mean_squared_error: 1.1628e-06\n","Epoch 198/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2588e-06 - mean_squared_error: 1.1570e-06 - val_loss: 1.2699e-06 - val_mean_squared_error: 1.1670e-06\n","Epoch 199/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.2578e-06 - mean_squared_error: 1.1568e-06 - val_loss: 1.2710e-06 - val_mean_squared_error: 1.1688e-06\n","Epoch 200/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.2571e-06 - mean_squared_error: 1.1570e-06 - val_loss: 1.2680e-06 - val_mean_squared_error: 1.1669e-06\n","Epoch 201/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.2561e-06 - mean_squared_error: 1.1569e-06 - val_loss: 1.2605e-06 - val_mean_squared_error: 1.1611e-06\n","Epoch 202/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.2554e-06 - mean_squared_error: 1.1570e-06 - val_loss: 1.2640e-06 - val_mean_squared_error: 1.1648e-06\n","Epoch 203/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.2542e-06 - mean_squared_error: 1.1568e-06 - val_loss: 1.2607e-06 - val_mean_squared_error: 1.1626e-06\n","Epoch 204/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.2524e-06 - mean_squared_error: 1.1556e-06 - val_loss: 1.2568e-06 - val_mean_squared_error: 1.1599e-06\n","Epoch 205/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2521e-06 - mean_squared_error: 1.1563e-06 - val_loss: 1.2700e-06 - val_mean_squared_error: 1.1724e-06\n","Epoch 206/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2514e-06 - mean_squared_error: 1.1563e-06 - val_loss: 1.2599e-06 - val_mean_squared_error: 1.1639e-06\n","Epoch 207/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2499e-06 - mean_squared_error: 1.1557e-06 - val_loss: 1.2679e-06 - val_mean_squared_error: 1.1719e-06\n","Epoch 208/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.2488e-06 - mean_squared_error: 1.1552e-06 - val_loss: 1.2551e-06 - val_mean_squared_error: 1.1611e-06\n","Epoch 209/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2483e-06 - mean_squared_error: 1.1556e-06 - val_loss: 1.2582e-06 - val_mean_squared_error: 1.1645e-06\n","Epoch 210/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2471e-06 - mean_squared_error: 1.1551e-06 - val_loss: 1.2605e-06 - val_mean_squared_error: 1.1672e-06\n","Epoch 211/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2462e-06 - mean_squared_error: 1.1550e-06 - val_loss: 1.2638e-06 - val_mean_squared_error: 1.1709e-06\n","Epoch 212/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2458e-06 - mean_squared_error: 1.1552e-06 - val_loss: 1.2570e-06 - val_mean_squared_error: 1.1653e-06\n","Epoch 213/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.2443e-06 - mean_squared_error: 1.1544e-06 - val_loss: 1.2496e-06 - val_mean_squared_error: 1.1594e-06\n","Epoch 214/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2438e-06 - mean_squared_error: 1.1547e-06 - val_loss: 1.2661e-06 - val_mean_squared_error: 1.1750e-06\n","Epoch 215/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2425e-06 - mean_squared_error: 1.1541e-06 - val_loss: 1.2588e-06 - val_mean_squared_error: 1.1689e-06\n","Epoch 216/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2419e-06 - mean_squared_error: 1.1540e-06 - val_loss: 1.2547e-06 - val_mean_squared_error: 1.1658e-06\n","Epoch 217/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.2413e-06 - mean_squared_error: 1.1542e-06 - val_loss: 1.2502e-06 - val_mean_squared_error: 1.1623e-06\n","Epoch 218/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.2402e-06 - mean_squared_error: 1.1538e-06 - val_loss: 1.2582e-06 - val_mean_squared_error: 1.1702e-06\n","Epoch 219/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2391e-06 - mean_squared_error: 1.1534e-06 - val_loss: 1.2582e-06 - val_mean_squared_error: 1.1708e-06\n","Epoch 220/350\n","225/225 [==============================] - 2s 8ms/step - loss: 1.2385e-06 - mean_squared_error: 1.1534e-06 - val_loss: 1.2499e-06 - val_mean_squared_error: 1.1638e-06\n","Epoch 221/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2381e-06 - mean_squared_error: 1.1535e-06 - val_loss: 1.2437e-06 - val_mean_squared_error: 1.1588e-06\n","Epoch 222/350\n","225/225 [==============================] - 2s 8ms/step - loss: 1.2372e-06 - mean_squared_error: 1.1535e-06 - val_loss: 1.2495e-06 - val_mean_squared_error: 1.1646e-06\n","Epoch 223/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2365e-06 - mean_squared_error: 1.1533e-06 - val_loss: 1.2498e-06 - val_mean_squared_error: 1.1655e-06\n","Epoch 224/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.2354e-06 - mean_squared_error: 1.1528e-06 - val_loss: 1.2478e-06 - val_mean_squared_error: 1.1642e-06\n","Epoch 225/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.2350e-06 - mean_squared_error: 1.1531e-06 - val_loss: 1.2456e-06 - val_mean_squared_error: 1.1628e-06\n","Epoch 226/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.2346e-06 - mean_squared_error: 1.1533e-06 - val_loss: 1.2452e-06 - val_mean_squared_error: 1.1629e-06\n","Epoch 227/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.2329e-06 - mean_squared_error: 1.1522e-06 - val_loss: 1.2557e-06 - val_mean_squared_error: 1.1732e-06\n","Epoch 228/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.2323e-06 - mean_squared_error: 1.1522e-06 - val_loss: 1.2490e-06 - val_mean_squared_error: 1.1675e-06\n","Epoch 229/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2317e-06 - mean_squared_error: 1.1522e-06 - val_loss: 1.2604e-06 - val_mean_squared_error: 1.1786e-06\n","Epoch 230/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2308e-06 - mean_squared_error: 1.1518e-06 - val_loss: 1.2460e-06 - val_mean_squared_error: 1.1658e-06\n","Epoch 231/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.2304e-06 - mean_squared_error: 1.1521e-06 - val_loss: 1.2537e-06 - val_mean_squared_error: 1.1735e-06\n","Epoch 232/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.2296e-06 - mean_squared_error: 1.1518e-06 - val_loss: 1.2464e-06 - val_mean_squared_error: 1.1672e-06\n","Epoch 233/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2289e-06 - mean_squared_error: 1.1516e-06 - val_loss: 1.2466e-06 - val_mean_squared_error: 1.1679e-06\n","Epoch 234/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2280e-06 - mean_squared_error: 1.1513e-06 - val_loss: 1.2523e-06 - val_mean_squared_error: 1.1738e-06\n","Epoch 235/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.2278e-06 - mean_squared_error: 1.1516e-06 - val_loss: 1.2531e-06 - val_mean_squared_error: 1.1750e-06\n","Epoch 236/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.2269e-06 - mean_squared_error: 1.1512e-06 - val_loss: 1.2443e-06 - val_mean_squared_error: 1.1673e-06\n","Epoch 237/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.2262e-06 - mean_squared_error: 1.1511e-06 - val_loss: 1.2388e-06 - val_mean_squared_error: 1.1627e-06\n","Epoch 238/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.2253e-06 - mean_squared_error: 1.1507e-06 - val_loss: 1.2381e-06 - val_mean_squared_error: 1.1626e-06\n","Epoch 239/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2247e-06 - mean_squared_error: 1.1507e-06 - val_loss: 1.2504e-06 - val_mean_squared_error: 1.1745e-06\n","Epoch 240/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2242e-06 - mean_squared_error: 1.1506e-06 - val_loss: 1.2421e-06 - val_mean_squared_error: 1.1672e-06\n","Epoch 241/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.2238e-06 - mean_squared_error: 1.1508e-06 - val_loss: 1.2438e-06 - val_mean_squared_error: 1.1692e-06\n","Epoch 242/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.2231e-06 - mean_squared_error: 1.1507e-06 - val_loss: 1.2501e-06 - val_mean_squared_error: 1.1756e-06\n","Epoch 243/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2223e-06 - mean_squared_error: 1.1503e-06 - val_loss: 1.2446e-06 - val_mean_squared_error: 1.1710e-06\n","Epoch 244/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2216e-06 - mean_squared_error: 1.1501e-06 - val_loss: 1.2388e-06 - val_mean_squared_error: 1.1660e-06\n","Epoch 245/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2207e-06 - mean_squared_error: 1.1497e-06 - val_loss: 1.2363e-06 - val_mean_squared_error: 1.1641e-06\n","Epoch 246/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2202e-06 - mean_squared_error: 1.1496e-06 - val_loss: 1.2442e-06 - val_mean_squared_error: 1.1719e-06\n","Epoch 247/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2206e-06 - mean_squared_error: 1.1504e-06 - val_loss: 1.2317e-06 - val_mean_squared_error: 1.1607e-06\n","Epoch 248/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2192e-06 - mean_squared_error: 1.1496e-06 - val_loss: 1.2469e-06 - val_mean_squared_error: 1.1754e-06\n","Epoch 249/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2182e-06 - mean_squared_error: 1.1491e-06 - val_loss: 1.2426e-06 - val_mean_squared_error: 1.1718e-06\n","Epoch 250/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.2182e-06 - mean_squared_error: 1.1494e-06 - val_loss: 1.2381e-06 - val_mean_squared_error: 1.1679e-06\n","Epoch 251/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2174e-06 - mean_squared_error: 1.1492e-06 - val_loss: 1.2308e-06 - val_mean_squared_error: 1.1616e-06\n","Epoch 252/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2172e-06 - mean_squared_error: 1.1494e-06 - val_loss: 1.2307e-06 - val_mean_squared_error: 1.1619e-06\n","Epoch 253/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2171e-06 - mean_squared_error: 1.1498e-06 - val_loss: 1.2332e-06 - val_mean_squared_error: 1.1647e-06\n","Epoch 254/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2160e-06 - mean_squared_error: 1.1491e-06 - val_loss: 1.2405e-06 - val_mean_squared_error: 1.1720e-06\n","Epoch 255/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2151e-06 - mean_squared_error: 1.1487e-06 - val_loss: 1.2442e-06 - val_mean_squared_error: 1.1759e-06\n","Epoch 256/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2148e-06 - mean_squared_error: 1.1488e-06 - val_loss: 1.2359e-06 - val_mean_squared_error: 1.1684e-06\n","Epoch 257/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2140e-06 - mean_squared_error: 1.1484e-06 - val_loss: 1.2401e-06 - val_mean_squared_error: 1.1728e-06\n","Epoch 258/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2143e-06 - mean_squared_error: 1.1491e-06 - val_loss: 1.2417e-06 - val_mean_squared_error: 1.1747e-06\n","Epoch 259/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2131e-06 - mean_squared_error: 1.1483e-06 - val_loss: 1.2324e-06 - val_mean_squared_error: 1.1664e-06\n","Epoch 260/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2132e-06 - mean_squared_error: 1.1489e-06 - val_loss: 1.2348e-06 - val_mean_squared_error: 1.1690e-06\n","Epoch 261/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2123e-06 - mean_squared_error: 1.1483e-06 - val_loss: 1.2352e-06 - val_mean_squared_error: 1.1697e-06\n","Epoch 262/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2114e-06 - mean_squared_error: 1.1479e-06 - val_loss: 1.2296e-06 - val_mean_squared_error: 1.1648e-06\n","Epoch 263/350\n","225/225 [==============================] - 2s 8ms/step - loss: 1.2106e-06 - mean_squared_error: 1.1476e-06 - val_loss: 1.2457e-06 - val_mean_squared_error: 1.1805e-06\n","Epoch 264/350\n","225/225 [==============================] - 2s 10ms/step - loss: 1.2107e-06 - mean_squared_error: 1.1479e-06 - val_loss: 1.2362e-06 - val_mean_squared_error: 1.1718e-06\n","Epoch 265/350\n","225/225 [==============================] - 2s 11ms/step - loss: 1.2101e-06 - mean_squared_error: 1.1477e-06 - val_loss: 1.2298e-06 - val_mean_squared_error: 1.1661e-06\n","Epoch 266/350\n","225/225 [==============================] - 2s 10ms/step - loss: 1.2095e-06 - mean_squared_error: 1.1476e-06 - val_loss: 1.2294e-06 - val_mean_squared_error: 1.1662e-06\n","Epoch 267/350\n","225/225 [==============================] - 2s 11ms/step - loss: 1.2092e-06 - mean_squared_error: 1.1477e-06 - val_loss: 1.2405e-06 - val_mean_squared_error: 1.1770e-06\n","Epoch 268/350\n","225/225 [==============================] - 3s 12ms/step - loss: 1.2089e-06 - mean_squared_error: 1.1477e-06 - val_loss: 1.2372e-06 - val_mean_squared_error: 1.1743e-06\n","Epoch 269/350\n","225/225 [==============================] - 2s 10ms/step - loss: 1.2082e-06 - mean_squared_error: 1.1474e-06 - val_loss: 1.2320e-06 - val_mean_squared_error: 1.1697e-06\n","Epoch 270/350\n","225/225 [==============================] - 2s 10ms/step - loss: 1.2076e-06 - mean_squared_error: 1.1472e-06 - val_loss: 1.2328e-06 - val_mean_squared_error: 1.1709e-06\n","Epoch 271/350\n","225/225 [==============================] - 2s 8ms/step - loss: 1.2069e-06 - mean_squared_error: 1.1469e-06 - val_loss: 1.2306e-06 - val_mean_squared_error: 1.1691e-06\n","Epoch 272/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2066e-06 - mean_squared_error: 1.1470e-06 - val_loss: 1.2329e-06 - val_mean_squared_error: 1.1716e-06\n","Epoch 273/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.2061e-06 - mean_squared_error: 1.1467e-06 - val_loss: 1.2222e-06 - val_mean_squared_error: 1.1619e-06\n","Epoch 274/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2059e-06 - mean_squared_error: 1.1470e-06 - val_loss: 1.2264e-06 - val_mean_squared_error: 1.1662e-06\n","Epoch 275/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2050e-06 - mean_squared_error: 1.1464e-06 - val_loss: 1.2284e-06 - val_mean_squared_error: 1.1684e-06\n","Epoch 276/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2050e-06 - mean_squared_error: 1.1468e-06 - val_loss: 1.2276e-06 - val_mean_squared_error: 1.1680e-06\n","Epoch 277/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2046e-06 - mean_squared_error: 1.1468e-06 - val_loss: 1.2331e-06 - val_mean_squared_error: 1.1735e-06\n","Epoch 278/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.2040e-06 - mean_squared_error: 1.1465e-06 - val_loss: 1.2261e-06 - val_mean_squared_error: 1.1672e-06\n","Epoch 279/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2037e-06 - mean_squared_error: 1.1465e-06 - val_loss: 1.2372e-06 - val_mean_squared_error: 1.1781e-06\n","Epoch 280/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2038e-06 - mean_squared_error: 1.1469e-06 - val_loss: 1.2243e-06 - val_mean_squared_error: 1.1662e-06\n","Epoch 281/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2027e-06 - mean_squared_error: 1.1462e-06 - val_loss: 1.2306e-06 - val_mean_squared_error: 1.1725e-06\n","Epoch 282/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2024e-06 - mean_squared_error: 1.1462e-06 - val_loss: 1.2323e-06 - val_mean_squared_error: 1.1744e-06\n","Epoch 283/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2015e-06 - mean_squared_error: 1.1455e-06 - val_loss: 1.2167e-06 - val_mean_squared_error: 1.1599e-06\n","Epoch 284/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2018e-06 - mean_squared_error: 1.1463e-06 - val_loss: 1.2263e-06 - val_mean_squared_error: 1.1694e-06\n","Epoch 285/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2016e-06 - mean_squared_error: 1.1464e-06 - val_loss: 1.2288e-06 - val_mean_squared_error: 1.1721e-06\n","Epoch 286/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2007e-06 - mean_squared_error: 1.1457e-06 - val_loss: 1.2175e-06 - val_mean_squared_error: 1.1617e-06\n","Epoch 287/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2008e-06 - mean_squared_error: 1.1463e-06 - val_loss: 1.2235e-06 - val_mean_squared_error: 1.1676e-06\n","Epoch 288/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.1999e-06 - mean_squared_error: 1.1456e-06 - val_loss: 1.2288e-06 - val_mean_squared_error: 1.1729e-06\n","Epoch 289/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1993e-06 - mean_squared_error: 1.1453e-06 - val_loss: 1.2246e-06 - val_mean_squared_error: 1.1693e-06\n","Epoch 290/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1990e-06 - mean_squared_error: 1.1454e-06 - val_loss: 1.2227e-06 - val_mean_squared_error: 1.1678e-06\n","Epoch 291/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1984e-06 - mean_squared_error: 1.1451e-06 - val_loss: 1.2257e-06 - val_mean_squared_error: 1.1710e-06\n","Epoch 292/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1985e-06 - mean_squared_error: 1.1455e-06 - val_loss: 1.2190e-06 - val_mean_squared_error: 1.1649e-06\n","Epoch 293/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1983e-06 - mean_squared_error: 1.1456e-06 - val_loss: 1.2301e-06 - val_mean_squared_error: 1.1757e-06\n","Epoch 294/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1977e-06 - mean_squared_error: 1.1452e-06 - val_loss: 1.2329e-06 - val_mean_squared_error: 1.1787e-06\n","Epoch 295/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1973e-06 - mean_squared_error: 1.1452e-06 - val_loss: 1.2275e-06 - val_mean_squared_error: 1.1738e-06\n","Epoch 296/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1968e-06 - mean_squared_error: 1.1450e-06 - val_loss: 1.2318e-06 - val_mean_squared_error: 1.1782e-06\n","Epoch 297/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.1963e-06 - mean_squared_error: 1.1447e-06 - val_loss: 1.2216e-06 - val_mean_squared_error: 1.1687e-06\n","Epoch 298/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1960e-06 - mean_squared_error: 1.1447e-06 - val_loss: 1.2174e-06 - val_mean_squared_error: 1.1650e-06\n","Epoch 299/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1956e-06 - mean_squared_error: 1.1447e-06 - val_loss: 1.2210e-06 - val_mean_squared_error: 1.1687e-06\n","Epoch 300/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1954e-06 - mean_squared_error: 1.1448e-06 - val_loss: 1.2266e-06 - val_mean_squared_error: 1.1744e-06\n","Epoch 301/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.1951e-06 - mean_squared_error: 1.1447e-06 - val_loss: 1.2193e-06 - val_mean_squared_error: 1.1676e-06\n","Epoch 302/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.1946e-06 - mean_squared_error: 1.1445e-06 - val_loss: 1.2161e-06 - val_mean_squared_error: 1.1649e-06\n","Epoch 303/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1941e-06 - mean_squared_error: 1.1443e-06 - val_loss: 1.2250e-06 - val_mean_squared_error: 1.1736e-06\n","Epoch 304/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1944e-06 - mean_squared_error: 1.1449e-06 - val_loss: 1.2311e-06 - val_mean_squared_error: 1.1797e-06\n","Epoch 305/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1934e-06 - mean_squared_error: 1.1441e-06 - val_loss: 1.2184e-06 - val_mean_squared_error: 1.1678e-06\n","Epoch 306/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1932e-06 - mean_squared_error: 1.1441e-06 - val_loss: 1.2180e-06 - val_mean_squared_error: 1.1677e-06\n","Epoch 307/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1931e-06 - mean_squared_error: 1.1444e-06 - val_loss: 1.2226e-06 - val_mean_squared_error: 1.1724e-06\n","Epoch 308/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1924e-06 - mean_squared_error: 1.1438e-06 - val_loss: 1.2114e-06 - val_mean_squared_error: 1.1619e-06\n","Epoch 309/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1924e-06 - mean_squared_error: 1.1443e-06 - val_loss: 1.2259e-06 - val_mean_squared_error: 1.1761e-06\n","Epoch 310/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1922e-06 - mean_squared_error: 1.1442e-06 - val_loss: 1.2197e-06 - val_mean_squared_error: 1.1704e-06\n","Epoch 311/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1918e-06 - mean_squared_error: 1.1441e-06 - val_loss: 1.2180e-06 - val_mean_squared_error: 1.1690e-06\n","Epoch 312/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1915e-06 - mean_squared_error: 1.1441e-06 - val_loss: 1.2161e-06 - val_mean_squared_error: 1.1675e-06\n","Epoch 313/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1914e-06 - mean_squared_error: 1.1442e-06 - val_loss: 1.2197e-06 - val_mean_squared_error: 1.1712e-06\n","Epoch 314/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1906e-06 - mean_squared_error: 1.1437e-06 - val_loss: 1.2111e-06 - val_mean_squared_error: 1.1631e-06\n","Epoch 315/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1902e-06 - mean_squared_error: 1.1435e-06 - val_loss: 1.2170e-06 - val_mean_squared_error: 1.1690e-06\n","Epoch 316/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1901e-06 - mean_squared_error: 1.1436e-06 - val_loss: 1.2135e-06 - val_mean_squared_error: 1.1659e-06\n","Epoch 317/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1895e-06 - mean_squared_error: 1.1434e-06 - val_loss: 1.2293e-06 - val_mean_squared_error: 1.1814e-06\n","Epoch 318/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1894e-06 - mean_squared_error: 1.1434e-06 - val_loss: 1.2271e-06 - val_mean_squared_error: 1.1795e-06\n","Epoch 319/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1893e-06 - mean_squared_error: 1.1436e-06 - val_loss: 1.2185e-06 - val_mean_squared_error: 1.1715e-06\n","Epoch 320/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1891e-06 - mean_squared_error: 1.1436e-06 - val_loss: 1.2140e-06 - val_mean_squared_error: 1.1673e-06\n","Epoch 321/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1886e-06 - mean_squared_error: 1.1434e-06 - val_loss: 1.2203e-06 - val_mean_squared_error: 1.1736e-06\n","Epoch 322/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1881e-06 - mean_squared_error: 1.1430e-06 - val_loss: 1.2137e-06 - val_mean_squared_error: 1.1675e-06\n","Epoch 323/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1877e-06 - mean_squared_error: 1.1430e-06 - val_loss: 1.2252e-06 - val_mean_squared_error: 1.1788e-06\n","Epoch 324/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1874e-06 - mean_squared_error: 1.1429e-06 - val_loss: 1.2105e-06 - val_mean_squared_error: 1.1649e-06\n","Epoch 325/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1872e-06 - mean_squared_error: 1.1429e-06 - val_loss: 1.2194e-06 - val_mean_squared_error: 1.1737e-06\n","Epoch 326/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1873e-06 - mean_squared_error: 1.1432e-06 - val_loss: 1.2217e-06 - val_mean_squared_error: 1.1762e-06\n","Epoch 327/350\n","225/225 [==============================] - 2s 9ms/step - loss: 1.1869e-06 - mean_squared_error: 1.1430e-06 - val_loss: 1.2255e-06 - val_mean_squared_error: 1.1800e-06\n","Epoch 328/350\n","225/225 [==============================] - 2s 10ms/step - loss: 1.1867e-06 - mean_squared_error: 1.1431e-06 - val_loss: 1.2173e-06 - val_mean_squared_error: 1.1724e-06\n","Epoch 329/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1859e-06 - mean_squared_error: 1.1425e-06 - val_loss: 1.2199e-06 - val_mean_squared_error: 1.1751e-06\n","Epoch 330/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1859e-06 - mean_squared_error: 1.1427e-06 - val_loss: 1.2125e-06 - val_mean_squared_error: 1.1682e-06\n","Epoch 331/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1858e-06 - mean_squared_error: 1.1429e-06 - val_loss: 1.2108e-06 - val_mean_squared_error: 1.1667e-06\n","Epoch 332/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.1852e-06 - mean_squared_error: 1.1425e-06 - val_loss: 1.2266e-06 - val_mean_squared_error: 1.1822e-06\n","Epoch 333/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1854e-06 - mean_squared_error: 1.1428e-06 - val_loss: 1.2192e-06 - val_mean_squared_error: 1.1752e-06\n","Epoch 334/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1848e-06 - mean_squared_error: 1.1424e-06 - val_loss: 1.2189e-06 - val_mean_squared_error: 1.1751e-06\n","Epoch 335/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1845e-06 - mean_squared_error: 1.1424e-06 - val_loss: 1.2091e-06 - val_mean_squared_error: 1.1659e-06\n","Epoch 336/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1838e-06 - mean_squared_error: 1.1419e-06 - val_loss: 1.2188e-06 - val_mean_squared_error: 1.1755e-06\n","Epoch 337/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1843e-06 - mean_squared_error: 1.1426e-06 - val_loss: 1.2101e-06 - val_mean_squared_error: 1.1673e-06\n","Epoch 338/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1839e-06 - mean_squared_error: 1.1424e-06 - val_loss: 1.2122e-06 - val_mean_squared_error: 1.1695e-06\n","Epoch 339/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1833e-06 - mean_squared_error: 1.1420e-06 - val_loss: 1.2156e-06 - val_mean_squared_error: 1.1730e-06\n","Epoch 340/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1837e-06 - mean_squared_error: 1.1427e-06 - val_loss: 1.2183e-06 - val_mean_squared_error: 1.1758e-06\n","Epoch 341/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1829e-06 - mean_squared_error: 1.1420e-06 - val_loss: 1.2208e-06 - val_mean_squared_error: 1.1784e-06\n","Epoch 342/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1829e-06 - mean_squared_error: 1.1422e-06 - val_loss: 1.2131e-06 - val_mean_squared_error: 1.1712e-06\n","Epoch 343/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1823e-06 - mean_squared_error: 1.1418e-06 - val_loss: 1.2109e-06 - val_mean_squared_error: 1.1693e-06\n","Epoch 344/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1826e-06 - mean_squared_error: 1.1423e-06 - val_loss: 1.2162e-06 - val_mean_squared_error: 1.1746e-06\n","Epoch 345/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1820e-06 - mean_squared_error: 1.1418e-06 - val_loss: 1.2124e-06 - val_mean_squared_error: 1.1711e-06\n","Epoch 346/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1814e-06 - mean_squared_error: 1.1415e-06 - val_loss: 1.2091e-06 - val_mean_squared_error: 1.1681e-06\n","Epoch 347/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1814e-06 - mean_squared_error: 1.1417e-06 - val_loss: 1.2146e-06 - val_mean_squared_error: 1.1736e-06\n","Epoch 348/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1811e-06 - mean_squared_error: 1.1417e-06 - val_loss: 1.2210e-06 - val_mean_squared_error: 1.1800e-06\n","Epoch 349/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1810e-06 - mean_squared_error: 1.1416e-06 - val_loss: 1.2111e-06 - val_mean_squared_error: 1.1706e-06\n","Epoch 350/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1806e-06 - mean_squared_error: 1.1415e-06 - val_loss: 1.2062e-06 - val_mean_squared_error: 1.1661e-06\n","./defensive_models/350_0903_DAE_GTSRB_II\n"]}]},{"cell_type":"markdown","source":["### MagNet - 1"],"metadata":{"id":"mzltzwx8he_N"}},{"cell_type":"code","source":["ad_examples1 = np.array(ad_examples)\n","orig_labels1 = to_categorical(orig_labels)"],"metadata":{"id":"BZXZc5yXGbHR","executionInfo":{"status":"ok","timestamp":1663418629563,"user_tz":-540,"elapsed":19,"user":{"displayName":"김채현코랩3","userId":"12600322500441715060"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["# 원본 이미지\n","classifier = Classifier(\"./models/gtsrb_classifier\")\n","loss, accuracy = classifier.model.evaluate(data.x_test, data.y_test)\n","\n","print('test set accuracy (original) : ', accuracy * 100)"],"metadata":{"id":"0vMxKPzjhhAy","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"error","timestamp":1663418631809,"user_tz":-540,"elapsed":2262,"user":{"displayName":"김채현코랩3","userId":"12600322500441715060"}},"outputId":"4a037d90-e4c8-46b2-9bd5-c47666fed64b"},"execution_count":25,"outputs":[{"output_type":"error","ename":"DataLossError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mDataLossError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-9d8a6d0c2d55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 원본 이미지\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./models/gtsrb_classifier\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test set accuracy (original) : '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-20-6a2604e90f6f>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, classifier_path)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \"\"\"\n\u001b[1;32m    136\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mDataLossError\u001b[0m: TensorBundle at ./models/gtsrb_classifier/variables/variables shard 0 (10368 bytes): Checksum does not match: stored 3286647065 vs. calculated on the restored bytes 3102643309 [Op:RestoreV2]"]}]},{"cell_type":"code","source":["# 공격받은 이미지\n","classifier = Classifier(\"./models/gtsrb_classifier\")\n","loss, accuracy = classifier.model.evaluate(ad_examples1, orig_labels1)\n","\n","print('test set accuracy (attacked) : ', accuracy * 100)"],"metadata":{"id":"ca5TN0fGhrgk","executionInfo":{"status":"aborted","timestamp":1663418631810,"user_tz":-540,"elapsed":10,"user":{"displayName":"김채현코랩3","userId":"12600322500441715060"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["DAE_detector_I = AEDetector(\"./defensive_models/350_0903_DAE_GTSRB_I\", p=2)\n","DAE_detector_II = AEDetector(\"./defensive_models/350_0903_DAE_GTSRB_II\", p=1)\n","DAE_reformer = SimpleReformer(\"./defensive_models/350_0903_DAE_GTSRB_I\")\n","\n","\n","DAE_id_reformer = IdReformer()\n","DAE_classifier = Classifier(\"./models/gtsrb_classifier\")"],"metadata":{"id":"L6gv49XOhtCl","executionInfo":{"status":"aborted","timestamp":1663418631810,"user_tz":-540,"elapsed":10,"user":{"displayName":"김채현코랩3","userId":"12600322500441715060"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["detector_JSD1 = DBDetector(DAE_id_reformer, DAE_reformer, DAE_classifier, T=10)\n","detector_JSD2 = DBDetector(DAE_id_reformer, DAE_reformer, DAE_classifier, T=40)\n","\n","\n","DAE_detector_dict = dict()\n","DAE_detector_dict[\"I\"] = DAE_detector_I\n","DAE_detector_dict[\"II\"] = DAE_detector_II\n","DAE_detector_dict[\"JSD1\"] = detector_JSD1\n","DAE_detector_dict[\"JSD2\"] = detector_JSD2"],"metadata":{"id":"qRcUtasdhuRN","executionInfo":{"status":"aborted","timestamp":1663418631810,"user_tz":-540,"elapsed":10,"user":{"displayName":"김채현코랩3","userId":"12600322500441715060"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["DAE_operator = Operator(data, DAE_classifier, DAE_detector_dict, DAE_reformer)\n","DAE_testAttack = AttackData(ad_examples1, orig_labels, \"GTSRB FSGM\")"],"metadata":{"id":"36Yx1eqahvso","executionInfo":{"status":"aborted","timestamp":1663418631810,"user_tz":-540,"elapsed":10,"user":{"displayName":"김채현코랩3","userId":"12600322500441715060"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["DAE_evaluator = Evaluator(DAE_operator, DAE_testAttack)\n","DAE_evaluator.plot_various_confidences(\"defense_performance\", drop_rate={\"I\": 0.001, \"II\": 0.001,\"JSD1\": 0.001,\"JSD2\": 0.001})"],"metadata":{"id":"C3MbM1HDhwv0","executionInfo":{"status":"aborted","timestamp":1663418631810,"user_tz":-540,"elapsed":10,"user":{"displayName":"김채현코랩3","userId":"12600322500441715060"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('with reformer')\n","\n","predict = np.array((DAE_reformer.model.predict(ad_examples1))).reshape(-1,32,32,3)\n","predicted1 = np.argmax(classifier.model.predict(predict),axis=1)\n","\n","print(np.mean(predicted1[:len(orig_labels)] == orig_labels[:len(orig_labels)]))\n","# print(.sum(predicted==orig_labels))#,predicted)"],"metadata":{"id":"gBi_uO4Dhx6D","executionInfo":{"status":"aborted","timestamp":1663418631811,"user_tz":-540,"elapsed":10,"user":{"displayName":"김채현코랩3","userId":"12600322500441715060"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(type(data.x_train))\n","print(type(ad_examples))"],"metadata":{"id":"AmEhY0bFhzJd","executionInfo":{"status":"aborted","timestamp":1663418631811,"user_tz":-540,"elapsed":10,"user":{"displayName":"김채현코랩3","userId":"12600322500441715060"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Defense-GAN"],"metadata":{"id":"vIK9wb4vIIlv"}},{"cell_type":"markdown","metadata":{"id":"P9v5DhrcQTi_"},"source":["###  Defense Model 1 : DefenseGAN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1w18KhjvQaN-"},"outputs":[],"source":["import numpy as np\n","import os\n","import gzip\n","import urllib.request\n","\n","from keras.models import load_model\n","\n","def ordered_onehotencoding(labels):\n","    labels_ordered = []\n","    for i in range(len(labels)):\n","        if labels[i] == 3:\n","            labels_ordered.append(0)\n","        elif labels[i] == 7:\n","            labels_ordered.append(1)\n","        elif labels[i] == 9:\n","            labels_ordered.append(2)\n","        elif labels[i] == 10:\n","            labels_ordered.append(3)\n","        elif labels[i] == 11:\n","            labels_ordered.append(4)\n","        elif labels[i] == 12:\n","            labels_ordered.append(5)\n","        elif labels[i] == 13:\n","            labels_ordered.append(6)\n","        elif labels[i] == 17:\n","            labels_ordered.append(7)\n","        elif labels[i] == 18:\n","            labels_ordered.append(8)\n","        elif labels[i] == 25:\n","            labels_ordered.append(9)\n","        elif labels[i] == 35:\n","            labels_ordered.append(10)\n","        elif labels[i] == 38:\n","            labels_ordered.append(11)\n","    \n","    return np.array(labels_ordered)\n","\n","class GTSRB_defenseGAN:\n","    def __init__(self):\n","        imgs_path = \"Train\"\n","        data_list = []\n","        labels_list = []\n","\n","        result_class = [3,7, 9, 10, 11, 12, 13, 17, 18, 25, 35, 38]\n","\n","        for i in result_class:\n","            i_path = os.path.join(imgs_path, str(i)) # 3, 7, 9, 10, 11, 12,13, 17, 18, 25, 35, 38\n","            num = 0\n","            for img in os.listdir(i_path):\n","          \n","                im = Image.open(i_path +'/'+ img)\n","                im = im.resize((32,32))\n","                im = np.array(im)\n","\n","                data_list.append(im)\n","                labels_list.append(i)\n","                num = num + 1\n","                if num == 1000:\n","                    break;\n","\n","        data = np.array(data_list)\n","        labels = ordered_onehotencoding(labels_list)\n","\n","        labels = to_categorical(labels)\n","\n","        VALIDATION_SIZE = 5000\n","        \n","        data = (data.astype(np.float32) - 127.5) / 127.5 #모든 데이터 픽셀 값을 -1~1로 피팅 시킨다 (GAN 학습을 위함)\n","        \n","        self.x_train = np.array(data)\n","        self.y_train = labels\n","\n","    @staticmethod\n","    def print():\n","        return \"GTSRB_defenseGAN\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jFZPnqlWRPA7"},"outputs":[],"source":["data_train_GAN = GTSRB_defenseGAN()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a_zbYD_uRrNQ"},"outputs":[],"source":["print(data_train_GAN.x_train.shape)\n","print(data_train_GAN.y_train.shape)"]},{"cell_type":"markdown","metadata":{"id":"nZvOoqJqTtgW"},"source":["GAN 생성"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rOz8KOvWRqFq"},"outputs":[],"source":["import numpy as np \n","import matplotlib.pyplot as plt \n","\n","from keras.datasets import mnist\n","\n","from keras.models import Sequential, Model\n","\n","from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n","from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.layers.convolutional import UpSampling2D, Conv2D\n","\n","from tensorflow.keras.optimizers import Adam\n","\n","noise_data = np.random.normal(0, 1, (32, 100))\n","#generated_images = 0.5 * generator.predict(np.random.normal(0, 1, (32, 100))) + 0.5\n","\n","def show_images(generated_images, n=4, m=8, figsize=(9, 5)):\n","    f, axes = plt.subplots(n, m, figsize=figsize)\n","    #plt.subplots_adjust(top=1, bottom=0, hspace=0, wspace=0.05)\n","    for i in range(0, n):\n","        for j in range(0, m):\n","            ax = axes[i][j]\n","            ax.imshow(generated_images[i * m + j])\n","            ax.grid(False)\n","            ax.xaxis.set_ticks([])\n","            ax.yaxis.set_ticks([])\n","    plt.tight_layout()\n","    plt.savefig('20220729_basicgan.svg')\n","    plt.show()   \n","#show_images(0.5 * generator.predict(np.random.normal(0, 1, (32, 100))) + 0.5)\n","\n","\n","## create generator         \n","generator_ = Sequential([\n","    Dense(128 * 8 * 8, activation=\"relu\", input_shape=(100,)), \n","    Reshape((8, 8, 128)), \n","    \n","    BatchNormalization(momentum=0.8), # what is batch normalization?? \n","    UpSampling2D(), # what is upsampling?? \n","    Conv2D(128, kernel_size=3, padding=\"same\"),\n","    Activation(\"relu\"), \n","    \n","    BatchNormalization(momentum=0.8), \n","    UpSampling2D(), \n","    Conv2D(64, kernel_size=3, padding=\"same\"), \n","    Activation(\"relu\"), \n","    \n","    BatchNormalization(momentum=0.8), \n","    Conv2D(3, kernel_size=3, padding=\"same\"), \n","    Activation(\"tanh\"), \n","])\n","\n","noise_input = Input(shape=(100,), name=\"noise_input\")\n","generator_base = Model(noise_input, generator_(noise_input), name=\"generator\")\n","\n","generator_.summary()# summary가 매우 유용하군요. \n","\n","optimizer = Adam(0.0002, 0.5)\n","generator_base.compile(loss='binary_crossentropy', optimizer=optimizer)\n","\n","### create discriminator\n","discriminator_ = Sequential([\n","    Conv2D(32, kernel_size=3, strides=2, input_shape=(32, 32, 3), padding=\"same\"), \n","    LeakyReLU(alpha=0.2), \n","    Dropout(0.25), \n","    \n","    Conv2D(64, kernel_size=3, strides=2, padding=\"same\"), \n","    ZeroPadding2D(padding=((0,1),(0,1))), \n","    LeakyReLU(alpha=0.2), \n","    Dropout(0.25), \n","    BatchNormalization(momentum=0.8), \n","    \n","    Conv2D(128, kernel_size=3, strides=2, padding=\"same\"), \n","    LeakyReLU(alpha=0.2), \n","    Dropout(0.25), \n","    BatchNormalization(momentum=0.8), \n","    \n","    Conv2D(256, kernel_size=3, strides=1, padding=\"same\"), \n","    LeakyReLU(alpha=0.2), \n","    Dropout(0.25), \n","    Flatten(), \n","    Dense(1, activation='sigmoid'), \n","])\n","image_input = Input(shape=(32, 32, 3), name=\"image_input\")\n","\n","discriminator = Model(image_input, discriminator_(image_input), name=\"discriminator\")\n","discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","discriminator_.summary()\n","\n","### Combined Model\n","noise_input2 = Input(shape=(100,), name=\"noise_input2\")\n","\"\"\"\n","model과 sequential의 차이는?? \n","가설1: 레이어를 쌓는 것이 sequential 이라면, sequential을 쌓는 것이 model인가???\n","\n","1) 다음 모델의 경우는 랜덤으로 만든 이미지로부터 학습해서 새로운 이미지를 만들어내는 generator의 데이터를 \n","2) discriminator가 분류하는 형식으로 진행된다. \n","\"\"\"\n","combined = Model(noise_input2, discriminator(generator_base(noise_input2)))\n","combined.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7NWG3wxrSF4p"},"outputs":[],"source":["## training\n","\"\"\"\n","- 이 코드에서는 fit을 사용한 것이 아니라, train_on_batch를 사용했음. \n","- train_on_batch와의 차이점?을 구글에 검색해보니, 큰 차이가 없다고 하긴 하는데\n","    - train_on_batch의 경우, 넘겨 받은 데이터에 대해서 gradient vector를 계산해서 적용하고 끝내는 것이고(1epoch)\n","    - fit의 경우는 epoch과 batch_size를 한번에 모두 넘겨준다는 것 정도가 차이가 된다. \n","- GAN의 경우, discriminator의 학습시 마다 generator가 생성하는 데이터가 변화하게 된다. \n","    - 즉 처음부터 모든 데이터가 존재하고 이를 한번에 학습시키는 fit과는 다르게, 한번씩 업데이트를 할때마다 모델이 변화하므로, \n","    - train_on_batch를 사용하는 것이 매우 합당함.\n","\"\"\"\n","batch_size = 256\n","half_batch = batch_size // 2\n","\n","def train(epochs, print_step=10):\n","    history = []\n","    for epoch in range(epochs):\n","        # discriminator 트레이닝 단계\n","        #######################################################################3\n","        # 데이터 절반은 실제 이미지, 절반은 generator가 생성한 가짜 이미지\n","        # discriminator가 실제 이미지와 가짜 이미지를 구별하도록 discriminator를 트레이닝\n","        discriminator.trainable = True\n","        d_loss_real = discriminator.train_on_batch(data_train_GAN.x_train[np.random.randint(0, data_train_GAN.x_train.shape[0], half_batch)], \n","                                                   np.ones((half_batch, 1)))\n","        d_loss_fake = discriminator.train_on_batch(generator_base.predict(np.random.normal(0, 1, (half_batch, 100))), \n","                                                   np.zeros((half_batch, 1)))\n","        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","        # generator 트레이닝 단계\n","        #######################################################################3\n","        # 전부 generator가 생성한 가짜 이미지를 사용. \n","        # discriminator가 구별하지 못하도록 generator를 트레이닝\n","        \n","        \"\"\"\n","        generator를 트레이닝할 때는, 반드시 discriminator가 필요함. \n","        generator가 만든 image를 평가해야 하고, 그래야 feedback이 생겨서 generator가 학습됨. \n","        따라서, generator는 combined model을 통해 학습시키는데, 이때, discriminator도 함께 학습되면 안되기 때문에\n","        discriminator.trainable 을 False로 변경시켜 둔다. \n","        \"\"\"\n","        noise = np.random.normal(0, 1, (batch_size, 100))\n","        discriminator.trainable = False \n","        g_loss = combined.train_on_batch(noise, np.ones((batch_size, 1)))  #여기서는 왜 만들어준 fake img의 y 값을 1로 두는 걸까 ..\n","        # 기록\n","        record = (epoch, d_loss[0], 100 * d_loss[1], g_loss[0], 100 * g_loss[1])\n","        history.append(record)\n","        if epoch % print_step == 0:\n","            print(\"%5d [D loss: %.3f, acc.: %.2f%%] [G loss: %.3f, acc.: %.2f%%]\" % record)\n","            show_images(0.5 * generator_base.predict(noise_data) + 0.5)\n","    return history\n","#%%time, 은\n","history100 = train(20000, 500)\n","show_images(0.5 * generator_base.predict(noise_data) + 0.5)"]},{"cell_type":"code","source":["# GAN 모델 저장\n","from keras.models import load_model\n","\n","generator_base.save('baseGAN_Generator_attacked0.02.h5')"],"metadata":{"id":"dXXJ-Wgyu_bT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4BPL_wcJTvXO"},"source":["DefenseGAN 구현 - FGSM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h5JFZsEPTqeY"},"outputs":[],"source":["ad_example_data = ad_examples1 #/255로 이미 정규화가 된 이미지이다\n","orig_label_data = orig_labels1\n","\n","print(ad_example_data.shape)\n","print(orig_label_data.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LrHjDgblT_c1"},"outputs":[],"source":["def DefenseGAN(img_at,L,R):\n","    z_list = []\n","    img = img_at.reshape(32,32,3)\n","    img_st = (img - np.mean(img)) / np.std(img) \n","    img_var = tf.Variable(img_st,dtype = float)\n","    opt = tf.keras.optimizers.SGD(learning_rate=0.1,momentum = 0.7)\n","\n","    def compute():\n","        z_hats_recs = generator_base(z_var)\n","        z_hats_recs = tf.reshape(z_hats_recs, [32,32,3])\n","        num_dim = len(z_hats_recs.get_shape())\n","        axes = range(1, num_dim)\n","        image_rec_loss = tf.reduce_mean(tf.square(z_hats_recs - img_var),axis=axes)\n","        rec_loss = tf.reduce_sum(image_rec_loss)\n","        return rec_loss\n","\n","    for r in range(R):\n","        z = np.random.normal(0, 1, (1, 100))\n","        z_var = tf.Variable(z,dtype = float)\n","    \n","        for l in range(L):\n","            opt.minimize(compute,[z_var])\n","        z_list.append(z_var)\n","\n","    def compute_10(z):\n","        #generator_base.trainable = False #아직 더해야하는지 뺴야하는지 판단 x\n","        z_hats_recs = generator_base(z)\n","        z_hats_recs = tf.reshape(z_hats_recs, [32,32,3])\n","        num_dim = len(z_hats_recs.get_shape())\n","        axes = range(1, num_dim)\n","        image_rec_loss = tf.reduce_mean(tf.square(z_hats_recs - img_var),axis=axes)\n","        rec_loss = tf.reduce_sum(image_rec_loss)\n","        return rec_loss\n","    \n","\n","    loss_list = []\n","    \n","    for i in range(len(z_list)):\n","        loss = compute_10(z_list[i])\n","        loss_list.append(loss)\n","    \n","    index_min = np.argmin(loss_list)\n","\n","    z_min = np.array(z_list[index_min])\n","\n","    generated_images = 0.5 * generator_base.predict(z_min)+ 0.5\n","\n","    generated_images = generated_images.reshape(32,32,3)\n","\n","    return generated_images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9ks2QRZbUKO_"},"outputs":[],"source":["## predict_output에 한개씩 넣는 것부터 구현해야한다. (전체가 들어가는 것만 정상 작동함)\n","\n","def test(classifier, ad_example_data, orig_label_data):\n","\n","    # 정확도 카운터\n","    correct = 0\n","    defense_correct = 0\n","    df_examples = []\n","    # 테스트 셋의 모든 예제에 대해 루프를 돕니다\n","\n","    loss, accuracy = classifier.evaluate(ad_examples1, orig_labels1)\n","\n","    print('방어 전 모델 정확도 : ',accuracy * 100)\n","\n","    for i in range(len(ad_example_data)):\n","        data = ad_example_data[i].reshape(-1,32,32,3)\n","        target = orig_label_data[i]\n","        \n","        data_plot = data.reshape(32,32,3)\n","        print('원본 label : ',np.argmax(target))\n","        plt.imshow(data_plot)\n","        plt.show();\n","\n","        generated_img = DefenseGAN(data.reshape(32,32,3),200,10).reshape(-1,32,32,3)\n","\n","        generated_img_plot = generated_img.reshape(32,32,3)\n","\n","\n","        defense_output = classifier.predict(generated_img.reshape(1,32,32,3))\n","\n","        defense_pred= int(np.argmax(defense_output))\n","\n","        print('방어 라벨 : ',defense_pred)\n","        plt.imshow(generated_img_plot)\n","        plt.show();\n","\n","        if defense_pred == int(np.argmax(target)):\n","            defense_correct += 1\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","        else:\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","\n","        print('Working...!')\n","\n","\n","    defense_acc = defense_correct / float(len(ad_example_data))\n","    print(\"Defense Accuracy = {} / {} = {}\".format(defense_correct, len(ad_example_data), defense_acc))\n","    # 정확도와 적대적 예제를 리턴합니다\n","    return defense_acc, df_examples"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UmgqhBaWaqXz"},"outputs":[],"source":["accuracies_df = []\n","examples_df = []\n","\n","acc_df, ex_df = test(model, ad_example_data[:100], orig_label_data[:100])\n","\n","accuracies_df.append(acc_df)\n","examples_df.append(ex_df)"]},{"cell_type":"markdown","source":["### DefenseGAN 구현 - BIM\n","\n"],"metadata":{"id":"2TtBNBJxn2Db"}},{"cell_type":"code","source":["ad_examples_BIM = np.array(ad_examples) # 이미 정규화되어서 나온 값으로 추가적인 /255 정규화 필요 없음\n","orig_labels_BIM = to_categorical(orig_labels)\n","\n","print(ad_examples_BIM.shape)\n","print(orig_labels_BIM.shape)"],"metadata":{"id":"fhZ-PyFGn3lz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# GAN 모델 저장\n","from keras.models import load_model\n","\n","generator_base = load_model('baseGAN_Generator_attacked0.02.h5')"],"metadata":{"id":"lZngn6VduEUE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.imshow(generator_base.predict(np.random.normal(0, 1, (1, 100))).reshape(32,32,3))"],"metadata":{"id":"P4m8Jituudng"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def DefenseGAN(img_at,L,R):\n","    z_list = []\n","    img = img_at.reshape(32,32,3)\n","    img_st = (img - np.mean(img)) / np.std(img) \n","    img_var = tf.Variable(img_st,dtype = float)\n","    opt = tf.keras.optimizers.SGD(learning_rate=0.1,momentum = 0.7)\n","\n","    def compute():\n","        z_hats_recs = generator_base(z_var)\n","        z_hats_recs = tf.reshape(z_hats_recs, [32,32,3])\n","        num_dim = len(z_hats_recs.get_shape())\n","        axes = range(1, num_dim)\n","        image_rec_loss = tf.reduce_mean(tf.square(z_hats_recs - img_var),axis=axes)\n","        rec_loss = tf.reduce_sum(image_rec_loss)\n","        return rec_loss\n","\n","    for r in range(R):\n","        z = np.random.normal(0, 1, (1, 100))\n","        z_var = tf.Variable(z,dtype = float)\n","    \n","        for l in range(L):\n","            opt.minimize(compute,[z_var])\n","        z_list.append(z_var)\n","\n","    def compute_10(z):\n","        #generator_base.trainable = False #아직 더해야하는지 뺴야하는지 판단 x\n","        z_hats_recs = generator_base(z)\n","        z_hats_recs = tf.reshape(z_hats_recs, [32,32,3])\n","        num_dim = len(z_hats_recs.get_shape())\n","        axes = range(1, num_dim)\n","        image_rec_loss = tf.reduce_mean(tf.square(z_hats_recs - img_var),axis=axes)\n","        rec_loss = tf.reduce_sum(image_rec_loss)\n","        return rec_loss\n","    \n","\n","    loss_list = []\n","    \n","    for i in range(len(z_list)):\n","        loss = compute_10(z_list[i])\n","        loss_list.append(loss)\n","    \n","    index_min = np.argmin(loss_list)\n","\n","    z_min = np.array(z_list[index_min])\n","\n","    generated_images = 0.5 * generator_base.predict(z_min)+ 0.5\n","\n","    generated_images = generated_images.reshape(32,32,3)\n","\n","    return generated_images"],"metadata":{"id":"2Zppe2W6n3n9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## predict_output에 한개씩 넣는 것부터 구현해야한다. (전체가 들어가는 것만 정상 작동함)\n","\n","def test(classifier, ad_example_data, orig_label_data):\n","\n","    # 정확도 카운터\n","    correct = 0\n","    defense_correct = 0\n","    df_examples = []\n","    # 테스트 셋의 모든 예제에 대해 루프를 돕니다\n","\n","    loss, accuracy = classifier.evaluate(ad_example_data, orig_label_data)\n","\n","    print('방어 전 모델 정확도 : ',accuracy * 100)\n","\n","    for i in range(len(ad_example_data)):\n","        data = ad_example_data[i].reshape(-1,32,32,3)\n","        target = orig_label_data[i]\n","        \n","        data_plot = data.reshape(32,32,3)\n","        print('원본 label : ',np.argmax(target))\n","        plt.imshow(data_plot)\n","        plt.show();\n","\n","        generated_img = DefenseGAN(data.reshape(32,32,3),200,10).reshape(-1,32,32,3)\n","\n","        generated_img_plot = generated_img.reshape(32,32,3)\n","\n","\n","        defense_output = classifier.predict(generated_img.reshape(1,32,32,3))\n","\n","        defense_pred= int(np.argmax(defense_output))\n","\n","        print('방어 라벨 : ',defense_pred)\n","        plt.imshow(generated_img_plot)\n","        plt.show();\n","\n","        if defense_pred == int(np.argmax(target)):\n","            defense_correct += 1\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","        else:\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","\n","        print('Working...!')\n","\n","\n","    defense_acc = defense_correct / float(len(ad_example_data))\n","    print(\"Defense Accuracy = {} / {} = {}\".format(defense_correct, len(ad_example_data), defense_acc))\n","    # 정확도와 적대적 예제를 리턴합니다\n","    return defense_acc, df_examples"],"metadata":{"id":"HsGI-NY4n3qe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["accuracies_df = []\n","examples_df = []\n","\n","acc_df, ex_df = test(model, ad_examples_BIM[:100], orig_labels_BIM[:100])\n","\n","accuracies_df.append(acc_df)\n","examples_df.append(ex_df)"],"metadata":{"id":"qnYmHP5Bn3tC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## PCA"],"metadata":{"id":"63SBpYd-IL2u"}},{"cell_type":"markdown","metadata":{"id":"1ywsHS3sfPxD"},"source":["### Defense 2 : PCA (Components = 5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KuoOeVKxsyvD"},"outputs":[],"source":["ad_example_data = ad_examples1 #/255로 이미 정규화가 된 이미지이다\n","orig_label_data = orig_labels1\n","\n","print(ad_example_data.shape)\n","print(orig_label_data.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rAB3avuSbB3q"},"outputs":[],"source":["from sklearn.decomposition import PCA\n","\n","# data shape이 32,32,3이어야한다.\n","def defense_PCA(data,component):\n","    #r,g,b를 각각 나눠준다\n","    data = data.reshape(32,32,3)\n","    r = data[:,:,0]\n","    g = data[:,:,1]\n","    b = data[:,:,2]\n","\n","    pca_r = PCA(n_components=component)\n","    pca_r_trans = pca_r.fit_transform(r)\n","\n","    pca_g = PCA(n_components=component)\n","    pca_g_trans = pca_g.fit_transform(g)\n","\n","    pca_b = PCA(n_components=component)\n","    pca_b_trans = pca_b.fit_transform(b)\n","\n","    pca_r_org = pca_r.inverse_transform(pca_r_trans)\n","    pca_g_org = pca_g.inverse_transform(pca_g_trans)\n","    pca_b_org = pca_b.inverse_transform(pca_b_trans)\n","\n","    img_compressed = np.stack((pca_r_org, pca_g_org, pca_b_org),axis = 2)\n","\n","    return img_compressed.reshape((-1,32,32,3))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j2uWTxjIf-a-"},"outputs":[],"source":["## predict_output에 한개씩 넣는 것부터 구현해야한다. (전체가 들어가는 것만 정상 작동함)\n","\n","def test(classifier, ad_example_data, orig_label_data):\n","\n","    # 정확도 카운터\n","    correct = 0\n","    defense_correct = 0\n","    df_examples = []\n","    # 테스트 셋의 모든 예제에 대해 루프를 돕니다\n","\n","    loss, accuracy = classifier.evaluate(ad_examples1, orig_labels1)\n","\n","    print('방어 전 모델 정확도 : ',accuracy * 100)\n","\n","    for i in range(len(ad_example_data)):\n","        data = ad_example_data[i].reshape(-1,32,32,3)\n","        target = orig_label_data[i]\n","        \n","        data_plot = data.reshape(32,32,3)\n","        print('원본 label : ',np.argmax(target))\n","        plt.imshow(data_plot)\n","        plt.show();\n","\n","        generated_img = defense_PCA(data,5)\n","\n","        generated_img_plot = generated_img.reshape(32,32,3)\n","\n","        defense_output = classifier.predict(generated_img.reshape(1,32,32,3))\n","\n","        defense_pred= int(np.argmax(defense_output))\n","\n","        print('방어 라벨 : ',defense_pred)\n","        plt.imshow(generated_img_plot)\n","        plt.show();\n","\n","        if defense_pred == int(np.argmax(target)):\n","            defense_correct += 1\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","        else:\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","\n","        print('Working...!')\n","\n","\n","    defense_acc = defense_correct / float(len(ad_example_data))\n","    print(\"Defense Accuracy = {} / {} = {}\".format(defense_correct, len(ad_example_data), defense_acc))\n","    # 정확도와 적대적 예제를 리턴합니다\n","    return defense_acc, df_examples"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TGm6ObXDhR2V"},"outputs":[],"source":["accuracies_df = []\n","examples_df = []\n","\n","acc_df, ex_df = test(model, ad_example_data, orig_label_data)\n","\n","accuracies_df.append(acc_df)\n","examples_df.append(ex_df)"]},{"cell_type":"markdown","metadata":{"id":"9Y_-9xiJiAeC"},"source":["### Defense 2 : PCA (Components = 10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZOiE-bIgsz6w"},"outputs":[],"source":["ad_example_data = ad_examples1 #/255로 이미 정규화가 된 이미지이다\n","orig_label_data = orig_labels1\n","\n","print(ad_example_data.shape)\n","print(orig_label_data.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EyLQ-kGQwqEZ"},"outputs":[],"source":["from sklearn.decomposition import PCA\n","\n","# data shape이 32,32,3이어야한다.\n","def defense_PCA(data,component):\n","    #r,g,b를 각각 나눠준다\n","    data = data.reshape(32,32,3)\n","    r = data[:,:,0]\n","    g = data[:,:,1]\n","    b = data[:,:,2]\n","\n","    pca_r = PCA(n_components=component)\n","    pca_r_trans = pca_r.fit_transform(r)\n","\n","    pca_g = PCA(n_components=component)\n","    pca_g_trans = pca_g.fit_transform(g)\n","\n","    pca_b = PCA(n_components=component)\n","    pca_b_trans = pca_b.fit_transform(b)\n","\n","    pca_r_org = pca_r.inverse_transform(pca_r_trans)\n","    pca_g_org = pca_g.inverse_transform(pca_g_trans)\n","    pca_b_org = pca_b.inverse_transform(pca_b_trans)\n","\n","    img_compressed = np.stack((pca_r_org, pca_g_org, pca_b_org),axis = 2)\n","\n","    return img_compressed.reshape((-1,32,32,3))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lWXuP7V4iPO0"},"outputs":[],"source":["## predict_output에 한개씩 넣는 것부터 구현해야한다. (전체가 들어가는 것만 정상 작동함)\n","\n","def test(classifier, ad_example_data, orig_label_data):\n","\n","    # 정확도 카운터\n","    correct = 0\n","    defense_correct = 0\n","    df_examples = []\n","    # 테스트 셋의 모든 예제에 대해 루프를 돕니다\n","\n","    loss, accuracy = classifier.evaluate(ad_examples1, orig_labels1)\n","\n","    print('방어 전 모델 정확도 : ',accuracy * 100)\n","\n","    for i in range(len(ad_example_data)):\n","        data = ad_example_data[i].reshape(-1,32,32,3)\n","        target = orig_label_data[i]\n","        \n","        data_plot = data.reshape(32,32,3)\n","        print('원본 label : ',np.argmax(target))\n","        plt.imshow(data_plot)\n","        plt.show();\n","\n","        generated_img = defense_PCA(data,10)\n","\n","        generated_img_plot = generated_img.reshape(32,32,3)\n","\n","        defense_output = classifier.predict(generated_img.reshape(1,32,32,3))\n","\n","        defense_pred= int(np.argmax(defense_output))\n","\n","        print('방어 라벨 : ',defense_pred)\n","        plt.imshow(generated_img_plot)\n","        plt.show();\n","\n","        if defense_pred == int(np.argmax(target)):\n","            defense_correct += 1\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","        else:\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","\n","        print('Working...!')\n","\n","\n","    defense_acc = defense_correct / float(len(ad_example_data))\n","    print(\"Defense Accuracy = {} / {} = {}\".format(defense_correct, len(ad_example_data), defense_acc))\n","    # 정확도와 적대적 예제를 리턴합니다\n","    return defense_acc, df_examples"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HP7_KoXqiWhf"},"outputs":[],"source":["accuracies_df = []\n","examples_df = []\n","\n","acc_df, ex_df = test(model, ad_example_data, orig_label_data)\n","\n","accuracies_df.append(acc_df)\n","examples_df.append(ex_df)"]},{"cell_type":"markdown","source":["### Defense 2 : PCA (Components = 5)"],"metadata":{"id":"hGoEmuWF4S1T"}},{"cell_type":"code","source":["ad_examples_BIM = np.array(ad_examples) # 이미 정규화되어서 나온 값으로 추가적인 /255 정규화 필요 없음\n","orig_labels_BIM = to_categorical(orig_labels)\n","\n","print(ad_examples_BIM.shape)\n","print(orig_labels_BIM.shape)\n","\n","from sklearn.decomposition import PCA\n","\n","# data shape이 32,32,3이어야한다.\n","def defense_PCA(data,component):\n","    #r,g,b를 각각 나눠준다\n","    data = data.reshape(32,32,3)\n","    r = data[:,:,0]\n","    g = data[:,:,1]\n","    b = data[:,:,2]\n","\n","    pca_r = PCA(n_components=component)\n","    pca_r_trans = pca_r.fit_transform(r)\n","\n","    pca_g = PCA(n_components=component)\n","    pca_g_trans = pca_g.fit_transform(g)\n","\n","    pca_b = PCA(n_components=component)\n","    pca_b_trans = pca_b.fit_transform(b)\n","\n","    pca_r_org = pca_r.inverse_transform(pca_r_trans)\n","    pca_g_org = pca_g.inverse_transform(pca_g_trans)\n","    pca_b_org = pca_b.inverse_transform(pca_b_trans)\n","\n","    img_compressed = np.stack((pca_r_org, pca_g_org, pca_b_org),axis = 2)\n","\n","    return img_compressed.reshape((-1,32,32,3))\n","\n","## predict_output에 한개씩 넣는 것부터 구현해야한다. (전체가 들어가는 것만 정상 작동함)\n","\n","def test(classifier, ad_example_data, orig_label_data):\n","\n","    # 정확도 카운터\n","    correct = 0\n","    defense_correct = 0\n","    df_examples = []\n","    # 테스트 셋의 모든 예제에 대해 루프를 돕니다\n","\n","    loss, accuracy = classifier.evaluate(ad_examples_BIM, orig_labels_BIM)\n","\n","    print('방어 전 모델 정확도 : ',accuracy * 100)\n","\n","    for i in range(len(ad_example_data)):\n","        data = ad_example_data[i].reshape(-1,32,32,3)\n","        target = orig_label_data[i]\n","        \n","        data_plot = data.reshape(32,32,3)\n","        print('원본 label : ',np.argmax(target))\n","        plt.imshow(data_plot)\n","        plt.show();\n","\n","        generated_img = defense_PCA(data,5)\n","\n","        generated_img_plot = generated_img.reshape(32,32,3)\n","\n","        defense_output = classifier.predict(generated_img.reshape(1,32,32,3))\n","\n","        defense_pred= int(np.argmax(defense_output))\n","\n","        print('방어 라벨 : ',defense_pred)\n","        plt.imshow(generated_img_plot)\n","        plt.show();\n","\n","        if defense_pred == int(np.argmax(target)):\n","            defense_correct += 1\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","        else:\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","\n","        print('Working...!')\n","\n","\n","    defense_acc = defense_correct / float(len(ad_example_data))\n","    print(\"Defense Accuracy = {} / {} = {}\".format(defense_correct, len(ad_example_data), defense_acc))\n","    # 정확도와 적대적 예제를 리턴합니다\n","    return defense_acc, df_examples"],"metadata":{"id":"sP6AyMGH4bkk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["accuracies_df = []\n","examples_df = []\n","\n","acc_df, ex_df = test(model, ad_examples_BIM[:1000], orig_labels_BIM[:1000])\n","\n","accuracies_df.append(acc_df)\n","examples_df.append(ex_df)"],"metadata":{"id":"pJv8QiS94bm8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Defense 2 : PCA (Components = 10)"],"metadata":{"id":"7rWZ6_Kf48hG"}},{"cell_type":"code","source":["ad_examples_BIM = np.array(ad_examples) # 이미 정규화되어서 나온 값으로 추가적인 /255 정규화 필요 없음\n","orig_labels_BIM = to_categorical(orig_labels)\n","\n","print(ad_examples_BIM.shape)\n","print(orig_labels_BIM.shape)\n","\n","from sklearn.decomposition import PCA\n","\n","# data shape이 32,32,3이어야한다.\n","def defense_PCA(data,component):\n","    #r,g,b를 각각 나눠준다\n","    data = data.reshape(32,32,3)\n","    r = data[:,:,0]\n","    g = data[:,:,1]\n","    b = data[:,:,2]\n","\n","    pca_r = PCA(n_components=component)\n","    pca_r_trans = pca_r.fit_transform(r)\n","\n","    pca_g = PCA(n_components=component)\n","    pca_g_trans = pca_g.fit_transform(g)\n","\n","    pca_b = PCA(n_components=component)\n","    pca_b_trans = pca_b.fit_transform(b)\n","\n","    pca_r_org = pca_r.inverse_transform(pca_r_trans)\n","    pca_g_org = pca_g.inverse_transform(pca_g_trans)\n","    pca_b_org = pca_b.inverse_transform(pca_b_trans)\n","\n","    img_compressed = np.stack((pca_r_org, pca_g_org, pca_b_org),axis = 2)\n","\n","    return img_compressed.reshape((-1,32,32,3))\n","\n","## predict_output에 한개씩 넣는 것부터 구현해야한다. (전체가 들어가는 것만 정상 작동함)\n","\n","def test(classifier, ad_example_data, orig_label_data):\n","\n","    # 정확도 카운터\n","    correct = 0\n","    defense_correct = 0\n","    df_examples = []\n","    # 테스트 셋의 모든 예제에 대해 루프를 돕니다\n","\n","    loss, accuracy = classifier.evaluate(ad_examples_BIM, orig_labels_BIM)\n","\n","    print('방어 전 모델 정확도 : ',accuracy * 100)\n","\n","    for i in range(len(ad_example_data)):\n","        data = ad_example_data[i].reshape(-1,32,32,3)\n","        target = orig_label_data[i]\n","        \n","        data_plot = data.reshape(32,32,3)\n","        print('원본 label : ',np.argmax(target))\n","        plt.imshow(data_plot)\n","        plt.show();\n","\n","        generated_img = defense_PCA(data,10)\n","\n","        generated_img_plot = generated_img.reshape(32,32,3)\n","\n","        defense_output = classifier.predict(generated_img.reshape(1,32,32,3))\n","\n","        defense_pred= int(np.argmax(defense_output))\n","\n","        print('방어 라벨 : ',defense_pred)\n","        plt.imshow(generated_img_plot)\n","        plt.show();\n","\n","        if defense_pred == int(np.argmax(target)):\n","            defense_correct += 1\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","        else:\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","\n","        print('Working...!')\n","\n","\n","    defense_acc = defense_correct / float(len(ad_example_data))\n","    print(\"Defense Accuracy = {} / {} = {}\".format(defense_correct, len(ad_example_data), defense_acc))\n","    # 정확도와 적대적 예제를 리턴합니다\n","    return defense_acc, df_examples"],"metadata":{"id":"fpPzHByO4bpO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["accuracies_df = []\n","examples_df = []\n","\n","acc_df, ex_df = test(model, ad_examples_BIM[:1000], orig_labels_BIM[:1000])\n","\n","accuracies_df.append(acc_df)\n","examples_df.append(ex_df)"],"metadata":{"id":"aCH5IdKe4br4"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"collapsed_sections":["H5r08xIXerXB","FhnfS-0MH1sa","XWfrLWt3EtSN","6DfDZcE5_GGB","Lb-doZmmIFqj","-Yc-yrW7ktMW","bt4nIJ5xg73T","EhncucofhEvv","4e-GBUowhNUQ","ukxjkHWahV8B","mzltzwx8he_N","vIK9wb4vIIlv","P9v5DhrcQTi_","2TtBNBJxn2Db","63SBpYd-IL2u","1ywsHS3sfPxD","9Y_-9xiJiAeC","hGoEmuWF4S1T","7rWZ6_Kf48hG"],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}