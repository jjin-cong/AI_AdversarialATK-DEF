{"cells":[{"cell_type":"markdown","metadata":{"id":"05NggkxjGxlN"},"source":["## 데이터셋 설정 관련\n","* for문으로 돌리려다가, 하나하나 돌리는게 너무 오래 걸려서 코드로 나누고 계정별로 돌릴 수 있게 코드 변경했습니다\n","* 공격 종류 (FGSM, PGD), 공격 입실론 (0.02 등)을 목차 [Attack 수행 : 공격 데이터셋 만드는 코드] 부분에서 수정하고 코드 돌리면 됩니다"]},{"cell_type":"markdown","metadata":{"id":"H5r08xIXerXB"},"source":["# 기본 import"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WgKss5hJBb5B"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","import os\n","import pathlib\n","\n","import cv2 #영상처리에 사용하는 오픈소스 라이브러리, 컴퓨터가 사람 눈처럼 인식할 수 있게 처리\n","from PIL import Image # 파이썬 이미지 처리 pillow 라이브러리\n","from tensorflow.keras.preprocessing import image\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator #imagedatagenerater는 이미지를 학습시킬 때 학습 데이터의 양이 적을 경우 학습데이터를 조금씩 변형 시켜서 학습데이터의 양을 늘리는 방식중 하나\n","from tensorflow.keras.preprocessing.image import img_to_array, array_to_img, load_img\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n","from tensorflow.keras.models import Sequential\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","import matplotlib.pyplot as plt\n","\n","from tqdm.auto import tqdm\n","\n","#난수 랜덤성 고정\n","np.random.seed(42)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17801,"status":"ok","timestamp":1663416744287,"user":{"displayName":"김채현코랩4","userId":"10582796771083497311"},"user_tz":-540},"id":"Qn7HC1qiBnNE","outputId":"fa6db095-6674-44d3-add4-1749b515ba36"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1587,"status":"ok","timestamp":1663416745870,"user":{"displayName":"김채현코랩4","userId":"10582796771083497311"},"user_tz":-540},"id":"VwTVXhm7BoaE","outputId":"5af04eb8-9cc5-4bd1-8627-61655899d969"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1WKEjdIyqtzI-NV5o0O_ixsHslngaSiQX/[한이음] 적대적 AI 공격에 대한 인공지능 보안기술 연구/3. 소스코드/GTSRB\n"]}],"source":["cd drive/MyDrive/[한이음] 적대적 AI 공격에 대한 인공지능 보안기술 연구/3. 소스코드/GTSRB"]},{"cell_type":"markdown","metadata":{"id":"FhnfS-0MH1sa"},"source":["# Train & Test 데이터 불러오기"]},{"cell_type":"markdown","metadata":{"id":"JjBcm524Fams"},"source":["Train Data 불러오기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kZnmTWHIBo_E"},"outputs":[],"source":["import numpy as np\n","import os\n","import gzip\n","import urllib.request\n","\n","from keras.models import load_model\n","\n","def ordered_onehotencoding(labels):\n","    labels_ordered = []\n","    for i in range(len(labels)):\n","        if labels[i] == 3:\n","            labels_ordered.append(0)\n","        elif labels[i] == 7:\n","            labels_ordered.append(1)\n","        elif labels[i] == 9:\n","            labels_ordered.append(2)\n","        elif labels[i] == 10:\n","            labels_ordered.append(3)\n","        elif labels[i] == 11:\n","            labels_ordered.append(4)\n","        elif labels[i] == 12:\n","            labels_ordered.append(5)\n","        elif labels[i] == 13:\n","            labels_ordered.append(6)\n","        elif labels[i] == 17:\n","            labels_ordered.append(7)\n","        elif labels[i] == 18:\n","            labels_ordered.append(8)\n","        elif labels[i] == 25:\n","            labels_ordered.append(9)\n","        elif labels[i] == 35:\n","            labels_ordered.append(10)\n","        elif labels[i] == 38:\n","            labels_ordered.append(11)\n","    \n","    return np.array(labels_ordered)\n","\n","class GTSRB:\n","    def __init__(self):\n","        imgs_path = \"Train\"\n","        data_list = []\n","        labels_list = []\n","\n","        result_class = [3,7, 9, 10, 11, 12, 13, 17, 18, 25, 35, 38]\n","\n","        for i in result_class:\n","            i_path = os.path.join(imgs_path, str(i)) # 3, 7, 9, 10, 11, 12,13, 17, 18, 25, 35, 38\n","            num = 0\n","            for img in os.listdir(i_path):\n","          \n","                im = Image.open(i_path +'/'+ img)\n","                im = im.resize((32,32))\n","                im = np.array(im)\n","\n","                data_list.append(im)\n","                labels_list.append(i)\n","                num = num + 1\n","                if num == 1000:\n","                    break;\n","\n","        data = np.array(data_list)\n","        labels = ordered_onehotencoding(labels_list)\n","\n","        labels = to_categorical(labels)\n","\n","        VALIDATION_SIZE = 5000\n","        \n","        self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(np.array(data), labels, test_size=0.4)    \n","\n","    @staticmethod\n","    def print():\n","        return \"GTSRB\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lWo9BzndEm67"},"outputs":[],"source":["data = GTSRB()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1663417054189,"user":{"displayName":"김채현코랩4","userId":"10582796771083497311"},"user_tz":-540},"id":"Zc5Q_EXiEppb","outputId":"63a52976-db3e-408c-d3b4-abacfe0789b6"},"outputs":[{"output_type":"stream","name":"stdout","text":["(7200, 32, 32, 3)\n","(4800, 32, 32, 3)\n","(7200, 12)\n","(4800, 12)\n"]}],"source":["print(data.x_train.shape)\n","print(data.x_test.shape)\n","print(data.y_train.shape)\n","print(data.y_test.shape)"]},{"cell_type":"markdown","metadata":{"id":"P2uSEM66FdVa"},"source":["Test Data 불러오기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_shX58HHFisj"},"outputs":[],"source":["metainfo = pd.read_csv(\"Meta.csv\")\n","traininfo = pd.read_csv(\"Train.csv\")\n","testinfo = pd.read_csv(\"Test.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z9HPAPg2FZ9L"},"outputs":[],"source":["import natsort\n","\n","class GTSRB_test:\n","    def __init__(self):\n","        imgs_path = \"Test\"\n","        data_list = []\n","        labels_list = []\n","        \n","        for img in natsort.natsorted(os.listdir(imgs_path)):\n","            im = Image.open(imgs_path +'/'+ img)\n","            im = im.resize((32,32))\n","            im = np.array(im)\n","            data_list.append(im)\n","        data_test = np.array(data_list)\n","        \n","        for i in range(len(testinfo.ClassId)):\n","            labels_list.append(testinfo.ClassId[i])\n","        \n","        labels_test = np.array(labels_list)\n","\n","        labels_test_index = []\n","        for i in range(len(labels_test)):\n","            if (labels_test[i] == 3) | (labels_test[i] == 7) | (labels_test[i] == 9) | (labels_test[i] == 10) | (labels_test[i] == 11) | (labels_test[i] == 12) | (labels_test[i] == 13) | (labels_test[i] == 17) | (labels_test[i] == 18) | (labels_test[i] == 25) | (labels_test[i] == 35) | (labels_test[i] == 38):\n","                labels_test_index.append(i)\n","\n","        test_data = []\n","        test_label = []\n","        for i in labels_test_index:\n","            test_data.append(data_test[i])\n","            test_label.append(labels_test[i])\n","\n","        data_test = np.array(test_data)\n","\n","        labels_test =ordered_onehotencoding(test_label)\n","\n","        labels_test = to_categorical(labels_test)\n","        \n","        self.x_test = data_test\n","        self.y_test = labels_test    \n","\n","    @staticmethod\n","    def print():\n","        return \"GTSRB_test\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CcWfJaa6Ft7z"},"outputs":[],"source":["data_test = GTSRB_test()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1663417259955,"user":{"displayName":"김채현코랩4","userId":"10582796771083497311"},"user_tz":-540},"id":"VE9NTZrAFv7e","outputId":"52ea5c06-a3dc-4c89-d1e8-cdbef5a872d8"},"outputs":[{"output_type":"stream","name":"stdout","text":["(6180, 32, 32, 3)\n","(6180, 12)\n"]}],"source":["print(data_test.x_test.shape)\n","print(data_test.y_test.shape)"]},{"cell_type":"markdown","metadata":{"id":"XWfrLWt3EtSN"},"source":["# 분류기 : CNN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TqQDIy-WEwQz"},"outputs":[],"source":["data.x_train, data.y_train, data.x_test, data.y_test =data.x_train/255, data.y_train/255, data.x_test/255, data.y_test/255"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":55264,"status":"ok","timestamp":1663417315199,"user":{"displayName":"김채현코랩4","userId":"10582796771083497311"},"user_tz":-540},"id":"gI5nIfEQE0Dt","outputId":"505c5eb8-07e8-4baf-af19-5917b1d3aae9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 30, 30, 96)        2688      \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 15, 15, 96)       0         \n"," )                                                               \n","                                                                 \n"," dropout (Dropout)           (None, 15, 15, 96)        0         \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 13, 13, 192)       166080    \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 6, 6, 192)        0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_1 (Dropout)         (None, 6, 6, 192)         0         \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 4, 4, 192)         331968    \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 64)                196672    \n","                                                                 \n"," dense_1 (Dense)             (None, 12)                780       \n","                                                                 \n","=================================================================\n","Total params: 698,188\n","Trainable params: 698,188\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/30\n","60/60 [==============================] - 13s 23ms/step - loss: 0.0457 - accuracy: 0.0789 - val_loss: 0.0061 - val_accuracy: 0.0846\n","Epoch 2/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0042 - accuracy: 0.0906 - val_loss: 0.0033 - val_accuracy: 0.1088\n","Epoch 3/30\n","60/60 [==============================] - 1s 23ms/step - loss: 0.0031 - accuracy: 0.1224 - val_loss: 0.0033 - val_accuracy: 0.1240\n","Epoch 4/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0030 - accuracy: 0.1429 - val_loss: 0.0032 - val_accuracy: 0.1531\n","Epoch 5/30\n","60/60 [==============================] - 1s 23ms/step - loss: 0.0030 - accuracy: 0.1682 - val_loss: 0.0032 - val_accuracy: 0.1894\n","Epoch 6/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0029 - accuracy: 0.1806 - val_loss: 0.0033 - val_accuracy: 0.2150\n","Epoch 7/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0029 - accuracy: 0.1919 - val_loss: 0.0031 - val_accuracy: 0.2019\n","Epoch 8/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0029 - accuracy: 0.2211 - val_loss: 0.0032 - val_accuracy: 0.2548\n","Epoch 9/30\n","60/60 [==============================] - 1s 24ms/step - loss: 0.0029 - accuracy: 0.2447 - val_loss: 0.0031 - val_accuracy: 0.2942\n","Epoch 10/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0029 - accuracy: 0.2956 - val_loss: 0.0031 - val_accuracy: 0.3404\n","Epoch 11/30\n","60/60 [==============================] - 1s 23ms/step - loss: 0.0028 - accuracy: 0.4342 - val_loss: 0.0029 - val_accuracy: 0.5431\n","Epoch 12/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.5504 - val_loss: 0.0027 - val_accuracy: 0.6162\n","Epoch 13/30\n","60/60 [==============================] - 1s 23ms/step - loss: 0.0026 - accuracy: 0.6132 - val_loss: 0.0027 - val_accuracy: 0.6835\n","Epoch 14/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0025 - accuracy: 0.6749 - val_loss: 0.0027 - val_accuracy: 0.7348\n","Epoch 15/30\n","60/60 [==============================] - 1s 23ms/step - loss: 0.0025 - accuracy: 0.7254 - val_loss: 0.0026 - val_accuracy: 0.7892\n","Epoch 16/30\n","60/60 [==============================] - 1s 19ms/step - loss: 0.0025 - accuracy: 0.7707 - val_loss: 0.0025 - val_accuracy: 0.8102\n","Epoch 17/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0024 - accuracy: 0.8015 - val_loss: 0.0025 - val_accuracy: 0.8571\n","Epoch 18/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0024 - accuracy: 0.8282 - val_loss: 0.0024 - val_accuracy: 0.8704\n","Epoch 19/30\n","60/60 [==============================] - 1s 23ms/step - loss: 0.0024 - accuracy: 0.8522 - val_loss: 0.0025 - val_accuracy: 0.8869\n","Epoch 20/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0024 - accuracy: 0.8708 - val_loss: 0.0025 - val_accuracy: 0.9021\n","Epoch 21/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0024 - accuracy: 0.8814 - val_loss: 0.0025 - val_accuracy: 0.9008\n","Epoch 22/30\n","60/60 [==============================] - 1s 24ms/step - loss: 0.0024 - accuracy: 0.8954 - val_loss: 0.0025 - val_accuracy: 0.9225\n","Epoch 23/30\n","60/60 [==============================] - 1s 23ms/step - loss: 0.0023 - accuracy: 0.9067 - val_loss: 0.0024 - val_accuracy: 0.9315\n","Epoch 24/30\n","60/60 [==============================] - 1s 23ms/step - loss: 0.0023 - accuracy: 0.9144 - val_loss: 0.0024 - val_accuracy: 0.9373\n","Epoch 25/30\n","60/60 [==============================] - 1s 24ms/step - loss: 0.0023 - accuracy: 0.9201 - val_loss: 0.0024 - val_accuracy: 0.9413\n","Epoch 26/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0023 - accuracy: 0.9251 - val_loss: 0.0024 - val_accuracy: 0.9540\n","Epoch 27/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0023 - accuracy: 0.9357 - val_loss: 0.0024 - val_accuracy: 0.9533\n","Epoch 28/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0023 - accuracy: 0.9394 - val_loss: 0.0025 - val_accuracy: 0.9563\n","Epoch 29/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0023 - accuracy: 0.9471 - val_loss: 0.0024 - val_accuracy: 0.9646\n","Epoch 30/30\n","60/60 [==============================] - 1s 23ms/step - loss: 0.0023 - accuracy: 0.9572 - val_loss: 0.0024 - val_accuracy: 0.9721\n"]}],"source":["from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D,GlobalAveragePooling2D\n","from tensorflow.keras.optimizers import SGD\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","import tensorflow as tf\n","import os\n","\n","\n","def train(data, file_name, num_epochs=50, batch_size=128):\n","    \"\"\"\n","    Standard neural network training procedure.\n","    \"\"\"\n","    model = Sequential()\n","\n","    IMG_HEIGHT = 32\n","    IMG_WIDTH = 32\n","\n","    # 첫번째 Convolutional Layer : 입력 데이터로부터 특징을 추출\n","    model.add(Conv2D(filters=96, kernel_size=3, activation='relu', input_shape=data.x_train.shape[1:]))\n","    model.add(MaxPool2D(pool_size=(2, 2)))\n","    model.add(Dropout(rate=0.25))\n","\n","    # 두번째 Convolutional Layer\n","    model.add(Conv2D(filters=192, kernel_size=3, activation='relu'))\n","    model.add(MaxPool2D(pool_size=(2, 2)))\n","    model.add(Dropout(rate=0.25)) # 인풋데이터의 25%를 무작위로 0으로 만듦\n","\n","    # 세번째 Convolutional Layer\n","    model.add(Conv2D(filters=192, kernel_size=3, activation='relu')) # 특징을 추출하는 기능을 하는 필터, 비선형 값으로 바꿔주는 activation 함수->relu\n","    # model.add(GlobalAveragePooling2D())\n","    model.add(Flatten())\n","\n","    model.add(Dense(units=64, activation='relu'))\n","    model.add(Dense(12, activation='softmax'))\n","\n","\n","    # 모델 컴파일 하기\n","    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    model.summary()\n","\n","    # 모델 핏하기\n","    EPOCHS = num_epochs\n","    model.fit(data.x_train, data.y_train,\n","              validation_data = (data.x_test, data.y_test), \n","              epochs=EPOCHS, steps_per_epoch=60\n","              )\n","\n","    if file_name != None:\n","        model.save(file_name)\n","\n","    return model\n","\n","\n","if not os.path.isdir('models'):\n","    os.makedirs('models')\n","\n","model = train(data, \"models/gtsrb_classifier\", num_epochs=30)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1524,"status":"ok","timestamp":1663417316702,"user":{"displayName":"김채현코랩4","userId":"10582796771083497311"},"user_tz":-540},"id":"Ez-W2phKFLws","outputId":"f508170b-ff40-4d35-cd31-550d0169846c"},"outputs":[{"output_type":"stream","name":"stdout","text":["225/225 [==============================] - 1s 3ms/step - loss: 0.0024 - accuracy: 0.9769\n","test set accuracy:  97.69444465637207\n","150/150 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.9721\n","test set accuracy:  97.2083330154419\n"]}],"source":["loss, accuracy = model.evaluate(data.x_train, data.y_train)\n","\n","print('test set accuracy: ', accuracy * 100)\n","\n","loss, accuracy = model.evaluate(data.x_test, data.y_test)\n","\n","print('test set accuracy: ', accuracy * 100)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2267,"status":"ok","timestamp":1663417318964,"user":{"displayName":"김채현코랩4","userId":"10582796771083497311"},"user_tz":-540},"id":"xbYmfSHYHOIa","outputId":"57d2ba78-5446-44bf-ba15-3e5c1743dbfc"},"outputs":[{"output_type":"stream","name":"stdout","text":["194/194 [==============================] - 1s 4ms/step - loss: 31.7821 - accuracy: 0.8704\n","test set accuracy:  87.03883290290833\n","194/194 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9273\n","test set accuracy with nomalization:  92.73462891578674\n"]}],"source":["# test data set\n","loss, accuracy = model.evaluate(data_test.x_test, data_test.y_test)\n","\n","print('test set accuracy: ', accuracy * 100)\n","\n","# --> 애초에 오버피팅 되어있음을 확인할 수 있다.\n","\n","loss, accuracy = model.evaluate(data_test.x_test/255, data_test.y_test/255)\n","\n","print('test set accuracy with nomalization: ', accuracy * 100)\n","\n","# --> /255로 정규화 시켜준다면 어느정도 성능 회복 "]},{"cell_type":"markdown","metadata":{"id":"QNRCIvO3-8lf"},"source":["# 공격 데이터셋 : FGSM & PGD"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dn9x64obA9UB"},"outputs":[],"source":["def tf_preprocess(image):\n","  image = tf.cast(image, tf.float32)\n","  image = image/255\n","  image = tf.image.resize(image, (32, 32))\n","  image = image[None, ...]\n","  return image\n","\n","# 확률 벡터에서 레이블을 추출해주는 헬퍼 메서드\n","def get_tf_label(labels):\n","    label = tf.cast(labels, tf.int32)\n","    label = tf.reshape(label,[1,12])\n","    return label\n","\n","loss_object = tf.keras.losses.CategoricalCrossentropy()\n","\n","def create_adversarial_pattern(input_image, input_label):\n","  with tf.GradientTape() as tape:\n","    tape.watch(input_image)\n","    input_img = tf.reshape(input_image,[1,32,32,3])\n","    prediction = model(input_img)\n","    loss = loss_object(input_label, prediction)\n","\n","  # 입력 이미지에 대한 손실 함수의 기울기를 구합니다.\n","  gradient = tape.gradient(loss, input_image)\n","  # 왜곡을 생성하기 위해 그래디언트의 부호를 구합니다.\n","  signed_grad = tf.sign(gradient)\n","  return signed_grad"]},{"cell_type":"markdown","metadata":{"id":"4SUb6-MoJtay"},"source":["### FGSM & PGD define"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DGBdi7tWJT1K"},"outputs":[],"source":["def fgsm_attack(model,test_x,test_y,eps):\n","    \n","    correct = 0\n","    adv_examples = []\n","    save_adv_examples = [] # 공격받은 이미지들이 저장될 리스트\n","    save_original_output = [] # 공격받은 이미지들의 정답 라벨 값이 저장될 리스트\n","    \n","    for i in range(len(test_x)):\n","        # 1장의 이미지와 그 label\n","        data = test_x[i]\n","        target_onehot = test_y[i] # one-hot 형태\n","        target_label = int(np.argmax(target_onehot)) # label 형태\n","\n","        # model이 정상 데이터를 분류한 결과 (각각 one-hot 형태, int label 형태)\n","        result_onehot = model.predict(data.reshape(1,32,32,3) / 255) # one-hot 형태\n","        result_label = int(np.argmax(result_onehot))\n","\n","        # 모델이 정상 데이터인데도 잘못 분류했다면 사용하지 않는다 (아래 코드 실행하지 않고 다음 이미지로 넘어감)\n","        if target_label != result_label:\n","            continue\n","\n","        # 이미지 전처리\n","        img =  tf_preprocess(data) # 텐서플로 전처리\n","        label = get_tf_label(target_onehot) # 확률벡터에서 레이블 추출\n","        \n","        # FGSM 공격 수행\n","        perturbations = create_adversarial_pattern(img, label)\n","        adv_x = img + eps * perturbations\n","        adv_x = tf.clip_by_value(adv_x, 0, 1) # 공격받은 이미지\n","\n","        # 공격 이미지를 분류기에 넣은 결과; 잘못 분류되어야 할 것 \n","        atkresult_onehot = model.predict(adv_x) # one-hot 형태\n","        atkresult_label = int(np.argmax(atkresult_onehot)) # label 형태\n","\n","        # 만약 공격 받아도 제대로 분류된다면 correct로 count\n","        if atkresult_label == target_label:\n","            correct += 1\n","        # ####################################################################################\n","        # ################ 여기 코드는 필요 없지 않나?\n","        #     if (eps == 0) and (len(adv_examples) < 5):\n","        #         adv_ex = adv_x\n","        #         adv_examples.append((init_output,final_pred,adv_x))\n","        # else:\n","        #     if len(adv_examples) < 5:\n","        #         adv_ex = adv_x\n","        #         adv_examples.append((init_output,final_pred,adv_x))\n","        # ####################################################################################\n","        \n","        # 공격 적용된 이미지, 그 공격 받은 이미지의 원래 정답 label을 각각 리스트에 저장합니다\n","        save_adv_examples.append(tf.reshape(adv_x,[32,32,3]))\n","        save_original_output.append(atkresult_label)\n","\n","    # 해당 엡실론에서의 최종 정확도를 계산합니다\n","    final_acc = correct/float(len(test_x))\n","    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(eps, correct, len(test_x), final_acc))\n","\n","    # 정확도와 적대적 예제를 리턴합니다\n","    return final_acc, adv_examples, save_adv_examples, save_original_output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GmiLgFduVhR0"},"outputs":[],"source":["def pgd_attack(model,test_x,test_y,eps,step_size=2,num_steps=7): \n","    \"\"\"\n","    FGSM 코드와 차이점\n","    - step_size, num_steps 파라미터 추가됨\n","    - unifrom distribution 코드 추가\n","    - FGSM 공격 수행 -> PGD 공격 수행\n","    ** 모든 return 형식은 동일함\n","    \n","    default 값\n","    - step_size = 2 (alpha 값)\n","    - num_steps = 7 (iterations 값)\n","\n","    \"\"\"\n","\n","    prog = 0 # 진행상황 확인용 변수\n","\n","    correct = 0\n","    adv_examples = []\n","    save_adv_examples = [] # 공격받은 이미지들이 저장될 리스트\n","    save_original_output = [] # 공격받은 이미지들의 정답 라벨 값이 저장될 리스트\n","    \n","    for i in range(len(test_x)):\n","        # 1장의 이미지와 그 label\n","        data = test_x[i]\n","        target_onehot = test_y[i] # one-hot 형태\n","        target_label = int(np.argmax(target_onehot)) # label 형태\n","\n","        # model이 정상 데이터를 분류한 결과 (각각 one-hot 형태, int label 형태)\n","        result_onehot = model.predict(data.reshape(1,32,32,3) / 255) # one-hot 형태\n","        result_label = int(np.argmax(result_onehot))\n","\n","        # 모델이 정상 데이터인데도 잘못 분류했다면 사용하지 않는다 (아래 코드 실행하지 않고 다음 이미지로 넘어감)\n","        if target_label != result_label:\n","            continue\n","\n","        # PGD uniform distribution 코드\n","        data = data + np.random.uniform(-eps,eps,data.shape)\n","        data = np.clip(data,0,255)\n","\n","        # 이미지 전처리\n","        img =  tf_preprocess(data) # 텐서플로 전처리\n","        label = get_tf_label(target_onehot) # 확률벡터에서 레이블 추출\n","        \n","        # PGD 공격 수행\n","        adv_x = img # 공격받은 이미지 (for문으로 업데이트)\n","        for num_step in range(num_steps):\n","          perturbations = create_adversarial_pattern(adv_x,label) # signed_grad를 리턴한 값\n","          adv_x += step_size * perturbations\n","          adv_x = tf.clip_by_value(adv_x,img-eps,img+eps)\n","          adv_x = tf.clip_by_value(adv_x,0,1)\n","\n","        # 공격 이미지를 분류기에 넣은 결과; 잘못 분류되어야 할 것 \n","        atkresult_onehot = model.predict(adv_x) # one-hot 형태\n","        atkresult_label = int(np.argmax(atkresult_onehot)) # label 형태\n","\n","        # 만약 공격 받아도 제대로 분류된다면 correct로 count\n","        if atkresult_label == target_label:\n","            correct += 1\n","        # ####################################################################################\n","        # ################ 여기 코드는 필요 없지 않나?\n","        #     if (eps == 0) and (len(adv_examples) < 5):\n","        #         adv_ex = adv_x\n","        #         adv_examples.append((init_output,final_pred,adv_x))\n","        # else:\n","        #     if len(adv_examples) < 5:\n","        #         adv_ex = adv_x\n","        #         adv_examples.append((init_output,final_pred,adv_x))\n","        # ####################################################################################\n","        \n","        # 공격 적용된 이미지, 그 공격 받은 이미지의 원래 정답 label을 각각 리스트에 저장합니다\n","        save_adv_examples.append(tf.reshape(adv_x,[32,32,3]))\n","        save_original_output.append(atkresult_label)\n","\n","        prog += 1\n","        if prog%3000 == 0:\n","          print(\"prog :\", prog)\n","\n","    # 해당 엡실론에서의 최종 정확도를 계산합니다\n","    final_acc = correct/float(len(test_x))\n","    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(eps, correct, len(test_x), final_acc))\n","\n","    # 정확도와 적대적 예제를 리턴합니다\n","    return final_acc, adv_examples, save_adv_examples, save_original_output"]},{"cell_type":"markdown","metadata":{"id":"AVs5AnagBdTK"},"source":["### Attack 수행 : 공격 데이터셋 만드는 코드\n","\n","**여기에서 [attack_type]과 [eps] 설정하면 됩니다!!!**\n","\n","* attack_type : FGSM, PGD\n","* eps = 0.02, 0.03, 8/255, 0.05, 0.08, 0.10\n","* 정상 이미지에 대한 분류기 정확도 -> 위에 있음 (분류기:CNN; 약 91%)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":922610,"status":"ok","timestamp":1663418241571,"user":{"displayName":"김채현코랩4","userId":"10582796771083497311"},"user_tz":-540},"id":"ZE2wZtfAEOBh","outputId":"ebd8928a-af07-4183-e256-00c0931314e2"},"outputs":[{"output_type":"stream","name":"stdout","text":["prog : 3000\n","Epsilon: 0.02\tTest Accuracy = 2750 / 6180 = 0.4449838187702265\n","Attack Data 생성 완료\n"]}],"source":["################################################################################\n","# 공격 데이터 설정 #################################################################\n","attack_type = \"PGD\" # FGSM, PGD\n","eps = 0.02 # 0.02, 0.03, 8/255, 0.05, 0.08, 0.10\n","################################################################################\n","################################################################################\n","\n","if attack_type == \"FGSM\":\n","  acc, ex, ad_examples, orig_labels = fgsm_attack(model, data_test.x_test, data_test.y_test, eps)\n","elif attack_type == \"PGD\":\n","  acc, ex, ad_examples, orig_labels = pgd_attack(model, data_test.x_test, data_test.y_test, eps)\n","\n","print(\"Attack Data 생성 완료\")"]},{"cell_type":"markdown","metadata":{"id":"6DfDZcE5_GGB"},"source":["# 방어모델 : MagNet, Defense-GAN, PCA"]},{"cell_type":"markdown","metadata":{"id":"Lb-doZmmIFqj"},"source":["## MagNet"]},{"cell_type":"markdown","metadata":{"id":"-Yc-yrW7ktMW"},"source":["### MagNet - def (utils, worker, Defensive Model)"]},{"cell_type":"markdown","metadata":{"id":"bt4nIJ5xg73T"},"source":["#### MagNet - utils"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hAvlahKmMFdO"},"outputs":[],"source":["## utils.py -- utility functions\n","##\n","## Copyright (C) 2017, Dongyu Meng <zbshfmmm@gmail.com>.\n","##\n","## This program is licenced under the BSD 2-Clause licence,\n","## contained in the LICENCE file in this directory.\n","\n","import pickle\n","import os\n","import numpy as np\n","\n","\n","def prepare_data(dataset, idx):\n","    \"\"\"\n","    Extract data from index.\n","\n","    dataset: Full, working dataset. Such as MNIST().\n","    idx: Index of test examples that we care about.\n","    return: X, targets, Y\n","    \"\"\"\n","    return dataset.x_test[idx], dataset.y_test[idx], np.argmax(dataset.y_test[idx], axis=1)\n","\n","\n","def save_obj(obj, name, directory='./attack_data/'):\n","    with open(os.path.join(directory, name + '.pkl'), 'wb') as f:\n","        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n","\n","\n","def load_obj(name, directory='./attack_data/'):\n","    if name.endswith(\".pkl\"): name = name[:-4]\n","    with open(os.path.join(directory, name + '.pkl'), 'rb') as f:\n","        return pickle.load(f)"]},{"cell_type":"markdown","metadata":{"id":"EhncucofhEvv"},"source":["#### MagNet - worker"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZRv7EXuShHMK"},"outputs":[],"source":["## setup_mnist.py -- mnist data and model loading code\n","##\n","## Copyright (C) 2016, Nicholas Carlini <nicholas@carlini.com>.\n","##\n","## This program is licenced under the BSD 2-Clause licence,\n","## contained in the LICENCE file in this directory.\n","\n","## Modified for MagNet's use.\n","\n","## worker.py -- evaluation code\n","##\n","## Copyright (C) 2017, Dongyu Meng <zbshfmmm@gmail.com>.\n","##\n","## This program is licenced under the BSD 2-Clause licence,\n","## contained in the LICENCE file in this directory.\n","\n","import matplotlib\n","matplotlib.use('Agg')\n","from scipy.stats import entropy\n","from numpy.linalg import norm\n","from matplotlib.ticker import FuncFormatter\n","from keras.models import Sequential, load_model\n","from keras.activations import softmax\n","from keras.layers import Lambda\n","import numpy as np\n","import pylab\n","import os\n","import matplotlib.pyplot as plt\n","\n","\n","class AEDetector:\n","    def __init__(self, path, p=1):\n","        \"\"\"\n","        Error based detector.\n","        Marks examples for filtering decisions.\n","\n","        path: Path to the autoencoder used.\n","        p: Distance measure to use.\n","        \"\"\"\n","\n","        self.model = load_model(path)\n","        self.path = path\n","        self.p = p\n","\n","    def mark(self, X):\n","        diff = np.abs(X - self.model.predict(X)) # input X와 예측값 X'(autoencoder를 통해 노이즈가 더해진 값) 의 오차 값\n","        marks = np.mean(np.power(diff, self.p), axis=(1,2,3)) # 오차값의 분산\n","        return marks\n","\n","    def print(self):\n","        return \"AEDetector:\" + self.path.split(\"/\")[-1]\n","\n","\n","class IdReformer:\n","    def __init__(self, path=\"IdentityFunction\"):\n","        \"\"\"\n","        Identity reformer.\n","        Reforms an example to itself.\n","        \"\"\"\n","        self.path = path\n","        self.heal = lambda X: X\n","\n","    def print(self):\n","        return \"IdReformer:\" + self.path\n","\n","\n","class SimpleReformer:\n","    def __init__(self, path):\n","        \"\"\"\n","        Reformer.\n","        Reforms examples with autoencoder. Action of reforming is called heal.\n","\n","        path: Path to the autoencoder used.\n","        \"\"\"\n","        self.model = load_model(path)\n","        self.path = path\n","\n","    def heal(self, X):\n","        X = self.model.predict(X) # autoencoder로 X값 재구성\n","        return np.clip(X, 0.0, 1.0)\n","\n","    def print(self):\n","        return \"SimpleReformer:\" + self.path.split(\"/\")[-1]\n","\n","\n","def JSD(P, Q):\n","    _P = P / norm(P, ord=1)\n","    _Q = Q / norm(Q, ord=1)\n","    _M = 0.5 * (_P + _Q)\n","    return 0.5 * (entropy(_P, _M) + entropy(_Q, _M)) # Xp와 Xr의 분포의 entropy \n","    # KL divergence: Q(one autoencoder)를 기반으로 했을 때의 cross entropy와 P(magnet)를 기반으로 했을 때의 entropy의 차이\n","\n","\n","\n","class DBDetector:\n","    def __init__(self, reconstructor, prober, classifier, option=\"jsd\", T=1):\n","        \"\"\"\n","        Divergence-Based Detector.\n","\n","        reconstructor: One autoencoder.\n","        prober: Another autoencoder.\n","        classifier: Classifier object.\n","        option: Measure of distance, jsd as default.\n","        T: Temperature to soften the classification decision.\n","        \"\"\"\n","        self.prober = prober\n","        self.reconstructor = reconstructor\n","        self.classifier = classifier\n","        self.option = option\n","        self.T = T\n","\n","    def mark(self, X):\n","        return self.mark_jsd(X)\n","\n","    def mark_jsd(self, X):\n","        Xp = self.prober.heal(X) # 1번 autoencoder로 생성한 이미지 \n","        Xr = self.reconstructor.heal(X) #2번 autoencoder로 생성한 이미지 \n","        Pp = self.classifier.classify(Xp, option=\"prob\", T=self.T) # Xp의 확률\n","        Pr = self.classifier.classify(Xr, option=\"prob\", T=self.T) # Xr의 확률\n","\n","        marks = [(JSD(Pp[i], Pr[i])) for i in range(len(Pr))]\n","        return np.array(marks)\n","\n","    def print(self):\n","        return \"Divergence-Based Detector\"\n","\n","\n","class Classifier:\n","    def __init__(self, classifier_path):\n","        \"\"\"\n","        Keras classifier wrapper.\n","        Note that the wrapped classifier should spit logits as output.\n","\n","        classifier_path: Path to Keras classifier file.\n","        \"\"\"\n","        self.path = classifier_path\n","        self.model = load_model(classifier_path)\n","        self.softmax = Sequential()\n","        self.softmax.add(Lambda(lambda X: softmax(X, axis=1)))\n","\n","    def classify(self, X, option=\"logit\", T=1):\n","        if option == \"logit\":\n","            return self.model.predict(X)\n","        if option == \"prob\":\n","            logits = self.model.predict(X)/T\n","            return self.softmax.predict(logits)\n","\n","    def print(self):\n","        return \"Classifier:\"+self.path.split(\"/\")[-1]\n","\n","\n","class Operator:\n","    def __init__(self, data, classifier, det_dict, reformer):\n","        \"\"\"\n","        Operator.\n","        Describes the classification problem and defense.\n","\n","        data: Standard problem dataset. Including train, test, and validation.\n","        classifier: Target classifier.\n","        reformer: Reformer of defense.\n","        det_dict: Detector(s) of defense.\n","        \"\"\"\n","\n","        self.data = data\n","        self.classifier = classifier\n","        self.det_dict = det_dict \n","        self.reformer = reformer\n","        self.normal = self.operate(AttackData(data.x_train, np.argmax(data.y_train, axis=1), \"Normal\"))\n","        \n","\n","    def get_thrs(self, drop_rate):\n","        \"\"\"\n","        Get filtering threshold by marking validation set.\n","        \"\"\"\n","        thrs = dict()\n","        for name, detector in self.det_dict.items():\n","            num = int(len(data.x_test) * drop_rate[name])\n","            marks = detector.mark(data.x_test)\n","            marks = np.sort(marks)\n","            thrs[name] = marks[-num]\n","        return thrs\n","\n","    def operate(self, untrusted_obj):\n","        \"\"\"\n","        For untrusted input(normal or adversarial), classify original input and\n","        reformed input. Classifier is unaware of the source of input.\n","\n","        untrusted_obj: Input data.\n","        \"\"\"\n","\n","        X = untrusted_obj.data\n","        Y_true = untrusted_obj.labels\n","\n","\n","        X_prime = self.reformer.heal(X) # autoencoder 값으로 재구성\n","        Y = np.argmax(self.classifier.classify(X), axis=1) # 원본 input X 분류\n","        Y_judgement = (Y == Y_true[:len(X_prime)]) # 실제 label과 X 분류 label 비교\n","        Y_prime = np.argmax(self.classifier.classify(X_prime), axis=1)  # autoencoder로 재구성한 X' 분류\n","        Y_prime_judgement = (Y_prime == Y_true[:len(X_prime)])  # 실제 label과 X' 분류 label 비교\n","        return np.array(list(zip(Y_judgement, Y_prime_judgement)))\n","\n","    def filter(self, X, thrs):\n","        \"\"\"\n","        untrusted_obj: Untrusted input to test against.\n","        thrs: Thresholds.\n","\n","        return:\n","        all_pass: Index of examples that passed all detectors.\n","        collector: Number of examples that escaped each detector.\n","        \"\"\"\n","        collector = dict()\n","        all_pass = np.array(range(10000)) #Index\n","        for name, detector in self.det_dict.items():\n","            marks = detector.mark(X) #  KL divergnece: Xp와 Xr의 분포의 entropy \n","            idx_pass = np.argwhere(marks < thrs[name]) # KL divergnece가 thershold보다 작을 경우 pass, 클 경우 reject\n","            collector[name] = len(idx_pass) # pass가 된 수\n","            all_pass = np.intersect1d(all_pass, idx_pass) # 전체 index array와 pass된 array의 교집합\n","        return all_pass, collector\n","\n","    def print(self):\n","        components = [self.reformer, self.classifier]\n","        return \" \".join(map(lambda obj: getattr(obj, \"print\")(), components))\n","\n","\n","class AttackData:\n","    def __init__(self, examples, labels, name=\"\"):\n","        \"\"\"\n","        Input data wrapper. May be normal or adversarial.\n","\n","        examples: Path or object of input examples.\n","        labels: Ground truth labels.\n","        \"\"\"\n","        # if isinstance(examples, str): \n","        #   self.data = load_obj(examples)\n","        # else: \n","\n","        self.data = examples\n","        self.labels = labels\n","        self.name = name\n","\n","    def print(self):\n","        return \"Attack:\"+self.name\n","\n","\n","class Evaluator:\n","    def __init__(self, operator, untrusted_data, graph_dir=\"./graph\"):\n","        \"\"\"\n","        Evaluator.\n","        For strategy described by operator, conducts tests on untrusted input.\n","        Mainly stats and plotting code. Most methods omitted for clarity.\n","\n","        operator: Operator object.\n","        untrusted_data: Input data to test against.\n","        graph_dir: Where to spit the graphs.\n","        \"\"\"\n","        self.operator = operator\n","        self.untrusted_data = untrusted_data # attacked data\n","        self.graph_dir = graph_dir\n","        self.data_package = operator.operate(untrusted_data)\n","\n","    def bind_operator(self, operator):\n","        self.operator = operator\n","        self.data_package = operator.operate(self.untrusted_data)\n","\n","    def load_data(self, data):\n","        self.untrusted_data = data\n","        self.data_package = self.operator.operate(self.untrusted_data)\n","\n","    def get_normal_acc(self, normal_all_pass):\n","        \"\"\"\n","        traning data에 대한 정확도\n","\n","        Break down of who does what in defense. Accuracy of defense on normal\n","        input.\n","\n","        both: Both detectors and reformer take effect\n","        det_only: detector(s) take effect\n","        ref_only: Only reformer takes effect\n","        none: Attack effect with no defense\n","        \"\"\"\n","        normal_tups = self.operator.normal\n","        num_normal = len(normal_tups)\n","        filtered_normal_tups = normal_tups[normal_all_pass]\n","\n","        both_acc = sum(1 for _, XpC in filtered_normal_tups if XpC)/num_normal # detector and refomer\n","        det_only_acc = sum(1 for XC, XpC in filtered_normal_tups if XC)/num_normal # only detector\n","        ref_only_acc = sum([1 for _, XpC in normal_tups if XpC])/num_normal # only reformer\n","        none_acc = sum([1 for XC, _ in normal_tups if XC])/num_normal # no defense\n","\n","        return both_acc, det_only_acc, ref_only_acc, none_acc\n","\n","    def get_attack_acc(self, attack_pass):\n","        \"\"\"\n","        attacked data에 대한 정확도 \n","        \"\"\"\n","        attack_tups = self.data_package\n","        num_untrusted = len(attack_tups)\n","        filtered_attack_tups = attack_tups[attack_pass]\n","\n","\n","        both_acc = 1 - sum(1 for _, XpC in filtered_attack_tups if not XpC)/num_untrusted # detector and refomer\n","        det_only_acc = 1 - sum(1 for XC, XpC in filtered_attack_tups if not XC)/num_untrusted # only detector\n","        ref_only_acc = sum([1 for _, XpC in attack_tups if XpC])/num_untrusted # only reformer\n","        none_acc = sum([1 for XC, _ in attack_tups if XC])/num_untrusted # no defense\n","        \n","        return both_acc, det_only_acc, ref_only_acc, none_acc\n","\n","    def plot_various_confidences(self, graph_name, drop_rate,\n","                                 idx_file=\"example_idx\",\n","                                 confs=(0.0, 10.0),\n","                                 get_attack_data_name=lambda c: \"example_carlini_\"+str(c)):\n","        \"\"\"\n","        Test defense performance against Carlini L2 attack of various confidences.\n","\n","        graph_name: Name of graph file.\n","        drop_rate: How many normal examples should each detector drops?\n","        idx_file: Index of adversarial examples in standard test set.\n","        confs: A series of confidence to test against.\n","        get_attack_data_name: Function mapping confidence to corresponding file.\n","        \"\"\"\n","        pylab.rcParams['figure.figsize'] = 6, 4\n","        fig = plt.figure(1, (6, 4))\n","        ax = fig.add_subplot(1, 1, 1)\n","\n","        idx = orig_labels\n","        # idx = original_labels_list\n","        X, _, Y = prepare_data(self.operator.data, idx)\n","\n","\n","        det_only = []\n","        ref_only = []\n","        both = []\n","        none = []\n","\n","        print(\"\\n==========================================================\")\n","        print(\"Drop Rate:\", drop_rate)\n","        thrs = self.operator.get_thrs(drop_rate)\n","\n","        all_pass, _ = self.operator.filter(self.operator.data.x_train, thrs)\n","        all_on_acc, _, _, _ = self.get_normal_acc(all_pass)\n","\n","        print(\"Classification accuracy with all defense on:\", all_on_acc)\n","\n","        for confidence in confs:\n","            # f = get_attack_data_name(confidence)\n","            self.load_data(AttackData(ad_examples1, orig_labels, \"GTSRB FSGM\"))\n","\n","            print(\"----------------------------------------------------------\")\n","            print(\"Confidence:\", confidence)\n","            all_pass, detector_breakdown = self.operator.filter(self.untrusted_data.data, thrs)\n","            both_acc, det_only_acc, ref_only_acc, none_acc = self.get_attack_acc(all_pass)\n","            print(detector_breakdown)\n","            both.append(both_acc)\n","            det_only.append(det_only_acc)\n","            ref_only.append(ref_only_acc)\n","            none.append(none_acc)\n","\n","        size = 2.5\n","\n","        print(\"With detector & reformer: \", both_acc)\n","        print(\"With detector: \",det_only_acc)\n","        print(\"With reformer: \", ref_only_acc)\n","        print(\"No Defense: \",none_acc)\n","\n","        # print(\"With detector & reformer: \", both)\n","        # print(\"With detector: \",det_only)\n","        # print(\"With reformer: \", ref_only)\n","        # print(\"No Defense: \",none)\n","\n","        plt.plot(confs, none, c=\"green\", label=\"No Defense\", marker=\"x\", markersize=size,alpha=0.5)\n","        # plt.plot(confs, det_only, c=\"orange\", label=\"With detector\", marker=\"o\", markersize=size,alpha=0.5)\n","        # plt.plot(confs, ref_only, c=\"blue\", label=\"With reformer\", marker=\"^\", markersize=size,alpha=0.5)\n","        plt.plot(confs, both, c=\"red\", label=\"With detector & reformer\", marker=\"s\", markersize=size,alpha=0.5)\n","\n","        pylab.legend(loc='lower left', bbox_to_anchor=(0.02, 0.1), prop={'size':8})\n","        plt.grid(linestyle='dotted')\n","        plt.xlabel(r\"Confidence in Carlini $L^2$ attack\")\n","        plt.ylabel(\"Classification accuracy\")\n","        plt.xlim(min(confs)-1.0, max(confs)+1.0)\n","        plt.ylim(-0.05, 1.05)\n","        ax.yaxis.set_major_formatter(FuncFormatter('{0:.0%}'.format))\n","\n","        save_path = os.path.join(self.graph_dir, graph_name+\".pdf\")\n","        plt.savefig(save_path)\n","        plt.clf()\n","\n","    def print(self):\n","        return \" \".join([self.operator.print(), self.untrusted_data.print()])"]},{"cell_type":"markdown","metadata":{"id":"4e-GBUowhNUQ"},"source":["#### MagNet - Defensive Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HyIrYmBIhPRc"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import os\n","import numpy as np\n","from keras.layers.core import Lambda\n","from keras.layers.merge import Average, add\n","from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, AveragePooling2D\n","from keras.models import Model\n","import keras.regularizers as regs\n","\n","\n","class DenoisingAutoEncoder:\n","    def __init__(self, image_shape,\n","                 structure,\n","                 v_noise=0.0,\n","                 activation=\"relu\",\n","                 model_dir=\"./defensive_models/\",\n","                 reg_strength=0.0):\n","        \"\"\"\n","        Denoising Autoencoder(DAE)\n","        training data에 nosie를 추가하여 인코더에 넣어서 학습된 결과가 \n","        noise를 붙이기 전 데이터와의 error을 최소화하는 목적을 가진 Autoencoder\n","\n","        image_shape: Shape of input image. e.g. 28, 28, 1.\n","        structure: Structure of autoencoder.\n","        v_noise: Volume of noise while training.\n","        activation: What activation function to use.\n","        model_dir: Where to save / load model from.\n","        reg_strength: Strength of L2 regularization.\n","        \"\"\"\n","        h, w, c = image_shape\n","        self.image_shape = image_shape # shape of input image (32,32,3)\n","        self.model_dir = model_dir \n","        self.v_noise = v_noise\n","\n","        input_img = Input(shape=self.image_shape)\n","        x = input_img\n","\n","        # encoder 정의 \n","        for layer in structure: \n","            if isinstance(layer, int):\n","                x = Conv2D(layer, (3, 3), activation=activation, padding=\"same\",\n","                           activity_regularizer=regs.l2(reg_strength))(x)\n","            elif layer == \"max\":\n","                x = MaxPooling2D((2, 2), padding=\"same\")(x)\n","            elif layer == \"average\":\n","                x = AveragePooling2D((2, 2), padding=\"same\")(x)\n","            else:\n","                print(layer, \"is not recognized!\")\n","                exit(0)\n","        \n","        for layer in reversed(structure):\n","            if isinstance(layer, int):\n","                x = Conv2D(layer, (3, 3), activation=activation, padding=\"same\",\n","                           activity_regularizer=regs.l2(reg_strength))(x)\n","            elif layer == \"max\" or layer == \"average\":\n","                x = UpSampling2D((2, 2))(x)\n","\n","        # decoder 정의 \n","        decoded = Conv2D(c, (3, 3), activation='sigmoid', padding='same',\n","                         activity_regularizer=regs.l2(reg_strength))(x)\n","\n","        self.model = Model(input_img, decoded) # autoencoder 모델\n","\n","    def train(self, data, archive_name, num_epochs=100, batch_size=32):\n","        self.model.compile(loss='mean_squared_error',\n","                           metrics=['mean_squared_error'],\n","                           optimizer='adam')\n","        \n","        noise = self.v_noise * np.random.normal(size=np.shape(data.x_train)) # 랜덤 노이즈 \n","        noisy_train_data = data.x_train + noise # Input Data에 랜덤 노이즈 추가 \n","        noisy_train_data = np.clip(noisy_train_data, 0.0, 1.0) # [0,1] 범위로 재구성\n","\n","        self.model.fit(noisy_train_data, data.x_train,\n","                       batch_size=batch_size,\n","                       validation_data=(data.x_test, data.x_test),\n","                       epochs=num_epochs,\n","                       shuffle=True)\n","\n","        print(os.path.join(self.model_dir, archive_name))        \n","        self.model.save(os.path.join(self.model_dir, archive_name))\n","\n","    def load(self, archive_name, model_dir=None):\n","        if model_dir is None: model_dir = self.model_dir\n","        self.model.load_weights(os.path.join(model_dir, archive_name))\n","\n","\n","class PackedAutoEncoder:\n","    def __init__(self, image_shape, structure, data,\n","                 v_noise=0.1, n_pack=2, pre_epochs=3, activation=\"relu\",\n","                 model_dir=\"./defensive_models/\"):\n","        \"\"\"\n","        Train different autoencoders.\n","        Demo code for graybox scenario.\n","\n","        pre_epochs: How many epochs do we train before fine-tuning.\n","        n_pack: Number of autoencoders we want to train at once.\n","        \"\"\"\n","        self.v_noise = v_noise\n","        self.n_pack = n_pack\n","        self.model_dir = model_dir\n","        pack = []\n","\n","\n","\n","        for i in range(n_pack):\n","            dae = DenoisingAutoEncoder(image_shape, structure, v_noise=v_noise,\n","                                       activation=activation, model_dir=model_dir)\n","            dae.train(data, \"\", num_epochs=pre_epochs)\n","            pack.append(dae.model)\n","\n","\n","        shared_input = Input(shape=image_shape, name=\"shared_input\")\n","        outputs = [dae(shared_input) for dae in pack]\n","        avg_output = Average()(outputs)\n","        delta_outputs = [add([avg_output, Lambda(lambda x: -x)(output)])\n","                         for output in outputs]\n","\n","        self.model = Model(inputs=shared_input, outputs=outputs+delta_outputs)\n","\n","    def train(self, data, archive_name, alpha, num_epochs=10, batch_size=32):\n","        noise = self.v_noise * np.random.normal(size=np.shape(data.x_train))\n","        noisy_train_data = data.x_train + noise\n","        noisy_train_data = np.clip(noisy_train_data, 0.0, 1.0)\n","\n","        train_zeros = [np.zeros_like(data.x_train)] * self.n_pack\n","        val_zeros = [np.zeros_like(data.x_test)] * self.n_pack\n","\n","        self.model.compile(loss=\"mean_squared_error\", optimizer=\"adam\",\n","                           loss_weights=[1.0]*self.n_pack + [-alpha]*self.n_pack)\n","\n","        self.model.fit(noisy_train_data,\n","                       [data.x_train]*self.n_pack + train_zeros,\n","                       batch_size=batch_size,\n","                       validation_data=(data.x_test,\n","                            [data.x_test]*self.n_pack+val_zeros),\n","                       epochs=num_epochs,\n","                       shuffle=True)\n","\n","        for i in range(self.n_pack):\n","            model = Model(self.model.input, self.model.outputs[i])\n","            self.model.save(\"\")\n","            print(os.path.join(self.model_dir, archive_name+\"_\"+str(i)))\n","            self.model.save(os.path.join(self.model_dir, archive_name+\"_\"+str(i)))\n","\n","    def load(self, archive_name, model_dir=None):\n","        if model_dir is None: model_dir = self.model_dir\n","        self.model.load_weights(os.path.join(model_dir, archive_name))"]},{"cell_type":"markdown","metadata":{"id":"ukxjkHWahV8B"},"source":["### MagNet - Train Defensive Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y-CppiQYhYQp"},"outputs":[],"source":["data.x_train, data.y_train, data.x_test, data.y_test =data.x_train/255, data.y_train/255, data.x_test/255, data.y_test/255"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C5S8s9wxhanJ","executionInfo":{"status":"ok","timestamp":1663419316251,"user_tz":-540,"elapsed":1073263,"user":{"displayName":"김채현코랩4","userId":"10582796771083497311"}},"outputId":"732e5b9f-d461-46ce-f924-a3203aca1d2d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/350\n","225/225 [==============================] - 3s 8ms/step - loss: 0.0488 - mean_squared_error: 0.0488 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n","Epoch 2/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n","Epoch 3/350\n","225/225 [==============================] - 2s 7ms/step - loss: 8.9155e-04 - mean_squared_error: 8.8652e-04 - val_loss: 6.5364e-04 - val_mean_squared_error: 6.4870e-04\n","Epoch 4/350\n","225/225 [==============================] - 1s 6ms/step - loss: 5.2112e-04 - mean_squared_error: 5.1599e-04 - val_loss: 4.1735e-04 - val_mean_squared_error: 4.1233e-04\n","Epoch 5/350\n","225/225 [==============================] - 1s 6ms/step - loss: 3.4946e-04 - mean_squared_error: 3.4428e-04 - val_loss: 2.9336e-04 - val_mean_squared_error: 2.8830e-04\n","Epoch 6/350\n","225/225 [==============================] - 2s 7ms/step - loss: 2.5324e-04 - mean_squared_error: 2.4801e-04 - val_loss: 2.1891e-04 - val_mean_squared_error: 2.1383e-04\n","Epoch 7/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.9294e-04 - mean_squared_error: 1.8769e-04 - val_loss: 1.7018e-04 - val_mean_squared_error: 1.6506e-04\n","Epoch 8/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.5228e-04 - mean_squared_error: 1.4700e-04 - val_loss: 1.3628e-04 - val_mean_squared_error: 1.3115e-04\n","Epoch 9/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2337e-04 - mean_squared_error: 1.1807e-04 - val_loss: 1.1164e-04 - val_mean_squared_error: 1.0649e-04\n","Epoch 10/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.0200e-04 - mean_squared_error: 9.6696e-05 - val_loss: 9.3106e-05 - val_mean_squared_error: 8.7953e-05\n","Epoch 11/350\n","225/225 [==============================] - 2s 7ms/step - loss: 8.5722e-05 - mean_squared_error: 8.0408e-05 - val_loss: 7.8798e-05 - val_mean_squared_error: 7.3637e-05\n","Epoch 12/350\n","225/225 [==============================] - 2s 7ms/step - loss: 7.3011e-05 - mean_squared_error: 6.7694e-05 - val_loss: 6.7504e-05 - val_mean_squared_error: 6.2337e-05\n","Epoch 13/350\n","225/225 [==============================] - 1s 6ms/step - loss: 6.2892e-05 - mean_squared_error: 5.7575e-05 - val_loss: 5.8435e-05 - val_mean_squared_error: 5.3266e-05\n","Epoch 14/350\n","225/225 [==============================] - 2s 7ms/step - loss: 5.4703e-05 - mean_squared_error: 4.9389e-05 - val_loss: 5.1042e-05 - val_mean_squared_error: 4.5873e-05\n","Epoch 15/350\n","225/225 [==============================] - 1s 6ms/step - loss: 4.7986e-05 - mean_squared_error: 4.2679e-05 - val_loss: 4.4943e-05 - val_mean_squared_error: 3.9776e-05\n","Epoch 16/350\n","225/225 [==============================] - 2s 7ms/step - loss: 4.2412e-05 - mean_squared_error: 3.7116e-05 - val_loss: 3.9856e-05 - val_mean_squared_error: 3.4693e-05\n","Epoch 17/350\n","225/225 [==============================] - 2s 7ms/step - loss: 3.7742e-05 - mean_squared_error: 3.2458e-05 - val_loss: 3.5577e-05 - val_mean_squared_error: 3.0420e-05\n","Epoch 18/350\n","225/225 [==============================] - 2s 7ms/step - loss: 3.3796e-05 - mean_squared_error: 2.8528e-05 - val_loss: 3.1947e-05 - val_mean_squared_error: 2.6800e-05\n","Epoch 19/350\n","225/225 [==============================] - 2s 7ms/step - loss: 3.0437e-05 - mean_squared_error: 2.5187e-05 - val_loss: 2.8849e-05 - val_mean_squared_error: 2.3712e-05\n","Epoch 20/350\n","225/225 [==============================] - 1s 5ms/step - loss: 2.7558e-05 - mean_squared_error: 2.2330e-05 - val_loss: 2.6188e-05 - val_mean_squared_error: 2.1065e-05\n","Epoch 21/350\n","225/225 [==============================] - 1s 5ms/step - loss: 2.5077e-05 - mean_squared_error: 1.9874e-05 - val_loss: 2.3891e-05 - val_mean_squared_error: 1.8784e-05\n","Epoch 22/350\n","225/225 [==============================] - 1s 5ms/step - loss: 2.2927e-05 - mean_squared_error: 1.7753e-05 - val_loss: 2.1898e-05 - val_mean_squared_error: 1.6809e-05\n","Epoch 23/350\n","225/225 [==============================] - 2s 7ms/step - loss: 2.1057e-05 - mean_squared_error: 1.5914e-05 - val_loss: 2.0162e-05 - val_mean_squared_error: 1.5094e-05\n","Epoch 24/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.9424e-05 - mean_squared_error: 1.4314e-05 - val_loss: 1.8643e-05 - val_mean_squared_error: 1.3600e-05\n","Epoch 25/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.7991e-05 - mean_squared_error: 1.2919e-05 - val_loss: 1.7311e-05 - val_mean_squared_error: 1.2294e-05\n","Epoch 26/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.6730e-05 - mean_squared_error: 1.1698e-05 - val_loss: 1.6138e-05 - val_mean_squared_error: 1.1150e-05\n","Epoch 27/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.5618e-05 - mean_squared_error: 1.0627e-05 - val_loss: 1.5103e-05 - val_mean_squared_error: 1.0146e-05\n","Epoch 28/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.4633e-05 - mean_squared_error: 9.6867e-06 - val_loss: 1.4186e-05 - val_mean_squared_error: 9.2644e-06\n","Epoch 29/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3759e-05 - mean_squared_error: 8.8593e-06 - val_loss: 1.3373e-05 - val_mean_squared_error: 8.4871e-06\n","Epoch 30/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2982e-05 - mean_squared_error: 8.1304e-06 - val_loss: 1.2649e-05 - val_mean_squared_error: 7.8021e-06\n","Epoch 31/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2289e-05 - mean_squared_error: 7.4875e-06 - val_loss: 1.2005e-05 - val_mean_squared_error: 7.1974e-06\n","Epoch 32/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1671e-05 - mean_squared_error: 6.9198e-06 - val_loss: 1.1429e-05 - val_mean_squared_error: 6.6638e-06\n","Epoch 33/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1119e-05 - mean_squared_error: 6.4180e-06 - val_loss: 1.0914e-05 - val_mean_squared_error: 6.1916e-06\n","Epoch 34/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.0624e-05 - mean_squared_error: 5.9741e-06 - val_loss: 1.0453e-05 - val_mean_squared_error: 5.7740e-06\n","Epoch 35/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.0182e-05 - mean_squared_error: 5.5814e-06 - val_loss: 1.0039e-05 - val_mean_squared_error: 5.4040e-06\n","Epoch 36/350\n","225/225 [==============================] - 2s 7ms/step - loss: 9.7848e-06 - mean_squared_error: 5.2338e-06 - val_loss: 9.6683e-06 - val_mean_squared_error: 5.0772e-06\n","Epoch 37/350\n","225/225 [==============================] - 2s 7ms/step - loss: 9.4289e-06 - mean_squared_error: 4.9260e-06 - val_loss: 9.3347e-06 - val_mean_squared_error: 4.7874e-06\n","Epoch 38/350\n","225/225 [==============================] - 2s 7ms/step - loss: 9.1097e-06 - mean_squared_error: 4.6534e-06 - val_loss: 9.0349e-06 - val_mean_squared_error: 4.5310e-06\n","Epoch 39/350\n","225/225 [==============================] - 2s 7ms/step - loss: 8.8233e-06 - mean_squared_error: 4.4120e-06 - val_loss: 8.7649e-06 - val_mean_squared_error: 4.3037e-06\n","Epoch 40/350\n","225/225 [==============================] - 1s 6ms/step - loss: 8.5663e-06 - mean_squared_error: 4.1982e-06 - val_loss: 8.5220e-06 - val_mean_squared_error: 4.1027e-06\n","Epoch 41/350\n","225/225 [==============================] - 1s 6ms/step - loss: 8.3356e-06 - mean_squared_error: 4.0088e-06 - val_loss: 8.3034e-06 - val_mean_squared_error: 3.9249e-06\n","Epoch 42/350\n","225/225 [==============================] - 2s 7ms/step - loss: 8.1285e-06 - mean_squared_error: 3.8412e-06 - val_loss: 8.1063e-06 - val_mean_squared_error: 3.7675e-06\n","Epoch 43/350\n","225/225 [==============================] - 1s 6ms/step - loss: 7.9426e-06 - mean_squared_error: 3.6929e-06 - val_loss: 7.9283e-06 - val_mean_squared_error: 3.6282e-06\n","Epoch 44/350\n","225/225 [==============================] - 2s 7ms/step - loss: 7.7755e-06 - mean_squared_error: 3.5617e-06 - val_loss: 7.7677e-06 - val_mean_squared_error: 3.5051e-06\n","Epoch 45/350\n","225/225 [==============================] - 1s 6ms/step - loss: 7.6253e-06 - mean_squared_error: 3.4457e-06 - val_loss: 7.6226e-06 - val_mean_squared_error: 3.3965e-06\n","Epoch 46/350\n","225/225 [==============================] - 1s 6ms/step - loss: 7.4900e-06 - mean_squared_error: 3.3434e-06 - val_loss: 7.4913e-06 - val_mean_squared_error: 3.3007e-06\n","Epoch 47/350\n","225/225 [==============================] - 2s 7ms/step - loss: 7.3680e-06 - mean_squared_error: 3.2530e-06 - val_loss: 7.3721e-06 - val_mean_squared_error: 3.2161e-06\n","Epoch 48/350\n","225/225 [==============================] - 1s 6ms/step - loss: 7.2577e-06 - mean_squared_error: 3.1733e-06 - val_loss: 7.2637e-06 - val_mean_squared_error: 3.1417e-06\n","Epoch 49/350\n","225/225 [==============================] - 2s 7ms/step - loss: 7.1576e-06 - mean_squared_error: 3.1032e-06 - val_loss: 7.1647e-06 - val_mean_squared_error: 3.0763e-06\n","Epoch 50/350\n","225/225 [==============================] - 1s 6ms/step - loss: 7.0665e-06 - mean_squared_error: 3.0416e-06 - val_loss: 7.0741e-06 - val_mean_squared_error: 3.0189e-06\n","Epoch 51/350\n","225/225 [==============================] - 1s 6ms/step - loss: 6.9830e-06 - mean_squared_error: 2.9875e-06 - val_loss: 6.9905e-06 - val_mean_squared_error: 2.9686e-06\n","Epoch 52/350\n","225/225 [==============================] - 1s 6ms/step - loss: 6.9059e-06 - mean_squared_error: 2.9401e-06 - val_loss: 6.9128e-06 - val_mean_squared_error: 2.9246e-06\n","Epoch 53/350\n","225/225 [==============================] - 1s 6ms/step - loss: 6.8343e-06 - mean_squared_error: 2.8988e-06 - val_loss: 6.8402e-06 - val_mean_squared_error: 2.8862e-06\n","Epoch 54/350\n","225/225 [==============================] - 2s 7ms/step - loss: 6.7671e-06 - mean_squared_error: 2.8627e-06 - val_loss: 6.7715e-06 - val_mean_squared_error: 2.8528e-06\n","Epoch 55/350\n","225/225 [==============================] - 2s 8ms/step - loss: 6.7034e-06 - mean_squared_error: 2.8314e-06 - val_loss: 6.7059e-06 - val_mean_squared_error: 2.8240e-06\n","Epoch 56/350\n","225/225 [==============================] - 2s 8ms/step - loss: 6.6421e-06 - mean_squared_error: 2.8044e-06 - val_loss: 6.6425e-06 - val_mean_squared_error: 2.7991e-06\n","Epoch 57/350\n","225/225 [==============================] - 1s 6ms/step - loss: 6.5824e-06 - mean_squared_error: 2.7811e-06 - val_loss: 6.5804e-06 - val_mean_squared_error: 2.7777e-06\n","Epoch 58/350\n","225/225 [==============================] - 1s 6ms/step - loss: 6.5234e-06 - mean_squared_error: 2.7612e-06 - val_loss: 6.5188e-06 - val_mean_squared_error: 2.7596e-06\n","Epoch 59/350\n","225/225 [==============================] - 2s 7ms/step - loss: 6.4643e-06 - mean_squared_error: 2.7442e-06 - val_loss: 6.4566e-06 - val_mean_squared_error: 2.7442e-06\n","Epoch 60/350\n","225/225 [==============================] - 1s 6ms/step - loss: 6.4041e-06 - mean_squared_error: 2.7301e-06 - val_loss: 6.3933e-06 - val_mean_squared_error: 2.7314e-06\n","Epoch 61/350\n","225/225 [==============================] - 1s 6ms/step - loss: 6.3420e-06 - mean_squared_error: 2.7184e-06 - val_loss: 6.3277e-06 - val_mean_squared_error: 2.7211e-06\n","Epoch 62/350\n","225/225 [==============================] - 2s 7ms/step - loss: 6.2768e-06 - mean_squared_error: 2.7091e-06 - val_loss: 6.2587e-06 - val_mean_squared_error: 2.7130e-06\n","Epoch 63/350\n","225/225 [==============================] - 2s 7ms/step - loss: 6.2070e-06 - mean_squared_error: 2.7020e-06 - val_loss: 6.1848e-06 - val_mean_squared_error: 2.7070e-06\n","Epoch 64/350\n","225/225 [==============================] - 1s 6ms/step - loss: 6.1310e-06 - mean_squared_error: 2.6971e-06 - val_loss: 6.1043e-06 - val_mean_squared_error: 2.7028e-06\n","Epoch 65/350\n","225/225 [==============================] - 2s 7ms/step - loss: 6.0461e-06 - mean_squared_error: 2.6940e-06 - val_loss: 6.0139e-06 - val_mean_squared_error: 2.7008e-06\n","Epoch 66/350\n","225/225 [==============================] - 2s 7ms/step - loss: 5.9472e-06 - mean_squared_error: 2.6930e-06 - val_loss: 5.9062e-06 - val_mean_squared_error: 2.7010e-06\n","Epoch 67/350\n","225/225 [==============================] - 1s 6ms/step - loss: 5.8216e-06 - mean_squared_error: 2.6949e-06 - val_loss: 5.7620e-06 - val_mean_squared_error: 2.7038e-06\n","Epoch 68/350\n","225/225 [==============================] - 1s 6ms/step - loss: 5.6354e-06 - mean_squared_error: 2.6984e-06 - val_loss: 5.5292e-06 - val_mean_squared_error: 2.7089e-06\n","Epoch 69/350\n","225/225 [==============================] - 1s 6ms/step - loss: 5.2990e-06 - mean_squared_error: 2.6998e-06 - val_loss: 5.0758e-06 - val_mean_squared_error: 2.6965e-06\n","Epoch 70/350\n","225/225 [==============================] - 2s 7ms/step - loss: 4.6900e-06 - mean_squared_error: 2.6253e-06 - val_loss: 4.3614e-06 - val_mean_squared_error: 2.5296e-06\n","Epoch 71/350\n","225/225 [==============================] - 1s 6ms/step - loss: 4.0384e-06 - mean_squared_error: 2.3604e-06 - val_loss: 3.8025e-06 - val_mean_squared_error: 2.2175e-06\n","Epoch 72/350\n","225/225 [==============================] - 1s 6ms/step - loss: 3.5898e-06 - mean_squared_error: 2.0767e-06 - val_loss: 3.4313e-06 - val_mean_squared_error: 1.9608e-06\n","Epoch 73/350\n","225/225 [==============================] - 2s 7ms/step - loss: 3.2722e-06 - mean_squared_error: 1.8558e-06 - val_loss: 3.1544e-06 - val_mean_squared_error: 1.7753e-06\n","Epoch 74/350\n","225/225 [==============================] - 2s 7ms/step - loss: 3.0268e-06 - mean_squared_error: 1.6862e-06 - val_loss: 2.9388e-06 - val_mean_squared_error: 1.6193e-06\n","Epoch 75/350\n","225/225 [==============================] - 1s 6ms/step - loss: 2.8420e-06 - mean_squared_error: 1.5598e-06 - val_loss: 2.7867e-06 - val_mean_squared_error: 1.5338e-06\n","Epoch 76/350\n","225/225 [==============================] - 1s 5ms/step - loss: 2.7104e-06 - mean_squared_error: 1.4832e-06 - val_loss: 2.6741e-06 - val_mean_squared_error: 1.4667e-06\n","Epoch 77/350\n","225/225 [==============================] - 2s 7ms/step - loss: 2.6148e-06 - mean_squared_error: 1.4361e-06 - val_loss: 2.5900e-06 - val_mean_squared_error: 1.4269e-06\n","Epoch 78/350\n","225/225 [==============================] - 1s 6ms/step - loss: 2.5400e-06 - mean_squared_error: 1.4097e-06 - val_loss: 2.5226e-06 - val_mean_squared_error: 1.4132e-06\n","Epoch 79/350\n","225/225 [==============================] - 1s 6ms/step - loss: 2.4760e-06 - mean_squared_error: 1.3940e-06 - val_loss: 2.4612e-06 - val_mean_squared_error: 1.3973e-06\n","Epoch 80/350\n","225/225 [==============================] - 2s 7ms/step - loss: 2.4185e-06 - mean_squared_error: 1.3822e-06 - val_loss: 2.4079e-06 - val_mean_squared_error: 1.3948e-06\n","Epoch 81/350\n","225/225 [==============================] - 1s 6ms/step - loss: 2.3647e-06 - mean_squared_error: 1.3743e-06 - val_loss: 2.3529e-06 - val_mean_squared_error: 1.3775e-06\n","Epoch 82/350\n","225/225 [==============================] - 2s 7ms/step - loss: 2.3144e-06 - mean_squared_error: 1.3671e-06 - val_loss: 2.3041e-06 - val_mean_squared_error: 1.3710e-06\n","Epoch 83/350\n","225/225 [==============================] - 2s 7ms/step - loss: 2.2677e-06 - mean_squared_error: 1.3612e-06 - val_loss: 2.2594e-06 - val_mean_squared_error: 1.3706e-06\n","Epoch 84/350\n","225/225 [==============================] - 2s 7ms/step - loss: 2.2236e-06 - mean_squared_error: 1.3577e-06 - val_loss: 2.2149e-06 - val_mean_squared_error: 1.3626e-06\n","Epoch 85/350\n","225/225 [==============================] - 1s 6ms/step - loss: 2.1810e-06 - mean_squared_error: 1.3522e-06 - val_loss: 2.1733e-06 - val_mean_squared_error: 1.3559e-06\n","Epoch 86/350\n","225/225 [==============================] - 2s 7ms/step - loss: 2.1416e-06 - mean_squared_error: 1.3478e-06 - val_loss: 2.1344e-06 - val_mean_squared_error: 1.3519e-06\n","Epoch 87/350\n","225/225 [==============================] - 1s 6ms/step - loss: 2.1040e-06 - mean_squared_error: 1.3443e-06 - val_loss: 2.0975e-06 - val_mean_squared_error: 1.3456e-06\n","Epoch 88/350\n","225/225 [==============================] - 1s 6ms/step - loss: 2.0683e-06 - mean_squared_error: 1.3403e-06 - val_loss: 2.0633e-06 - val_mean_squared_error: 1.3404e-06\n","Epoch 89/350\n","225/225 [==============================] - 2s 7ms/step - loss: 2.0349e-06 - mean_squared_error: 1.3369e-06 - val_loss: 2.0298e-06 - val_mean_squared_error: 1.3381e-06\n","Epoch 90/350\n","225/225 [==============================] - 1s 6ms/step - loss: 2.0033e-06 - mean_squared_error: 1.3334e-06 - val_loss: 1.9986e-06 - val_mean_squared_error: 1.3343e-06\n","Epoch 91/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.9730e-06 - mean_squared_error: 1.3301e-06 - val_loss: 1.9693e-06 - val_mean_squared_error: 1.3350e-06\n","Epoch 92/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.9444e-06 - mean_squared_error: 1.3273e-06 - val_loss: 1.9411e-06 - val_mean_squared_error: 1.3270e-06\n","Epoch 93/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.9173e-06 - mean_squared_error: 1.3235e-06 - val_loss: 1.9161e-06 - val_mean_squared_error: 1.3232e-06\n","Epoch 94/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.8918e-06 - mean_squared_error: 1.3205e-06 - val_loss: 1.8887e-06 - val_mean_squared_error: 1.3242e-06\n","Epoch 95/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.8667e-06 - mean_squared_error: 1.3173e-06 - val_loss: 1.8654e-06 - val_mean_squared_error: 1.3168e-06\n","Epoch 96/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.8435e-06 - mean_squared_error: 1.3141e-06 - val_loss: 1.8439e-06 - val_mean_squared_error: 1.3137e-06\n","Epoch 97/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.8208e-06 - mean_squared_error: 1.3100e-06 - val_loss: 1.8190e-06 - val_mean_squared_error: 1.3139e-06\n","Epoch 98/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.7995e-06 - mean_squared_error: 1.3074e-06 - val_loss: 1.7989e-06 - val_mean_squared_error: 1.3069e-06\n","Epoch 99/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.7781e-06 - mean_squared_error: 1.3027e-06 - val_loss: 1.7771e-06 - val_mean_squared_error: 1.3058e-06\n","Epoch 100/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.7592e-06 - mean_squared_error: 1.3005e-06 - val_loss: 1.7588e-06 - val_mean_squared_error: 1.3000e-06\n","Epoch 101/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.7404e-06 - mean_squared_error: 1.2972e-06 - val_loss: 1.7428e-06 - val_mean_squared_error: 1.2973e-06\n","Epoch 102/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.7218e-06 - mean_squared_error: 1.2927e-06 - val_loss: 1.7210e-06 - val_mean_squared_error: 1.2930e-06\n","Epoch 103/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.7045e-06 - mean_squared_error: 1.2899e-06 - val_loss: 1.7060e-06 - val_mean_squared_error: 1.2896e-06\n","Epoch 104/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.6877e-06 - mean_squared_error: 1.2860e-06 - val_loss: 1.6910e-06 - val_mean_squared_error: 1.2869e-06\n","Epoch 105/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.6714e-06 - mean_squared_error: 1.2824e-06 - val_loss: 1.6706e-06 - val_mean_squared_error: 1.2819e-06\n","Epoch 106/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.6556e-06 - mean_squared_error: 1.2788e-06 - val_loss: 1.6551e-06 - val_mean_squared_error: 1.2781e-06\n","Epoch 107/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.6405e-06 - mean_squared_error: 1.2749e-06 - val_loss: 1.6398e-06 - val_mean_squared_error: 1.2746e-06\n","Epoch 108/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.6260e-06 - mean_squared_error: 1.2715e-06 - val_loss: 1.6258e-06 - val_mean_squared_error: 1.2706e-06\n","Epoch 109/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.6121e-06 - mean_squared_error: 1.2679e-06 - val_loss: 1.6156e-06 - val_mean_squared_error: 1.2683e-06\n","Epoch 110/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.5983e-06 - mean_squared_error: 1.2638e-06 - val_loss: 1.6035e-06 - val_mean_squared_error: 1.2654e-06\n","Epoch 111/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.5856e-06 - mean_squared_error: 1.2604e-06 - val_loss: 1.5883e-06 - val_mean_squared_error: 1.2605e-06\n","Epoch 112/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.5726e-06 - mean_squared_error: 1.2563e-06 - val_loss: 1.5787e-06 - val_mean_squared_error: 1.2586e-06\n","Epoch 113/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.5604e-06 - mean_squared_error: 1.2528e-06 - val_loss: 1.5670e-06 - val_mean_squared_error: 1.2553e-06\n","Epoch 114/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.5489e-06 - mean_squared_error: 1.2493e-06 - val_loss: 1.5514e-06 - val_mean_squared_error: 1.2494e-06\n","Epoch 115/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.5376e-06 - mean_squared_error: 1.2460e-06 - val_loss: 1.5425e-06 - val_mean_squared_error: 1.2474e-06\n","Epoch 116/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.5267e-06 - mean_squared_error: 1.2426e-06 - val_loss: 1.5295e-06 - val_mean_squared_error: 1.2427e-06\n","Epoch 117/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.5163e-06 - mean_squared_error: 1.2393e-06 - val_loss: 1.5209e-06 - val_mean_squared_error: 1.2405e-06\n","Epoch 118/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.5065e-06 - mean_squared_error: 1.2362e-06 - val_loss: 1.5088e-06 - val_mean_squared_error: 1.2363e-06\n","Epoch 119/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.4972e-06 - mean_squared_error: 1.2336e-06 - val_loss: 1.4990e-06 - val_mean_squared_error: 1.2333e-06\n","Epoch 120/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.4882e-06 - mean_squared_error: 1.2309e-06 - val_loss: 1.4934e-06 - val_mean_squared_error: 1.2324e-06\n","Epoch 121/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.4796e-06 - mean_squared_error: 1.2282e-06 - val_loss: 1.4851e-06 - val_mean_squared_error: 1.2300e-06\n","Epoch 122/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.4721e-06 - mean_squared_error: 1.2262e-06 - val_loss: 1.4752e-06 - val_mean_squared_error: 1.2267e-06\n","Epoch 123/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.4640e-06 - mean_squared_error: 1.2234e-06 - val_loss: 1.4667e-06 - val_mean_squared_error: 1.2251e-06\n","Epoch 124/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.4575e-06 - mean_squared_error: 1.2224e-06 - val_loss: 1.4611e-06 - val_mean_squared_error: 1.2232e-06\n","Epoch 125/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.4509e-06 - mean_squared_error: 1.2206e-06 - val_loss: 1.4541e-06 - val_mean_squared_error: 1.2215e-06\n","Epoch 126/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.4444e-06 - mean_squared_error: 1.2188e-06 - val_loss: 1.4519e-06 - val_mean_squared_error: 1.2221e-06\n","Epoch 127/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.4385e-06 - mean_squared_error: 1.2173e-06 - val_loss: 1.4425e-06 - val_mean_squared_error: 1.2190e-06\n","Epoch 128/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.4332e-06 - mean_squared_error: 1.2166e-06 - val_loss: 1.4396e-06 - val_mean_squared_error: 1.2190e-06\n","Epoch 129/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.4281e-06 - mean_squared_error: 1.2154e-06 - val_loss: 1.4330e-06 - val_mean_squared_error: 1.2172e-06\n","Epoch 130/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.4227e-06 - mean_squared_error: 1.2141e-06 - val_loss: 1.4279e-06 - val_mean_squared_error: 1.2162e-06\n","Epoch 131/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.4174e-06 - mean_squared_error: 1.2126e-06 - val_loss: 1.4227e-06 - val_mean_squared_error: 1.2152e-06\n","Epoch 132/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.4136e-06 - mean_squared_error: 1.2126e-06 - val_loss: 1.4211e-06 - val_mean_squared_error: 1.2158e-06\n","Epoch 133/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.4093e-06 - mean_squared_error: 1.2119e-06 - val_loss: 1.4146e-06 - val_mean_squared_error: 1.2138e-06\n","Epoch 134/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.4042e-06 - mean_squared_error: 1.2102e-06 - val_loss: 1.4141e-06 - val_mean_squared_error: 1.2153e-06\n","Epoch 135/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.4001e-06 - mean_squared_error: 1.2095e-06 - val_loss: 1.4056e-06 - val_mean_squared_error: 1.2121e-06\n","Epoch 136/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.3964e-06 - mean_squared_error: 1.2089e-06 - val_loss: 1.4015e-06 - val_mean_squared_error: 1.2123e-06\n","Epoch 137/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3923e-06 - mean_squared_error: 1.2082e-06 - val_loss: 1.3985e-06 - val_mean_squared_error: 1.2108e-06\n","Epoch 138/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3886e-06 - mean_squared_error: 1.2074e-06 - val_loss: 1.3954e-06 - val_mean_squared_error: 1.2104e-06\n","Epoch 139/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3853e-06 - mean_squared_error: 1.2071e-06 - val_loss: 1.3957e-06 - val_mean_squared_error: 1.2123e-06\n","Epoch 140/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.3817e-06 - mean_squared_error: 1.2062e-06 - val_loss: 1.3879e-06 - val_mean_squared_error: 1.2089e-06\n","Epoch 141/350\n","225/225 [==============================] - 2s 8ms/step - loss: 1.3777e-06 - mean_squared_error: 1.2052e-06 - val_loss: 1.3949e-06 - val_mean_squared_error: 1.2157e-06\n","Epoch 142/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3749e-06 - mean_squared_error: 1.2048e-06 - val_loss: 1.3830e-06 - val_mean_squared_error: 1.2085e-06\n","Epoch 143/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3725e-06 - mean_squared_error: 1.2051e-06 - val_loss: 1.3815e-06 - val_mean_squared_error: 1.2091e-06\n","Epoch 144/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3688e-06 - mean_squared_error: 1.2038e-06 - val_loss: 1.3759e-06 - val_mean_squared_error: 1.2068e-06\n","Epoch 145/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3648e-06 - mean_squared_error: 1.2026e-06 - val_loss: 1.3763e-06 - val_mean_squared_error: 1.2085e-06\n","Epoch 146/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3624e-06 - mean_squared_error: 1.2021e-06 - val_loss: 1.3686e-06 - val_mean_squared_error: 1.2048e-06\n","Epoch 147/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.3591e-06 - mean_squared_error: 1.2014e-06 - val_loss: 1.3664e-06 - val_mean_squared_error: 1.2046e-06\n","Epoch 148/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3567e-06 - mean_squared_error: 1.2012e-06 - val_loss: 1.3627e-06 - val_mean_squared_error: 1.2036e-06\n","Epoch 149/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3535e-06 - mean_squared_error: 1.2001e-06 - val_loss: 1.3618e-06 - val_mean_squared_error: 1.2040e-06\n","Epoch 150/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.3509e-06 - mean_squared_error: 1.1996e-06 - val_loss: 1.3566e-06 - val_mean_squared_error: 1.2027e-06\n","Epoch 151/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.3477e-06 - mean_squared_error: 1.1985e-06 - val_loss: 1.3550e-06 - val_mean_squared_error: 1.2020e-06\n","Epoch 152/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.3452e-06 - mean_squared_error: 1.1982e-06 - val_loss: 1.3560e-06 - val_mean_squared_error: 1.2038e-06\n","Epoch 153/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3428e-06 - mean_squared_error: 1.1975e-06 - val_loss: 1.3489e-06 - val_mean_squared_error: 1.2005e-06\n","Epoch 154/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3401e-06 - mean_squared_error: 1.1969e-06 - val_loss: 1.3462e-06 - val_mean_squared_error: 1.2003e-06\n","Epoch 155/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3375e-06 - mean_squared_error: 1.1962e-06 - val_loss: 1.3470e-06 - val_mean_squared_error: 1.2010e-06\n","Epoch 156/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.3356e-06 - mean_squared_error: 1.1960e-06 - val_loss: 1.3413e-06 - val_mean_squared_error: 1.1989e-06\n","Epoch 157/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3324e-06 - mean_squared_error: 1.1949e-06 - val_loss: 1.3421e-06 - val_mean_squared_error: 1.1997e-06\n","Epoch 158/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3305e-06 - mean_squared_error: 1.1946e-06 - val_loss: 1.3411e-06 - val_mean_squared_error: 1.2001e-06\n","Epoch 159/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3286e-06 - mean_squared_error: 1.1942e-06 - val_loss: 1.3345e-06 - val_mean_squared_error: 1.1970e-06\n","Epoch 160/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.3261e-06 - mean_squared_error: 1.1935e-06 - val_loss: 1.3333e-06 - val_mean_squared_error: 1.1968e-06\n","Epoch 161/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3239e-06 - mean_squared_error: 1.1929e-06 - val_loss: 1.3299e-06 - val_mean_squared_error: 1.1961e-06\n","Epoch 162/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3216e-06 - mean_squared_error: 1.1922e-06 - val_loss: 1.3278e-06 - val_mean_squared_error: 1.1955e-06\n","Epoch 163/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.3195e-06 - mean_squared_error: 1.1917e-06 - val_loss: 1.3258e-06 - val_mean_squared_error: 1.1947e-06\n","Epoch 164/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.3172e-06 - mean_squared_error: 1.1911e-06 - val_loss: 1.3256e-06 - val_mean_squared_error: 1.1950e-06\n","Epoch 165/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3156e-06 - mean_squared_error: 1.1907e-06 - val_loss: 1.3217e-06 - val_mean_squared_error: 1.1936e-06\n","Epoch 166/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3138e-06 - mean_squared_error: 1.1905e-06 - val_loss: 1.3202e-06 - val_mean_squared_error: 1.1932e-06\n","Epoch 167/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3111e-06 - mean_squared_error: 1.1892e-06 - val_loss: 1.3176e-06 - val_mean_squared_error: 1.1927e-06\n","Epoch 168/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3096e-06 - mean_squared_error: 1.1892e-06 - val_loss: 1.3179e-06 - val_mean_squared_error: 1.1931e-06\n","Epoch 169/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.3076e-06 - mean_squared_error: 1.1885e-06 - val_loss: 1.3144e-06 - val_mean_squared_error: 1.1916e-06\n","Epoch 170/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.3060e-06 - mean_squared_error: 1.1881e-06 - val_loss: 1.3119e-06 - val_mean_squared_error: 1.1912e-06\n","Epoch 171/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3032e-06 - mean_squared_error: 1.1868e-06 - val_loss: 1.3127e-06 - val_mean_squared_error: 1.1919e-06\n","Epoch 172/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3017e-06 - mean_squared_error: 1.1865e-06 - val_loss: 1.3103e-06 - val_mean_squared_error: 1.1910e-06\n","Epoch 173/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3002e-06 - mean_squared_error: 1.1862e-06 - val_loss: 1.3065e-06 - val_mean_squared_error: 1.1897e-06\n","Epoch 174/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2982e-06 - mean_squared_error: 1.1857e-06 - val_loss: 1.3089e-06 - val_mean_squared_error: 1.1916e-06\n","Epoch 175/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2968e-06 - mean_squared_error: 1.1853e-06 - val_loss: 1.3034e-06 - val_mean_squared_error: 1.1895e-06\n","Epoch 176/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2949e-06 - mean_squared_error: 1.1848e-06 - val_loss: 1.3028e-06 - val_mean_squared_error: 1.1886e-06\n","Epoch 177/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2933e-06 - mean_squared_error: 1.1843e-06 - val_loss: 1.3010e-06 - val_mean_squared_error: 1.1881e-06\n","Epoch 178/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2917e-06 - mean_squared_error: 1.1837e-06 - val_loss: 1.2981e-06 - val_mean_squared_error: 1.1870e-06\n","Epoch 179/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2900e-06 - mean_squared_error: 1.1833e-06 - val_loss: 1.2968e-06 - val_mean_squared_error: 1.1866e-06\n","Epoch 180/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2882e-06 - mean_squared_error: 1.1825e-06 - val_loss: 1.2951e-06 - val_mean_squared_error: 1.1870e-06\n","Epoch 181/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2873e-06 - mean_squared_error: 1.1828e-06 - val_loss: 1.2932e-06 - val_mean_squared_error: 1.1856e-06\n","Epoch 182/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2852e-06 - mean_squared_error: 1.1818e-06 - val_loss: 1.2920e-06 - val_mean_squared_error: 1.1863e-06\n","Epoch 183/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2835e-06 - mean_squared_error: 1.1811e-06 - val_loss: 1.2902e-06 - val_mean_squared_error: 1.1853e-06\n","Epoch 184/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2823e-06 - mean_squared_error: 1.1810e-06 - val_loss: 1.2889e-06 - val_mean_squared_error: 1.1851e-06\n","Epoch 185/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2806e-06 - mean_squared_error: 1.1805e-06 - val_loss: 1.2871e-06 - val_mean_squared_error: 1.1838e-06\n","Epoch 186/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2792e-06 - mean_squared_error: 1.1799e-06 - val_loss: 1.2856e-06 - val_mean_squared_error: 1.1836e-06\n","Epoch 187/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2777e-06 - mean_squared_error: 1.1794e-06 - val_loss: 1.2848e-06 - val_mean_squared_error: 1.1842e-06\n","Epoch 188/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2767e-06 - mean_squared_error: 1.1794e-06 - val_loss: 1.2835e-06 - val_mean_squared_error: 1.1839e-06\n","Epoch 189/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2748e-06 - mean_squared_error: 1.1786e-06 - val_loss: 1.2827e-06 - val_mean_squared_error: 1.1826e-06\n","Epoch 190/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2740e-06 - mean_squared_error: 1.1785e-06 - val_loss: 1.2802e-06 - val_mean_squared_error: 1.1816e-06\n","Epoch 191/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2722e-06 - mean_squared_error: 1.1777e-06 - val_loss: 1.2803e-06 - val_mean_squared_error: 1.1820e-06\n","Epoch 192/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2712e-06 - mean_squared_error: 1.1777e-06 - val_loss: 1.2774e-06 - val_mean_squared_error: 1.1807e-06\n","Epoch 193/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2699e-06 - mean_squared_error: 1.1772e-06 - val_loss: 1.2759e-06 - val_mean_squared_error: 1.1803e-06\n","Epoch 194/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2688e-06 - mean_squared_error: 1.1769e-06 - val_loss: 1.2747e-06 - val_mean_squared_error: 1.1799e-06\n","Epoch 195/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2666e-06 - mean_squared_error: 1.1756e-06 - val_loss: 1.2744e-06 - val_mean_squared_error: 1.1813e-06\n","Epoch 196/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2657e-06 - mean_squared_error: 1.1757e-06 - val_loss: 1.2722e-06 - val_mean_squared_error: 1.1796e-06\n","Epoch 197/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2646e-06 - mean_squared_error: 1.1753e-06 - val_loss: 1.2709e-06 - val_mean_squared_error: 1.1787e-06\n","Epoch 198/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2631e-06 - mean_squared_error: 1.1748e-06 - val_loss: 1.2697e-06 - val_mean_squared_error: 1.1783e-06\n","Epoch 199/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2625e-06 - mean_squared_error: 1.1749e-06 - val_loss: 1.2685e-06 - val_mean_squared_error: 1.1779e-06\n","Epoch 200/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2610e-06 - mean_squared_error: 1.1741e-06 - val_loss: 1.2692e-06 - val_mean_squared_error: 1.1806e-06\n","Epoch 201/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2596e-06 - mean_squared_error: 1.1736e-06 - val_loss: 1.2679e-06 - val_mean_squared_error: 1.1800e-06\n","Epoch 202/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2585e-06 - mean_squared_error: 1.1732e-06 - val_loss: 1.2651e-06 - val_mean_squared_error: 1.1768e-06\n","Epoch 203/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2574e-06 - mean_squared_error: 1.1729e-06 - val_loss: 1.2653e-06 - val_mean_squared_error: 1.1788e-06\n","Epoch 204/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2559e-06 - mean_squared_error: 1.1722e-06 - val_loss: 1.2649e-06 - val_mean_squared_error: 1.1794e-06\n","Epoch 205/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2559e-06 - mean_squared_error: 1.1729e-06 - val_loss: 1.2621e-06 - val_mean_squared_error: 1.1759e-06\n","Epoch 206/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2545e-06 - mean_squared_error: 1.1721e-06 - val_loss: 1.2630e-06 - val_mean_squared_error: 1.1790e-06\n","Epoch 207/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2531e-06 - mean_squared_error: 1.1716e-06 - val_loss: 1.2597e-06 - val_mean_squared_error: 1.1751e-06\n","Epoch 208/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2514e-06 - mean_squared_error: 1.1705e-06 - val_loss: 1.2585e-06 - val_mean_squared_error: 1.1752e-06\n","Epoch 209/350\n","225/225 [==============================] - 2s 8ms/step - loss: 1.2504e-06 - mean_squared_error: 1.1702e-06 - val_loss: 1.2573e-06 - val_mean_squared_error: 1.1743e-06\n","Epoch 210/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2496e-06 - mean_squared_error: 1.1702e-06 - val_loss: 1.2565e-06 - val_mean_squared_error: 1.1740e-06\n","Epoch 211/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2488e-06 - mean_squared_error: 1.1699e-06 - val_loss: 1.2558e-06 - val_mean_squared_error: 1.1739e-06\n","Epoch 212/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2479e-06 - mean_squared_error: 1.1696e-06 - val_loss: 1.2546e-06 - val_mean_squared_error: 1.1744e-06\n","Epoch 213/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2468e-06 - mean_squared_error: 1.1694e-06 - val_loss: 1.2531e-06 - val_mean_squared_error: 1.1731e-06\n","Epoch 214/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2456e-06 - mean_squared_error: 1.1687e-06 - val_loss: 1.2538e-06 - val_mean_squared_error: 1.1752e-06\n","Epoch 215/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2448e-06 - mean_squared_error: 1.1687e-06 - val_loss: 1.2516e-06 - val_mean_squared_error: 1.1725e-06\n","Epoch 216/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2441e-06 - mean_squared_error: 1.1685e-06 - val_loss: 1.2503e-06 - val_mean_squared_error: 1.1725e-06\n","Epoch 217/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2428e-06 - mean_squared_error: 1.1679e-06 - val_loss: 1.2492e-06 - val_mean_squared_error: 1.1718e-06\n","Epoch 218/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2416e-06 - mean_squared_error: 1.1673e-06 - val_loss: 1.2499e-06 - val_mean_squared_error: 1.1738e-06\n","Epoch 219/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2409e-06 - mean_squared_error: 1.1673e-06 - val_loss: 1.2485e-06 - val_mean_squared_error: 1.1717e-06\n","Epoch 220/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2403e-06 - mean_squared_error: 1.1672e-06 - val_loss: 1.2464e-06 - val_mean_squared_error: 1.1710e-06\n","Epoch 221/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2395e-06 - mean_squared_error: 1.1669e-06 - val_loss: 1.2456e-06 - val_mean_squared_error: 1.1708e-06\n","Epoch 222/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2384e-06 - mean_squared_error: 1.1664e-06 - val_loss: 1.2456e-06 - val_mean_squared_error: 1.1718e-06\n","Epoch 223/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2376e-06 - mean_squared_error: 1.1663e-06 - val_loss: 1.2438e-06 - val_mean_squared_error: 1.1701e-06\n","Epoch 224/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2367e-06 - mean_squared_error: 1.1659e-06 - val_loss: 1.2448e-06 - val_mean_squared_error: 1.1724e-06\n","Epoch 225/350\n","225/225 [==============================] - 2s 9ms/step - loss: 1.2355e-06 - mean_squared_error: 1.1654e-06 - val_loss: 1.2420e-06 - val_mean_squared_error: 1.1696e-06\n","Epoch 226/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2349e-06 - mean_squared_error: 1.1653e-06 - val_loss: 1.2415e-06 - val_mean_squared_error: 1.1698e-06\n","Epoch 227/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2339e-06 - mean_squared_error: 1.1649e-06 - val_loss: 1.2403e-06 - val_mean_squared_error: 1.1688e-06\n","Epoch 228/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2329e-06 - mean_squared_error: 1.1644e-06 - val_loss: 1.2398e-06 - val_mean_squared_error: 1.1692e-06\n","Epoch 229/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2321e-06 - mean_squared_error: 1.1642e-06 - val_loss: 1.2387e-06 - val_mean_squared_error: 1.1682e-06\n","Epoch 230/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2314e-06 - mean_squared_error: 1.1640e-06 - val_loss: 1.2385e-06 - val_mean_squared_error: 1.1682e-06\n","Epoch 231/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2307e-06 - mean_squared_error: 1.1637e-06 - val_loss: 1.2376e-06 - val_mean_squared_error: 1.1687e-06\n","Epoch 232/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2301e-06 - mean_squared_error: 1.1636e-06 - val_loss: 1.2384e-06 - val_mean_squared_error: 1.1705e-06\n","Epoch 233/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2292e-06 - mean_squared_error: 1.1634e-06 - val_loss: 1.2356e-06 - val_mean_squared_error: 1.1676e-06\n","Epoch 234/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2286e-06 - mean_squared_error: 1.1632e-06 - val_loss: 1.2346e-06 - val_mean_squared_error: 1.1669e-06\n","Epoch 235/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2273e-06 - mean_squared_error: 1.1624e-06 - val_loss: 1.2339e-06 - val_mean_squared_error: 1.1669e-06\n","Epoch 236/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2269e-06 - mean_squared_error: 1.1624e-06 - val_loss: 1.2331e-06 - val_mean_squared_error: 1.1666e-06\n","Epoch 237/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2259e-06 - mean_squared_error: 1.1620e-06 - val_loss: 1.2335e-06 - val_mean_squared_error: 1.1668e-06\n","Epoch 238/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2253e-06 - mean_squared_error: 1.1618e-06 - val_loss: 1.2317e-06 - val_mean_squared_error: 1.1658e-06\n","Epoch 239/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2247e-06 - mean_squared_error: 1.1617e-06 - val_loss: 1.2310e-06 - val_mean_squared_error: 1.1659e-06\n","Epoch 240/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2240e-06 - mean_squared_error: 1.1614e-06 - val_loss: 1.2304e-06 - val_mean_squared_error: 1.1659e-06\n","Epoch 241/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2233e-06 - mean_squared_error: 1.1612e-06 - val_loss: 1.2296e-06 - val_mean_squared_error: 1.1655e-06\n","Epoch 242/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2226e-06 - mean_squared_error: 1.1609e-06 - val_loss: 1.2288e-06 - val_mean_squared_error: 1.1650e-06\n","Epoch 243/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2215e-06 - mean_squared_error: 1.1603e-06 - val_loss: 1.2294e-06 - val_mean_squared_error: 1.1667e-06\n","Epoch 244/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2210e-06 - mean_squared_error: 1.1603e-06 - val_loss: 1.2274e-06 - val_mean_squared_error: 1.1644e-06\n","Epoch 245/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2204e-06 - mean_squared_error: 1.1601e-06 - val_loss: 1.2267e-06 - val_mean_squared_error: 1.1643e-06\n","Epoch 246/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2198e-06 - mean_squared_error: 1.1599e-06 - val_loss: 1.2260e-06 - val_mean_squared_error: 1.1640e-06\n","Epoch 247/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2190e-06 - mean_squared_error: 1.1595e-06 - val_loss: 1.2255e-06 - val_mean_squared_error: 1.1641e-06\n","Epoch 248/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2184e-06 - mean_squared_error: 1.1594e-06 - val_loss: 1.2247e-06 - val_mean_squared_error: 1.1637e-06\n","Epoch 249/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2175e-06 - mean_squared_error: 1.1589e-06 - val_loss: 1.2250e-06 - val_mean_squared_error: 1.1648e-06\n","Epoch 250/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2167e-06 - mean_squared_error: 1.1587e-06 - val_loss: 1.2244e-06 - val_mean_squared_error: 1.1637e-06\n","Epoch 251/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2165e-06 - mean_squared_error: 1.1587e-06 - val_loss: 1.2234e-06 - val_mean_squared_error: 1.1640e-06\n","Epoch 252/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2156e-06 - mean_squared_error: 1.1584e-06 - val_loss: 1.2229e-06 - val_mean_squared_error: 1.1631e-06\n","Epoch 253/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2154e-06 - mean_squared_error: 1.1584e-06 - val_loss: 1.2215e-06 - val_mean_squared_error: 1.1626e-06\n","Epoch 254/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2147e-06 - mean_squared_error: 1.1582e-06 - val_loss: 1.2209e-06 - val_mean_squared_error: 1.1623e-06\n","Epoch 255/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2142e-06 - mean_squared_error: 1.1581e-06 - val_loss: 1.2203e-06 - val_mean_squared_error: 1.1620e-06\n","Epoch 256/350\n","225/225 [==============================] - 2s 8ms/step - loss: 1.2135e-06 - mean_squared_error: 1.1577e-06 - val_loss: 1.2199e-06 - val_mean_squared_error: 1.1623e-06\n","Epoch 257/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2128e-06 - mean_squared_error: 1.1574e-06 - val_loss: 1.2193e-06 - val_mean_squared_error: 1.1622e-06\n","Epoch 258/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2122e-06 - mean_squared_error: 1.1572e-06 - val_loss: 1.2186e-06 - val_mean_squared_error: 1.1617e-06\n","Epoch 259/350\n","225/225 [==============================] - 2s 8ms/step - loss: 1.2116e-06 - mean_squared_error: 1.1570e-06 - val_loss: 1.2180e-06 - val_mean_squared_error: 1.1612e-06\n","Epoch 260/350\n","225/225 [==============================] - 2s 8ms/step - loss: 1.2108e-06 - mean_squared_error: 1.1564e-06 - val_loss: 1.2176e-06 - val_mean_squared_error: 1.1616e-06\n","Epoch 261/350\n","225/225 [==============================] - 2s 8ms/step - loss: 1.2104e-06 - mean_squared_error: 1.1565e-06 - val_loss: 1.2168e-06 - val_mean_squared_error: 1.1610e-06\n","Epoch 262/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2097e-06 - mean_squared_error: 1.1561e-06 - val_loss: 1.2201e-06 - val_mean_squared_error: 1.1655e-06\n","Epoch 263/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2092e-06 - mean_squared_error: 1.1561e-06 - val_loss: 1.2169e-06 - val_mean_squared_error: 1.1622e-06\n","Epoch 264/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2090e-06 - mean_squared_error: 1.1563e-06 - val_loss: 1.2151e-06 - val_mean_squared_error: 1.1603e-06\n","Epoch 265/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2084e-06 - mean_squared_error: 1.1559e-06 - val_loss: 1.2146e-06 - val_mean_squared_error: 1.1604e-06\n","Epoch 266/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2077e-06 - mean_squared_error: 1.1556e-06 - val_loss: 1.2140e-06 - val_mean_squared_error: 1.1600e-06\n","Epoch 267/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2068e-06 - mean_squared_error: 1.1551e-06 - val_loss: 1.2161e-06 - val_mean_squared_error: 1.1617e-06\n","Epoch 268/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2068e-06 - mean_squared_error: 1.1553e-06 - val_loss: 1.2133e-06 - val_mean_squared_error: 1.1602e-06\n","Epoch 269/350\n","225/225 [==============================] - 2s 8ms/step - loss: 1.2060e-06 - mean_squared_error: 1.1549e-06 - val_loss: 1.2131e-06 - val_mean_squared_error: 1.1597e-06\n","Epoch 270/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2057e-06 - mean_squared_error: 1.1549e-06 - val_loss: 1.2121e-06 - val_mean_squared_error: 1.1596e-06\n","Epoch 271/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2054e-06 - mean_squared_error: 1.1550e-06 - val_loss: 1.2114e-06 - val_mean_squared_error: 1.1592e-06\n","Epoch 272/350\n","225/225 [==============================] - 1s 7ms/step - loss: 1.2045e-06 - mean_squared_error: 1.1544e-06 - val_loss: 1.2139e-06 - val_mean_squared_error: 1.1626e-06\n","Epoch 273/350\n","225/225 [==============================] - 2s 8ms/step - loss: 1.2039e-06 - mean_squared_error: 1.1542e-06 - val_loss: 1.2108e-06 - val_mean_squared_error: 1.1589e-06\n","Epoch 274/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2039e-06 - mean_squared_error: 1.1544e-06 - val_loss: 1.2099e-06 - val_mean_squared_error: 1.1586e-06\n","Epoch 275/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2031e-06 - mean_squared_error: 1.1539e-06 - val_loss: 1.2102e-06 - val_mean_squared_error: 1.1595e-06\n","Epoch 276/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2030e-06 - mean_squared_error: 1.1542e-06 - val_loss: 1.2093e-06 - val_mean_squared_error: 1.1589e-06\n","Epoch 277/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2021e-06 - mean_squared_error: 1.1535e-06 - val_loss: 1.2085e-06 - val_mean_squared_error: 1.1583e-06\n","Epoch 278/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2021e-06 - mean_squared_error: 1.1539e-06 - val_loss: 1.2086e-06 - val_mean_squared_error: 1.1589e-06\n","Epoch 279/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2015e-06 - mean_squared_error: 1.1535e-06 - val_loss: 1.2098e-06 - val_mean_squared_error: 1.1606e-06\n","Epoch 280/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2010e-06 - mean_squared_error: 1.1535e-06 - val_loss: 1.2072e-06 - val_mean_squared_error: 1.1580e-06\n","Epoch 281/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2006e-06 - mean_squared_error: 1.1533e-06 - val_loss: 1.2066e-06 - val_mean_squared_error: 1.1576e-06\n","Epoch 282/350\n","225/225 [==============================] - 2s 8ms/step - loss: 1.2000e-06 - mean_squared_error: 1.1529e-06 - val_loss: 1.2062e-06 - val_mean_squared_error: 1.1575e-06\n","Epoch 283/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1993e-06 - mean_squared_error: 1.1525e-06 - val_loss: 1.2062e-06 - val_mean_squared_error: 1.1580e-06\n","Epoch 284/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1988e-06 - mean_squared_error: 1.1524e-06 - val_loss: 1.2054e-06 - val_mean_squared_error: 1.1573e-06\n","Epoch 285/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1983e-06 - mean_squared_error: 1.1521e-06 - val_loss: 1.2049e-06 - val_mean_squared_error: 1.1569e-06\n","Epoch 286/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1980e-06 - mean_squared_error: 1.1521e-06 - val_loss: 1.2048e-06 - val_mean_squared_error: 1.1575e-06\n","Epoch 287/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1975e-06 - mean_squared_error: 1.1519e-06 - val_loss: 1.2042e-06 - val_mean_squared_error: 1.1571e-06\n","Epoch 288/350\n","225/225 [==============================] - 2s 8ms/step - loss: 1.1974e-06 - mean_squared_error: 1.1521e-06 - val_loss: 1.2048e-06 - val_mean_squared_error: 1.1582e-06\n","Epoch 289/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1972e-06 - mean_squared_error: 1.1523e-06 - val_loss: 1.2032e-06 - val_mean_squared_error: 1.1563e-06\n","Epoch 290/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1966e-06 - mean_squared_error: 1.1519e-06 - val_loss: 1.2033e-06 - val_mean_squared_error: 1.1566e-06\n","Epoch 291/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1963e-06 - mean_squared_error: 1.1517e-06 - val_loss: 1.2025e-06 - val_mean_squared_error: 1.1565e-06\n","Epoch 292/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1957e-06 - mean_squared_error: 1.1516e-06 - val_loss: 1.2018e-06 - val_mean_squared_error: 1.1559e-06\n","Epoch 293/350\n","225/225 [==============================] - 2s 8ms/step - loss: 1.1950e-06 - mean_squared_error: 1.1511e-06 - val_loss: 1.2022e-06 - val_mean_squared_error: 1.1569e-06\n","Epoch 294/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1946e-06 - mean_squared_error: 1.1510e-06 - val_loss: 1.2014e-06 - val_mean_squared_error: 1.1562e-06\n","Epoch 295/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1945e-06 - mean_squared_error: 1.1510e-06 - val_loss: 1.2006e-06 - val_mean_squared_error: 1.1556e-06\n","Epoch 296/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1939e-06 - mean_squared_error: 1.1507e-06 - val_loss: 1.2004e-06 - val_mean_squared_error: 1.1558e-06\n","Epoch 297/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1935e-06 - mean_squared_error: 1.1506e-06 - val_loss: 1.2027e-06 - val_mean_squared_error: 1.1588e-06\n","Epoch 298/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1931e-06 - mean_squared_error: 1.1504e-06 - val_loss: 1.2004e-06 - val_mean_squared_error: 1.1565e-06\n","Epoch 299/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1931e-06 - mean_squared_error: 1.1507e-06 - val_loss: 1.1995e-06 - val_mean_squared_error: 1.1557e-06\n","Epoch 300/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1923e-06 - mean_squared_error: 1.1501e-06 - val_loss: 1.1986e-06 - val_mean_squared_error: 1.1549e-06\n","Epoch 301/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1920e-06 - mean_squared_error: 1.1501e-06 - val_loss: 1.1991e-06 - val_mean_squared_error: 1.1559e-06\n","Epoch 302/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1916e-06 - mean_squared_error: 1.1500e-06 - val_loss: 1.1985e-06 - val_mean_squared_error: 1.1550e-06\n","Epoch 303/350\n","225/225 [==============================] - 2s 8ms/step - loss: 1.1913e-06 - mean_squared_error: 1.1498e-06 - val_loss: 1.1986e-06 - val_mean_squared_error: 1.1559e-06\n","Epoch 304/350\n","225/225 [==============================] - 2s 8ms/step - loss: 1.1909e-06 - mean_squared_error: 1.1497e-06 - val_loss: 1.1972e-06 - val_mean_squared_error: 1.1543e-06\n","Epoch 305/350\n","225/225 [==============================] - 2s 9ms/step - loss: 1.1906e-06 - mean_squared_error: 1.1496e-06 - val_loss: 1.1972e-06 - val_mean_squared_error: 1.1548e-06\n","Epoch 306/350\n","225/225 [==============================] - 2s 8ms/step - loss: 1.1902e-06 - mean_squared_error: 1.1495e-06 - val_loss: 1.1965e-06 - val_mean_squared_error: 1.1541e-06\n","Epoch 307/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1900e-06 - mean_squared_error: 1.1495e-06 - val_loss: 1.1961e-06 - val_mean_squared_error: 1.1541e-06\n","Epoch 308/350\n","225/225 [==============================] - 2s 8ms/step - loss: 1.1898e-06 - mean_squared_error: 1.1495e-06 - val_loss: 1.1961e-06 - val_mean_squared_error: 1.1544e-06\n","Epoch 309/350\n","225/225 [==============================] - 2s 8ms/step - loss: 1.1892e-06 - mean_squared_error: 1.1492e-06 - val_loss: 1.1955e-06 - val_mean_squared_error: 1.1538e-06\n","Epoch 310/350\n","225/225 [==============================] - 2s 8ms/step - loss: 1.1889e-06 - mean_squared_error: 1.1491e-06 - val_loss: 1.1954e-06 - val_mean_squared_error: 1.1542e-06\n","Epoch 311/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1886e-06 - mean_squared_error: 1.1490e-06 - val_loss: 1.1953e-06 - val_mean_squared_error: 1.1545e-06\n","Epoch 312/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1883e-06 - mean_squared_error: 1.1489e-06 - val_loss: 1.1945e-06 - val_mean_squared_error: 1.1538e-06\n","Epoch 313/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1880e-06 - mean_squared_error: 1.1489e-06 - val_loss: 1.1941e-06 - val_mean_squared_error: 1.1535e-06\n","Epoch 314/350\n","225/225 [==============================] - 2s 8ms/step - loss: 1.1877e-06 - mean_squared_error: 1.1487e-06 - val_loss: 1.1938e-06 - val_mean_squared_error: 1.1534e-06\n","Epoch 315/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1871e-06 - mean_squared_error: 1.1483e-06 - val_loss: 1.1941e-06 - val_mean_squared_error: 1.1541e-06\n","Epoch 316/350\n","225/225 [==============================] - 2s 8ms/step - loss: 1.1865e-06 - mean_squared_error: 1.1481e-06 - val_loss: 1.1933e-06 - val_mean_squared_error: 1.1532e-06\n","Epoch 317/350\n","225/225 [==============================] - 2s 8ms/step - loss: 1.1869e-06 - mean_squared_error: 1.1486e-06 - val_loss: 1.1929e-06 - val_mean_squared_error: 1.1532e-06\n","Epoch 318/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1861e-06 - mean_squared_error: 1.1480e-06 - val_loss: 1.1925e-06 - val_mean_squared_error: 1.1530e-06\n","Epoch 319/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1861e-06 - mean_squared_error: 1.1482e-06 - val_loss: 1.1929e-06 - val_mean_squared_error: 1.1538e-06\n","Epoch 320/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1855e-06 - mean_squared_error: 1.1479e-06 - val_loss: 1.1918e-06 - val_mean_squared_error: 1.1527e-06\n","Epoch 321/350\n","225/225 [==============================] - 2s 8ms/step - loss: 1.1852e-06 - mean_squared_error: 1.1477e-06 - val_loss: 1.1927e-06 - val_mean_squared_error: 1.1541e-06\n","Epoch 322/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1849e-06 - mean_squared_error: 1.1477e-06 - val_loss: 1.1912e-06 - val_mean_squared_error: 1.1526e-06\n","Epoch 323/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1847e-06 - mean_squared_error: 1.1477e-06 - val_loss: 1.1911e-06 - val_mean_squared_error: 1.1527e-06\n","Epoch 324/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1844e-06 - mean_squared_error: 1.1476e-06 - val_loss: 1.1905e-06 - val_mean_squared_error: 1.1522e-06\n","Epoch 325/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1841e-06 - mean_squared_error: 1.1474e-06 - val_loss: 1.1907e-06 - val_mean_squared_error: 1.1528e-06\n","Epoch 326/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1840e-06 - mean_squared_error: 1.1475e-06 - val_loss: 1.1901e-06 - val_mean_squared_error: 1.1523e-06\n","Epoch 327/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1836e-06 - mean_squared_error: 1.1473e-06 - val_loss: 1.1898e-06 - val_mean_squared_error: 1.1522e-06\n","Epoch 328/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1832e-06 - mean_squared_error: 1.1472e-06 - val_loss: 1.1893e-06 - val_mean_squared_error: 1.1518e-06\n","Epoch 329/350\n","225/225 [==============================] - 2s 8ms/step - loss: 1.1829e-06 - mean_squared_error: 1.1470e-06 - val_loss: 1.1892e-06 - val_mean_squared_error: 1.1520e-06\n","Epoch 330/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1822e-06 - mean_squared_error: 1.1466e-06 - val_loss: 1.1890e-06 - val_mean_squared_error: 1.1517e-06\n","Epoch 331/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1824e-06 - mean_squared_error: 1.1469e-06 - val_loss: 1.1885e-06 - val_mean_squared_error: 1.1517e-06\n","Epoch 332/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1823e-06 - mean_squared_error: 1.1470e-06 - val_loss: 1.1882e-06 - val_mean_squared_error: 1.1515e-06\n","Epoch 333/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1819e-06 - mean_squared_error: 1.1467e-06 - val_loss: 1.1880e-06 - val_mean_squared_error: 1.1515e-06\n","Epoch 334/350\n","225/225 [==============================] - 2s 8ms/step - loss: 1.1815e-06 - mean_squared_error: 1.1466e-06 - val_loss: 1.1881e-06 - val_mean_squared_error: 1.1516e-06\n","Epoch 335/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1809e-06 - mean_squared_error: 1.1461e-06 - val_loss: 1.1881e-06 - val_mean_squared_error: 1.1522e-06\n","Epoch 336/350\n","225/225 [==============================] - 2s 8ms/step - loss: 1.1812e-06 - mean_squared_error: 1.1467e-06 - val_loss: 1.1871e-06 - val_mean_squared_error: 1.1511e-06\n","Epoch 337/350\n","225/225 [==============================] - 2s 8ms/step - loss: 1.1811e-06 - mean_squared_error: 1.1467e-06 - val_loss: 1.1873e-06 - val_mean_squared_error: 1.1518e-06\n","Epoch 338/350\n","225/225 [==============================] - 2s 8ms/step - loss: 1.1804e-06 - mean_squared_error: 1.1462e-06 - val_loss: 1.1878e-06 - val_mean_squared_error: 1.1525e-06\n","Epoch 339/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1808e-06 - mean_squared_error: 1.1468e-06 - val_loss: 1.1870e-06 - val_mean_squared_error: 1.1518e-06\n","Epoch 340/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1800e-06 - mean_squared_error: 1.1462e-06 - val_loss: 1.1862e-06 - val_mean_squared_error: 1.1511e-06\n","Epoch 341/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1795e-06 - mean_squared_error: 1.1458e-06 - val_loss: 1.1863e-06 - val_mean_squared_error: 1.1515e-06\n","Epoch 342/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1797e-06 - mean_squared_error: 1.1462e-06 - val_loss: 1.1855e-06 - val_mean_squared_error: 1.1506e-06\n","Epoch 343/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1791e-06 - mean_squared_error: 1.1457e-06 - val_loss: 1.1854e-06 - val_mean_squared_error: 1.1507e-06\n","Epoch 344/350\n","225/225 [==============================] - 2s 8ms/step - loss: 1.1790e-06 - mean_squared_error: 1.1458e-06 - val_loss: 1.1850e-06 - val_mean_squared_error: 1.1505e-06\n","Epoch 345/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1785e-06 - mean_squared_error: 1.1454e-06 - val_loss: 1.1856e-06 - val_mean_squared_error: 1.1515e-06\n","Epoch 346/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1784e-06 - mean_squared_error: 1.1456e-06 - val_loss: 1.1845e-06 - val_mean_squared_error: 1.1503e-06\n","Epoch 347/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1783e-06 - mean_squared_error: 1.1456e-06 - val_loss: 1.1843e-06 - val_mean_squared_error: 1.1502e-06\n","Epoch 348/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1780e-06 - mean_squared_error: 1.1454e-06 - val_loss: 1.1841e-06 - val_mean_squared_error: 1.1502e-06\n","Epoch 349/350\n","225/225 [==============================] - 2s 8ms/step - loss: 1.1778e-06 - mean_squared_error: 1.1455e-06 - val_loss: 1.1839e-06 - val_mean_squared_error: 1.1504e-06\n","Epoch 350/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1776e-06 - mean_squared_error: 1.1454e-06 - val_loss: 1.1843e-06 - val_mean_squared_error: 1.1510e-06\n","./defensive_models/350_0903_DAE_GTSRB_I\n","Epoch 1/350\n","225/225 [==============================] - 2s 9ms/step - loss: 0.0922 - mean_squared_error: 0.0922 - val_loss: 0.0085 - val_mean_squared_error: 0.0085\n","Epoch 2/350\n","225/225 [==============================] - 2s 8ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n","Epoch 3/350\n","225/225 [==============================] - 1s 7ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n","Epoch 4/350\n","225/225 [==============================] - 2s 7ms/step - loss: 8.6015e-04 - mean_squared_error: 8.5660e-04 - val_loss: 7.2781e-04 - val_mean_squared_error: 7.2439e-04\n","Epoch 5/350\n","225/225 [==============================] - 2s 7ms/step - loss: 5.6372e-04 - mean_squared_error: 5.6005e-04 - val_loss: 5.0492e-04 - val_mean_squared_error: 5.0141e-04\n","Epoch 6/350\n","225/225 [==============================] - 1s 6ms/step - loss: 4.0228e-04 - mean_squared_error: 3.9853e-04 - val_loss: 3.7312e-04 - val_mean_squared_error: 3.6956e-04\n","Epoch 7/350\n","225/225 [==============================] - 1s 6ms/step - loss: 3.0286e-04 - mean_squared_error: 2.9904e-04 - val_loss: 2.8760e-04 - val_mean_squared_error: 2.8399e-04\n","Epoch 8/350\n","225/225 [==============================] - 1s 6ms/step - loss: 2.3656e-04 - mean_squared_error: 2.3268e-04 - val_loss: 2.2848e-04 - val_mean_squared_error: 2.2483e-04\n","Epoch 9/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.8981e-04 - mean_squared_error: 1.8590e-04 - val_loss: 1.8567e-04 - val_mean_squared_error: 1.8198e-04\n","Epoch 10/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.5548e-04 - mean_squared_error: 1.5152e-04 - val_loss: 1.5357e-04 - val_mean_squared_error: 1.4985e-04\n","Epoch 11/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2944e-04 - mean_squared_error: 1.2545e-04 - val_loss: 1.2883e-04 - val_mean_squared_error: 1.2509e-04\n","Epoch 12/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.0920e-04 - mean_squared_error: 1.0517e-04 - val_loss: 1.0935e-04 - val_mean_squared_error: 1.0558e-04\n","Epoch 13/350\n","225/225 [==============================] - 1s 6ms/step - loss: 9.3140e-05 - mean_squared_error: 8.9087e-05 - val_loss: 9.3720e-05 - val_mean_squared_error: 8.9934e-05\n","Epoch 14/350\n","225/225 [==============================] - 1s 6ms/step - loss: 8.0189e-05 - mean_squared_error: 7.6110e-05 - val_loss: 8.0999e-05 - val_mean_squared_error: 7.7193e-05\n","Epoch 15/350\n","225/225 [==============================] - 1s 6ms/step - loss: 6.9599e-05 - mean_squared_error: 6.5496e-05 - val_loss: 7.0517e-05 - val_mean_squared_error: 6.6693e-05\n","Epoch 16/350\n","225/225 [==============================] - 1s 6ms/step - loss: 6.0838e-05 - mean_squared_error: 5.6714e-05 - val_loss: 6.1784e-05 - val_mean_squared_error: 5.7944e-05\n","Epoch 17/350\n","225/225 [==============================] - 1s 6ms/step - loss: 5.3519e-05 - mean_squared_error: 4.9374e-05 - val_loss: 5.4448e-05 - val_mean_squared_error: 5.0592e-05\n","Epoch 18/350\n","225/225 [==============================] - 1s 6ms/step - loss: 4.7352e-05 - mean_squared_error: 4.3189e-05 - val_loss: 4.8237e-05 - val_mean_squared_error: 4.4366e-05\n","Epoch 19/350\n","225/225 [==============================] - 1s 6ms/step - loss: 4.2120e-05 - mean_squared_error: 3.7938e-05 - val_loss: 4.2941e-05 - val_mean_squared_error: 3.9056e-05\n","Epoch 20/350\n","225/225 [==============================] - 1s 6ms/step - loss: 3.7652e-05 - mean_squared_error: 3.3453e-05 - val_loss: 3.8400e-05 - val_mean_squared_error: 3.4502e-05\n","Epoch 21/350\n","225/225 [==============================] - 1s 5ms/step - loss: 3.3816e-05 - mean_squared_error: 2.9602e-05 - val_loss: 3.4490e-05 - val_mean_squared_error: 3.0579e-05\n","Epoch 22/350\n","225/225 [==============================] - 1s 6ms/step - loss: 3.0508e-05 - mean_squared_error: 2.6278e-05 - val_loss: 3.1105e-05 - val_mean_squared_error: 2.7182e-05\n","Epoch 23/350\n","225/225 [==============================] - 2s 7ms/step - loss: 2.7643e-05 - mean_squared_error: 2.3399e-05 - val_loss: 2.8166e-05 - val_mean_squared_error: 2.4232e-05\n","Epoch 24/350\n","225/225 [==============================] - 1s 6ms/step - loss: 2.5153e-05 - mean_squared_error: 2.0895e-05 - val_loss: 2.5605e-05 - val_mean_squared_error: 2.1660e-05\n","Epoch 25/350\n","225/225 [==============================] - 1s 6ms/step - loss: 2.2983e-05 - mean_squared_error: 1.8712e-05 - val_loss: 2.3367e-05 - val_mean_squared_error: 1.9412e-05\n","Epoch 26/350\n","225/225 [==============================] - 1s 6ms/step - loss: 2.1086e-05 - mean_squared_error: 1.6803e-05 - val_loss: 2.1406e-05 - val_mean_squared_error: 1.7441e-05\n","Epoch 27/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.9424e-05 - mean_squared_error: 1.5130e-05 - val_loss: 1.9685e-05 - val_mean_squared_error: 1.5711e-05\n","Epoch 28/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.7966e-05 - mean_squared_error: 1.3661e-05 - val_loss: 1.8173e-05 - val_mean_squared_error: 1.4190e-05\n","Epoch 29/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.6684e-05 - mean_squared_error: 1.2368e-05 - val_loss: 1.6841e-05 - val_mean_squared_error: 1.2849e-05\n","Epoch 30/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.5554e-05 - mean_squared_error: 1.1229e-05 - val_loss: 1.5666e-05 - val_mean_squared_error: 1.1666e-05\n","Epoch 31/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.4558e-05 - mean_squared_error: 1.0224e-05 - val_loss: 1.4628e-05 - val_mean_squared_error: 1.0622e-05\n","Epoch 32/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3679e-05 - mean_squared_error: 9.3370e-06 - val_loss: 1.3710e-05 - val_mean_squared_error: 9.6963e-06\n","Epoch 33/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2902e-05 - mean_squared_error: 8.5527e-06 - val_loss: 1.2899e-05 - val_mean_squared_error: 8.8787e-06\n","Epoch 34/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.2215e-05 - mean_squared_error: 7.8589e-06 - val_loss: 1.2181e-05 - val_mean_squared_error: 8.1542e-06\n","Epoch 35/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1607e-05 - mean_squared_error: 7.2447e-06 - val_loss: 1.1544e-05 - val_mean_squared_error: 7.5123e-06\n","Epoch 36/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1068e-05 - mean_squared_error: 6.7010e-06 - val_loss: 1.0981e-05 - val_mean_squared_error: 6.9436e-06\n","Epoch 37/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.0591e-05 - mean_squared_error: 6.2194e-06 - val_loss: 1.0481e-05 - val_mean_squared_error: 6.4391e-06\n","Epoch 38/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.0168e-05 - mean_squared_error: 5.7927e-06 - val_loss: 1.0037e-05 - val_mean_squared_error: 5.9916e-06\n","Epoch 39/350\n","225/225 [==============================] - 1s 6ms/step - loss: 9.7918e-06 - mean_squared_error: 5.4147e-06 - val_loss: 9.6433e-06 - val_mean_squared_error: 5.5946e-06\n","Epoch 40/350\n","225/225 [==============================] - 1s 6ms/step - loss: 9.4579e-06 - mean_squared_error: 5.0797e-06 - val_loss: 9.2943e-06 - val_mean_squared_error: 5.2431e-06\n","Epoch 41/350\n","225/225 [==============================] - 1s 6ms/step - loss: 9.1612e-06 - mean_squared_error: 4.7830e-06 - val_loss: 8.9841e-06 - val_mean_squared_error: 4.9310e-06\n","Epoch 42/350\n","225/225 [==============================] - 1s 6ms/step - loss: 8.8971e-06 - mean_squared_error: 4.5202e-06 - val_loss: 8.7082e-06 - val_mean_squared_error: 4.6542e-06\n","Epoch 43/350\n","225/225 [==============================] - 1s 6ms/step - loss: 8.6618e-06 - mean_squared_error: 4.2875e-06 - val_loss: 8.4634e-06 - val_mean_squared_error: 4.4092e-06\n","Epoch 44/350\n","225/225 [==============================] - 1s 6ms/step - loss: 8.4517e-06 - mean_squared_error: 4.0815e-06 - val_loss: 8.2452e-06 - val_mean_squared_error: 4.1919e-06\n","Epoch 45/350\n","225/225 [==============================] - 1s 6ms/step - loss: 8.2638e-06 - mean_squared_error: 3.8992e-06 - val_loss: 8.0504e-06 - val_mean_squared_error: 3.9991e-06\n","Epoch 46/350\n","225/225 [==============================] - 1s 6ms/step - loss: 8.0953e-06 - mean_squared_error: 3.7381e-06 - val_loss: 7.8775e-06 - val_mean_squared_error: 3.8292e-06\n","Epoch 47/350\n","225/225 [==============================] - 1s 6ms/step - loss: 7.9439e-06 - mean_squared_error: 3.5959e-06 - val_loss: 7.7226e-06 - val_mean_squared_error: 3.6787e-06\n","Epoch 48/350\n","225/225 [==============================] - 1s 6ms/step - loss: 7.8071e-06 - mean_squared_error: 3.4703e-06 - val_loss: 7.5839e-06 - val_mean_squared_error: 3.5458e-06\n","Epoch 49/350\n","225/225 [==============================] - 1s 6ms/step - loss: 7.6830e-06 - mean_squared_error: 3.3596e-06 - val_loss: 7.4592e-06 - val_mean_squared_error: 3.4284e-06\n","Epoch 50/350\n","225/225 [==============================] - 1s 5ms/step - loss: 7.5699e-06 - mean_squared_error: 3.2621e-06 - val_loss: 7.3466e-06 - val_mean_squared_error: 3.3248e-06\n","Epoch 51/350\n","225/225 [==============================] - 1s 6ms/step - loss: 7.4659e-06 - mean_squared_error: 3.1762e-06 - val_loss: 7.2445e-06 - val_mean_squared_error: 3.2335e-06\n","Epoch 52/350\n","225/225 [==============================] - 1s 6ms/step - loss: 7.3697e-06 - mean_squared_error: 3.1008e-06 - val_loss: 7.1515e-06 - val_mean_squared_error: 3.1533e-06\n","Epoch 53/350\n","225/225 [==============================] - 1s 6ms/step - loss: 7.2800e-06 - mean_squared_error: 3.0348e-06 - val_loss: 7.0660e-06 - val_mean_squared_error: 3.0827e-06\n","Epoch 54/350\n","225/225 [==============================] - 1s 6ms/step - loss: 7.1956e-06 - mean_squared_error: 2.9769e-06 - val_loss: 6.9868e-06 - val_mean_squared_error: 3.0209e-06\n","Epoch 55/350\n","225/225 [==============================] - 1s 6ms/step - loss: 7.1153e-06 - mean_squared_error: 2.9264e-06 - val_loss: 6.9128e-06 - val_mean_squared_error: 2.9669e-06\n","Epoch 56/350\n","225/225 [==============================] - 1s 6ms/step - loss: 7.0382e-06 - mean_squared_error: 2.8825e-06 - val_loss: 6.8429e-06 - val_mean_squared_error: 2.9195e-06\n","Epoch 57/350\n","225/225 [==============================] - 1s 6ms/step - loss: 6.9634e-06 - mean_squared_error: 2.8443e-06 - val_loss: 6.7762e-06 - val_mean_squared_error: 2.8784e-06\n","Epoch 58/350\n","225/225 [==============================] - 1s 6ms/step - loss: 6.8902e-06 - mean_squared_error: 2.8113e-06 - val_loss: 6.7119e-06 - val_mean_squared_error: 2.8427e-06\n","Epoch 59/350\n","225/225 [==============================] - 1s 6ms/step - loss: 6.8179e-06 - mean_squared_error: 2.7827e-06 - val_loss: 6.6491e-06 - val_mean_squared_error: 2.8117e-06\n","Epoch 60/350\n","225/225 [==============================] - 1s 6ms/step - loss: 6.7459e-06 - mean_squared_error: 2.7584e-06 - val_loss: 6.5872e-06 - val_mean_squared_error: 2.7850e-06\n","Epoch 61/350\n","225/225 [==============================] - 1s 6ms/step - loss: 6.6738e-06 - mean_squared_error: 2.7375e-06 - val_loss: 6.5257e-06 - val_mean_squared_error: 2.7621e-06\n","Epoch 62/350\n","225/225 [==============================] - 1s 6ms/step - loss: 6.6012e-06 - mean_squared_error: 2.7200e-06 - val_loss: 6.4639e-06 - val_mean_squared_error: 2.7426e-06\n","Epoch 63/350\n","225/225 [==============================] - 2s 7ms/step - loss: 6.5276e-06 - mean_squared_error: 2.7053e-06 - val_loss: 6.4014e-06 - val_mean_squared_error: 2.7261e-06\n","Epoch 64/350\n","225/225 [==============================] - 1s 6ms/step - loss: 6.4528e-06 - mean_squared_error: 2.6932e-06 - val_loss: 6.3377e-06 - val_mean_squared_error: 2.7121e-06\n","Epoch 65/350\n","225/225 [==============================] - 1s 6ms/step - loss: 6.3763e-06 - mean_squared_error: 2.6835e-06 - val_loss: 6.2721e-06 - val_mean_squared_error: 2.7007e-06\n","Epoch 66/350\n","225/225 [==============================] - 1s 6ms/step - loss: 6.2975e-06 - mean_squared_error: 2.6757e-06 - val_loss: 6.2042e-06 - val_mean_squared_error: 2.6914e-06\n","Epoch 67/350\n","225/225 [==============================] - 1s 6ms/step - loss: 6.2156e-06 - mean_squared_error: 2.6703e-06 - val_loss: 6.1329e-06 - val_mean_squared_error: 2.6844e-06\n","Epoch 68/350\n","225/225 [==============================] - 1s 6ms/step - loss: 6.1295e-06 - mean_squared_error: 2.6666e-06 - val_loss: 6.0570e-06 - val_mean_squared_error: 2.6789e-06\n","Epoch 69/350\n","225/225 [==============================] - 1s 6ms/step - loss: 6.0377e-06 - mean_squared_error: 2.6646e-06 - val_loss: 5.9750e-06 - val_mean_squared_error: 2.6755e-06\n","Epoch 70/350\n","225/225 [==============================] - 1s 6ms/step - loss: 5.9378e-06 - mean_squared_error: 2.6650e-06 - val_loss: 5.8846e-06 - val_mean_squared_error: 2.6737e-06\n","Epoch 71/350\n","225/225 [==============================] - 1s 6ms/step - loss: 5.8272e-06 - mean_squared_error: 2.6666e-06 - val_loss: 5.7828e-06 - val_mean_squared_error: 2.6736e-06\n","Epoch 72/350\n","225/225 [==============================] - 1s 6ms/step - loss: 5.7023e-06 - mean_squared_error: 2.6700e-06 - val_loss: 5.6663e-06 - val_mean_squared_error: 2.6748e-06\n","Epoch 73/350\n","225/225 [==============================] - 1s 6ms/step - loss: 5.5602e-06 - mean_squared_error: 2.6752e-06 - val_loss: 5.5319e-06 - val_mean_squared_error: 2.6750e-06\n","Epoch 74/350\n","225/225 [==============================] - 1s 6ms/step - loss: 5.3989e-06 - mean_squared_error: 2.6782e-06 - val_loss: 5.3777e-06 - val_mean_squared_error: 2.6730e-06\n","Epoch 75/350\n","225/225 [==============================] - 1s 6ms/step - loss: 5.2197e-06 - mean_squared_error: 2.6775e-06 - val_loss: 5.2055e-06 - val_mean_squared_error: 2.6641e-06\n","Epoch 76/350\n","225/225 [==============================] - 1s 6ms/step - loss: 5.0271e-06 - mean_squared_error: 2.6677e-06 - val_loss: 5.0198e-06 - val_mean_squared_error: 2.6459e-06\n","Epoch 77/350\n","225/225 [==============================] - 1s 6ms/step - loss: 4.8270e-06 - mean_squared_error: 2.6452e-06 - val_loss: 4.8252e-06 - val_mean_squared_error: 2.6195e-06\n","Epoch 78/350\n","225/225 [==============================] - 1s 6ms/step - loss: 4.6243e-06 - mean_squared_error: 2.6112e-06 - val_loss: 4.6277e-06 - val_mean_squared_error: 2.5816e-06\n","Epoch 79/350\n","225/225 [==============================] - 1s 6ms/step - loss: 4.4218e-06 - mean_squared_error: 2.5667e-06 - val_loss: 4.4274e-06 - val_mean_squared_error: 2.5353e-06\n","Epoch 80/350\n","225/225 [==============================] - 1s 6ms/step - loss: 4.2198e-06 - mean_squared_error: 2.5116e-06 - val_loss: 4.2235e-06 - val_mean_squared_error: 2.4789e-06\n","Epoch 81/350\n","225/225 [==============================] - 1s 6ms/step - loss: 4.0167e-06 - mean_squared_error: 2.4465e-06 - val_loss: 4.0119e-06 - val_mean_squared_error: 2.4105e-06\n","Epoch 82/350\n","225/225 [==============================] - 1s 6ms/step - loss: 3.8093e-06 - mean_squared_error: 2.3674e-06 - val_loss: 3.7880e-06 - val_mean_squared_error: 2.3264e-06\n","Epoch 83/350\n","225/225 [==============================] - 1s 6ms/step - loss: 3.5937e-06 - mean_squared_error: 2.2750e-06 - val_loss: 3.5498e-06 - val_mean_squared_error: 2.2165e-06\n","Epoch 84/350\n","225/225 [==============================] - 1s 6ms/step - loss: 3.3647e-06 - mean_squared_error: 2.1589e-06 - val_loss: 3.2848e-06 - val_mean_squared_error: 2.0832e-06\n","Epoch 85/350\n","225/225 [==============================] - 1s 6ms/step - loss: 3.1178e-06 - mean_squared_error: 2.0187e-06 - val_loss: 3.0016e-06 - val_mean_squared_error: 1.9213e-06\n","Epoch 86/350\n","225/225 [==============================] - 1s 6ms/step - loss: 2.8546e-06 - mean_squared_error: 1.8544e-06 - val_loss: 2.7170e-06 - val_mean_squared_error: 1.7392e-06\n","Epoch 87/350\n","225/225 [==============================] - 1s 6ms/step - loss: 2.5912e-06 - mean_squared_error: 1.6732e-06 - val_loss: 2.5005e-06 - val_mean_squared_error: 1.6197e-06\n","Epoch 88/350\n","225/225 [==============================] - 2s 7ms/step - loss: 2.3621e-06 - mean_squared_error: 1.5120e-06 - val_loss: 2.3184e-06 - val_mean_squared_error: 1.4928e-06\n","Epoch 89/350\n","225/225 [==============================] - 1s 6ms/step - loss: 2.1913e-06 - mean_squared_error: 1.3911e-06 - val_loss: 2.2986e-06 - val_mean_squared_error: 1.5319e-06\n","Epoch 90/350\n","225/225 [==============================] - 1s 6ms/step - loss: 2.0750e-06 - mean_squared_error: 1.3163e-06 - val_loss: 2.2376e-06 - val_mean_squared_error: 1.5074e-06\n","Epoch 91/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.9957e-06 - mean_squared_error: 1.2722e-06 - val_loss: 2.2857e-06 - val_mean_squared_error: 1.5955e-06\n","Epoch 92/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.9363e-06 - mean_squared_error: 1.2447e-06 - val_loss: 2.2974e-06 - val_mean_squared_error: 1.6396e-06\n","Epoch 93/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.8917e-06 - mean_squared_error: 1.2290e-06 - val_loss: 2.4624e-06 - val_mean_squared_error: 1.8413e-06\n","Epoch 94/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.8550e-06 - mean_squared_error: 1.2198e-06 - val_loss: 2.4735e-06 - val_mean_squared_error: 1.8790e-06\n","Epoch 95/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.8221e-06 - mean_squared_error: 1.2126e-06 - val_loss: 2.4575e-06 - val_mean_squared_error: 1.8870e-06\n","Epoch 96/350\n","225/225 [==============================] - 2s 8ms/step - loss: 1.7944e-06 - mean_squared_error: 1.2086e-06 - val_loss: 2.4874e-06 - val_mean_squared_error: 1.9408e-06\n","Epoch 97/350\n","225/225 [==============================] - 2s 8ms/step - loss: 1.7701e-06 - mean_squared_error: 1.2062e-06 - val_loss: 2.3778e-06 - val_mean_squared_error: 1.8492e-06\n","Epoch 98/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.7466e-06 - mean_squared_error: 1.2043e-06 - val_loss: 2.4218e-06 - val_mean_squared_error: 1.9147e-06\n","Epoch 99/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.7255e-06 - mean_squared_error: 1.2022e-06 - val_loss: 2.3562e-06 - val_mean_squared_error: 1.8662e-06\n","Epoch 100/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.7061e-06 - mean_squared_error: 1.2011e-06 - val_loss: 2.5234e-06 - val_mean_squared_error: 2.0558e-06\n","Epoch 101/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.6904e-06 - mean_squared_error: 1.2031e-06 - val_loss: 2.4160e-06 - val_mean_squared_error: 1.9625e-06\n","Epoch 102/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.6708e-06 - mean_squared_error: 1.2001e-06 - val_loss: 2.3985e-06 - val_mean_squared_error: 1.9605e-06\n","Epoch 103/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.6546e-06 - mean_squared_error: 1.1989e-06 - val_loss: 2.4146e-06 - val_mean_squared_error: 1.9921e-06\n","Epoch 104/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.6398e-06 - mean_squared_error: 1.1993e-06 - val_loss: 2.3121e-06 - val_mean_squared_error: 1.9016e-06\n","Epoch 105/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.6254e-06 - mean_squared_error: 1.1990e-06 - val_loss: 2.1782e-06 - val_mean_squared_error: 1.7781e-06\n","Epoch 106/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.6121e-06 - mean_squared_error: 1.1987e-06 - val_loss: 2.3343e-06 - val_mean_squared_error: 1.9509e-06\n","Epoch 107/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.5987e-06 - mean_squared_error: 1.1980e-06 - val_loss: 2.2585e-06 - val_mean_squared_error: 1.8856e-06\n","Epoch 108/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.5856e-06 - mean_squared_error: 1.1967e-06 - val_loss: 2.3596e-06 - val_mean_squared_error: 2.0003e-06\n","Epoch 109/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.5742e-06 - mean_squared_error: 1.1967e-06 - val_loss: 2.2540e-06 - val_mean_squared_error: 1.9036e-06\n","Epoch 110/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.5627e-06 - mean_squared_error: 1.1959e-06 - val_loss: 2.1567e-06 - val_mean_squared_error: 1.8146e-06\n","Epoch 111/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.5522e-06 - mean_squared_error: 1.1954e-06 - val_loss: 2.1166e-06 - val_mean_squared_error: 1.7836e-06\n","Epoch 112/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.5416e-06 - mean_squared_error: 1.1946e-06 - val_loss: 2.0505e-06 - val_mean_squared_error: 1.7254e-06\n","Epoch 113/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.5328e-06 - mean_squared_error: 1.1948e-06 - val_loss: 2.0452e-06 - val_mean_squared_error: 1.7289e-06\n","Epoch 114/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.5227e-06 - mean_squared_error: 1.1934e-06 - val_loss: 2.0663e-06 - val_mean_squared_error: 1.7590e-06\n","Epoch 115/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.5144e-06 - mean_squared_error: 1.1932e-06 - val_loss: 1.9560e-06 - val_mean_squared_error: 1.6544e-06\n","Epoch 116/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.5065e-06 - mean_squared_error: 1.1931e-06 - val_loss: 2.0292e-06 - val_mean_squared_error: 1.7370e-06\n","Epoch 117/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.4986e-06 - mean_squared_error: 1.1929e-06 - val_loss: 1.9076e-06 - val_mean_squared_error: 1.6200e-06\n","Epoch 118/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.4896e-06 - mean_squared_error: 1.1909e-06 - val_loss: 1.8634e-06 - val_mean_squared_error: 1.5818e-06\n","Epoch 119/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.4822e-06 - mean_squared_error: 1.1903e-06 - val_loss: 1.8022e-06 - val_mean_squared_error: 1.5258e-06\n","Epoch 120/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.4746e-06 - mean_squared_error: 1.1890e-06 - val_loss: 1.8023e-06 - val_mean_squared_error: 1.5326e-06\n","Epoch 121/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.4675e-06 - mean_squared_error: 1.1884e-06 - val_loss: 1.8087e-06 - val_mean_squared_error: 1.5454e-06\n","Epoch 122/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.4607e-06 - mean_squared_error: 1.1875e-06 - val_loss: 1.7481e-06 - val_mean_squared_error: 1.4893e-06\n","Epoch 123/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.4538e-06 - mean_squared_error: 1.1864e-06 - val_loss: 1.6661e-06 - val_mean_squared_error: 1.4107e-06\n","Epoch 124/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.4481e-06 - mean_squared_error: 1.1862e-06 - val_loss: 1.6414e-06 - val_mean_squared_error: 1.3908e-06\n","Epoch 125/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.4418e-06 - mean_squared_error: 1.1852e-06 - val_loss: 1.6465e-06 - val_mean_squared_error: 1.4015e-06\n","Epoch 126/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.4364e-06 - mean_squared_error: 1.1849e-06 - val_loss: 1.6263e-06 - val_mean_squared_error: 1.3859e-06\n","Epoch 127/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.4312e-06 - mean_squared_error: 1.1845e-06 - val_loss: 1.6573e-06 - val_mean_squared_error: 1.4229e-06\n","Epoch 128/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.4256e-06 - mean_squared_error: 1.1838e-06 - val_loss: 1.5806e-06 - val_mean_squared_error: 1.3485e-06\n","Epoch 129/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.4195e-06 - mean_squared_error: 1.1821e-06 - val_loss: 1.5996e-06 - val_mean_squared_error: 1.3728e-06\n","Epoch 130/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.4154e-06 - mean_squared_error: 1.1823e-06 - val_loss: 1.5591e-06 - val_mean_squared_error: 1.3353e-06\n","Epoch 131/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.4100e-06 - mean_squared_error: 1.1810e-06 - val_loss: 1.5629e-06 - val_mean_squared_error: 1.3436e-06\n","Epoch 132/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.4049e-06 - mean_squared_error: 1.1801e-06 - val_loss: 1.4944e-06 - val_mean_squared_error: 1.2763e-06\n","Epoch 133/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.4006e-06 - mean_squared_error: 1.1795e-06 - val_loss: 1.5234e-06 - val_mean_squared_error: 1.3108e-06\n","Epoch 134/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3981e-06 - mean_squared_error: 1.1808e-06 - val_loss: 1.4905e-06 - val_mean_squared_error: 1.2803e-06\n","Epoch 135/350\n","225/225 [==============================] - 1s 5ms/step - loss: 1.3919e-06 - mean_squared_error: 1.1782e-06 - val_loss: 1.4779e-06 - val_mean_squared_error: 1.2709e-06\n","Epoch 136/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3883e-06 - mean_squared_error: 1.1782e-06 - val_loss: 1.4842e-06 - val_mean_squared_error: 1.2813e-06\n","Epoch 137/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3854e-06 - mean_squared_error: 1.1784e-06 - val_loss: 1.4700e-06 - val_mean_squared_error: 1.2698e-06\n","Epoch 138/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.3806e-06 - mean_squared_error: 1.1771e-06 - val_loss: 1.4454e-06 - val_mean_squared_error: 1.2473e-06\n","Epoch 139/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3765e-06 - mean_squared_error: 1.1760e-06 - val_loss: 1.4401e-06 - val_mean_squared_error: 1.2452e-06\n","Epoch 140/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.3733e-06 - mean_squared_error: 1.1760e-06 - val_loss: 1.4273e-06 - val_mean_squared_error: 1.2349e-06\n","Epoch 141/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.3696e-06 - mean_squared_error: 1.1751e-06 - val_loss: 1.4264e-06 - val_mean_squared_error: 1.2372e-06\n","Epoch 142/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3656e-06 - mean_squared_error: 1.1742e-06 - val_loss: 1.4217e-06 - val_mean_squared_error: 1.2354e-06\n","Epoch 143/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3625e-06 - mean_squared_error: 1.1739e-06 - val_loss: 1.3938e-06 - val_mean_squared_error: 1.2084e-06\n","Epoch 144/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3588e-06 - mean_squared_error: 1.1729e-06 - val_loss: 1.3927e-06 - val_mean_squared_error: 1.2104e-06\n","Epoch 145/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3561e-06 - mean_squared_error: 1.1728e-06 - val_loss: 1.3914e-06 - val_mean_squared_error: 1.2119e-06\n","Epoch 146/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3528e-06 - mean_squared_error: 1.1722e-06 - val_loss: 1.3832e-06 - val_mean_squared_error: 1.2060e-06\n","Epoch 147/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3498e-06 - mean_squared_error: 1.1717e-06 - val_loss: 1.3875e-06 - val_mean_squared_error: 1.2135e-06\n","Epoch 148/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3467e-06 - mean_squared_error: 1.1710e-06 - val_loss: 1.3940e-06 - val_mean_squared_error: 1.2232e-06\n","Epoch 149/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3447e-06 - mean_squared_error: 1.1718e-06 - val_loss: 1.3623e-06 - val_mean_squared_error: 1.1912e-06\n","Epoch 150/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3418e-06 - mean_squared_error: 1.1710e-06 - val_loss: 1.3621e-06 - val_mean_squared_error: 1.1938e-06\n","Epoch 151/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3393e-06 - mean_squared_error: 1.1707e-06 - val_loss: 1.3669e-06 - val_mean_squared_error: 1.2018e-06\n","Epoch 152/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3366e-06 - mean_squared_error: 1.1703e-06 - val_loss: 1.3536e-06 - val_mean_squared_error: 1.1895e-06\n","Epoch 153/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3336e-06 - mean_squared_error: 1.1694e-06 - val_loss: 1.3598e-06 - val_mean_squared_error: 1.1990e-06\n","Epoch 154/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3308e-06 - mean_squared_error: 1.1689e-06 - val_loss: 1.3424e-06 - val_mean_squared_error: 1.1815e-06\n","Epoch 155/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3285e-06 - mean_squared_error: 1.1685e-06 - val_loss: 1.3408e-06 - val_mean_squared_error: 1.1823e-06\n","Epoch 156/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3261e-06 - mean_squared_error: 1.1682e-06 - val_loss: 1.3362e-06 - val_mean_squared_error: 1.1792e-06\n","Epoch 157/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3243e-06 - mean_squared_error: 1.1684e-06 - val_loss: 1.3334e-06 - val_mean_squared_error: 1.1783e-06\n","Epoch 158/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3215e-06 - mean_squared_error: 1.1674e-06 - val_loss: 1.3313e-06 - val_mean_squared_error: 1.1784e-06\n","Epoch 159/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3191e-06 - mean_squared_error: 1.1671e-06 - val_loss: 1.3274e-06 - val_mean_squared_error: 1.1757e-06\n","Epoch 160/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3173e-06 - mean_squared_error: 1.1669e-06 - val_loss: 1.3275e-06 - val_mean_squared_error: 1.1786e-06\n","Epoch 161/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3154e-06 - mean_squared_error: 1.1670e-06 - val_loss: 1.3226e-06 - val_mean_squared_error: 1.1745e-06\n","Epoch 162/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3132e-06 - mean_squared_error: 1.1665e-06 - val_loss: 1.3212e-06 - val_mean_squared_error: 1.1754e-06\n","Epoch 163/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3106e-06 - mean_squared_error: 1.1655e-06 - val_loss: 1.3240e-06 - val_mean_squared_error: 1.1811e-06\n","Epoch 164/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3093e-06 - mean_squared_error: 1.1660e-06 - val_loss: 1.3164e-06 - val_mean_squared_error: 1.1739e-06\n","Epoch 165/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3066e-06 - mean_squared_error: 1.1650e-06 - val_loss: 1.3137e-06 - val_mean_squared_error: 1.1718e-06\n","Epoch 166/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3056e-06 - mean_squared_error: 1.1655e-06 - val_loss: 1.3114e-06 - val_mean_squared_error: 1.1715e-06\n","Epoch 167/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3023e-06 - mean_squared_error: 1.1639e-06 - val_loss: 1.3120e-06 - val_mean_squared_error: 1.1723e-06\n","Epoch 168/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.3018e-06 - mean_squared_error: 1.1647e-06 - val_loss: 1.3078e-06 - val_mean_squared_error: 1.1706e-06\n","Epoch 169/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2991e-06 - mean_squared_error: 1.1637e-06 - val_loss: 1.3055e-06 - val_mean_squared_error: 1.1705e-06\n","Epoch 170/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2981e-06 - mean_squared_error: 1.1641e-06 - val_loss: 1.3040e-06 - val_mean_squared_error: 1.1697e-06\n","Epoch 171/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2960e-06 - mean_squared_error: 1.1634e-06 - val_loss: 1.3021e-06 - val_mean_squared_error: 1.1693e-06\n","Epoch 172/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2938e-06 - mean_squared_error: 1.1627e-06 - val_loss: 1.3034e-06 - val_mean_squared_error: 1.1711e-06\n","Epoch 173/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2927e-06 - mean_squared_error: 1.1629e-06 - val_loss: 1.2985e-06 - val_mean_squared_error: 1.1685e-06\n","Epoch 174/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2905e-06 - mean_squared_error: 1.1621e-06 - val_loss: 1.3011e-06 - val_mean_squared_error: 1.1713e-06\n","Epoch 175/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2890e-06 - mean_squared_error: 1.1619e-06 - val_loss: 1.2945e-06 - val_mean_squared_error: 1.1677e-06\n","Epoch 176/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2875e-06 - mean_squared_error: 1.1617e-06 - val_loss: 1.2934e-06 - val_mean_squared_error: 1.1674e-06\n","Epoch 177/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2859e-06 - mean_squared_error: 1.1614e-06 - val_loss: 1.2918e-06 - val_mean_squared_error: 1.1671e-06\n","Epoch 178/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2839e-06 - mean_squared_error: 1.1608e-06 - val_loss: 1.2894e-06 - val_mean_squared_error: 1.1665e-06\n","Epoch 179/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2831e-06 - mean_squared_error: 1.1613e-06 - val_loss: 1.2893e-06 - val_mean_squared_error: 1.1669e-06\n","Epoch 180/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2813e-06 - mean_squared_error: 1.1607e-06 - val_loss: 1.2916e-06 - val_mean_squared_error: 1.1696e-06\n","Epoch 181/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2805e-06 - mean_squared_error: 1.1609e-06 - val_loss: 1.2874e-06 - val_mean_squared_error: 1.1672e-06\n","Epoch 182/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2790e-06 - mean_squared_error: 1.1608e-06 - val_loss: 1.2899e-06 - val_mean_squared_error: 1.1701e-06\n","Epoch 183/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2773e-06 - mean_squared_error: 1.1601e-06 - val_loss: 1.2850e-06 - val_mean_squared_error: 1.1669e-06\n","Epoch 184/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2762e-06 - mean_squared_error: 1.1603e-06 - val_loss: 1.2831e-06 - val_mean_squared_error: 1.1664e-06\n","Epoch 185/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2742e-06 - mean_squared_error: 1.1593e-06 - val_loss: 1.2795e-06 - val_mean_squared_error: 1.1644e-06\n","Epoch 186/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2732e-06 - mean_squared_error: 1.1595e-06 - val_loss: 1.2830e-06 - val_mean_squared_error: 1.1680e-06\n","Epoch 187/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2720e-06 - mean_squared_error: 1.1592e-06 - val_loss: 1.2763e-06 - val_mean_squared_error: 1.1636e-06\n","Epoch 188/350\n","225/225 [==============================] - 2s 8ms/step - loss: 1.2706e-06 - mean_squared_error: 1.1591e-06 - val_loss: 1.2772e-06 - val_mean_squared_error: 1.1649e-06\n","Epoch 189/350\n","225/225 [==============================] - 2s 8ms/step - loss: 1.2693e-06 - mean_squared_error: 1.1589e-06 - val_loss: 1.2815e-06 - val_mean_squared_error: 1.1694e-06\n","Epoch 190/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2678e-06 - mean_squared_error: 1.1583e-06 - val_loss: 1.2750e-06 - val_mean_squared_error: 1.1647e-06\n","Epoch 191/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2667e-06 - mean_squared_error: 1.1582e-06 - val_loss: 1.2747e-06 - val_mean_squared_error: 1.1653e-06\n","Epoch 192/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2653e-06 - mean_squared_error: 1.1579e-06 - val_loss: 1.2820e-06 - val_mean_squared_error: 1.1725e-06\n","Epoch 193/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2647e-06 - mean_squared_error: 1.1582e-06 - val_loss: 1.2754e-06 - val_mean_squared_error: 1.1675e-06\n","Epoch 194/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2635e-06 - mean_squared_error: 1.1579e-06 - val_loss: 1.2719e-06 - val_mean_squared_error: 1.1653e-06\n","Epoch 195/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2622e-06 - mean_squared_error: 1.1576e-06 - val_loss: 1.2696e-06 - val_mean_squared_error: 1.1642e-06\n","Epoch 196/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2611e-06 - mean_squared_error: 1.1574e-06 - val_loss: 1.2699e-06 - val_mean_squared_error: 1.1652e-06\n","Epoch 197/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2593e-06 - mean_squared_error: 1.1567e-06 - val_loss: 1.2699e-06 - val_mean_squared_error: 1.1659e-06\n","Epoch 198/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2588e-06 - mean_squared_error: 1.1571e-06 - val_loss: 1.2676e-06 - val_mean_squared_error: 1.1648e-06\n","Epoch 199/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2575e-06 - mean_squared_error: 1.1567e-06 - val_loss: 1.2707e-06 - val_mean_squared_error: 1.1682e-06\n","Epoch 200/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2566e-06 - mean_squared_error: 1.1566e-06 - val_loss: 1.2694e-06 - val_mean_squared_error: 1.1678e-06\n","Epoch 201/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2553e-06 - mean_squared_error: 1.1562e-06 - val_loss: 1.2652e-06 - val_mean_squared_error: 1.1649e-06\n","Epoch 202/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2543e-06 - mean_squared_error: 1.1560e-06 - val_loss: 1.2623e-06 - val_mean_squared_error: 1.1632e-06\n","Epoch 203/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2532e-06 - mean_squared_error: 1.1558e-06 - val_loss: 1.2649e-06 - val_mean_squared_error: 1.1661e-06\n","Epoch 204/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2521e-06 - mean_squared_error: 1.1555e-06 - val_loss: 1.2631e-06 - val_mean_squared_error: 1.1652e-06\n","Epoch 205/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2516e-06 - mean_squared_error: 1.1559e-06 - val_loss: 1.2600e-06 - val_mean_squared_error: 1.1632e-06\n","Epoch 206/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2501e-06 - mean_squared_error: 1.1552e-06 - val_loss: 1.2609e-06 - val_mean_squared_error: 1.1647e-06\n","Epoch 207/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2495e-06 - mean_squared_error: 1.1554e-06 - val_loss: 1.2665e-06 - val_mean_squared_error: 1.1705e-06\n","Epoch 208/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2483e-06 - mean_squared_error: 1.1550e-06 - val_loss: 1.2593e-06 - val_mean_squared_error: 1.1647e-06\n","Epoch 209/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2468e-06 - mean_squared_error: 1.1542e-06 - val_loss: 1.2549e-06 - val_mean_squared_error: 1.1615e-06\n","Epoch 210/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2467e-06 - mean_squared_error: 1.1549e-06 - val_loss: 1.2604e-06 - val_mean_squared_error: 1.1670e-06\n","Epoch 211/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2457e-06 - mean_squared_error: 1.1546e-06 - val_loss: 1.2592e-06 - val_mean_squared_error: 1.1666e-06\n","Epoch 212/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2445e-06 - mean_squared_error: 1.1543e-06 - val_loss: 1.2695e-06 - val_mean_squared_error: 1.1767e-06\n","Epoch 213/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2441e-06 - mean_squared_error: 1.1544e-06 - val_loss: 1.2575e-06 - val_mean_squared_error: 1.1664e-06\n","Epoch 214/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2427e-06 - mean_squared_error: 1.1538e-06 - val_loss: 1.2589e-06 - val_mean_squared_error: 1.1683e-06\n","Epoch 215/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2416e-06 - mean_squared_error: 1.1535e-06 - val_loss: 1.2577e-06 - val_mean_squared_error: 1.1678e-06\n","Epoch 216/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2408e-06 - mean_squared_error: 1.1533e-06 - val_loss: 1.2560e-06 - val_mean_squared_error: 1.1669e-06\n","Epoch 217/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2404e-06 - mean_squared_error: 1.1536e-06 - val_loss: 1.2491e-06 - val_mean_squared_error: 1.1614e-06\n","Epoch 218/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2400e-06 - mean_squared_error: 1.1540e-06 - val_loss: 1.2659e-06 - val_mean_squared_error: 1.1774e-06\n","Epoch 219/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2387e-06 - mean_squared_error: 1.1533e-06 - val_loss: 1.2591e-06 - val_mean_squared_error: 1.1716e-06\n","Epoch 220/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2378e-06 - mean_squared_error: 1.1530e-06 - val_loss: 1.2453e-06 - val_mean_squared_error: 1.1597e-06\n","Epoch 221/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2365e-06 - mean_squared_error: 1.1525e-06 - val_loss: 1.2600e-06 - val_mean_squared_error: 1.1737e-06\n","Epoch 222/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2360e-06 - mean_squared_error: 1.1525e-06 - val_loss: 1.2462e-06 - val_mean_squared_error: 1.1617e-06\n","Epoch 223/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2353e-06 - mean_squared_error: 1.1525e-06 - val_loss: 1.2508e-06 - val_mean_squared_error: 1.1664e-06\n","Epoch 224/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2351e-06 - mean_squared_error: 1.1529e-06 - val_loss: 1.2474e-06 - val_mean_squared_error: 1.1638e-06\n","Epoch 225/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2335e-06 - mean_squared_error: 1.1520e-06 - val_loss: 1.2526e-06 - val_mean_squared_error: 1.1692e-06\n","Epoch 226/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2329e-06 - mean_squared_error: 1.1520e-06 - val_loss: 1.2490e-06 - val_mean_squared_error: 1.1664e-06\n","Epoch 227/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2323e-06 - mean_squared_error: 1.1519e-06 - val_loss: 1.2497e-06 - val_mean_squared_error: 1.1676e-06\n","Epoch 228/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2316e-06 - mean_squared_error: 1.1519e-06 - val_loss: 1.2454e-06 - val_mean_squared_error: 1.1643e-06\n","Epoch 229/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2307e-06 - mean_squared_error: 1.1516e-06 - val_loss: 1.2448e-06 - val_mean_squared_error: 1.1643e-06\n","Epoch 230/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2302e-06 - mean_squared_error: 1.1517e-06 - val_loss: 1.2537e-06 - val_mean_squared_error: 1.1731e-06\n","Epoch 231/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2292e-06 - mean_squared_error: 1.1513e-06 - val_loss: 1.2496e-06 - val_mean_squared_error: 1.1698e-06\n","Epoch 232/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2291e-06 - mean_squared_error: 1.1518e-06 - val_loss: 1.2511e-06 - val_mean_squared_error: 1.1717e-06\n","Epoch 233/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2275e-06 - mean_squared_error: 1.1507e-06 - val_loss: 1.2452e-06 - val_mean_squared_error: 1.1667e-06\n","Epoch 234/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2269e-06 - mean_squared_error: 1.1506e-06 - val_loss: 1.2400e-06 - val_mean_squared_error: 1.1624e-06\n","Epoch 235/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2268e-06 - mean_squared_error: 1.1512e-06 - val_loss: 1.2510e-06 - val_mean_squared_error: 1.1732e-06\n","Epoch 236/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2257e-06 - mean_squared_error: 1.1506e-06 - val_loss: 1.2502e-06 - val_mean_squared_error: 1.1729e-06\n","Epoch 237/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2251e-06 - mean_squared_error: 1.1504e-06 - val_loss: 1.2428e-06 - val_mean_squared_error: 1.1665e-06\n","Epoch 238/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2242e-06 - mean_squared_error: 1.1501e-06 - val_loss: 1.2409e-06 - val_mean_squared_error: 1.1653e-06\n","Epoch 239/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2238e-06 - mean_squared_error: 1.1502e-06 - val_loss: 1.2453e-06 - val_mean_squared_error: 1.1698e-06\n","Epoch 240/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2234e-06 - mean_squared_error: 1.1503e-06 - val_loss: 1.2391e-06 - val_mean_squared_error: 1.1645e-06\n","Epoch 241/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2223e-06 - mean_squared_error: 1.1497e-06 - val_loss: 1.2334e-06 - val_mean_squared_error: 1.1598e-06\n","Epoch 242/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2222e-06 - mean_squared_error: 1.1502e-06 - val_loss: 1.2362e-06 - val_mean_squared_error: 1.1628e-06\n","Epoch 243/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2214e-06 - mean_squared_error: 1.1499e-06 - val_loss: 1.2436e-06 - val_mean_squared_error: 1.1702e-06\n","Epoch 244/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2207e-06 - mean_squared_error: 1.1496e-06 - val_loss: 1.2495e-06 - val_mean_squared_error: 1.1762e-06\n","Epoch 245/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2201e-06 - mean_squared_error: 1.1495e-06 - val_loss: 1.2399e-06 - val_mean_squared_error: 1.1676e-06\n","Epoch 246/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2192e-06 - mean_squared_error: 1.1491e-06 - val_loss: 1.2495e-06 - val_mean_squared_error: 1.1771e-06\n","Epoch 247/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2185e-06 - mean_squared_error: 1.1490e-06 - val_loss: 1.2441e-06 - val_mean_squared_error: 1.1725e-06\n","Epoch 248/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2185e-06 - mean_squared_error: 1.1492e-06 - val_loss: 1.2345e-06 - val_mean_squared_error: 1.1639e-06\n","Epoch 249/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2175e-06 - mean_squared_error: 1.1489e-06 - val_loss: 1.2371e-06 - val_mean_squared_error: 1.1667e-06\n","Epoch 250/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2175e-06 - mean_squared_error: 1.1493e-06 - val_loss: 1.2380e-06 - val_mean_squared_error: 1.1680e-06\n","Epoch 251/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2166e-06 - mean_squared_error: 1.1488e-06 - val_loss: 1.2333e-06 - val_mean_squared_error: 1.1640e-06\n","Epoch 252/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2158e-06 - mean_squared_error: 1.1485e-06 - val_loss: 1.2398e-06 - val_mean_squared_error: 1.1706e-06\n","Epoch 253/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2153e-06 - mean_squared_error: 1.1484e-06 - val_loss: 1.2308e-06 - val_mean_squared_error: 1.1625e-06\n","Epoch 254/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2147e-06 - mean_squared_error: 1.1483e-06 - val_loss: 1.2326e-06 - val_mean_squared_error: 1.1647e-06\n","Epoch 255/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2141e-06 - mean_squared_error: 1.1482e-06 - val_loss: 1.2319e-06 - val_mean_squared_error: 1.1645e-06\n","Epoch 256/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2135e-06 - mean_squared_error: 1.1480e-06 - val_loss: 1.2439e-06 - val_mean_squared_error: 1.1761e-06\n","Epoch 257/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2135e-06 - mean_squared_error: 1.1483e-06 - val_loss: 1.2323e-06 - val_mean_squared_error: 1.1657e-06\n","Epoch 258/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2125e-06 - mean_squared_error: 1.1478e-06 - val_loss: 1.2349e-06 - val_mean_squared_error: 1.1684e-06\n","Epoch 259/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2123e-06 - mean_squared_error: 1.1480e-06 - val_loss: 1.2265e-06 - val_mean_squared_error: 1.1610e-06\n","Epoch 260/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2116e-06 - mean_squared_error: 1.1477e-06 - val_loss: 1.2255e-06 - val_mean_squared_error: 1.1604e-06\n","Epoch 261/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2109e-06 - mean_squared_error: 1.1475e-06 - val_loss: 1.2291e-06 - val_mean_squared_error: 1.1642e-06\n","Epoch 262/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2108e-06 - mean_squared_error: 1.1478e-06 - val_loss: 1.2337e-06 - val_mean_squared_error: 1.1689e-06\n","Epoch 263/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2100e-06 - mean_squared_error: 1.1473e-06 - val_loss: 1.2273e-06 - val_mean_squared_error: 1.1632e-06\n","Epoch 264/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2097e-06 - mean_squared_error: 1.1475e-06 - val_loss: 1.2341e-06 - val_mean_squared_error: 1.1700e-06\n","Epoch 265/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2091e-06 - mean_squared_error: 1.1473e-06 - val_loss: 1.2263e-06 - val_mean_squared_error: 1.1630e-06\n","Epoch 266/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2086e-06 - mean_squared_error: 1.1471e-06 - val_loss: 1.2338e-06 - val_mean_squared_error: 1.1705e-06\n","Epoch 267/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2080e-06 - mean_squared_error: 1.1469e-06 - val_loss: 1.2344e-06 - val_mean_squared_error: 1.1714e-06\n","Epoch 268/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2076e-06 - mean_squared_error: 1.1469e-06 - val_loss: 1.2285e-06 - val_mean_squared_error: 1.1662e-06\n","Epoch 269/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2074e-06 - mean_squared_error: 1.1470e-06 - val_loss: 1.2340e-06 - val_mean_squared_error: 1.1718e-06\n","Epoch 270/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2064e-06 - mean_squared_error: 1.1464e-06 - val_loss: 1.2221e-06 - val_mean_squared_error: 1.1610e-06\n","Epoch 271/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2063e-06 - mean_squared_error: 1.1468e-06 - val_loss: 1.2276e-06 - val_mean_squared_error: 1.1665e-06\n","Epoch 272/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2061e-06 - mean_squared_error: 1.1469e-06 - val_loss: 1.2340e-06 - val_mean_squared_error: 1.1729e-06\n","Epoch 273/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2050e-06 - mean_squared_error: 1.1462e-06 - val_loss: 1.2345e-06 - val_mean_squared_error: 1.1737e-06\n","Epoch 274/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2047e-06 - mean_squared_error: 1.1463e-06 - val_loss: 1.2331e-06 - val_mean_squared_error: 1.1727e-06\n","Epoch 275/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2043e-06 - mean_squared_error: 1.1462e-06 - val_loss: 1.2308e-06 - val_mean_squared_error: 1.1709e-06\n","Epoch 276/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2040e-06 - mean_squared_error: 1.1463e-06 - val_loss: 1.2258e-06 - val_mean_squared_error: 1.1665e-06\n","Epoch 277/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2035e-06 - mean_squared_error: 1.1461e-06 - val_loss: 1.2307e-06 - val_mean_squared_error: 1.1715e-06\n","Epoch 278/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2029e-06 - mean_squared_error: 1.1458e-06 - val_loss: 1.2232e-06 - val_mean_squared_error: 1.1647e-06\n","Epoch 279/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2026e-06 - mean_squared_error: 1.1459e-06 - val_loss: 1.2280e-06 - val_mean_squared_error: 1.1695e-06\n","Epoch 280/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2021e-06 - mean_squared_error: 1.1457e-06 - val_loss: 1.2314e-06 - val_mean_squared_error: 1.1731e-06\n","Epoch 281/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2017e-06 - mean_squared_error: 1.1456e-06 - val_loss: 1.2256e-06 - val_mean_squared_error: 1.1680e-06\n","Epoch 282/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.2011e-06 - mean_squared_error: 1.1453e-06 - val_loss: 1.2257e-06 - val_mean_squared_error: 1.1684e-06\n","Epoch 283/350\n","225/225 [==============================] - 2s 8ms/step - loss: 1.2007e-06 - mean_squared_error: 1.1454e-06 - val_loss: 1.2350e-06 - val_mean_squared_error: 1.1775e-06\n","Epoch 284/350\n","225/225 [==============================] - 2s 8ms/step - loss: 1.2004e-06 - mean_squared_error: 1.1453e-06 - val_loss: 1.2155e-06 - val_mean_squared_error: 1.1594e-06\n","Epoch 285/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.2003e-06 - mean_squared_error: 1.1457e-06 - val_loss: 1.2270e-06 - val_mean_squared_error: 1.1705e-06\n","Epoch 286/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1997e-06 - mean_squared_error: 1.1452e-06 - val_loss: 1.2190e-06 - val_mean_squared_error: 1.1632e-06\n","Epoch 287/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1995e-06 - mean_squared_error: 1.1455e-06 - val_loss: 1.2252e-06 - val_mean_squared_error: 1.1695e-06\n","Epoch 288/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1990e-06 - mean_squared_error: 1.1452e-06 - val_loss: 1.2234e-06 - val_mean_squared_error: 1.1680e-06\n","Epoch 289/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1983e-06 - mean_squared_error: 1.1448e-06 - val_loss: 1.2142e-06 - val_mean_squared_error: 1.1597e-06\n","Epoch 290/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1981e-06 - mean_squared_error: 1.1450e-06 - val_loss: 1.2337e-06 - val_mean_squared_error: 1.1785e-06\n","Epoch 291/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1976e-06 - mean_squared_error: 1.1448e-06 - val_loss: 1.2263e-06 - val_mean_squared_error: 1.1717e-06\n","Epoch 292/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1973e-06 - mean_squared_error: 1.1447e-06 - val_loss: 1.2178e-06 - val_mean_squared_error: 1.1639e-06\n","Epoch 293/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1969e-06 - mean_squared_error: 1.1447e-06 - val_loss: 1.2212e-06 - val_mean_squared_error: 1.1674e-06\n","Epoch 294/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1965e-06 - mean_squared_error: 1.1446e-06 - val_loss: 1.2233e-06 - val_mean_squared_error: 1.1698e-06\n","Epoch 295/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1962e-06 - mean_squared_error: 1.1445e-06 - val_loss: 1.2200e-06 - val_mean_squared_error: 1.1668e-06\n","Epoch 296/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1959e-06 - mean_squared_error: 1.1445e-06 - val_loss: 1.2148e-06 - val_mean_squared_error: 1.1622e-06\n","Epoch 297/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1955e-06 - mean_squared_error: 1.1444e-06 - val_loss: 1.2234e-06 - val_mean_squared_error: 1.1707e-06\n","Epoch 298/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1952e-06 - mean_squared_error: 1.1445e-06 - val_loss: 1.2227e-06 - val_mean_squared_error: 1.1702e-06\n","Epoch 299/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1948e-06 - mean_squared_error: 1.1443e-06 - val_loss: 1.2173e-06 - val_mean_squared_error: 1.1654e-06\n","Epoch 300/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1944e-06 - mean_squared_error: 1.1442e-06 - val_loss: 1.2284e-06 - val_mean_squared_error: 1.1763e-06\n","Epoch 301/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1941e-06 - mean_squared_error: 1.1441e-06 - val_loss: 1.2128e-06 - val_mean_squared_error: 1.1616e-06\n","Epoch 302/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1936e-06 - mean_squared_error: 1.1440e-06 - val_loss: 1.2125e-06 - val_mean_squared_error: 1.1616e-06\n","Epoch 303/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1932e-06 - mean_squared_error: 1.1439e-06 - val_loss: 1.2301e-06 - val_mean_squared_error: 1.1787e-06\n","Epoch 304/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1929e-06 - mean_squared_error: 1.1437e-06 - val_loss: 1.2078e-06 - val_mean_squared_error: 1.1577e-06\n","Epoch 305/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1928e-06 - mean_squared_error: 1.1440e-06 - val_loss: 1.2211e-06 - val_mean_squared_error: 1.1707e-06\n","Epoch 306/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1922e-06 - mean_squared_error: 1.1437e-06 - val_loss: 1.2121e-06 - val_mean_squared_error: 1.1623e-06\n","Epoch 307/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1920e-06 - mean_squared_error: 1.1437e-06 - val_loss: 1.2192e-06 - val_mean_squared_error: 1.1693e-06\n","Epoch 308/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1918e-06 - mean_squared_error: 1.1438e-06 - val_loss: 1.2237e-06 - val_mean_squared_error: 1.1739e-06\n","Epoch 309/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1912e-06 - mean_squared_error: 1.1434e-06 - val_loss: 1.2144e-06 - val_mean_squared_error: 1.1652e-06\n","Epoch 310/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1913e-06 - mean_squared_error: 1.1437e-06 - val_loss: 1.2169e-06 - val_mean_squared_error: 1.1679e-06\n","Epoch 311/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1902e-06 - mean_squared_error: 1.1430e-06 - val_loss: 1.2359e-06 - val_mean_squared_error: 1.1865e-06\n","Epoch 312/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1901e-06 - mean_squared_error: 1.1431e-06 - val_loss: 1.2257e-06 - val_mean_squared_error: 1.1768e-06\n","Epoch 313/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1898e-06 - mean_squared_error: 1.1430e-06 - val_loss: 1.2148e-06 - val_mean_squared_error: 1.1667e-06\n","Epoch 314/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1897e-06 - mean_squared_error: 1.1432e-06 - val_loss: 1.2169e-06 - val_mean_squared_error: 1.1689e-06\n","Epoch 315/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1894e-06 - mean_squared_error: 1.1432e-06 - val_loss: 1.2197e-06 - val_mean_squared_error: 1.1718e-06\n","Epoch 316/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1892e-06 - mean_squared_error: 1.1432e-06 - val_loss: 1.2097e-06 - val_mean_squared_error: 1.1625e-06\n","Epoch 317/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1888e-06 - mean_squared_error: 1.1430e-06 - val_loss: 1.2082e-06 - val_mean_squared_error: 1.1613e-06\n","Epoch 318/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1884e-06 - mean_squared_error: 1.1429e-06 - val_loss: 1.2131e-06 - val_mean_squared_error: 1.1662e-06\n","Epoch 319/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1882e-06 - mean_squared_error: 1.1429e-06 - val_loss: 1.2078e-06 - val_mean_squared_error: 1.1614e-06\n","Epoch 320/350\n","225/225 [==============================] - 2s 8ms/step - loss: 1.1878e-06 - mean_squared_error: 1.1429e-06 - val_loss: 1.2305e-06 - val_mean_squared_error: 1.1834e-06\n","Epoch 321/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1879e-06 - mean_squared_error: 1.1430e-06 - val_loss: 1.2141e-06 - val_mean_squared_error: 1.1678e-06\n","Epoch 322/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1874e-06 - mean_squared_error: 1.1428e-06 - val_loss: 1.2162e-06 - val_mean_squared_error: 1.1701e-06\n","Epoch 323/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1867e-06 - mean_squared_error: 1.1424e-06 - val_loss: 1.2233e-06 - val_mean_squared_error: 1.1772e-06\n","Epoch 324/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1868e-06 - mean_squared_error: 1.1427e-06 - val_loss: 1.2200e-06 - val_mean_squared_error: 1.1743e-06\n","Epoch 325/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1863e-06 - mean_squared_error: 1.1424e-06 - val_loss: 1.2129e-06 - val_mean_squared_error: 1.1676e-06\n","Epoch 326/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1862e-06 - mean_squared_error: 1.1425e-06 - val_loss: 1.2068e-06 - val_mean_squared_error: 1.1620e-06\n","Epoch 327/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1858e-06 - mean_squared_error: 1.1424e-06 - val_loss: 1.2133e-06 - val_mean_squared_error: 1.1684e-06\n","Epoch 328/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1856e-06 - mean_squared_error: 1.1424e-06 - val_loss: 1.2099e-06 - val_mean_squared_error: 1.1654e-06\n","Epoch 329/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1854e-06 - mean_squared_error: 1.1424e-06 - val_loss: 1.2086e-06 - val_mean_squared_error: 1.1644e-06\n","Epoch 330/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1851e-06 - mean_squared_error: 1.1424e-06 - val_loss: 1.2037e-06 - val_mean_squared_error: 1.1599e-06\n","Epoch 331/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1845e-06 - mean_squared_error: 1.1420e-06 - val_loss: 1.2098e-06 - val_mean_squared_error: 1.1659e-06\n","Epoch 332/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1845e-06 - mean_squared_error: 1.1422e-06 - val_loss: 1.2139e-06 - val_mean_squared_error: 1.1700e-06\n","Epoch 333/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1839e-06 - mean_squared_error: 1.1417e-06 - val_loss: 1.2102e-06 - val_mean_squared_error: 1.1667e-06\n","Epoch 334/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1837e-06 - mean_squared_error: 1.1418e-06 - val_loss: 1.2116e-06 - val_mean_squared_error: 1.1683e-06\n","Epoch 335/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1834e-06 - mean_squared_error: 1.1417e-06 - val_loss: 1.2088e-06 - val_mean_squared_error: 1.1658e-06\n","Epoch 336/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1831e-06 - mean_squared_error: 1.1416e-06 - val_loss: 1.2267e-06 - val_mean_squared_error: 1.1832e-06\n","Epoch 337/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1834e-06 - mean_squared_error: 1.1421e-06 - val_loss: 1.2116e-06 - val_mean_squared_error: 1.1689e-06\n","Epoch 338/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1829e-06 - mean_squared_error: 1.1418e-06 - val_loss: 1.2131e-06 - val_mean_squared_error: 1.1705e-06\n","Epoch 339/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1824e-06 - mean_squared_error: 1.1415e-06 - val_loss: 1.2145e-06 - val_mean_squared_error: 1.1721e-06\n","Epoch 340/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1823e-06 - mean_squared_error: 1.1416e-06 - val_loss: 1.2140e-06 - val_mean_squared_error: 1.1718e-06\n","Epoch 341/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1822e-06 - mean_squared_error: 1.1417e-06 - val_loss: 1.2072e-06 - val_mean_squared_error: 1.1655e-06\n","Epoch 342/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1819e-06 - mean_squared_error: 1.1416e-06 - val_loss: 1.2053e-06 - val_mean_squared_error: 1.1638e-06\n","Epoch 343/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1815e-06 - mean_squared_error: 1.1414e-06 - val_loss: 1.2172e-06 - val_mean_squared_error: 1.1755e-06\n","Epoch 344/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1816e-06 - mean_squared_error: 1.1417e-06 - val_loss: 1.2125e-06 - val_mean_squared_error: 1.1712e-06\n","Epoch 345/350\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1810e-06 - mean_squared_error: 1.1413e-06 - val_loss: 1.2109e-06 - val_mean_squared_error: 1.1698e-06\n","Epoch 346/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1811e-06 - mean_squared_error: 1.1416e-06 - val_loss: 1.2108e-06 - val_mean_squared_error: 1.1699e-06\n","Epoch 347/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1806e-06 - mean_squared_error: 1.1413e-06 - val_loss: 1.2143e-06 - val_mean_squared_error: 1.1735e-06\n","Epoch 348/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1803e-06 - mean_squared_error: 1.1412e-06 - val_loss: 1.2105e-06 - val_mean_squared_error: 1.1700e-06\n","Epoch 349/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1801e-06 - mean_squared_error: 1.1412e-06 - val_loss: 1.2175e-06 - val_mean_squared_error: 1.1770e-06\n","Epoch 350/350\n","225/225 [==============================] - 1s 6ms/step - loss: 1.1799e-06 - mean_squared_error: 1.1412e-06 - val_loss: 1.2156e-06 - val_mean_squared_error: 1.1753e-06\n","./defensive_models/350_0903_DAE_GTSRB_II\n"]}],"source":["DAE = DenoisingAutoEncoder\n","PAE = PackedAutoEncoder\n","\n","shape = [32, 32, 3]\n","combination_I = [3, \"average\", 3]\n","combination_II = [3]\n","activation = \"sigmoid\"\n","reg_strength = 1e-9\n","epochs = 350\n","\n","# data = GTSRB()\n","\n","# AE_II = PAE(shape, combination_II, data, v_noise=0.025, activation=activation, n_pack=8)\n","# AE_II.train(data, \"_8_PAE_GTSRB_II\", alpha=.2, num_epochs=epochs)\n","\n","# AE_II = PAE(shape, combination_II, data, v_noise=0.025, activation=activation)\n","# AE_II.train(data, \"_PAE_GTSRB_II\", alpha=.2, num_epochs=epochs)    \n","\n","# AE_II = PAE(shape, combination_II, data, v_noise=0.025, activation=activation, n_pack=32)\n","# AE_II.train(data, \"O32_PAE_GTSRB_II\", alpha=.2, num_epochs=epochs)  \n","\n","AE_I = DAE(shape, combination_I, v_noise=0.1, activation=activation, reg_strength=reg_strength)\n","AE_I.train(data, \"350_0903_DAE_GTSRB_I\", num_epochs=epochs)\n","\n","AE_II = DAE(shape, combination_II, v_noise=0.1, activation=activation,  reg_strength=reg_strength)\n","AE_II.train(data, \"350_0903_DAE_GTSRB_II\", num_epochs=epochs)"]},{"cell_type":"markdown","metadata":{"id":"mzltzwx8he_N"},"source":["### MagNet - 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BZXZc5yXGbHR"},"outputs":[],"source":["ad_examples1 = np.array(ad_examples)\n","orig_labels1 = to_categorical(orig_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0vMxKPzjhhAy","executionInfo":{"status":"ok","timestamp":1663419318019,"user_tz":-540,"elapsed":1201,"user":{"displayName":"김채현코랩4","userId":"10582796771083497311"}},"outputId":"af8e4228-c36e-4183-e350-e1ec1a341dba"},"outputs":[{"output_type":"stream","name":"stdout","text":["150/150 [==============================] - 1s 3ms/step - loss: 0.0010 - accuracy: 0.1104\n","test set accuracy (original) :  11.041666567325592\n"]}],"source":["# 원본 이미지\n","classifier = Classifier(\"./models/gtsrb_classifier\")\n","loss, accuracy = classifier.model.evaluate(data.x_test, data.y_test)\n","\n","print('test set accuracy (original) : ', accuracy * 100)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ca5TN0fGhrgk","executionInfo":{"status":"ok","timestamp":1663419319651,"user_tz":-540,"elapsed":1634,"user":{"displayName":"김채현코랩4","userId":"10582796771083497311"}},"outputId":"0a13e3db-512b-4522-c38b-e157183a111a"},"outputs":[{"output_type":"stream","name":"stdout","text":["180/180 [==============================] - 1s 4ms/step - loss: 0.4804 - accuracy: 1.0000\n","test set accuracy (attacked) :  100.0\n"]}],"source":["# 공격받은 이미지\n","classifier = Classifier(\"./models/gtsrb_classifier\")\n","loss, accuracy = classifier.model.evaluate(ad_examples1, orig_labels1)\n","\n","print('test set accuracy (attacked) : ', accuracy * 100)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L6gv49XOhtCl"},"outputs":[],"source":["DAE_detector_I = AEDetector(\"./defensive_models/350_0903_DAE_GTSRB_I\", p=2)\n","DAE_detector_II = AEDetector(\"./defensive_models/350_0903_DAE_GTSRB_II\", p=1)\n","DAE_reformer = SimpleReformer(\"./defensive_models/350_0903_DAE_GTSRB_I\")\n","\n","\n","DAE_id_reformer = IdReformer()\n","DAE_classifier = Classifier(\"./models/gtsrb_classifier\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qRcUtasdhuRN"},"outputs":[],"source":["detector_JSD1 = DBDetector(DAE_id_reformer, DAE_reformer, DAE_classifier, T=10)\n","detector_JSD2 = DBDetector(DAE_id_reformer, DAE_reformer, DAE_classifier, T=40)\n","\n","\n","DAE_detector_dict = dict()\n","DAE_detector_dict[\"I\"] = DAE_detector_I\n","DAE_detector_dict[\"II\"] = DAE_detector_II\n","DAE_detector_dict[\"JSD1\"] = detector_JSD1\n","DAE_detector_dict[\"JSD2\"] = detector_JSD2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"36Yx1eqahvso"},"outputs":[],"source":["DAE_operator = Operator(data, DAE_classifier, DAE_detector_dict, DAE_reformer)\n","DAE_testAttack = AttackData(ad_examples1, orig_labels, \"GTSRB FSGM\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C3MbM1HDhwv0","executionInfo":{"status":"ok","timestamp":1663419360517,"user_tz":-540,"elapsed":34254,"user":{"displayName":"김채현코랩4","userId":"10582796771083497311"}},"outputId":"618a4e76-b9b3-489d-9d43-7acc5b7ef484"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==========================================================\n","Drop Rate: {'I': 0.001, 'II': 0.001, 'JSD1': 0.001, 'JSD2': 0.001}\n","Classification accuracy with all defense on: 0.08625\n","----------------------------------------------------------\n","Confidence: 0.0\n","{'I': 0, 'II': 0, 'JSD1': 0, 'JSD2': 7}\n","----------------------------------------------------------\n","Confidence: 10.0\n","{'I': 0, 'II': 0, 'JSD1': 0, 'JSD2': 7}\n","With detector & reformer:  1.0\n","With detector:  1.0\n","With reformer:  0.05287035421392427\n","No Defense:  1.0\n"]}],"source":["DAE_evaluator = Evaluator(DAE_operator, DAE_testAttack)\n","DAE_evaluator.plot_various_confidences(\"defense_performance\", drop_rate={\"I\": 0.001, \"II\": 0.001,\"JSD1\": 0.001,\"JSD2\": 0.001})"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gBi_uO4Dhx6D","executionInfo":{"status":"ok","timestamp":1663419362158,"user_tz":-540,"elapsed":1657,"user":{"displayName":"김채현코랩4","userId":"10582796771083497311"}},"outputId":"713c8f2c-0b73-4e8b-d5c9-67e5e3679f3b"},"outputs":[{"output_type":"stream","name":"stdout","text":["with reformer\n","0.05287035421392427\n"]}],"source":["print('with reformer')\n","\n","predict = np.array((DAE_reformer.model.predict(ad_examples1))).reshape(-1,32,32,3)\n","predicted1 = np.argmax(classifier.model.predict(predict),axis=1)\n","\n","print(np.mean(predicted1[:len(orig_labels)] == orig_labels[:len(orig_labels)]))\n","# print(.sum(predicted==orig_labels))#,predicted)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AmEhY0bFhzJd","executionInfo":{"status":"ok","timestamp":1663419362158,"user_tz":-540,"elapsed":8,"user":{"displayName":"김채현코랩4","userId":"10582796771083497311"}},"outputId":"4612d6ce-995d-4807-d831-6241bc18630f"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'numpy.ndarray'>\n","<class 'list'>\n"]}],"source":["print(type(data.x_train))\n","print(type(ad_examples))"]},{"cell_type":"markdown","metadata":{"id":"vIK9wb4vIIlv"},"source":["## Defense-GAN"]},{"cell_type":"markdown","metadata":{"id":"P9v5DhrcQTi_"},"source":["###  Defense Model 1 : DefenseGAN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1w18KhjvQaN-"},"outputs":[],"source":["import numpy as np\n","import os\n","import gzip\n","import urllib.request\n","\n","from keras.models import load_model\n","\n","def ordered_onehotencoding(labels):\n","    labels_ordered = []\n","    for i in range(len(labels)):\n","        if labels[i] == 3:\n","            labels_ordered.append(0)\n","        elif labels[i] == 7:\n","            labels_ordered.append(1)\n","        elif labels[i] == 9:\n","            labels_ordered.append(2)\n","        elif labels[i] == 10:\n","            labels_ordered.append(3)\n","        elif labels[i] == 11:\n","            labels_ordered.append(4)\n","        elif labels[i] == 12:\n","            labels_ordered.append(5)\n","        elif labels[i] == 13:\n","            labels_ordered.append(6)\n","        elif labels[i] == 17:\n","            labels_ordered.append(7)\n","        elif labels[i] == 18:\n","            labels_ordered.append(8)\n","        elif labels[i] == 25:\n","            labels_ordered.append(9)\n","        elif labels[i] == 35:\n","            labels_ordered.append(10)\n","        elif labels[i] == 38:\n","            labels_ordered.append(11)\n","    \n","    return np.array(labels_ordered)\n","\n","class GTSRB_defenseGAN:\n","    def __init__(self):\n","        imgs_path = \"Train\"\n","        data_list = []\n","        labels_list = []\n","\n","        result_class = [3,7, 9, 10, 11, 12, 13, 17, 18, 25, 35, 38]\n","\n","        for i in result_class:\n","            i_path = os.path.join(imgs_path, str(i)) # 3, 7, 9, 10, 11, 12,13, 17, 18, 25, 35, 38\n","            num = 0\n","            for img in os.listdir(i_path):\n","          \n","                im = Image.open(i_path +'/'+ img)\n","                im = im.resize((32,32))\n","                im = np.array(im)\n","\n","                data_list.append(im)\n","                labels_list.append(i)\n","                num = num + 1\n","                if num == 1000:\n","                    break;\n","\n","        data = np.array(data_list)\n","        labels = ordered_onehotencoding(labels_list)\n","\n","        labels = to_categorical(labels)\n","\n","        VALIDATION_SIZE = 5000\n","        \n","        data = (data.astype(np.float32) - 127.5) / 127.5 #모든 데이터 픽셀 값을 -1~1로 피팅 시킨다 (GAN 학습을 위함)\n","        \n","        self.x_train = np.array(data)\n","        self.y_train = labels\n","\n","    @staticmethod\n","    def print():\n","        return \"GTSRB_defenseGAN\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jFZPnqlWRPA7"},"outputs":[],"source":["data_train_GAN = GTSRB_defenseGAN()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a_zbYD_uRrNQ"},"outputs":[],"source":["print(data_train_GAN.x_train.shape)\n","print(data_train_GAN.y_train.shape)"]},{"cell_type":"markdown","metadata":{"id":"nZvOoqJqTtgW"},"source":["GAN 생성"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rOz8KOvWRqFq"},"outputs":[],"source":["import numpy as np \n","import matplotlib.pyplot as plt \n","\n","from keras.datasets import mnist\n","\n","from keras.models import Sequential, Model\n","\n","from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n","from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.layers.convolutional import UpSampling2D, Conv2D\n","\n","from tensorflow.keras.optimizers import Adam\n","\n","noise_data = np.random.normal(0, 1, (32, 100))\n","#generated_images = 0.5 * generator.predict(np.random.normal(0, 1, (32, 100))) + 0.5\n","\n","def show_images(generated_images, n=4, m=8, figsize=(9, 5)):\n","    f, axes = plt.subplots(n, m, figsize=figsize)\n","    #plt.subplots_adjust(top=1, bottom=0, hspace=0, wspace=0.05)\n","    for i in range(0, n):\n","        for j in range(0, m):\n","            ax = axes[i][j]\n","            ax.imshow(generated_images[i * m + j])\n","            ax.grid(False)\n","            ax.xaxis.set_ticks([])\n","            ax.yaxis.set_ticks([])\n","    plt.tight_layout()\n","    plt.savefig('20220729_basicgan.svg')\n","    plt.show()   \n","#show_images(0.5 * generator.predict(np.random.normal(0, 1, (32, 100))) + 0.5)\n","\n","\n","## create generator         \n","generator_ = Sequential([\n","    Dense(128 * 8 * 8, activation=\"relu\", input_shape=(100,)), \n","    Reshape((8, 8, 128)), \n","    \n","    BatchNormalization(momentum=0.8), # what is batch normalization?? \n","    UpSampling2D(), # what is upsampling?? \n","    Conv2D(128, kernel_size=3, padding=\"same\"),\n","    Activation(\"relu\"), \n","    \n","    BatchNormalization(momentum=0.8), \n","    UpSampling2D(), \n","    Conv2D(64, kernel_size=3, padding=\"same\"), \n","    Activation(\"relu\"), \n","    \n","    BatchNormalization(momentum=0.8), \n","    Conv2D(3, kernel_size=3, padding=\"same\"), \n","    Activation(\"tanh\"), \n","])\n","\n","noise_input = Input(shape=(100,), name=\"noise_input\")\n","generator_base = Model(noise_input, generator_(noise_input), name=\"generator\")\n","\n","generator_.summary()# summary가 매우 유용하군요. \n","\n","optimizer = Adam(0.0002, 0.5)\n","generator_base.compile(loss='binary_crossentropy', optimizer=optimizer)\n","\n","### create discriminator\n","discriminator_ = Sequential([\n","    Conv2D(32, kernel_size=3, strides=2, input_shape=(32, 32, 3), padding=\"same\"), \n","    LeakyReLU(alpha=0.2), \n","    Dropout(0.25), \n","    \n","    Conv2D(64, kernel_size=3, strides=2, padding=\"same\"), \n","    ZeroPadding2D(padding=((0,1),(0,1))), \n","    LeakyReLU(alpha=0.2), \n","    Dropout(0.25), \n","    BatchNormalization(momentum=0.8), \n","    \n","    Conv2D(128, kernel_size=3, strides=2, padding=\"same\"), \n","    LeakyReLU(alpha=0.2), \n","    Dropout(0.25), \n","    BatchNormalization(momentum=0.8), \n","    \n","    Conv2D(256, kernel_size=3, strides=1, padding=\"same\"), \n","    LeakyReLU(alpha=0.2), \n","    Dropout(0.25), \n","    Flatten(), \n","    Dense(1, activation='sigmoid'), \n","])\n","image_input = Input(shape=(32, 32, 3), name=\"image_input\")\n","\n","discriminator = Model(image_input, discriminator_(image_input), name=\"discriminator\")\n","discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","discriminator_.summary()\n","\n","### Combined Model\n","noise_input2 = Input(shape=(100,), name=\"noise_input2\")\n","\"\"\"\n","model과 sequential의 차이는?? \n","가설1: 레이어를 쌓는 것이 sequential 이라면, sequential을 쌓는 것이 model인가???\n","\n","1) 다음 모델의 경우는 랜덤으로 만든 이미지로부터 학습해서 새로운 이미지를 만들어내는 generator의 데이터를 \n","2) discriminator가 분류하는 형식으로 진행된다. \n","\"\"\"\n","combined = Model(noise_input2, discriminator(generator_base(noise_input2)))\n","combined.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7NWG3wxrSF4p"},"outputs":[],"source":["## training\n","\"\"\"\n","- 이 코드에서는 fit을 사용한 것이 아니라, train_on_batch를 사용했음. \n","- train_on_batch와의 차이점?을 구글에 검색해보니, 큰 차이가 없다고 하긴 하는데\n","    - train_on_batch의 경우, 넘겨 받은 데이터에 대해서 gradient vector를 계산해서 적용하고 끝내는 것이고(1epoch)\n","    - fit의 경우는 epoch과 batch_size를 한번에 모두 넘겨준다는 것 정도가 차이가 된다. \n","- GAN의 경우, discriminator의 학습시 마다 generator가 생성하는 데이터가 변화하게 된다. \n","    - 즉 처음부터 모든 데이터가 존재하고 이를 한번에 학습시키는 fit과는 다르게, 한번씩 업데이트를 할때마다 모델이 변화하므로, \n","    - train_on_batch를 사용하는 것이 매우 합당함.\n","\"\"\"\n","batch_size = 256\n","half_batch = batch_size // 2\n","\n","def train(epochs, print_step=10):\n","    history = []\n","    for epoch in range(epochs):\n","        # discriminator 트레이닝 단계\n","        #######################################################################3\n","        # 데이터 절반은 실제 이미지, 절반은 generator가 생성한 가짜 이미지\n","        # discriminator가 실제 이미지와 가짜 이미지를 구별하도록 discriminator를 트레이닝\n","        discriminator.trainable = True\n","        d_loss_real = discriminator.train_on_batch(data_train_GAN.x_train[np.random.randint(0, data_train_GAN.x_train.shape[0], half_batch)], \n","                                                   np.ones((half_batch, 1)))\n","        d_loss_fake = discriminator.train_on_batch(generator_base.predict(np.random.normal(0, 1, (half_batch, 100))), \n","                                                   np.zeros((half_batch, 1)))\n","        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","        # generator 트레이닝 단계\n","        #######################################################################3\n","        # 전부 generator가 생성한 가짜 이미지를 사용. \n","        # discriminator가 구별하지 못하도록 generator를 트레이닝\n","        \n","        \"\"\"\n","        generator를 트레이닝할 때는, 반드시 discriminator가 필요함. \n","        generator가 만든 image를 평가해야 하고, 그래야 feedback이 생겨서 generator가 학습됨. \n","        따라서, generator는 combined model을 통해 학습시키는데, 이때, discriminator도 함께 학습되면 안되기 때문에\n","        discriminator.trainable 을 False로 변경시켜 둔다. \n","        \"\"\"\n","        noise = np.random.normal(0, 1, (batch_size, 100))\n","        discriminator.trainable = False \n","        g_loss = combined.train_on_batch(noise, np.ones((batch_size, 1)))  #여기서는 왜 만들어준 fake img의 y 값을 1로 두는 걸까 ..\n","        # 기록\n","        record = (epoch, d_loss[0], 100 * d_loss[1], g_loss[0], 100 * g_loss[1])\n","        history.append(record)\n","        if epoch % print_step == 0:\n","            print(\"%5d [D loss: %.3f, acc.: %.2f%%] [G loss: %.3f, acc.: %.2f%%]\" % record)\n","            show_images(0.5 * generator_base.predict(noise_data) + 0.5)\n","    return history\n","#%%time, 은\n","history100 = train(20000, 500)\n","show_images(0.5 * generator_base.predict(noise_data) + 0.5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dXXJ-Wgyu_bT"},"outputs":[],"source":["# GAN 모델 저장\n","from keras.models import load_model\n","\n","generator_base.save('baseGAN_Generator_attacked0.02.h5')"]},{"cell_type":"markdown","metadata":{"id":"4BPL_wcJTvXO"},"source":["DefenseGAN 구현 - FGSM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h5JFZsEPTqeY"},"outputs":[],"source":["ad_example_data = ad_examples1 #/255로 이미 정규화가 된 이미지이다\n","orig_label_data = orig_labels1\n","\n","print(ad_example_data.shape)\n","print(orig_label_data.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LrHjDgblT_c1"},"outputs":[],"source":["def DefenseGAN(img_at,L,R):\n","    z_list = []\n","    img = img_at.reshape(32,32,3)\n","    img_st = (img - np.mean(img)) / np.std(img) \n","    img_var = tf.Variable(img_st,dtype = float)\n","    opt = tf.keras.optimizers.SGD(learning_rate=0.1,momentum = 0.7)\n","\n","    def compute():\n","        z_hats_recs = generator_base(z_var)\n","        z_hats_recs = tf.reshape(z_hats_recs, [32,32,3])\n","        num_dim = len(z_hats_recs.get_shape())\n","        axes = range(1, num_dim)\n","        image_rec_loss = tf.reduce_mean(tf.square(z_hats_recs - img_var),axis=axes)\n","        rec_loss = tf.reduce_sum(image_rec_loss)\n","        return rec_loss\n","\n","    for r in range(R):\n","        z = np.random.normal(0, 1, (1, 100))\n","        z_var = tf.Variable(z,dtype = float)\n","    \n","        for l in range(L):\n","            opt.minimize(compute,[z_var])\n","        z_list.append(z_var)\n","\n","    def compute_10(z):\n","        #generator_base.trainable = False #아직 더해야하는지 뺴야하는지 판단 x\n","        z_hats_recs = generator_base(z)\n","        z_hats_recs = tf.reshape(z_hats_recs, [32,32,3])\n","        num_dim = len(z_hats_recs.get_shape())\n","        axes = range(1, num_dim)\n","        image_rec_loss = tf.reduce_mean(tf.square(z_hats_recs - img_var),axis=axes)\n","        rec_loss = tf.reduce_sum(image_rec_loss)\n","        return rec_loss\n","    \n","\n","    loss_list = []\n","    \n","    for i in range(len(z_list)):\n","        loss = compute_10(z_list[i])\n","        loss_list.append(loss)\n","    \n","    index_min = np.argmin(loss_list)\n","\n","    z_min = np.array(z_list[index_min])\n","\n","    generated_images = 0.5 * generator_base.predict(z_min)+ 0.5\n","\n","    generated_images = generated_images.reshape(32,32,3)\n","\n","    return generated_images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9ks2QRZbUKO_"},"outputs":[],"source":["## predict_output에 한개씩 넣는 것부터 구현해야한다. (전체가 들어가는 것만 정상 작동함)\n","\n","def test(classifier, ad_example_data, orig_label_data):\n","\n","    # 정확도 카운터\n","    correct = 0\n","    defense_correct = 0\n","    df_examples = []\n","    # 테스트 셋의 모든 예제에 대해 루프를 돕니다\n","\n","    loss, accuracy = classifier.evaluate(ad_examples1, orig_labels1)\n","\n","    print('방어 전 모델 정확도 : ',accuracy * 100)\n","\n","    for i in range(len(ad_example_data)):\n","        data = ad_example_data[i].reshape(-1,32,32,3)\n","        target = orig_label_data[i]\n","        \n","        data_plot = data.reshape(32,32,3)\n","        print('원본 label : ',np.argmax(target))\n","        plt.imshow(data_plot)\n","        plt.show();\n","\n","        generated_img = DefenseGAN(data.reshape(32,32,3),200,10).reshape(-1,32,32,3)\n","\n","        generated_img_plot = generated_img.reshape(32,32,3)\n","\n","\n","        defense_output = classifier.predict(generated_img.reshape(1,32,32,3))\n","\n","        defense_pred= int(np.argmax(defense_output))\n","\n","        print('방어 라벨 : ',defense_pred)\n","        plt.imshow(generated_img_plot)\n","        plt.show();\n","\n","        if defense_pred == int(np.argmax(target)):\n","            defense_correct += 1\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","        else:\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","\n","        print('Working...!')\n","\n","\n","    defense_acc = defense_correct / float(len(ad_example_data))\n","    print(\"Defense Accuracy = {} / {} = {}\".format(defense_correct, len(ad_example_data), defense_acc))\n","    # 정확도와 적대적 예제를 리턴합니다\n","    return defense_acc, df_examples"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UmgqhBaWaqXz"},"outputs":[],"source":["accuracies_df = []\n","examples_df = []\n","\n","acc_df, ex_df = test(model, ad_example_data[:100], orig_label_data[:100])\n","\n","accuracies_df.append(acc_df)\n","examples_df.append(ex_df)"]},{"cell_type":"markdown","metadata":{"id":"2TtBNBJxn2Db"},"source":["### DefenseGAN 구현 - BIM\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fhZ-PyFGn3lz"},"outputs":[],"source":["ad_examples_BIM = np.array(ad_examples) # 이미 정규화되어서 나온 값으로 추가적인 /255 정규화 필요 없음\n","orig_labels_BIM = to_categorical(orig_labels)\n","\n","print(ad_examples_BIM.shape)\n","print(orig_labels_BIM.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lZngn6VduEUE"},"outputs":[],"source":["# GAN 모델 저장\n","from keras.models import load_model\n","\n","generator_base = load_model('baseGAN_Generator_attacked0.02.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P4m8Jituudng"},"outputs":[],"source":["plt.imshow(generator_base.predict(np.random.normal(0, 1, (1, 100))).reshape(32,32,3))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Zppe2W6n3n9"},"outputs":[],"source":["def DefenseGAN(img_at,L,R):\n","    z_list = []\n","    img = img_at.reshape(32,32,3)\n","    img_st = (img - np.mean(img)) / np.std(img) \n","    img_var = tf.Variable(img_st,dtype = float)\n","    opt = tf.keras.optimizers.SGD(learning_rate=0.1,momentum = 0.7)\n","\n","    def compute():\n","        z_hats_recs = generator_base(z_var)\n","        z_hats_recs = tf.reshape(z_hats_recs, [32,32,3])\n","        num_dim = len(z_hats_recs.get_shape())\n","        axes = range(1, num_dim)\n","        image_rec_loss = tf.reduce_mean(tf.square(z_hats_recs - img_var),axis=axes)\n","        rec_loss = tf.reduce_sum(image_rec_loss)\n","        return rec_loss\n","\n","    for r in range(R):\n","        z = np.random.normal(0, 1, (1, 100))\n","        z_var = tf.Variable(z,dtype = float)\n","    \n","        for l in range(L):\n","            opt.minimize(compute,[z_var])\n","        z_list.append(z_var)\n","\n","    def compute_10(z):\n","        #generator_base.trainable = False #아직 더해야하는지 뺴야하는지 판단 x\n","        z_hats_recs = generator_base(z)\n","        z_hats_recs = tf.reshape(z_hats_recs, [32,32,3])\n","        num_dim = len(z_hats_recs.get_shape())\n","        axes = range(1, num_dim)\n","        image_rec_loss = tf.reduce_mean(tf.square(z_hats_recs - img_var),axis=axes)\n","        rec_loss = tf.reduce_sum(image_rec_loss)\n","        return rec_loss\n","    \n","\n","    loss_list = []\n","    \n","    for i in range(len(z_list)):\n","        loss = compute_10(z_list[i])\n","        loss_list.append(loss)\n","    \n","    index_min = np.argmin(loss_list)\n","\n","    z_min = np.array(z_list[index_min])\n","\n","    generated_images = 0.5 * generator_base.predict(z_min)+ 0.5\n","\n","    generated_images = generated_images.reshape(32,32,3)\n","\n","    return generated_images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HsGI-NY4n3qe"},"outputs":[],"source":["## predict_output에 한개씩 넣는 것부터 구현해야한다. (전체가 들어가는 것만 정상 작동함)\n","\n","def test(classifier, ad_example_data, orig_label_data):\n","\n","    # 정확도 카운터\n","    correct = 0\n","    defense_correct = 0\n","    df_examples = []\n","    # 테스트 셋의 모든 예제에 대해 루프를 돕니다\n","\n","    loss, accuracy = classifier.evaluate(ad_example_data, orig_label_data)\n","\n","    print('방어 전 모델 정확도 : ',accuracy * 100)\n","\n","    for i in range(len(ad_example_data)):\n","        data = ad_example_data[i].reshape(-1,32,32,3)\n","        target = orig_label_data[i]\n","        \n","        data_plot = data.reshape(32,32,3)\n","        print('원본 label : ',np.argmax(target))\n","        plt.imshow(data_plot)\n","        plt.show();\n","\n","        generated_img = DefenseGAN(data.reshape(32,32,3),200,10).reshape(-1,32,32,3)\n","\n","        generated_img_plot = generated_img.reshape(32,32,3)\n","\n","\n","        defense_output = classifier.predict(generated_img.reshape(1,32,32,3))\n","\n","        defense_pred= int(np.argmax(defense_output))\n","\n","        print('방어 라벨 : ',defense_pred)\n","        plt.imshow(generated_img_plot)\n","        plt.show();\n","\n","        if defense_pred == int(np.argmax(target)):\n","            defense_correct += 1\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","        else:\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","\n","        print('Working...!')\n","\n","\n","    defense_acc = defense_correct / float(len(ad_example_data))\n","    print(\"Defense Accuracy = {} / {} = {}\".format(defense_correct, len(ad_example_data), defense_acc))\n","    # 정확도와 적대적 예제를 리턴합니다\n","    return defense_acc, df_examples"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qnYmHP5Bn3tC"},"outputs":[],"source":["accuracies_df = []\n","examples_df = []\n","\n","acc_df, ex_df = test(model, ad_examples_BIM[:100], orig_labels_BIM[:100])\n","\n","accuracies_df.append(acc_df)\n","examples_df.append(ex_df)"]},{"cell_type":"markdown","metadata":{"id":"63SBpYd-IL2u"},"source":["## PCA"]},{"cell_type":"markdown","metadata":{"id":"1ywsHS3sfPxD"},"source":["### Defense 2 : PCA (Components = 5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KuoOeVKxsyvD"},"outputs":[],"source":["ad_example_data = ad_examples1 #/255로 이미 정규화가 된 이미지이다\n","orig_label_data = orig_labels1\n","\n","print(ad_example_data.shape)\n","print(orig_label_data.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rAB3avuSbB3q"},"outputs":[],"source":["from sklearn.decomposition import PCA\n","\n","# data shape이 32,32,3이어야한다.\n","def defense_PCA(data,component):\n","    #r,g,b를 각각 나눠준다\n","    data = data.reshape(32,32,3)\n","    r = data[:,:,0]\n","    g = data[:,:,1]\n","    b = data[:,:,2]\n","\n","    pca_r = PCA(n_components=component)\n","    pca_r_trans = pca_r.fit_transform(r)\n","\n","    pca_g = PCA(n_components=component)\n","    pca_g_trans = pca_g.fit_transform(g)\n","\n","    pca_b = PCA(n_components=component)\n","    pca_b_trans = pca_b.fit_transform(b)\n","\n","    pca_r_org = pca_r.inverse_transform(pca_r_trans)\n","    pca_g_org = pca_g.inverse_transform(pca_g_trans)\n","    pca_b_org = pca_b.inverse_transform(pca_b_trans)\n","\n","    img_compressed = np.stack((pca_r_org, pca_g_org, pca_b_org),axis = 2)\n","\n","    return img_compressed.reshape((-1,32,32,3))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j2uWTxjIf-a-"},"outputs":[],"source":["## predict_output에 한개씩 넣는 것부터 구현해야한다. (전체가 들어가는 것만 정상 작동함)\n","\n","def test(classifier, ad_example_data, orig_label_data):\n","\n","    # 정확도 카운터\n","    correct = 0\n","    defense_correct = 0\n","    df_examples = []\n","    # 테스트 셋의 모든 예제에 대해 루프를 돕니다\n","\n","    loss, accuracy = classifier.evaluate(ad_examples1, orig_labels1)\n","\n","    print('방어 전 모델 정확도 : ',accuracy * 100)\n","\n","    for i in range(len(ad_example_data)):\n","        data = ad_example_data[i].reshape(-1,32,32,3)\n","        target = orig_label_data[i]\n","        \n","        data_plot = data.reshape(32,32,3)\n","        print('원본 label : ',np.argmax(target))\n","        plt.imshow(data_plot)\n","        plt.show();\n","\n","        generated_img = defense_PCA(data,5)\n","\n","        generated_img_plot = generated_img.reshape(32,32,3)\n","\n","        defense_output = classifier.predict(generated_img.reshape(1,32,32,3))\n","\n","        defense_pred= int(np.argmax(defense_output))\n","\n","        print('방어 라벨 : ',defense_pred)\n","        plt.imshow(generated_img_plot)\n","        plt.show();\n","\n","        if defense_pred == int(np.argmax(target)):\n","            defense_correct += 1\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","        else:\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","\n","        print('Working...!')\n","\n","\n","    defense_acc = defense_correct / float(len(ad_example_data))\n","    print(\"Defense Accuracy = {} / {} = {}\".format(defense_correct, len(ad_example_data), defense_acc))\n","    # 정확도와 적대적 예제를 리턴합니다\n","    return defense_acc, df_examples"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TGm6ObXDhR2V"},"outputs":[],"source":["accuracies_df = []\n","examples_df = []\n","\n","acc_df, ex_df = test(model, ad_example_data, orig_label_data)\n","\n","accuracies_df.append(acc_df)\n","examples_df.append(ex_df)"]},{"cell_type":"markdown","metadata":{"id":"9Y_-9xiJiAeC"},"source":["### Defense 2 : PCA (Components = 10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZOiE-bIgsz6w"},"outputs":[],"source":["ad_example_data = ad_examples1 #/255로 이미 정규화가 된 이미지이다\n","orig_label_data = orig_labels1\n","\n","print(ad_example_data.shape)\n","print(orig_label_data.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EyLQ-kGQwqEZ"},"outputs":[],"source":["from sklearn.decomposition import PCA\n","\n","# data shape이 32,32,3이어야한다.\n","def defense_PCA(data,component):\n","    #r,g,b를 각각 나눠준다\n","    data = data.reshape(32,32,3)\n","    r = data[:,:,0]\n","    g = data[:,:,1]\n","    b = data[:,:,2]\n","\n","    pca_r = PCA(n_components=component)\n","    pca_r_trans = pca_r.fit_transform(r)\n","\n","    pca_g = PCA(n_components=component)\n","    pca_g_trans = pca_g.fit_transform(g)\n","\n","    pca_b = PCA(n_components=component)\n","    pca_b_trans = pca_b.fit_transform(b)\n","\n","    pca_r_org = pca_r.inverse_transform(pca_r_trans)\n","    pca_g_org = pca_g.inverse_transform(pca_g_trans)\n","    pca_b_org = pca_b.inverse_transform(pca_b_trans)\n","\n","    img_compressed = np.stack((pca_r_org, pca_g_org, pca_b_org),axis = 2)\n","\n","    return img_compressed.reshape((-1,32,32,3))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lWXuP7V4iPO0"},"outputs":[],"source":["## predict_output에 한개씩 넣는 것부터 구현해야한다. (전체가 들어가는 것만 정상 작동함)\n","\n","def test(classifier, ad_example_data, orig_label_data):\n","\n","    # 정확도 카운터\n","    correct = 0\n","    defense_correct = 0\n","    df_examples = []\n","    # 테스트 셋의 모든 예제에 대해 루프를 돕니다\n","\n","    loss, accuracy = classifier.evaluate(ad_examples1, orig_labels1)\n","\n","    print('방어 전 모델 정확도 : ',accuracy * 100)\n","\n","    for i in range(len(ad_example_data)):\n","        data = ad_example_data[i].reshape(-1,32,32,3)\n","        target = orig_label_data[i]\n","        \n","        data_plot = data.reshape(32,32,3)\n","        print('원본 label : ',np.argmax(target))\n","        plt.imshow(data_plot)\n","        plt.show();\n","\n","        generated_img = defense_PCA(data,10)\n","\n","        generated_img_plot = generated_img.reshape(32,32,3)\n","\n","        defense_output = classifier.predict(generated_img.reshape(1,32,32,3))\n","\n","        defense_pred= int(np.argmax(defense_output))\n","\n","        print('방어 라벨 : ',defense_pred)\n","        plt.imshow(generated_img_plot)\n","        plt.show();\n","\n","        if defense_pred == int(np.argmax(target)):\n","            defense_correct += 1\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","        else:\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","\n","        print('Working...!')\n","\n","\n","    defense_acc = defense_correct / float(len(ad_example_data))\n","    print(\"Defense Accuracy = {} / {} = {}\".format(defense_correct, len(ad_example_data), defense_acc))\n","    # 정확도와 적대적 예제를 리턴합니다\n","    return defense_acc, df_examples"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HP7_KoXqiWhf"},"outputs":[],"source":["accuracies_df = []\n","examples_df = []\n","\n","acc_df, ex_df = test(model, ad_example_data, orig_label_data)\n","\n","accuracies_df.append(acc_df)\n","examples_df.append(ex_df)"]},{"cell_type":"markdown","metadata":{"id":"hGoEmuWF4S1T"},"source":["### Defense 2 : PCA (Components = 5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sP6AyMGH4bkk"},"outputs":[],"source":["ad_examples_BIM = np.array(ad_examples) # 이미 정규화되어서 나온 값으로 추가적인 /255 정규화 필요 없음\n","orig_labels_BIM = to_categorical(orig_labels)\n","\n","print(ad_examples_BIM.shape)\n","print(orig_labels_BIM.shape)\n","\n","from sklearn.decomposition import PCA\n","\n","# data shape이 32,32,3이어야한다.\n","def defense_PCA(data,component):\n","    #r,g,b를 각각 나눠준다\n","    data = data.reshape(32,32,3)\n","    r = data[:,:,0]\n","    g = data[:,:,1]\n","    b = data[:,:,2]\n","\n","    pca_r = PCA(n_components=component)\n","    pca_r_trans = pca_r.fit_transform(r)\n","\n","    pca_g = PCA(n_components=component)\n","    pca_g_trans = pca_g.fit_transform(g)\n","\n","    pca_b = PCA(n_components=component)\n","    pca_b_trans = pca_b.fit_transform(b)\n","\n","    pca_r_org = pca_r.inverse_transform(pca_r_trans)\n","    pca_g_org = pca_g.inverse_transform(pca_g_trans)\n","    pca_b_org = pca_b.inverse_transform(pca_b_trans)\n","\n","    img_compressed = np.stack((pca_r_org, pca_g_org, pca_b_org),axis = 2)\n","\n","    return img_compressed.reshape((-1,32,32,3))\n","\n","## predict_output에 한개씩 넣는 것부터 구현해야한다. (전체가 들어가는 것만 정상 작동함)\n","\n","def test(classifier, ad_example_data, orig_label_data):\n","\n","    # 정확도 카운터\n","    correct = 0\n","    defense_correct = 0\n","    df_examples = []\n","    # 테스트 셋의 모든 예제에 대해 루프를 돕니다\n","\n","    loss, accuracy = classifier.evaluate(ad_examples_BIM, orig_labels_BIM)\n","\n","    print('방어 전 모델 정확도 : ',accuracy * 100)\n","\n","    for i in range(len(ad_example_data)):\n","        data = ad_example_data[i].reshape(-1,32,32,3)\n","        target = orig_label_data[i]\n","        \n","        data_plot = data.reshape(32,32,3)\n","        print('원본 label : ',np.argmax(target))\n","        plt.imshow(data_plot)\n","        plt.show();\n","\n","        generated_img = defense_PCA(data,5)\n","\n","        generated_img_plot = generated_img.reshape(32,32,3)\n","\n","        defense_output = classifier.predict(generated_img.reshape(1,32,32,3))\n","\n","        defense_pred= int(np.argmax(defense_output))\n","\n","        print('방어 라벨 : ',defense_pred)\n","        plt.imshow(generated_img_plot)\n","        plt.show();\n","\n","        if defense_pred == int(np.argmax(target)):\n","            defense_correct += 1\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","        else:\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","\n","        print('Working...!')\n","\n","\n","    defense_acc = defense_correct / float(len(ad_example_data))\n","    print(\"Defense Accuracy = {} / {} = {}\".format(defense_correct, len(ad_example_data), defense_acc))\n","    # 정확도와 적대적 예제를 리턴합니다\n","    return defense_acc, df_examples"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pJv8QiS94bm8"},"outputs":[],"source":["accuracies_df = []\n","examples_df = []\n","\n","acc_df, ex_df = test(model, ad_examples_BIM[:1000], orig_labels_BIM[:1000])\n","\n","accuracies_df.append(acc_df)\n","examples_df.append(ex_df)"]},{"cell_type":"markdown","metadata":{"id":"7rWZ6_Kf48hG"},"source":["### Defense 2 : PCA (Components = 10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fpPzHByO4bpO"},"outputs":[],"source":["ad_examples_BIM = np.array(ad_examples) # 이미 정규화되어서 나온 값으로 추가적인 /255 정규화 필요 없음\n","orig_labels_BIM = to_categorical(orig_labels)\n","\n","print(ad_examples_BIM.shape)\n","print(orig_labels_BIM.shape)\n","\n","from sklearn.decomposition import PCA\n","\n","# data shape이 32,32,3이어야한다.\n","def defense_PCA(data,component):\n","    #r,g,b를 각각 나눠준다\n","    data = data.reshape(32,32,3)\n","    r = data[:,:,0]\n","    g = data[:,:,1]\n","    b = data[:,:,2]\n","\n","    pca_r = PCA(n_components=component)\n","    pca_r_trans = pca_r.fit_transform(r)\n","\n","    pca_g = PCA(n_components=component)\n","    pca_g_trans = pca_g.fit_transform(g)\n","\n","    pca_b = PCA(n_components=component)\n","    pca_b_trans = pca_b.fit_transform(b)\n","\n","    pca_r_org = pca_r.inverse_transform(pca_r_trans)\n","    pca_g_org = pca_g.inverse_transform(pca_g_trans)\n","    pca_b_org = pca_b.inverse_transform(pca_b_trans)\n","\n","    img_compressed = np.stack((pca_r_org, pca_g_org, pca_b_org),axis = 2)\n","\n","    return img_compressed.reshape((-1,32,32,3))\n","\n","## predict_output에 한개씩 넣는 것부터 구현해야한다. (전체가 들어가는 것만 정상 작동함)\n","\n","def test(classifier, ad_example_data, orig_label_data):\n","\n","    # 정확도 카운터\n","    correct = 0\n","    defense_correct = 0\n","    df_examples = []\n","    # 테스트 셋의 모든 예제에 대해 루프를 돕니다\n","\n","    loss, accuracy = classifier.evaluate(ad_examples_BIM, orig_labels_BIM)\n","\n","    print('방어 전 모델 정확도 : ',accuracy * 100)\n","\n","    for i in range(len(ad_example_data)):\n","        data = ad_example_data[i].reshape(-1,32,32,3)\n","        target = orig_label_data[i]\n","        \n","        data_plot = data.reshape(32,32,3)\n","        print('원본 label : ',np.argmax(target))\n","        plt.imshow(data_plot)\n","        plt.show();\n","\n","        generated_img = defense_PCA(data,10)\n","\n","        generated_img_plot = generated_img.reshape(32,32,3)\n","\n","        defense_output = classifier.predict(generated_img.reshape(1,32,32,3))\n","\n","        defense_pred= int(np.argmax(defense_output))\n","\n","        print('방어 라벨 : ',defense_pred)\n","        plt.imshow(generated_img_plot)\n","        plt.show();\n","\n","        if defense_pred == int(np.argmax(target)):\n","            defense_correct += 1\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","        else:\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","\n","        print('Working...!')\n","\n","\n","    defense_acc = defense_correct / float(len(ad_example_data))\n","    print(\"Defense Accuracy = {} / {} = {}\".format(defense_correct, len(ad_example_data), defense_acc))\n","    # 정확도와 적대적 예제를 리턴합니다\n","    return defense_acc, df_examples"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aCH5IdKe4br4"},"outputs":[],"source":["accuracies_df = []\n","examples_df = []\n","\n","acc_df, ex_df = test(model, ad_examples_BIM[:1000], orig_labels_BIM[:1000])\n","\n","accuracies_df.append(acc_df)\n","examples_df.append(ex_df)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["H5r08xIXerXB","FhnfS-0MH1sa","XWfrLWt3EtSN","6DfDZcE5_GGB","Lb-doZmmIFqj","-Yc-yrW7ktMW","bt4nIJ5xg73T","EhncucofhEvv","4e-GBUowhNUQ","ukxjkHWahV8B","mzltzwx8he_N","vIK9wb4vIIlv","P9v5DhrcQTi_","2TtBNBJxn2Db","63SBpYd-IL2u","1ywsHS3sfPxD","9Y_-9xiJiAeC","hGoEmuWF4S1T","7rWZ6_Kf48hG"],"toc_visible":true,"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}