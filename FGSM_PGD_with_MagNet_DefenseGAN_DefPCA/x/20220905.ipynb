{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"WgKss5hJBb5B","executionInfo":{"status":"ok","timestamp":1663303181411,"user_tz":-540,"elapsed":3331,"user":{"displayName":"이진규","userId":"11520813773494359482"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","import os\n","import pathlib\n","\n","import cv2 #영상처리에 사용하는 오픈소스 라이브러리, 컴퓨터가 사람 눈처럼 인식할 수 있게 처리\n","from PIL import Image # 파이썬 이미지 처리 pillow 라이브러리\n","from tensorflow.keras.preprocessing import image\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator #imagedatagenerater는 이미지를 학습시킬 때 학습 데이터의 양이 적을 경우 학습데이터를 조금씩 변형 시켜서 학습데이터의 양을 늘리는 방식중 하나\n","from tensorflow.keras.preprocessing.image import img_to_array, array_to_img, load_img\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n","from tensorflow.keras.models import Sequential\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","import matplotlib.pyplot as plt\n","\n","from tqdm.auto import tqdm\n","\n","#난수 랜덤성 고정\n","np.random.seed(42)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25476,"status":"ok","timestamp":1663303206876,"user":{"displayName":"이진규","userId":"11520813773494359482"},"user_tz":-540},"id":"Qn7HC1qiBnNE","outputId":"d25bc450-da2e-4264-9b05-1e8526ecbd84"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2181,"status":"ok","timestamp":1663303215959,"user":{"displayName":"이진규","userId":"11520813773494359482"},"user_tz":-540},"id":"VwTVXhm7BoaE","outputId":"18f48e6b-7d7a-465c-f88d-5cec68533b23"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1WKEjdIyqtzI-NV5o0O_ixsHslngaSiQX/[한이음] 적대적 AI 공격에 대한 인공지능 보안기술 연구/3. 소스코드/GTSRB\n"]}],"source":["cd drive/MyDrive/[한이음] 적대적 AI 공격에 대한 인공지능 보안기술 연구/3. 소스코드/GTSRB"]},{"cell_type":"markdown","metadata":{"id":"JjBcm524Fams"},"source":["Train Data 불러오기"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"kZnmTWHIBo_E","executionInfo":{"status":"ok","timestamp":1663303215959,"user_tz":-540,"elapsed":4,"user":{"displayName":"이진규","userId":"11520813773494359482"}}},"outputs":[],"source":["import numpy as np\n","import os\n","import gzip\n","import urllib.request\n","\n","from keras.models import load_model\n","\n","def ordered_onehotencoding(labels):\n","    labels_ordered = []\n","    for i in range(len(labels)):\n","        if labels[i] == 3:\n","            labels_ordered.append(0)\n","        elif labels[i] == 7:\n","            labels_ordered.append(1)\n","        elif labels[i] == 9:\n","            labels_ordered.append(2)\n","        elif labels[i] == 10:\n","            labels_ordered.append(3)\n","        elif labels[i] == 11:\n","            labels_ordered.append(4)\n","        elif labels[i] == 12:\n","            labels_ordered.append(5)\n","        elif labels[i] == 13:\n","            labels_ordered.append(6)\n","        elif labels[i] == 17:\n","            labels_ordered.append(7)\n","        elif labels[i] == 18:\n","            labels_ordered.append(8)\n","        elif labels[i] == 25:\n","            labels_ordered.append(9)\n","        elif labels[i] == 35:\n","            labels_ordered.append(10)\n","        elif labels[i] == 38:\n","            labels_ordered.append(11)\n","    \n","    return np.array(labels_ordered)\n","\n","class GTSRB:\n","    def __init__(self):\n","        imgs_path = \"Train\"\n","        data_list = []\n","        labels_list = []\n","\n","        result_class = [3,7, 9, 10, 11, 12, 13, 17, 18, 25, 35, 38]\n","\n","        for i in result_class:\n","            i_path = os.path.join(imgs_path, str(i)) # 3, 7, 9, 10, 11, 12,13, 17, 18, 25, 35, 38\n","            num = 0\n","            for img in os.listdir(i_path):\n","          \n","                im = Image.open(i_path +'/'+ img)\n","                im = im.resize((32,32))\n","                im = np.array(im)\n","\n","                data_list.append(im)\n","                labels_list.append(i)\n","                num = num + 1\n","                if num == 1000:\n","                    break;\n","\n","        data = np.array(data_list)\n","        labels = ordered_onehotencoding(labels_list)\n","\n","        labels = to_categorical(labels)\n","\n","        VALIDATION_SIZE = 5000\n","        \n","        self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(np.array(data), labels, test_size=0.4)    \n","\n","    @staticmethod\n","    def print():\n","        return \"GTSRB\""]},{"cell_type":"code","execution_count":5,"metadata":{"id":"lWo9BzndEm67","executionInfo":{"status":"ok","timestamp":1663303535579,"user_tz":-540,"elapsed":319623,"user":{"displayName":"이진규","userId":"11520813773494359482"}}},"outputs":[],"source":["data = GTSRB()"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":38,"status":"ok","timestamp":1663303535581,"user":{"displayName":"이진규","userId":"11520813773494359482"},"user_tz":-540},"id":"Zc5Q_EXiEppb","outputId":"84f8f109-fe6c-4bc9-e60f-341c5fcaba71"},"outputs":[{"output_type":"stream","name":"stdout","text":["(7200, 32, 32, 3)\n","(4800, 32, 32, 3)\n","(7200, 12)\n","(4800, 12)\n"]}],"source":["print(data.x_train.shape)\n","print(data.x_test.shape)\n","print(data.y_train.shape)\n","print(data.y_test.shape)"]},{"cell_type":"markdown","metadata":{"id":"P2uSEM66FdVa"},"source":["Test Data 불러오기"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"_shX58HHFisj","executionInfo":{"status":"ok","timestamp":1663303537314,"user_tz":-540,"elapsed":1741,"user":{"displayName":"이진규","userId":"11520813773494359482"}}},"outputs":[],"source":["metainfo = pd.read_csv(\"Meta.csv\")\n","traininfo = pd.read_csv(\"Train.csv\")\n","testinfo = pd.read_csv(\"Test.csv\")"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"z9HPAPg2FZ9L","executionInfo":{"status":"ok","timestamp":1663303537316,"user_tz":-540,"elapsed":7,"user":{"displayName":"이진규","userId":"11520813773494359482"}}},"outputs":[],"source":["import natsort\n","\n","class GTSRB_test:\n","    def __init__(self):\n","        imgs_path = \"Test\"\n","        data_list = []\n","        labels_list = []\n","        \n","        for img in natsort.natsorted(os.listdir(imgs_path)):\n","            im = Image.open(imgs_path +'/'+ img)\n","            im = im.resize((32,32))\n","            im = np.array(im)\n","            data_list.append(im)\n","        data_test = np.array(data_list)\n","        \n","        for i in range(len(testinfo.ClassId)):\n","            labels_list.append(testinfo.ClassId[i])\n","        \n","        labels_test = np.array(labels_list)\n","\n","        labels_test_index = []\n","        for i in range(len(labels_test)):\n","            if (labels_test[i] == 3) | (labels_test[i] == 7) | (labels_test[i] == 9) | (labels_test[i] == 10) | (labels_test[i] == 11) | (labels_test[i] == 12) | (labels_test[i] == 13) | (labels_test[i] == 17) | (labels_test[i] == 18) | (labels_test[i] == 25) | (labels_test[i] == 35) | (labels_test[i] == 38):\n","                labels_test_index.append(i)\n","\n","        test_data = []\n","        test_label = []\n","        for i in labels_test_index:\n","            test_data.append(data_test[i])\n","            test_label.append(labels_test[i])\n","\n","        data_test = np.array(test_data)\n","\n","        labels_test =ordered_onehotencoding(test_label)\n","\n","        labels_test = to_categorical(labels_test)\n","        \n","        self.x_test = data_test\n","        self.y_test = labels_test    \n","\n","    @staticmethod\n","    def print():\n","        return \"GTSRB_test\""]},{"cell_type":"code","execution_count":9,"metadata":{"id":"CcWfJaa6Ft7z","executionInfo":{"status":"ok","timestamp":1663303694693,"user_tz":-540,"elapsed":157382,"user":{"displayName":"이진규","userId":"11520813773494359482"}}},"outputs":[],"source":["data_test = GTSRB_test()"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1663303694694,"user":{"displayName":"이진규","userId":"11520813773494359482"},"user_tz":-540},"id":"VE9NTZrAFv7e","outputId":"3b377a5c-9dc0-453f-d922-9c53344ad321"},"outputs":[{"output_type":"stream","name":"stdout","text":["(6180, 32, 32, 3)\n","(6180, 12)\n"]}],"source":["print(data_test.x_test.shape)\n","print(data_test.y_test.shape)"]},{"cell_type":"markdown","metadata":{"id":"XWfrLWt3EtSN"},"source":["### 분류기 : CNN"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"TqQDIy-WEwQz","executionInfo":{"status":"ok","timestamp":1663303863502,"user_tz":-540,"elapsed":275,"user":{"displayName":"이진규","userId":"11520813773494359482"}}},"outputs":[],"source":["data.x_train, data.y_train, data.x_test, data.y_test =data.x_train/255, data.y_train/255, data.x_test/255, data.y_test/255"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":55367,"status":"ok","timestamp":1663303919249,"user":{"displayName":"이진규","userId":"11520813773494359482"},"user_tz":-540},"id":"gI5nIfEQE0Dt","outputId":"474e8c7b-e407-4b2f-c170-68e99c45b0f7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 30, 30, 96)        2688      \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 15, 15, 96)       0         \n"," )                                                               \n","                                                                 \n"," dropout (Dropout)           (None, 15, 15, 96)        0         \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 13, 13, 192)       166080    \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 6, 6, 192)        0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_1 (Dropout)         (None, 6, 6, 192)         0         \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 4, 4, 192)         331968    \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 64)                196672    \n","                                                                 \n"," dense_1 (Dense)             (None, 12)                780       \n","                                                                 \n","=================================================================\n","Total params: 698,188\n","Trainable params: 698,188\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/30\n","60/60 [==============================] - 14s 28ms/step - loss: 0.0466 - accuracy: 0.0843 - val_loss: 0.0061 - val_accuracy: 0.0919\n","Epoch 2/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0042 - accuracy: 0.0856 - val_loss: 0.0034 - val_accuracy: 0.0940\n","Epoch 3/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0030 - accuracy: 0.1072 - val_loss: 0.0032 - val_accuracy: 0.1204\n","Epoch 4/30\n","60/60 [==============================] - 1s 19ms/step - loss: 0.0030 - accuracy: 0.1285 - val_loss: 0.0031 - val_accuracy: 0.1265\n","Epoch 5/30\n","60/60 [==============================] - 1s 19ms/step - loss: 0.0030 - accuracy: 0.1614 - val_loss: 0.0032 - val_accuracy: 0.1813\n","Epoch 6/30\n","60/60 [==============================] - 1s 19ms/step - loss: 0.0030 - accuracy: 0.1719 - val_loss: 0.0033 - val_accuracy: 0.2165\n","Epoch 7/30\n","60/60 [==============================] - 1s 24ms/step - loss: 0.0029 - accuracy: 0.1790 - val_loss: 0.0031 - val_accuracy: 0.2085\n","Epoch 8/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0029 - accuracy: 0.2107 - val_loss: 0.0032 - val_accuracy: 0.2477\n","Epoch 9/30\n","60/60 [==============================] - 1s 19ms/step - loss: 0.0029 - accuracy: 0.2333 - val_loss: 0.0031 - val_accuracy: 0.2663\n","Epoch 10/30\n","60/60 [==============================] - 1s 24ms/step - loss: 0.0029 - accuracy: 0.2607 - val_loss: 0.0031 - val_accuracy: 0.2402\n","Epoch 11/30\n","60/60 [==============================] - 1s 19ms/step - loss: 0.0029 - accuracy: 0.2754 - val_loss: 0.0031 - val_accuracy: 0.3517\n","Epoch 12/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0029 - accuracy: 0.3122 - val_loss: 0.0031 - val_accuracy: 0.3256\n","Epoch 13/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0028 - accuracy: 0.3799 - val_loss: 0.0030 - val_accuracy: 0.4235\n","Epoch 14/30\n","60/60 [==============================] - 1s 24ms/step - loss: 0.0027 - accuracy: 0.4833 - val_loss: 0.0028 - val_accuracy: 0.5969\n","Epoch 15/30\n","60/60 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.6004 - val_loss: 0.0028 - val_accuracy: 0.6971\n","Epoch 16/30\n","60/60 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.6687 - val_loss: 0.0026 - val_accuracy: 0.7529\n","Epoch 17/30\n","60/60 [==============================] - 1s 24ms/step - loss: 0.0025 - accuracy: 0.7311 - val_loss: 0.0026 - val_accuracy: 0.7854\n","Epoch 18/30\n","60/60 [==============================] - 1s 24ms/step - loss: 0.0025 - accuracy: 0.7910 - val_loss: 0.0025 - val_accuracy: 0.8490\n","Epoch 19/30\n","60/60 [==============================] - 1s 19ms/step - loss: 0.0024 - accuracy: 0.8325 - val_loss: 0.0025 - val_accuracy: 0.8850\n","Epoch 20/30\n","60/60 [==============================] - 1s 24ms/step - loss: 0.0024 - accuracy: 0.8622 - val_loss: 0.0024 - val_accuracy: 0.8904\n","Epoch 21/30\n","60/60 [==============================] - 1s 24ms/step - loss: 0.0024 - accuracy: 0.8804 - val_loss: 0.0024 - val_accuracy: 0.9094\n","Epoch 22/30\n","60/60 [==============================] - 1s 19ms/step - loss: 0.0024 - accuracy: 0.8935 - val_loss: 0.0025 - val_accuracy: 0.9175\n","Epoch 23/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0023 - accuracy: 0.9029 - val_loss: 0.0025 - val_accuracy: 0.9277\n","Epoch 24/30\n","60/60 [==============================] - 1s 19ms/step - loss: 0.0023 - accuracy: 0.9082 - val_loss: 0.0024 - val_accuracy: 0.9273\n","Epoch 25/30\n","60/60 [==============================] - 1s 18ms/step - loss: 0.0023 - accuracy: 0.9167 - val_loss: 0.0023 - val_accuracy: 0.9346\n","Epoch 26/30\n","60/60 [==============================] - 1s 24ms/step - loss: 0.0023 - accuracy: 0.9210 - val_loss: 0.0023 - val_accuracy: 0.9460\n","Epoch 27/30\n","60/60 [==============================] - 1s 19ms/step - loss: 0.0023 - accuracy: 0.9211 - val_loss: 0.0024 - val_accuracy: 0.9440\n","Epoch 28/30\n","60/60 [==============================] - 1s 19ms/step - loss: 0.0023 - accuracy: 0.9306 - val_loss: 0.0024 - val_accuracy: 0.9481\n","Epoch 29/30\n","60/60 [==============================] - 1s 24ms/step - loss: 0.0023 - accuracy: 0.9315 - val_loss: 0.0023 - val_accuracy: 0.9502\n","Epoch 30/30\n","60/60 [==============================] - 1s 19ms/step - loss: 0.0023 - accuracy: 0.9388 - val_loss: 0.0024 - val_accuracy: 0.9535\n"]}],"source":["from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D,GlobalAveragePooling2D\n","from tensorflow.keras.optimizers import SGD\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","import tensorflow as tf\n","import os\n","\n","\n","def train(data, file_name, num_epochs=50, batch_size=128):\n","    \"\"\"\n","    Standard neural network training procedure.\n","    \"\"\"\n","    model = Sequential()\n","\n","    IMG_HEIGHT = 32\n","    IMG_WIDTH = 32\n","\n","    # 첫번째 Convolutional Layer : 입력 데이터로부터 특징을 추출\n","    model.add(Conv2D(filters=96, kernel_size=3, activation='relu', input_shape=data.x_train.shape[1:]))\n","    model.add(MaxPool2D(pool_size=(2, 2)))\n","    model.add(Dropout(rate=0.25))\n","\n","    # 두번째 Convolutional Layer\n","    model.add(Conv2D(filters=192, kernel_size=3, activation='relu'))\n","    model.add(MaxPool2D(pool_size=(2, 2)))\n","    model.add(Dropout(rate=0.25)) # 인풋데이터의 25%를 무작위로 0으로 만듦\n","\n","    # 세번째 Convolutional Layer\n","    model.add(Conv2D(filters=192, kernel_size=3, activation='relu')) # 특징을 추출하는 기능을 하는 필터, 비선형 값으로 바꿔주는 activation 함수->relu\n","    # model.add(GlobalAveragePooling2D())\n","    model.add(Flatten())\n","\n","    model.add(Dense(units=64, activation='relu'))\n","    model.add(Dense(12, activation='softmax'))\n","\n","\n","    # 모델 컴파일 하기\n","    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    model.summary()\n","\n","    # 모델 핏하기\n","    EPOCHS = num_epochs\n","    model.fit(data.x_train, data.y_train,\n","              validation_data = (data.x_test, data.y_test), \n","              epochs=EPOCHS, steps_per_epoch=60\n","              )\n","\n","    if file_name != None:\n","        model.save(file_name)\n","\n","    return model\n","\n","\n","if not os.path.isdir('models'):\n","    os.makedirs('models')\n","\n","model = train(data, \"models/gtsrb_classifier\", num_epochs=30)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1624,"status":"ok","timestamp":1663303920848,"user":{"displayName":"이진규","userId":"11520813773494359482"},"user_tz":-540},"id":"Ez-W2phKFLws","outputId":"73f3cb70-eac3-4ff3-e29c-9e6d9de801b5"},"outputs":[{"output_type":"stream","name":"stdout","text":["225/225 [==============================] - 1s 3ms/step - loss: 0.0024 - accuracy: 0.9597\n","test set accuracy:  95.97222208976746\n","150/150 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.9535\n","test set accuracy:  95.35416960716248\n"]}],"source":["loss, accuracy = model.evaluate(data.x_train, data.y_train)\n","\n","print('test set accuracy: ', accuracy * 100)\n","\n","loss, accuracy = model.evaluate(data.x_test, data.y_test)\n","\n","print('test set accuracy: ', accuracy * 100)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2176,"status":"ok","timestamp":1663303923022,"user":{"displayName":"이진규","userId":"11520813773494359482"},"user_tz":-540},"id":"xbYmfSHYHOIa","outputId":"5ddf0cf8-de1c-4896-ff1e-02c049fff1e7"},"outputs":[{"output_type":"stream","name":"stdout","text":["194/194 [==============================] - 1s 4ms/step - loss: 34.6723 - accuracy: 0.8523\n","test set accuracy:  85.22653579711914\n","194/194 [==============================] - 1s 4ms/step - loss: 0.0024 - accuracy: 0.8903\n","test set accuracy with nomalization:  89.02912735939026\n"]}],"source":["# test data set\n","loss, accuracy = model.evaluate(data_test.x_test, data_test.y_test)\n","\n","print('test set accuracy: ', accuracy * 100)\n","\n","# --> 애초에 오버피팅 되어있음을 확인할 수 있다.\n","\n","loss, accuracy = model.evaluate(data_test.x_test/255, data_test.y_test/255)\n","\n","print('test set accuracy with nomalization: ', accuracy * 100)\n","\n","# --> /255로 정규화 시켜준다면 어느정도 성능 회복 "]},{"cell_type":"markdown","metadata":{"id":"4SUb6-MoJtay"},"source":["### FGSM \n","epsilon = 0.02로 FGSM Attack을 가해주겠다"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DGBdi7tWJT1K"},"outputs":[],"source":["def tf_preprocess(image):\n","  image = tf.cast(image, tf.float32)\n","  image = image/255\n","  image = tf.image.resize(image, (32, 32))\n","  image = image[None, ...]\n","  return image\n","\n","# 확률 벡터에서 레이블을 추출해주는 헬퍼 메서드\n","def get_tf_label(labels):\n","    label = tf.cast(labels, tf.int32)\n","    label = tf.reshape(label,[1,12])\n","    return label\n","\n","loss_object = tf.keras.losses.CategoricalCrossentropy()\n","\n","def create_adversarial_pattern(input_image, input_label):\n","  with tf.GradientTape() as tape:\n","    tape.watch(input_image)\n","    input_img = tf.reshape(input_image,[1,32,32,3])\n","    prediction = model(input_img)\n","    loss = loss_object(input_label, prediction)\n","\n","  # 입력 이미지에 대한 손실 함수의 기울기를 구합니다.\n","  gradient = tape.gradient(loss, input_image)\n","  # 왜곡을 생성하기 위해 그래디언트의 부호를 구합니다.\n","  signed_grad = tf.sign(gradient)\n","  return signed_grad\n","\n","def fgsm_attack(model,test_x,test_y,eps):\n","    \n","    correct = 0\n","    adv_examples = []\n","    save_adv_examples = []\n","    save_original_output = []\n","    \n","    for i in range(len(test_x)):\n","        data = test_x[i]\n","        target = test_y[i]\n","\n","        result = model.predict(data.reshape(1,32,32,3) / 255)\n","        init_output = int(np.argmax(result))\n"," \n","        if init_output != np.argmax(target):\n","            continue\n","\n","        img =  tf_preprocess(data)\n","        label = get_tf_label(target)\n","        \n","        perturbations = create_adversarial_pattern(img, label)\n","\n","        adv_x = img + eps*perturbations\n","        adv_x = tf.clip_by_value(adv_x, 0, 1)\n","\n","\n","        output = model.predict(adv_x)\n","\n","        final_pred = int(np.argmax(output))\n","\n","        if final_pred == int(np.argmax(target)):\n","            correct += 1\n","            if (eps == 0) and (len(adv_examples) < 5):\n","                adv_ex = adv_x\n","                adv_examples.append((init_output,final_pred,adv_x))\n","        else:\n","            if len(adv_examples) < 5:\n","                adv_ex = adv_x\n","                adv_examples.append((init_output,final_pred,adv_x))\n","\n","        save_adv_examples.append(tf.reshape(adv_x,[32,32,3]))\n","        save_original_output.append(init_output)\n","\n","\n","    # 해당 엡실론에서의 최종 정확도를 계산합니다\n","    final_acc = correct/float(len(test_x))\n","    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(eps, correct, len(test_x), final_acc))\n","\n","    # 정확도와 적대적 예제를 리턴합니다\n","    return final_acc, adv_examples, save_adv_examples, save_original_output"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":536251,"status":"ok","timestamp":1663051841793,"user":{"displayName":"이진규","userId":"11520813773494359482"},"user_tz":-540},"id":"MbqAcNpoKBu-","outputId":"b7a244dc-2d48-4b09-c025-3917460b5291"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epsilon: 0.02\tTest Accuracy = 2626 / 6180 = 0.4249190938511327\n"]}],"source":["eps = 0.02\n","\n","accuracies = []\n","examples = []\n","\n","# 각 엡실론에 대해 테스트 함수를 실행합니다\n","acc, ex, ad_examples, orig_labels = fgsm_attack(model, data_test.x_test, data_test.y_test, eps) # 9 min"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32,"status":"ok","timestamp":1663051841794,"user":{"displayName":"이진규","userId":"11520813773494359482"},"user_tz":-540},"id":"lbuz0sLSKEig","outputId":"f798614f-47f7-4bbc-8622-7893af6580b9"},"outputs":[{"name":"stdout","output_type":"stream","text":["(5318, 32, 32, 3)\n","(5318, 12)\n"]}],"source":["ad_examples1 = np.array(ad_examples) # 이미 정규화되어서 나온 값으로 추가적인 /255 정규화 필요 없음\n","orig_labels1 = to_categorical(orig_labels)\n","\n","print(ad_examples1.shape)\n","print(orig_labels1.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2101,"status":"ok","timestamp":1663051843882,"user":{"displayName":"이진규","userId":"11520813773494359482"},"user_tz":-540},"id":"6wiuBj7TNl4f","outputId":"6d41567f-9fa8-496f-ca41-626ab9c28d62"},"outputs":[{"name":"stdout","output_type":"stream","text":["167/167 [==============================] - 1s 5ms/step - loss: 0.5732 - accuracy: 0.4938\n","test(not train) set attacked accuracy:  49.379464983940125\n"]}],"source":["loss, accuracy = model.evaluate(ad_examples1, orig_labels1)\n","\n","print('test(not train) set attacked accuracy: ', accuracy * 100)"]},{"cell_type":"markdown","metadata":{"id":"P9v5DhrcQTi_"},"source":["###  Defense Model 1 : DefenseGAN"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"1w18KhjvQaN-","executionInfo":{"status":"ok","timestamp":1663219236939,"user_tz":-540,"elapsed":989,"user":{"displayName":"이진규","userId":"11520813773494359482"}}},"outputs":[],"source":["import numpy as np\n","import os\n","import gzip\n","import urllib.request\n","\n","from keras.models import load_model\n","\n","def ordered_onehotencoding(labels):\n","    labels_ordered = []\n","    for i in range(len(labels)):\n","        if labels[i] == 3:\n","            labels_ordered.append(0)\n","        elif labels[i] == 7:\n","            labels_ordered.append(1)\n","        elif labels[i] == 9:\n","            labels_ordered.append(2)\n","        elif labels[i] == 10:\n","            labels_ordered.append(3)\n","        elif labels[i] == 11:\n","            labels_ordered.append(4)\n","        elif labels[i] == 12:\n","            labels_ordered.append(5)\n","        elif labels[i] == 13:\n","            labels_ordered.append(6)\n","        elif labels[i] == 17:\n","            labels_ordered.append(7)\n","        elif labels[i] == 18:\n","            labels_ordered.append(8)\n","        elif labels[i] == 25:\n","            labels_ordered.append(9)\n","        elif labels[i] == 35:\n","            labels_ordered.append(10)\n","        elif labels[i] == 38:\n","            labels_ordered.append(11)\n","    \n","    return np.array(labels_ordered)\n","\n","class GTSRB_defenseGAN:\n","    def __init__(self):\n","        imgs_path = \"Train\"\n","        data_list = []\n","        labels_list = []\n","\n","        result_class = [3,7, 9, 10, 11, 12, 13, 17, 18, 25, 35, 38]\n","\n","        for i in result_class:\n","            i_path = os.path.join(imgs_path, str(i)) # 3, 7, 9, 10, 11, 12,13, 17, 18, 25, 35, 38\n","            num = 0\n","            for img in os.listdir(i_path):\n","          \n","                im = Image.open(i_path +'/'+ img)\n","                im = im.resize((32,32))\n","                im = np.array(im)\n","\n","                data_list.append(im)\n","                labels_list.append(i)\n","                num = num + 1\n","                if num == 1000:\n","                    break;\n","\n","        data = np.array(data_list)\n","        labels = ordered_onehotencoding(labels_list)\n","\n","        labels = to_categorical(labels)\n","\n","        VALIDATION_SIZE = 5000\n","        \n","        data = (data.astype(np.float32) - 127.5) / 127.5 #모든 데이터 픽셀 값을 -1~1로 피팅 시킨다 (GAN 학습을 위함)\n","        \n","        self.x_train = np.array(data)\n","        self.y_train = labels\n","\n","    @staticmethod\n","    def print():\n","        return \"GTSRB_defenseGAN\""]},{"cell_type":"code","execution_count":33,"metadata":{"id":"jFZPnqlWRPA7","executionInfo":{"status":"ok","timestamp":1663219262854,"user_tz":-540,"elapsed":23585,"user":{"displayName":"이진규","userId":"11520813773494359482"}}},"outputs":[],"source":["data_train_GAN = GTSRB_defenseGAN()"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34,"status":"ok","timestamp":1663219262855,"user":{"displayName":"이진규","userId":"11520813773494359482"},"user_tz":-540},"id":"a_zbYD_uRrNQ","outputId":"71c78426-dff8-474f-f47e-1d7e515f7c69"},"outputs":[{"output_type":"stream","name":"stdout","text":["(12000, 32, 32, 3)\n","(12000, 12)\n"]}],"source":["print(data_train_GAN.x_train.shape)\n","print(data_train_GAN.y_train.shape)"]},{"cell_type":"markdown","metadata":{"id":"nZvOoqJqTtgW"},"source":["GAN 생성"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":907,"status":"ok","timestamp":1663219263735,"user":{"displayName":"이진규","userId":"11520813773494359482"},"user_tz":-540},"id":"rOz8KOvWRqFq","outputId":"ac2986e7-8fa4-429d-e8c9-b28c8f41c035"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_2 (Dense)             (None, 8192)              827392    \n","                                                                 \n"," reshape (Reshape)           (None, 8, 8, 128)         0         \n","                                                                 \n"," batch_normalization (BatchN  (None, 8, 8, 128)        512       \n"," ormalization)                                                   \n","                                                                 \n"," up_sampling2d (UpSampling2D  (None, 16, 16, 128)      0         \n"," )                                                               \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 16, 16, 128)       147584    \n","                                                                 \n"," activation (Activation)     (None, 16, 16, 128)       0         \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 16, 16, 128)      512       \n"," hNormalization)                                                 \n","                                                                 \n"," up_sampling2d_1 (UpSampling  (None, 32, 32, 128)      0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 32, 32, 64)        73792     \n","                                                                 \n"," activation_1 (Activation)   (None, 32, 32, 64)        0         \n","                                                                 \n"," batch_normalization_2 (Batc  (None, 32, 32, 64)       256       \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 32, 32, 3)         1731      \n","                                                                 \n"," activation_2 (Activation)   (None, 32, 32, 3)         0         \n","                                                                 \n","=================================================================\n","Total params: 1,051,779\n","Trainable params: 1,051,139\n","Non-trainable params: 640\n","_________________________________________________________________\n","Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_6 (Conv2D)           (None, 16, 16, 32)        896       \n","                                                                 \n"," leaky_re_lu (LeakyReLU)     (None, 16, 16, 32)        0         \n","                                                                 \n"," dropout_2 (Dropout)         (None, 16, 16, 32)        0         \n","                                                                 \n"," conv2d_7 (Conv2D)           (None, 8, 8, 64)          18496     \n","                                                                 \n"," zero_padding2d (ZeroPadding  (None, 9, 9, 64)         0         \n"," 2D)                                                             \n","                                                                 \n"," leaky_re_lu_1 (LeakyReLU)   (None, 9, 9, 64)          0         \n","                                                                 \n"," dropout_3 (Dropout)         (None, 9, 9, 64)          0         \n","                                                                 \n"," batch_normalization_3 (Batc  (None, 9, 9, 64)         256       \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_8 (Conv2D)           (None, 5, 5, 128)         73856     \n","                                                                 \n"," leaky_re_lu_2 (LeakyReLU)   (None, 5, 5, 128)         0         \n","                                                                 \n"," dropout_4 (Dropout)         (None, 5, 5, 128)         0         \n","                                                                 \n"," batch_normalization_4 (Batc  (None, 5, 5, 128)        512       \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_9 (Conv2D)           (None, 5, 5, 256)         295168    \n","                                                                 \n"," leaky_re_lu_3 (LeakyReLU)   (None, 5, 5, 256)         0         \n","                                                                 \n"," dropout_5 (Dropout)         (None, 5, 5, 256)         0         \n","                                                                 \n"," flatten_1 (Flatten)         (None, 6400)              0         \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 6401      \n","                                                                 \n","=================================================================\n","Total params: 395,585\n","Trainable params: 395,201\n","Non-trainable params: 384\n","_________________________________________________________________\n"]}],"source":["import numpy as np \n","import matplotlib.pyplot as plt \n","\n","from keras.datasets import mnist\n","\n","from keras.models import Sequential, Model\n","\n","from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n","from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.layers.convolutional import UpSampling2D, Conv2D\n","\n","from tensorflow.keras.optimizers import Adam\n","\n","noise_data = np.random.normal(0, 1, (32, 100))\n","#generated_images = 0.5 * generator.predict(np.random.normal(0, 1, (32, 100))) + 0.5\n","\n","def show_images(generated_images, n=4, m=8, figsize=(9, 5)):\n","    f, axes = plt.subplots(n, m, figsize=figsize)\n","    #plt.subplots_adjust(top=1, bottom=0, hspace=0, wspace=0.05)\n","    for i in range(0, n):\n","        for j in range(0, m):\n","            ax = axes[i][j]\n","            ax.imshow(generated_images[i * m + j])\n","            ax.grid(False)\n","            ax.xaxis.set_ticks([])\n","            ax.yaxis.set_ticks([])\n","    plt.tight_layout()\n","    plt.savefig('20220729_basicgan.svg')\n","    plt.show()   \n","#show_images(0.5 * generator.predict(np.random.normal(0, 1, (32, 100))) + 0.5)\n","\n","\n","## create generator         \n","generator_ = Sequential([\n","    Dense(128 * 8 * 8, activation=\"relu\", input_shape=(100,)), \n","    Reshape((8, 8, 128)), \n","    \n","    BatchNormalization(momentum=0.8), # what is batch normalization?? \n","    UpSampling2D(), # what is upsampling?? \n","    Conv2D(128, kernel_size=3, padding=\"same\"),\n","    Activation(\"relu\"), \n","    \n","    BatchNormalization(momentum=0.8), \n","    UpSampling2D(), \n","    Conv2D(64, kernel_size=3, padding=\"same\"), \n","    Activation(\"relu\"), \n","    \n","    BatchNormalization(momentum=0.8), \n","    Conv2D(3, kernel_size=3, padding=\"same\"), \n","    Activation(\"tanh\"), \n","])\n","\n","noise_input = Input(shape=(100,), name=\"noise_input\")\n","generator_base = Model(noise_input, generator_(noise_input), name=\"generator\")\n","\n","generator_.summary()# summary가 매우 유용하군요. \n","\n","optimizer = Adam(0.0002, 0.5)\n","generator_base.compile(loss='binary_crossentropy', optimizer=optimizer)\n","\n","### create discriminator\n","discriminator_ = Sequential([\n","    Conv2D(32, kernel_size=3, strides=2, input_shape=(32, 32, 3), padding=\"same\"), \n","    LeakyReLU(alpha=0.2), \n","    Dropout(0.25), \n","    \n","    Conv2D(64, kernel_size=3, strides=2, padding=\"same\"), \n","    ZeroPadding2D(padding=((0,1),(0,1))), \n","    LeakyReLU(alpha=0.2), \n","    Dropout(0.25), \n","    BatchNormalization(momentum=0.8), \n","    \n","    Conv2D(128, kernel_size=3, strides=2, padding=\"same\"), \n","    LeakyReLU(alpha=0.2), \n","    Dropout(0.25), \n","    BatchNormalization(momentum=0.8), \n","    \n","    Conv2D(256, kernel_size=3, strides=1, padding=\"same\"), \n","    LeakyReLU(alpha=0.2), \n","    Dropout(0.25), \n","    Flatten(), \n","    Dense(1, activation='sigmoid'), \n","])\n","image_input = Input(shape=(32, 32, 3), name=\"image_input\")\n","\n","discriminator = Model(image_input, discriminator_(image_input), name=\"discriminator\")\n","discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","discriminator_.summary()\n","\n","### Combined Model\n","noise_input2 = Input(shape=(100,), name=\"noise_input2\")\n","\"\"\"\n","model과 sequential의 차이는?? \n","가설1: 레이어를 쌓는 것이 sequential 이라면, sequential을 쌓는 것이 model인가???\n","\n","1) 다음 모델의 경우는 랜덤으로 만든 이미지로부터 학습해서 새로운 이미지를 만들어내는 generator의 데이터를 \n","2) discriminator가 분류하는 형식으로 진행된다. \n","\"\"\"\n","combined = Model(noise_input2, discriminator(generator_base(noise_input2)))\n","combined.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"14r85lYqjvDw2fltDLA2hVUvTUJrKYp87","height":1000},"executionInfo":{"elapsed":611677,"status":"ok","timestamp":1663222222925,"user":{"displayName":"이진규","userId":"11520813773494359482"},"user_tz":-540},"id":"7NWG3wxrSF4p","outputId":"34308175-ef61-4d59-8931-c0fcad082fca"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["## training\n","\"\"\"\n","- 이 코드에서는 fit을 사용한 것이 아니라, train_on_batch를 사용했음. \n","- train_on_batch와의 차이점?을 구글에 검색해보니, 큰 차이가 없다고 하긴 하는데\n","    - train_on_batch의 경우, 넘겨 받은 데이터에 대해서 gradient vector를 계산해서 적용하고 끝내는 것이고(1epoch)\n","    - fit의 경우는 epoch과 batch_size를 한번에 모두 넘겨준다는 것 정도가 차이가 된다. \n","- GAN의 경우, discriminator의 학습시 마다 generator가 생성하는 데이터가 변화하게 된다. \n","    - 즉 처음부터 모든 데이터가 존재하고 이를 한번에 학습시키는 fit과는 다르게, 한번씩 업데이트를 할때마다 모델이 변화하므로, \n","    - train_on_batch를 사용하는 것이 매우 합당함.\n","\"\"\"\n","batch_size = 256\n","half_batch = batch_size // 2\n","\n","def train(epochs, print_step=10):\n","    history = []\n","    for epoch in range(epochs):\n","        # discriminator 트레이닝 단계\n","        #######################################################################3\n","        # 데이터 절반은 실제 이미지, 절반은 generator가 생성한 가짜 이미지\n","        # discriminator가 실제 이미지와 가짜 이미지를 구별하도록 discriminator를 트레이닝\n","        discriminator.trainable = True\n","        d_loss_real = discriminator.train_on_batch(data_train_GAN.x_train[np.random.randint(0, data_train_GAN.x_train.shape[0], half_batch)], \n","                                                   np.ones((half_batch, 1)))\n","        d_loss_fake = discriminator.train_on_batch(generator_base.predict(np.random.normal(0, 1, (half_batch, 100))), \n","                                                   np.zeros((half_batch, 1)))\n","        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","        # generator 트레이닝 단계\n","        #######################################################################3\n","        # 전부 generator가 생성한 가짜 이미지를 사용. \n","        # discriminator가 구별하지 못하도록 generator를 트레이닝\n","        \n","        \"\"\"\n","        generator를 트레이닝할 때는, 반드시 discriminator가 필요함. \n","        generator가 만든 image를 평가해야 하고, 그래야 feedback이 생겨서 generator가 학습됨. \n","        따라서, generator는 combined model을 통해 학습시키는데, 이때, discriminator도 함께 학습되면 안되기 때문에\n","        discriminator.trainable 을 False로 변경시켜 둔다. \n","        \"\"\"\n","        noise = np.random.normal(0, 1, (batch_size, 100))\n","        discriminator.trainable = False \n","        g_loss = combined.train_on_batch(noise, np.ones((batch_size, 1)))  #여기서는 왜 만들어준 fake img의 y 값을 1로 두는 걸까 ..\n","        # 기록\n","        record = (epoch, d_loss[0], 100 * d_loss[1], g_loss[0], 100 * g_loss[1])\n","        history.append(record)\n","        if epoch % print_step == 0:\n","            print(\"%5d [D loss: %.3f, acc.: %.2f%%] [G loss: %.3f, acc.: %.2f%%]\" % record)\n","            show_images(0.5 * generator_base.predict(noise_data) + 0.5)\n","    return history\n","#%%time, 은\n","history100 = train(20000, 500)\n","show_images(0.5 * generator_base.predict(noise_data) + 0.5)"]},{"cell_type":"code","source":["# GAN 모델 저장\n","from keras.models import load_model\n","\n","generator_base.save('baseGAN_Generator_attacked0.02.h5')"],"metadata":{"id":"dXXJ-Wgyu_bT","executionInfo":{"status":"ok","timestamp":1663222295626,"user_tz":-540,"elapsed":707,"user":{"displayName":"이진규","userId":"11520813773494359482"}}},"execution_count":39,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4BPL_wcJTvXO"},"source":["DefenseGAN 구현 - FGSM"]},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":245},"executionInfo":{"elapsed":461,"status":"error","timestamp":1663222477718,"user":{"displayName":"이진규","userId":"11520813773494359482"},"user_tz":-540},"id":"h5JFZsEPTqeY","outputId":"54d1549a-9569-4741-87ea-bf5aa14bccfc"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-47-479fd5129cfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mad_example_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mad_examples1\u001b[0m \u001b[0;31m#/255로 이미 정규화가 된 이미지이다\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0morig_label_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morig_labels1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mad_example_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_label_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'ad_examples1' is not defined"]}],"source":["ad_example_data = ad_examples1 #/255로 이미 정규화가 된 이미지이다\n","orig_label_data = orig_labels1\n","\n","print(ad_example_data.shape)\n","print(orig_label_data.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LrHjDgblT_c1"},"outputs":[],"source":["def DefenseGAN(img_at,L,R):\n","    z_list = []\n","    img = img_at.reshape(32,32,3)\n","    img_st = (img - np.mean(img)) / np.std(img) \n","    img_var = tf.Variable(img_st,dtype = float)\n","    opt = tf.keras.optimizers.SGD(learning_rate=0.1,momentum = 0.7)\n","\n","    def compute():\n","        z_hats_recs = generator_base(z_var)\n","        z_hats_recs = tf.reshape(z_hats_recs, [32,32,3])\n","        num_dim = len(z_hats_recs.get_shape())\n","        axes = range(1, num_dim)\n","        image_rec_loss = tf.reduce_mean(tf.square(z_hats_recs - img_var),axis=axes)\n","        rec_loss = tf.reduce_sum(image_rec_loss)\n","        return rec_loss\n","\n","    for r in range(R):\n","        z = np.random.normal(0, 1, (1, 100))\n","        z_var = tf.Variable(z,dtype = float)\n","    \n","        for l in range(L):\n","            opt.minimize(compute,[z_var])\n","        z_list.append(z_var)\n","\n","    def compute_10(z):\n","        #generator_base.trainable = False #아직 더해야하는지 뺴야하는지 판단 x\n","        z_hats_recs = generator_base(z)\n","        z_hats_recs = tf.reshape(z_hats_recs, [32,32,3])\n","        num_dim = len(z_hats_recs.get_shape())\n","        axes = range(1, num_dim)\n","        image_rec_loss = tf.reduce_mean(tf.square(z_hats_recs - img_var),axis=axes)\n","        rec_loss = tf.reduce_sum(image_rec_loss)\n","        return rec_loss\n","    \n","\n","    loss_list = []\n","    \n","    for i in range(len(z_list)):\n","        loss = compute_10(z_list[i])\n","        loss_list.append(loss)\n","    \n","    index_min = np.argmin(loss_list)\n","\n","    z_min = np.array(z_list[index_min])\n","\n","    generated_images = 0.5 * generator_base.predict(z_min)+ 0.5\n","\n","    generated_images = generated_images.reshape(32,32,3)\n","\n","    return generated_images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9ks2QRZbUKO_"},"outputs":[],"source":["## predict_output에 한개씩 넣는 것부터 구현해야한다. (전체가 들어가는 것만 정상 작동함)\n","\n","def test(classifier, ad_example_data, orig_label_data):\n","\n","    # 정확도 카운터\n","    correct = 0\n","    defense_correct = 0\n","    df_examples = []\n","    # 테스트 셋의 모든 예제에 대해 루프를 돕니다\n","\n","    loss, accuracy = classifier.evaluate(ad_examples1, orig_labels1)\n","\n","    print('방어 전 모델 정확도 : ',accuracy * 100)\n","\n","    for i in range(len(ad_example_data)):\n","        data = ad_example_data[i].reshape(-1,32,32,3)\n","        target = orig_label_data[i]\n","        \n","        data_plot = data.reshape(32,32,3)\n","        print('원본 label : ',np.argmax(target))\n","        plt.imshow(data_plot)\n","        plt.show();\n","\n","        generated_img = DefenseGAN(data.reshape(32,32,3),200,10).reshape(-1,32,32,3)\n","\n","        generated_img_plot = generated_img.reshape(32,32,3)\n","\n","\n","        defense_output = classifier.predict(generated_img.reshape(1,32,32,3))\n","\n","        defense_pred= int(np.argmax(defense_output))\n","\n","        print('방어 라벨 : ',defense_pred)\n","        plt.imshow(generated_img_plot)\n","        plt.show();\n","\n","        if defense_pred == int(np.argmax(target)):\n","            defense_correct += 1\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","        else:\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","\n","        print('Working...!')\n","\n","\n","    defense_acc = defense_correct / float(len(ad_example_data))\n","    print(\"Defense Accuracy = {} / {} = {}\".format(defense_correct, len(ad_example_data), defense_acc))\n","    # 정확도와 적대적 예제를 리턴합니다\n","    return defense_acc, df_examples"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"16NMMt21yLvgitliyd3qPB0mBKCiIcmN2"},"executionInfo":{"elapsed":2267229,"status":"ok","timestamp":1662374381347,"user":{"displayName":"이진규","userId":"11520813773494359482"},"user_tz":-540},"id":"UmgqhBaWaqXz","outputId":"8c50e888-ad4a-4c2e-ba44-56b076c0ebf3"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["accuracies_df = []\n","examples_df = []\n","\n","acc_df, ex_df = test(model, ad_example_data[:100], orig_label_data[:100])\n","\n","accuracies_df.append(acc_df)\n","examples_df.append(ex_df)"]},{"cell_type":"markdown","metadata":{"id":"1ywsHS3sfPxD"},"source":["### Defense 2 : PCA (Components = 5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KuoOeVKxsyvD"},"outputs":[],"source":["ad_example_data = ad_examples1 #/255로 이미 정규화가 된 이미지이다\n","orig_label_data = orig_labels1\n","\n","print(ad_example_data.shape)\n","print(orig_label_data.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rAB3avuSbB3q"},"outputs":[],"source":["from sklearn.decomposition import PCA\n","\n","# data shape이 32,32,3이어야한다.\n","def defense_PCA(data,component):\n","    #r,g,b를 각각 나눠준다\n","    data = data.reshape(32,32,3)\n","    r = data[:,:,0]\n","    g = data[:,:,1]\n","    b = data[:,:,2]\n","\n","    pca_r = PCA(n_components=component)\n","    pca_r_trans = pca_r.fit_transform(r)\n","\n","    pca_g = PCA(n_components=component)\n","    pca_g_trans = pca_g.fit_transform(g)\n","\n","    pca_b = PCA(n_components=component)\n","    pca_b_trans = pca_b.fit_transform(b)\n","\n","    pca_r_org = pca_r.inverse_transform(pca_r_trans)\n","    pca_g_org = pca_g.inverse_transform(pca_g_trans)\n","    pca_b_org = pca_b.inverse_transform(pca_b_trans)\n","\n","    img_compressed = np.stack((pca_r_org, pca_g_org, pca_b_org),axis = 2)\n","\n","    return img_compressed.reshape((-1,32,32,3))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j2uWTxjIf-a-"},"outputs":[],"source":["## predict_output에 한개씩 넣는 것부터 구현해야한다. (전체가 들어가는 것만 정상 작동함)\n","\n","def test(classifier, ad_example_data, orig_label_data):\n","\n","    # 정확도 카운터\n","    correct = 0\n","    defense_correct = 0\n","    df_examples = []\n","    # 테스트 셋의 모든 예제에 대해 루프를 돕니다\n","\n","    loss, accuracy = classifier.evaluate(ad_examples1, orig_labels1)\n","\n","    print('방어 전 모델 정확도 : ',accuracy * 100)\n","\n","    for i in range(len(ad_example_data)):\n","        data = ad_example_data[i].reshape(-1,32,32,3)\n","        target = orig_label_data[i]\n","        \n","        data_plot = data.reshape(32,32,3)\n","        print('원본 label : ',np.argmax(target))\n","        plt.imshow(data_plot)\n","        plt.show();\n","\n","        generated_img = defense_PCA(data,5)\n","\n","        generated_img_plot = generated_img.reshape(32,32,3)\n","\n","        defense_output = classifier.predict(generated_img.reshape(1,32,32,3))\n","\n","        defense_pred= int(np.argmax(defense_output))\n","\n","        print('방어 라벨 : ',defense_pred)\n","        plt.imshow(generated_img_plot)\n","        plt.show();\n","\n","        if defense_pred == int(np.argmax(target)):\n","            defense_correct += 1\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","        else:\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","\n","        print('Working...!')\n","\n","\n","    defense_acc = defense_correct / float(len(ad_example_data))\n","    print(\"Defense Accuracy = {} / {} = {}\".format(defense_correct, len(ad_example_data), defense_acc))\n","    # 정확도와 적대적 예제를 리턴합니다\n","    return defense_acc, df_examples"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1vcs9zBuDgmHH0mKIcqpz00ng2GxphKoF"},"executionInfo":{"elapsed":3691644,"status":"ok","timestamp":1662370240621,"user":{"displayName":"이진규","userId":"11520813773494359482"},"user_tz":-540},"id":"TGm6ObXDhR2V","outputId":"3e7bbccc-a462-4d1a-894d-8e9726b0781f"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["accuracies_df = []\n","examples_df = []\n","\n","acc_df, ex_df = test(model, ad_example_data, orig_label_data)\n","\n","accuracies_df.append(acc_df)\n","examples_df.append(ex_df)"]},{"cell_type":"markdown","metadata":{"id":"9Y_-9xiJiAeC"},"source":["### Defense 2 : PCA (Components = 10)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":576,"status":"ok","timestamp":1663053288464,"user":{"displayName":"이진규","userId":"11520813773494359482"},"user_tz":-540},"id":"ZOiE-bIgsz6w","outputId":"b957b23b-075f-4290-9dc7-b5e0587ad4f0"},"outputs":[{"name":"stdout","output_type":"stream","text":["(5318, 32, 32, 3)\n","(5318, 12)\n"]}],"source":["ad_example_data = ad_examples1 #/255로 이미 정규화가 된 이미지이다\n","orig_label_data = orig_labels1\n","\n","print(ad_example_data.shape)\n","print(orig_label_data.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EyLQ-kGQwqEZ"},"outputs":[],"source":["from sklearn.decomposition import PCA\n","\n","# data shape이 32,32,3이어야한다.\n","def defense_PCA(data,component):\n","    #r,g,b를 각각 나눠준다\n","    data = data.reshape(32,32,3)\n","    r = data[:,:,0]\n","    g = data[:,:,1]\n","    b = data[:,:,2]\n","\n","    pca_r = PCA(n_components=component)\n","    pca_r_trans = pca_r.fit_transform(r)\n","\n","    pca_g = PCA(n_components=component)\n","    pca_g_trans = pca_g.fit_transform(g)\n","\n","    pca_b = PCA(n_components=component)\n","    pca_b_trans = pca_b.fit_transform(b)\n","\n","    pca_r_org = pca_r.inverse_transform(pca_r_trans)\n","    pca_g_org = pca_g.inverse_transform(pca_g_trans)\n","    pca_b_org = pca_b.inverse_transform(pca_b_trans)\n","\n","    img_compressed = np.stack((pca_r_org, pca_g_org, pca_b_org),axis = 2)\n","\n","    return img_compressed.reshape((-1,32,32,3))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lWXuP7V4iPO0"},"outputs":[],"source":["## predict_output에 한개씩 넣는 것부터 구현해야한다. (전체가 들어가는 것만 정상 작동함)\n","\n","def test(classifier, ad_example_data, orig_label_data):\n","\n","    # 정확도 카운터\n","    correct = 0\n","    defense_correct = 0\n","    df_examples = []\n","    # 테스트 셋의 모든 예제에 대해 루프를 돕니다\n","\n","    loss, accuracy = classifier.evaluate(ad_examples1, orig_labels1)\n","\n","    print('방어 전 모델 정확도 : ',accuracy * 100)\n","\n","    for i in range(len(ad_example_data)):\n","        data = ad_example_data[i].reshape(-1,32,32,3)\n","        target = orig_label_data[i]\n","        \n","        data_plot = data.reshape(32,32,3)\n","        print('원본 label : ',np.argmax(target))\n","        plt.imshow(data_plot)\n","        plt.show();\n","\n","        generated_img = defense_PCA(data,10)\n","\n","        generated_img_plot = generated_img.reshape(32,32,3)\n","\n","        defense_output = classifier.predict(generated_img.reshape(1,32,32,3))\n","\n","        defense_pred= int(np.argmax(defense_output))\n","\n","        print('방어 라벨 : ',defense_pred)\n","        plt.imshow(generated_img_plot)\n","        plt.show();\n","\n","        if defense_pred == int(np.argmax(target)):\n","            defense_correct += 1\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","        else:\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","\n","        print('Working...!')\n","\n","\n","    defense_acc = defense_correct / float(len(ad_example_data))\n","    print(\"Defense Accuracy = {} / {} = {}\".format(defense_correct, len(ad_example_data), defense_acc))\n","    # 정확도와 적대적 예제를 리턴합니다\n","    return defense_acc, df_examples"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"13NMiev6-7V3zdHr_gn1HfwVRBlTCKy9M"},"id":"HP7_KoXqiWhf","outputId":"d1389db6-2ae0-4b37-e712-113f4508055e"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["accuracies_df = []\n","examples_df = []\n","\n","acc_df, ex_df = test(model, ad_example_data, orig_label_data)\n","\n","accuracies_df.append(acc_df)\n","examples_df.append(ex_df)"]},{"cell_type":"markdown","source":["### BIM\n","\n","Basic Iteration Model를 통해 공격데이터를 생성하겠다"],"metadata":{"id":"T2HmvW0zab46"}},{"cell_type":"code","source":["data.x_train, data.y_train, data.x_test, data.y_test\n","print('train x 데이터 : ',data.x_train.shape)\n","print('train y 데이터 : ',data.y_train.shape)\n","print('test x 데이터 : ',data.x_test.shape)\n","print('test y 데이터 : ',data.y_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GPUITx4QahgT","executionInfo":{"status":"ok","timestamp":1663303971839,"user_tz":-540,"elapsed":285,"user":{"displayName":"이진규","userId":"11520813773494359482"}},"outputId":"895c151c-c94d-42cc-f845-08941fd381be"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["train x 데이터 :  (7200, 32, 32, 3)\n","train y 데이터 :  (7200, 12)\n","test x 데이터 :  (4800, 32, 32, 3)\n","test y 데이터 :  (4800, 12)\n"]}]},{"cell_type":"code","source":["# real test data\n","print(data_test.x_test.shape)\n","print(data_test.y_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"py777t5bCVUd","executionInfo":{"status":"ok","timestamp":1663303973489,"user_tz":-540,"elapsed":242,"user":{"displayName":"이진규","userId":"11520813773494359482"}},"outputId":"50ee467e-c367-4f2d-f8ad-8117f24e490c"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["(6180, 32, 32, 3)\n","(6180, 12)\n"]}]},{"cell_type":"code","source":["iterations = 7\n","alpha = 2\n","epsilon = 8/255"],"metadata":{"id":"rK3UDwvoahiR","executionInfo":{"status":"ok","timestamp":1663303975280,"user_tz":-540,"elapsed":259,"user":{"displayName":"이진규","userId":"11520813773494359482"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["def tf_preprocess(image):\n","  image = tf.cast(image, tf.float32)\n","  image = image/255\n","  image = tf.image.resize(image, (32, 32))\n","  image = image[None, ...]\n","  return image\n","\n","# 확률 벡터에서 레이블을 추출해주는 헬퍼 메서드\n","def get_tf_label(labels):\n","    label = tf.cast(labels, tf.int32)\n","    label = tf.reshape(label,[1,12])\n","    return label\n","\n","loss_object = tf.keras.losses.CategoricalCrossentropy()\n","\n","def pgd_attack(model,test_x,test_y,alpha,iterations,epsilon):\n","    \n","    correct = 0\n","    adv_examples = []\n","    save_adv_examples = []\n","    save_original_output = []\n","    \n","    for i in range(len(test_x)):\n","        data = test_x[i]\n","        target = test_y[i]\n","\n","        result = model.predict(data.reshape(1,32,32,3) / 255)\n","        init_output = int(np.argmax(result))\n"," \n","        if init_output != np.argmax(target):\n","            continue\n","\n","        img =  tf_preprocess(data)\n","        label = get_tf_label(target)\n","\n","        gen_img = img + tf.random.uniform(img.get_shape().as_list(), minval=-epsilon, maxval=+epsilon, dtype=tf.dtypes.float32)\n","\n","        for iters in range(iterations):\n","            imgv = tf.Variable(gen_img)\n","            with tf.GradientTape() as tape:\n","                tape.watch(imgv)\n","                predictions = model(imgv)\n","                loss = tf.keras.losses.CategoricalCrossentropy()(label, predictions)\n","            grads = tape.gradient(loss,imgv)\n","            signed_grads = tf.sign(grads)\n","            gen_img = gen_img + (alpha  * signed_grads)\n","            gen_img = tf.clip_by_value(gen_img, img-epsilon, img+epsilon)\n","\n","        adv_x = gen_img\n","\n","        output = model.predict(adv_x)\n","\n","        final_pred = int(np.argmax(output))\n","\n","        if final_pred == int(np.argmax(target)):\n","            correct += 1\n","            if (len(adv_examples) < 5):\n","                adv_ex = adv_x\n","                adv_examples.append((init_output,final_pred,adv_x))\n","        else:\n","            if len(adv_examples) < 5:\n","                adv_ex = adv_x\n","                adv_examples.append((init_output,final_pred,adv_x))\n","\n","        save_adv_examples.append(tf.reshape(adv_x,[32,32,3]))\n","        save_original_output.append(init_output)\n","\n","\n","    # 해당 엡실론에서의 최종 정확도를 계산합니다\n","    final_acc = correct/float(len(test_x))\n","    print(\"PGD: Test Accuracy = {} / {} = {}\".format(correct, len(test_x), final_acc))\n","\n","    # 정확도와 적대적 예제를 리턴합니다\n","    return final_acc, adv_examples, save_adv_examples, save_original_output"],"metadata":{"id":"iv-qQlouahmx","executionInfo":{"status":"ok","timestamp":1663304020857,"user_tz":-540,"elapsed":250,"user":{"displayName":"이진규","userId":"11520813773494359482"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["accuracies = []\n","examples = []\n","\n","# 각 엡실론에 대해 테스트 함수를 실행합니다\n","acc, ex, ad_examples, orig_labels = pgd_attack(model, data_test.x_test, data_test.y_test, alpha,iterations,epsilon) # 9 min"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yGMmo6w-ahpY","executionInfo":{"status":"ok","timestamp":1663304925154,"user_tz":-540,"elapsed":16742,"user":{"displayName":"이진규","userId":"11520813773494359482"}},"outputId":"a90a3465-981e-4c3f-8b8d-247dc0fb5416"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["PGD: Test Accuracy = 1535 / 6180 = 0.2483818770226537\n"]}]},{"cell_type":"code","source":["ad_examples_BIM = np.array(ad_examples) # 이미 정규화되어서 나온 값으로 추가적인 /255 정규화 필요 없음\n","orig_labels_BIM = to_categorical(orig_labels)\n","\n","print(ad_examples_BIM.shape)\n","print(orig_labels_BIM.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K94xz2Q9ahr0","executionInfo":{"status":"ok","timestamp":1663305214566,"user_tz":-540,"elapsed":303,"user":{"displayName":"이진규","userId":"11520813773494359482"}},"outputId":"7b169faf-0521-4d61-8f12-6f260408de2b"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["(5502, 32, 32, 3)\n","(5502, 12)\n"]}]},{"cell_type":"code","source":["plt.imshow(ad_examples_BIM[3])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":302},"id":"vi2l584lBXYh","executionInfo":{"status":"ok","timestamp":1663305221501,"user_tz":-540,"elapsed":695,"user":{"displayName":"이진규","userId":"11520813773494359482"}},"outputId":"e9af3bfb-dc8c-4c16-99fb-f5905f7d25a5"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"]},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f2bd8309d10>"]},"metadata":{},"execution_count":26},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["loss, accuracy = model.evaluate(ad_examples_BIM, orig_labels_BIM)\n","\n","print('test(not train) set attacked accuracy: ', accuracy * 100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IAajVuF-iKd7","executionInfo":{"status":"ok","timestamp":1663305228783,"user_tz":-540,"elapsed":1800,"user":{"displayName":"이진규","userId":"11520813773494359482"}},"outputId":"d9ea4837-c1a6-457a-ee2e-5b0329487218"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["172/172 [==============================] - 2s 9ms/step - loss: 0.6844 - accuracy: 0.2790\n","test(not train) set attacked accuracy:  27.898946404457092\n"]}]},{"cell_type":"markdown","source":["### DefenseGAN 구현 - BIM\n","\n"],"metadata":{"id":"2TtBNBJxn2Db"}},{"cell_type":"code","source":["ad_examples_BIM = np.array(ad_examples) # 이미 정규화되어서 나온 값으로 추가적인 /255 정규화 필요 없음\n","orig_labels_BIM = to_categorical(orig_labels)\n","\n","print(ad_examples_BIM.shape)\n","print(orig_labels_BIM.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fhZ-PyFGn3lz","executionInfo":{"status":"ok","timestamp":1663305243611,"user_tz":-540,"elapsed":690,"user":{"displayName":"이진규","userId":"11520813773494359482"}},"outputId":"5ad05b27-40c1-42b6-ce37-2aec7a6c2e76"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["(5502, 32, 32, 3)\n","(5502, 12)\n"]}]},{"cell_type":"code","source":["# GAN 모델 저장\n","from keras.models import load_model\n","\n","generator_base = load_model('baseGAN_Generator_attacked0.02.h5')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lZngn6VduEUE","executionInfo":{"status":"ok","timestamp":1663305365173,"user_tz":-540,"elapsed":1323,"user":{"displayName":"이진규","userId":"11520813773494359482"}},"outputId":"33d6e829-fe10-49ec-8f0e-6fb8098b13c2"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"]}]},{"cell_type":"code","source":["plt.imshow(generator_base.predict(np.random.normal(0, 1, (1, 100))).reshape(32,32,3))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":302},"id":"P4m8Jituudng","executionInfo":{"status":"ok","timestamp":1663305448563,"user_tz":-540,"elapsed":429,"user":{"displayName":"이진규","userId":"11520813773494359482"}},"outputId":"4e52cdd6-79e2-4c28-fe91-a52a7900020c"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"]},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f2bee2ea350>"]},"metadata":{},"execution_count":41},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["def DefenseGAN(img_at,L,R):\n","    z_list = []\n","    img = img_at.reshape(32,32,3)\n","    img_st = (img - np.mean(img)) / np.std(img) \n","    img_var = tf.Variable(img_st,dtype = float)\n","    opt = tf.keras.optimizers.SGD(learning_rate=0.1,momentum = 0.7)\n","\n","    def compute():\n","        z_hats_recs = generator_base(z_var)\n","        z_hats_recs = tf.reshape(z_hats_recs, [32,32,3])\n","        num_dim = len(z_hats_recs.get_shape())\n","        axes = range(1, num_dim)\n","        image_rec_loss = tf.reduce_mean(tf.square(z_hats_recs - img_var),axis=axes)\n","        rec_loss = tf.reduce_sum(image_rec_loss)\n","        return rec_loss\n","\n","    for r in range(R):\n","        z = np.random.normal(0, 1, (1, 100))\n","        z_var = tf.Variable(z,dtype = float)\n","    \n","        for l in range(L):\n","            opt.minimize(compute,[z_var])\n","        z_list.append(z_var)\n","\n","    def compute_10(z):\n","        #generator_base.trainable = False #아직 더해야하는지 뺴야하는지 판단 x\n","        z_hats_recs = generator_base(z)\n","        z_hats_recs = tf.reshape(z_hats_recs, [32,32,3])\n","        num_dim = len(z_hats_recs.get_shape())\n","        axes = range(1, num_dim)\n","        image_rec_loss = tf.reduce_mean(tf.square(z_hats_recs - img_var),axis=axes)\n","        rec_loss = tf.reduce_sum(image_rec_loss)\n","        return rec_loss\n","    \n","\n","    loss_list = []\n","    \n","    for i in range(len(z_list)):\n","        loss = compute_10(z_list[i])\n","        loss_list.append(loss)\n","    \n","    index_min = np.argmin(loss_list)\n","\n","    z_min = np.array(z_list[index_min])\n","\n","    generated_images = 0.5 * generator_base.predict(z_min)+ 0.5\n","\n","    generated_images = generated_images.reshape(32,32,3)\n","\n","    return generated_images"],"metadata":{"id":"2Zppe2W6n3n9","executionInfo":{"status":"ok","timestamp":1663305450402,"user_tz":-540,"elapsed":353,"user":{"displayName":"이진규","userId":"11520813773494359482"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["## predict_output에 한개씩 넣는 것부터 구현해야한다. (전체가 들어가는 것만 정상 작동함)\n","\n","def test(classifier, ad_example_data, orig_label_data):\n","\n","    # 정확도 카운터\n","    correct = 0\n","    defense_correct = 0\n","    df_examples = []\n","    # 테스트 셋의 모든 예제에 대해 루프를 돕니다\n","\n","    loss, accuracy = classifier.evaluate(ad_example_data, orig_label_data)\n","\n","    print('방어 전 모델 정확도 : ',accuracy * 100)\n","\n","    for i in range(len(ad_example_data)):\n","        data = ad_example_data[i].reshape(-1,32,32,3)\n","        target = orig_label_data[i]\n","        \n","        data_plot = data.reshape(32,32,3)\n","        print('원본 label : ',np.argmax(target))\n","        plt.imshow(data_plot)\n","        plt.show();\n","\n","        generated_img = DefenseGAN(data.reshape(32,32,3),200,10).reshape(-1,32,32,3)\n","\n","        generated_img_plot = generated_img.reshape(32,32,3)\n","\n","\n","        defense_output = classifier.predict(generated_img.reshape(1,32,32,3))\n","\n","        defense_pred= int(np.argmax(defense_output))\n","\n","        print('방어 라벨 : ',defense_pred)\n","        plt.imshow(generated_img_plot)\n","        plt.show();\n","\n","        if defense_pred == int(np.argmax(target)):\n","            defense_correct += 1\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","        else:\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","\n","        print('Working...!')\n","\n","\n","    defense_acc = defense_correct / float(len(ad_example_data))\n","    print(\"Defense Accuracy = {} / {} = {}\".format(defense_correct, len(ad_example_data), defense_acc))\n","    # 정확도와 적대적 예제를 리턴합니다\n","    return defense_acc, df_examples"],"metadata":{"id":"HsGI-NY4n3qe","executionInfo":{"status":"ok","timestamp":1663305457874,"user_tz":-540,"elapsed":393,"user":{"displayName":"이진규","userId":"11520813773494359482"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["accuracies_df = []\n","examples_df = []\n","\n","acc_df, ex_df = test(model, ad_examples_BIM[:100], orig_labels_BIM[:100])\n","\n","accuracies_df.append(acc_df)\n","examples_df.append(ex_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"188wZX872Go5ZaYkUPZlQi0R700-hWU3z"},"id":"qnYmHP5Bn3tC","executionInfo":{"status":"ok","timestamp":1663307724118,"user_tz":-540,"elapsed":75739,"user":{"displayName":"이진규","userId":"11520813773494359482"}},"outputId":"04c3b02f-12ce-4adc-edfa-6bf3e608ce74"},"execution_count":44,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["### Defense 2 : PCA (Components = 5)"],"metadata":{"id":"hGoEmuWF4S1T"}},{"cell_type":"code","source":["ad_examples_BIM = np.array(ad_examples) # 이미 정규화되어서 나온 값으로 추가적인 /255 정규화 필요 없음\n","orig_labels_BIM = to_categorical(orig_labels)\n","\n","print(ad_examples_BIM.shape)\n","print(orig_labels_BIM.shape)\n","\n","from sklearn.decomposition import PCA\n","\n","# data shape이 32,32,3이어야한다.\n","def defense_PCA(data,component):\n","    #r,g,b를 각각 나눠준다\n","    data = data.reshape(32,32,3)\n","    r = data[:,:,0]\n","    g = data[:,:,1]\n","    b = data[:,:,2]\n","\n","    pca_r = PCA(n_components=component)\n","    pca_r_trans = pca_r.fit_transform(r)\n","\n","    pca_g = PCA(n_components=component)\n","    pca_g_trans = pca_g.fit_transform(g)\n","\n","    pca_b = PCA(n_components=component)\n","    pca_b_trans = pca_b.fit_transform(b)\n","\n","    pca_r_org = pca_r.inverse_transform(pca_r_trans)\n","    pca_g_org = pca_g.inverse_transform(pca_g_trans)\n","    pca_b_org = pca_b.inverse_transform(pca_b_trans)\n","\n","    img_compressed = np.stack((pca_r_org, pca_g_org, pca_b_org),axis = 2)\n","\n","    return img_compressed.reshape((-1,32,32,3))\n","\n","## predict_output에 한개씩 넣는 것부터 구현해야한다. (전체가 들어가는 것만 정상 작동함)\n","\n","def test(classifier, ad_example_data, orig_label_data):\n","\n","    # 정확도 카운터\n","    correct = 0\n","    defense_correct = 0\n","    df_examples = []\n","    # 테스트 셋의 모든 예제에 대해 루프를 돕니다\n","\n","    loss, accuracy = classifier.evaluate(ad_examples_BIM, orig_labels_BIM)\n","\n","    print('방어 전 모델 정확도 : ',accuracy * 100)\n","\n","    for i in range(len(ad_example_data)):\n","        data = ad_example_data[i].reshape(-1,32,32,3)\n","        target = orig_label_data[i]\n","        \n","        data_plot = data.reshape(32,32,3)\n","        print('원본 label : ',np.argmax(target))\n","        plt.imshow(data_plot)\n","        plt.show();\n","\n","        generated_img = defense_PCA(data,5)\n","\n","        generated_img_plot = generated_img.reshape(32,32,3)\n","\n","        defense_output = classifier.predict(generated_img.reshape(1,32,32,3))\n","\n","        defense_pred= int(np.argmax(defense_output))\n","\n","        print('방어 라벨 : ',defense_pred)\n","        plt.imshow(generated_img_plot)\n","        plt.show();\n","\n","        if defense_pred == int(np.argmax(target)):\n","            defense_correct += 1\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","        else:\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","\n","        print('Working...!')\n","\n","\n","    defense_acc = defense_correct / float(len(ad_example_data))\n","    print(\"Defense Accuracy = {} / {} = {}\".format(defense_correct, len(ad_example_data), defense_acc))\n","    # 정확도와 적대적 예제를 리턴합니다\n","    return defense_acc, df_examples"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sP6AyMGH4bkk","executionInfo":{"status":"ok","timestamp":1663308088957,"user_tz":-540,"elapsed":283,"user":{"displayName":"이진규","userId":"11520813773494359482"}},"outputId":"b8a8c154-5586-47ab-ae52-2bb3dbbcf3a5"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["(5502, 32, 32, 3)\n","(5502, 12)\n"]}]},{"cell_type":"code","source":["accuracies_df = []\n","examples_df = []\n","\n","acc_df, ex_df = test(model, ad_examples_BIM[:1000], orig_labels_BIM[:1000])\n","\n","accuracies_df.append(acc_df)\n","examples_df.append(ex_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"11q3ZMKV2KjaRc2ktOF8BuRUtW9-yUVx1"},"id":"pJv8QiS94bm8","executionInfo":{"status":"ok","timestamp":1663308966717,"user_tz":-540,"elapsed":35747,"user":{"displayName":"이진규","userId":"11520813773494359482"}},"outputId":"a91ac3a8-1d55-4c31-8edb-097df9bb3000"},"execution_count":48,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["### Defense 2 : PCA (Components = 10)"],"metadata":{"id":"7rWZ6_Kf48hG"}},{"cell_type":"code","source":["ad_examples_BIM = np.array(ad_examples) # 이미 정규화되어서 나온 값으로 추가적인 /255 정규화 필요 없음\n","orig_labels_BIM = to_categorical(orig_labels)\n","\n","print(ad_examples_BIM.shape)\n","print(orig_labels_BIM.shape)\n","\n","from sklearn.decomposition import PCA\n","\n","# data shape이 32,32,3이어야한다.\n","def defense_PCA(data,component):\n","    #r,g,b를 각각 나눠준다\n","    data = data.reshape(32,32,3)\n","    r = data[:,:,0]\n","    g = data[:,:,1]\n","    b = data[:,:,2]\n","\n","    pca_r = PCA(n_components=component)\n","    pca_r_trans = pca_r.fit_transform(r)\n","\n","    pca_g = PCA(n_components=component)\n","    pca_g_trans = pca_g.fit_transform(g)\n","\n","    pca_b = PCA(n_components=component)\n","    pca_b_trans = pca_b.fit_transform(b)\n","\n","    pca_r_org = pca_r.inverse_transform(pca_r_trans)\n","    pca_g_org = pca_g.inverse_transform(pca_g_trans)\n","    pca_b_org = pca_b.inverse_transform(pca_b_trans)\n","\n","    img_compressed = np.stack((pca_r_org, pca_g_org, pca_b_org),axis = 2)\n","\n","    return img_compressed.reshape((-1,32,32,3))\n","\n","## predict_output에 한개씩 넣는 것부터 구현해야한다. (전체가 들어가는 것만 정상 작동함)\n","\n","def test(classifier, ad_example_data, orig_label_data):\n","\n","    # 정확도 카운터\n","    correct = 0\n","    defense_correct = 0\n","    df_examples = []\n","    # 테스트 셋의 모든 예제에 대해 루프를 돕니다\n","\n","    loss, accuracy = classifier.evaluate(ad_examples_BIM, orig_labels_BIM)\n","\n","    print('방어 전 모델 정확도 : ',accuracy * 100)\n","\n","    for i in range(len(ad_example_data)):\n","        data = ad_example_data[i].reshape(-1,32,32,3)\n","        target = orig_label_data[i]\n","        \n","        data_plot = data.reshape(32,32,3)\n","        print('원본 label : ',np.argmax(target))\n","        plt.imshow(data_plot)\n","        plt.show();\n","\n","        generated_img = defense_PCA(data,10)\n","\n","        generated_img_plot = generated_img.reshape(32,32,3)\n","\n","        defense_output = classifier.predict(generated_img.reshape(1,32,32,3))\n","\n","        defense_pred= int(np.argmax(defense_output))\n","\n","        print('방어 라벨 : ',defense_pred)\n","        plt.imshow(generated_img_plot)\n","        plt.show();\n","\n","        if defense_pred == int(np.argmax(target)):\n","            defense_correct += 1\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","        else:\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","\n","        print('Working...!')\n","\n","\n","    defense_acc = defense_correct / float(len(ad_example_data))\n","    print(\"Defense Accuracy = {} / {} = {}\".format(defense_correct, len(ad_example_data), defense_acc))\n","    # 정확도와 적대적 예제를 리턴합니다\n","    return defense_acc, df_examples"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fpPzHByO4bpO","executionInfo":{"status":"ok","timestamp":1663308966719,"user_tz":-540,"elapsed":19,"user":{"displayName":"이진규","userId":"11520813773494359482"}},"outputId":"d99d8660-60c8-4951-ae1c-ae7c8a767211"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["(5502, 32, 32, 3)\n","(5502, 12)\n"]}]},{"cell_type":"code","source":["accuracies_df = []\n","examples_df = []\n","\n","acc_df, ex_df = test(model, ad_examples_BIM[:1000], orig_labels_BIM[:1000])\n","\n","accuracies_df.append(acc_df)\n","examples_df.append(ex_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1oqmMrm5X8HVYaz89sXePvVDa2Ouuapha"},"id":"aCH5IdKe4br4","executionInfo":{"status":"ok","timestamp":1663309451489,"user_tz":-540,"elapsed":20813,"user":{"displayName":"이진규","userId":"11520813773494359482"}},"outputId":"0785203c-506b-4f24-e4b5-7ee218ec96e3"},"execution_count":50,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["### PGD\n","\n","Projected Gradient Descent를 통해 공격하겠다"],"metadata":{"id":"xndkVAn_l18l"}},{"cell_type":"code","source":["data.x_train, data.y_train, data.x_test, data.y_test\n","print('train x 데이터 : ',data.x_train.shape)\n","print('train y 데이터 : ',data.y_train.shape)\n","print('test x 데이터 : ',data.x_test.shape)\n","print('test y 데이터 : ',data.y_test.shape)"],"metadata":{"id":"F9nSAT6Dl7iC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def tf_preprocess(image):\n","  image = tf.cast(image, tf.float32)\n","  image = image/255\n","  image = tf.image.resize(image, (32, 32))\n","  image = image[None, ...]\n","  return image\n","\n","# 확률 벡터에서 레이블을 추출해주는 헬퍼 메서드\n","def get_tf_label(labels):\n","    label = tf.cast(labels, tf.int32)\n","    label = tf.reshape(label,[1,12])\n","    return label\n","\n","loss_object = tf.keras.losses.CategoricalCrossentropy()\n","\n","def pgd_attack(model,test_x,test_y,alpha,iterations,epsilon):\n","    \n","    correct = 0\n","    adv_examples = []\n","    save_adv_examples = []\n","    save_original_output = []\n","    \n","    for i in range(len(test_x)):\n","        data = test_x[i]\n","        target = test_y[i]\n","\n","        result = model.predict(data.reshape(1,32,32,3) / 255)\n","        init_output = int(np.argmax(result))\n"," \n","        if init_output != np.argmax(target):\n","            continue\n","\n","        img =  tf_preprocess(data)\n","        label = get_tf_label(target)\n","\n","        gen_img = img + tf.random.uniform(img.get_shape().as_list(), minval=-epsilon, maxval=+epsilon, dtype=tf.dtypes.float32)\n","\n","        for iters in range(iterations):\n","            imgv = tf.Variable(gen_img)\n","            with tf.GradientTape() as tape:\n","                tape.watch(imgv)\n","                predictions = model(imgv)\n","                loss = tf.keras.losses.CategoricalCrossentropy()(label, predictions)\n","            grads = tape.gradient(loss,imgv)\n","            signed_grads = tf.sign(grads)\n","            gen_img = gen_img + (alpha  * signed_grads)\n","            gen_img = tf.clip_by_value(gen_img, img-epsilon, img+epsilon)\n","\n","        adv_x = gen_img\n","\n","        output = model.predict(adv_x)\n","\n","        final_pred = int(np.argmax(output))\n","\n","        if final_pred == int(np.argmax(target)):\n","            correct += 1\n","            if (len(adv_examples) < 5):\n","                adv_ex = adv_x\n","                adv_examples.append((init_output,final_pred,adv_x))\n","        else:\n","            if len(adv_examples) < 5:\n","                adv_ex = adv_x\n","                adv_examples.append((init_output,final_pred,adv_x))\n","\n","        save_adv_examples.append(tf.reshape(adv_x,[32,32,3]))\n","        save_original_output.append(init_output)\n","\n","\n","    # 해당 엡실론에서의 최종 정확도를 계산합니다\n","    final_acc = correct/float(len(test_x))\n","    print(\"PGD: Test Accuracy = {} / {} = {}\".format(correct, len(test_x), final_acc))\n","\n","    # 정확도와 적대적 예제를 리턴합니다\n","    return final_acc, adv_examples, save_adv_examples, save_original_output"],"metadata":{"id":"npNQ6WzTl7kK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"gHWX4Z0Dl7my"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"csJrptwZl7pH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"nXAsukc7l7rb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"erOxaHtql7tg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ISV4UKP5iuVe"},"source":["### FGSM \n","epsilon = 0.04로 FGSM Attack을 가해주겠다"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YODdh4SOizoe"},"outputs":[],"source":["def tf_preprocess(image):\n","  image = tf.cast(image, tf.float32)\n","  image = image/255\n","  image = tf.image.resize(image, (32, 32))\n","  image = image[None, ...]\n","  return image\n","\n","# 확률 벡터에서 레이블을 추출해주는 헬퍼 메서드\n","def get_tf_label(labels):\n","    label = tf.cast(labels, tf.int32)\n","    label = tf.reshape(label,[1,12])\n","    return label\n","\n","loss_object = tf.keras.losses.CategoricalCrossentropy()\n","\n","def create_adversarial_pattern(input_image, input_label):\n","  with tf.GradientTape() as tape:\n","    tape.watch(input_image)\n","    input_img = tf.reshape(input_image,[1,32,32,3])\n","    prediction = model(input_img)\n","    loss = loss_object(input_label, prediction)\n","\n","  # 입력 이미지에 대한 손실 함수의 기울기를 구합니다.\n","  gradient = tape.gradient(loss, input_image)\n","  # 왜곡을 생성하기 위해 그래디언트의 부호를 구합니다.\n","  signed_grad = tf.sign(gradient)\n","  return signed_grad\n","\n","def fgsm_attack(model,test_x,test_y,eps):\n","    \n","    correct = 0\n","    adv_examples = []\n","    save_adv_examples = []\n","    save_original_output = []\n","    \n","    for i in range(len(test_x)):\n","        data = test_x[i]\n","        target = test_y[i]\n","\n","        result = model.predict(data.reshape(1,32,32,3) / 255)\n","        init_output = int(np.argmax(result))\n"," \n","        if init_output != np.argmax(target):\n","            continue\n","\n","        img =  tf_preprocess(data)\n","        label = get_tf_label(target)\n","        \n","        perturbations = create_adversarial_pattern(img, label)\n","\n","        adv_x = img + eps*perturbations\n","        adv_x = tf.clip_by_value(adv_x, 0, 1)\n","\n","\n","        output = model.predict(adv_x)\n","\n","        final_pred = int(np.argmax(output))\n","\n","        if final_pred == int(np.argmax(target)):\n","            correct += 1\n","            if (eps == 0) and (len(adv_examples) < 5):\n","                adv_ex = adv_x\n","                adv_examples.append((init_output,final_pred,adv_x))\n","        else:\n","            if len(adv_examples) < 5:\n","                adv_ex = adv_x\n","                adv_examples.append((init_output,final_pred,adv_x))\n","\n","        save_adv_examples.append(tf.reshape(adv_x,[32,32,3]))\n","        save_original_output.append(init_output)\n","\n","\n","    # 해당 엡실론에서의 최종 정확도를 계산합니다\n","    final_acc = correct/float(len(test_x))\n","    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(eps, correct, len(test_x), final_acc))\n","\n","    # 정확도와 적대적 예제를 리턴합니다\n","    return final_acc, adv_examples, save_adv_examples, save_original_output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AeIEH0YRi80g"},"outputs":[],"source":["eps = 0.04\n","\n","accuracies = []\n","examples = []\n","\n","# 각 엡실론에 대해 테스트 함수를 실행합니다\n","acc, ex, ad_examples, orig_labels = fgsm_attack(model, data_test.x_test, data_test.y_test, eps) # 9 min"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O8l7yFpnjg1y"},"outputs":[],"source":["ad_examples1 = np.array(ad_examples) # 이미 정규화되어서 나온 값으로 추가적인 /255 정규화 필요 없음\n","orig_labels1 = to_categorical(orig_labels)\n","\n","print(ad_examples1.shape)\n","print(orig_labels1.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bV-VLW3hjj4G"},"outputs":[],"source":["loss, accuracy = model.evaluate(ad_examples1, orig_labels1)\n","\n","print('test(not train) set attacked accuracy: ', accuracy * 100)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNRvxS2O0/0yVaHtoAKTCQX"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}