{"cells":[{"cell_type":"markdown","source":["데이터셋 설정 관련\n","* for문으로 돌리려다가, 방어기법에서까지 하나하나 돌리는게 너무 오래 걸려서 코드로 나누고 계정별로 돌릴 수 있게 코드 변경했습니다\n","* 공격 종류 (FGSM, PGD), 공격 입실론 (0.02 등)을 목차 [Attack 수행 : 공격 데이터셋 만드는 코드] 부분에서 수정하고 코드 돌리면 됩니다\n","\n","1. 모든 train valid 데이터는 0~1사이로 정규화 되어있음.\n","2. 모든 test 데이터는 0~255로 정규화 안되어있음\n","3. target 값은 정규화하면 안됨."],"metadata":{"id":"05NggkxjGxlN"}},{"cell_type":"markdown","source":["# 기본 import"],"metadata":{"id":"H5r08xIXerXB"}},{"cell_type":"code","execution_count":4,"metadata":{"id":"WgKss5hJBb5B","executionInfo":{"status":"ok","timestamp":1663465318096,"user_tz":-540,"elapsed":3176,"user":{"displayName":"이진규","userId":"11520813773494359482"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","import os\n","import pathlib\n","\n","import cv2 #영상처리에 사용하는 오픈소스 라이브러리, 컴퓨터가 사람 눈처럼 인식할 수 있게 처리\n","from PIL import Image # 파이썬 이미지 처리 pillow 라이브러리\n","from tensorflow.keras.preprocessing import image\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator #imagedatagenerater는 이미지를 학습시킬 때 학습 데이터의 양이 적을 경우 학습데이터를 조금씩 변형 시켜서 학습데이터의 양을 늘리는 방식중 하나\n","from tensorflow.keras.preprocessing.image import img_to_array, array_to_img, load_img\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n","from tensorflow.keras.models import Sequential\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","from tqdm.auto import tqdm\n","\n","#난수 랜덤성 고정\n","np.random.seed(42)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20618,"status":"ok","timestamp":1663465601914,"user":{"displayName":"이진규","userId":"11520813773494359482"},"user_tz":-540},"id":"Qn7HC1qiBnNE","outputId":"7de24f7e-72a0-4ad6-bd80-52a9a2e54eec"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1075,"status":"ok","timestamp":1663465680854,"user":{"displayName":"이진규","userId":"11520813773494359482"},"user_tz":-540},"id":"VwTVXhm7BoaE","outputId":"948ddd2e-dde8-4dd8-bf3b-0fa974d32ca7"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1WKEjdIyqtzI-NV5o0O_ixsHslngaSiQX/[한이음] 적대적 AI 공격에 대한 인공지능 보안기술 연구/3. 소스코드/GTSRB\n"]}],"source":["cd drive/MyDrive/[한이음] 적대적 AI 공격에 대한 인공지능 보안기술 연구/3. 소스코드/GTSRB"]},{"cell_type":"markdown","source":["# Train & Test 데이터 불러오기"],"metadata":{"id":"FhnfS-0MH1sa"}},{"cell_type":"markdown","metadata":{"id":"JjBcm524Fams"},"source":["Train Data 불러오기"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"kZnmTWHIBo_E","executionInfo":{"status":"ok","timestamp":1663465681188,"user_tz":-540,"elapsed":2,"user":{"displayName":"이진규","userId":"11520813773494359482"}}},"outputs":[],"source":["import numpy as np\n","import os\n","import gzip\n","import urllib.request\n","\n","from keras.models import load_model\n","\n","def ordered_onehotencoding(labels):\n","    labels_ordered = []\n","    for i in range(len(labels)):\n","        if labels[i] == 3:\n","            labels_ordered.append(0)\n","        elif labels[i] == 7:\n","            labels_ordered.append(1)\n","        elif labels[i] == 9:\n","            labels_ordered.append(2)\n","        elif labels[i] == 10:\n","            labels_ordered.append(3)\n","        elif labels[i] == 11:\n","            labels_ordered.append(4)\n","        elif labels[i] == 12:\n","            labels_ordered.append(5)\n","        elif labels[i] == 13:\n","            labels_ordered.append(6)\n","        elif labels[i] == 17:\n","            labels_ordered.append(7)\n","        elif labels[i] == 18:\n","            labels_ordered.append(8)\n","        elif labels[i] == 25:\n","            labels_ordered.append(9)\n","        elif labels[i] == 35:\n","            labels_ordered.append(10)\n","        elif labels[i] == 38:\n","            labels_ordered.append(11)\n","    \n","    return np.array(labels_ordered)\n","\n","class GTSRB:\n","    def __init__(self):\n","        imgs_path = \"Train\"\n","        data_list = []\n","        labels_list = []\n","\n","        result_class = [3,7, 9, 10, 11, 12, 13, 17, 18, 25, 35, 38]\n","\n","        for i in result_class:\n","            i_path = os.path.join(imgs_path, str(i)) # 3, 7, 9, 10, 11, 12,13, 17, 18, 25, 35, 38\n","            num = 0\n","            for img in os.listdir(i_path):\n","          \n","                im = Image.open(i_path +'/'+ img)\n","                im = im.resize((32,32))\n","                im = np.array(im)\n","\n","                data_list.append(im)\n","                labels_list.append(i)\n","                num = num + 1\n","                if num == 1000:\n","                    break;\n","\n","        data = np.array(data_list)\n","        labels = ordered_onehotencoding(labels_list)\n","\n","        labels = to_categorical(labels)\n","\n","        VALIDATION_SIZE = 5000\n","        \n","        self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(np.array(data), labels, test_size=0.4)    \n","\n","    @staticmethod\n","    def print():\n","        return \"GTSRB\""]},{"cell_type":"code","execution_count":53,"metadata":{"id":"lWo9BzndEm67","executionInfo":{"status":"ok","timestamp":1663469094454,"user_tz":-540,"elapsed":23317,"user":{"displayName":"이진규","userId":"11520813773494359482"}}},"outputs":[],"source":["data = GTSRB()"]},{"cell_type":"code","execution_count":54,"metadata":{"id":"Zc5Q_EXiEppb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663469097592,"user_tz":-540,"elapsed":311,"user":{"displayName":"이진규","userId":"11520813773494359482"}},"outputId":"3151fe4c-b5dc-4e30-debb-ad26f1f3caab"},"outputs":[{"output_type":"stream","name":"stdout","text":["(7200, 32, 32, 3)\n","(4800, 32, 32, 3)\n","(7200, 12)\n","(4800, 12)\n"]}],"source":["print(data.x_train.shape) # 0~255\n","print(data.x_test.shape) # 0~255\n","print(data.y_train.shape) # 0~11 원핫 인코딩\n","print(data.y_test.shape) # 0~11 원핫 인코딩"]},{"cell_type":"code","source":["print(np.min(data.x_train))\n","print(np.max(data.x_train))\n","print(np.min(data.x_test))\n","print(np.max(data.x_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JtM8GsuYfDFc","executionInfo":{"status":"ok","timestamp":1663469216555,"user_tz":-540,"elapsed":297,"user":{"displayName":"이진규","userId":"11520813773494359482"}},"outputId":"2532375f-5083-4aaa-b628-b695737742dd"},"execution_count":60,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","255\n","0\n","255\n"]}]},{"cell_type":"code","source":["data.x_train, data.y_train, data.x_test, data.y_test =data.x_train/255, data.y_train, data.x_test/255, data.y_test #0~1로 찐 train만 정규화"],"metadata":{"id":"L88pCixpf4wC","executionInfo":{"status":"ok","timestamp":1663469347152,"user_tz":-540,"elapsed":303,"user":{"displayName":"이진규","userId":"11520813773494359482"}}},"execution_count":62,"outputs":[]},{"cell_type":"code","source":["print(np.min(data.x_train))\n","print(np.max(data.x_train))\n","print(np.min(data.x_test))\n","print(np.max(data.x_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YoKSRN2ef-n0","executionInfo":{"status":"ok","timestamp":1663469392168,"user_tz":-540,"elapsed":305,"user":{"displayName":"이진규","userId":"11520813773494359482"}},"outputId":"46e45640-47f6-43c1-980c-b3dce806eeb0"},"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["0.0\n","1.0\n","0.0\n","1.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"P2uSEM66FdVa"},"source":["Test Data 불러오기"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"_shX58HHFisj","executionInfo":{"status":"ok","timestamp":1663465988354,"user_tz":-540,"elapsed":1350,"user":{"displayName":"이진규","userId":"11520813773494359482"}}},"outputs":[],"source":["metainfo = pd.read_csv(\"Meta.csv\")\n","traininfo = pd.read_csv(\"Train.csv\")\n","testinfo = pd.read_csv(\"Test.csv\")"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"z9HPAPg2FZ9L","executionInfo":{"status":"ok","timestamp":1663465988355,"user_tz":-540,"elapsed":4,"user":{"displayName":"이진규","userId":"11520813773494359482"}}},"outputs":[],"source":["import natsort\n","\n","class GTSRB_test:\n","    def __init__(self):\n","        imgs_path = \"Test\"\n","        data_list = []\n","        labels_list = []\n","        \n","        for img in natsort.natsorted(os.listdir(imgs_path)):\n","            im = Image.open(imgs_path +'/'+ img)\n","            im = im.resize((32,32))\n","            im = np.array(im)\n","            data_list.append(im)\n","        data_test = np.array(data_list)\n","        \n","        for i in range(len(testinfo.ClassId)):\n","            labels_list.append(testinfo.ClassId[i])\n","        \n","        labels_test = np.array(labels_list)\n","\n","        labels_test_index = []\n","        for i in range(len(labels_test)):\n","            if (labels_test[i] == 3) | (labels_test[i] == 7) | (labels_test[i] == 9) | (labels_test[i] == 10) | (labels_test[i] == 11) | (labels_test[i] == 12) | (labels_test[i] == 13) | (labels_test[i] == 17) | (labels_test[i] == 18) | (labels_test[i] == 25) | (labels_test[i] == 35) | (labels_test[i] == 38):\n","                labels_test_index.append(i)\n","\n","        test_data = []\n","        test_label = []\n","        for i in labels_test_index:\n","            test_data.append(data_test[i])\n","            test_label.append(labels_test[i])\n","\n","        data_test = np.array(test_data)\n","\n","        labels_test =ordered_onehotencoding(test_label)\n","\n","        labels_test = to_categorical(labels_test)\n","        \n","        self.x_test = data_test\n","        self.y_test = labels_test    \n","\n","    @staticmethod\n","    def print():\n","        return \"GTSRB_test\""]},{"cell_type":"code","execution_count":57,"metadata":{"id":"CcWfJaa6Ft7z","executionInfo":{"status":"ok","timestamp":1663469188244,"user_tz":-540,"elapsed":23161,"user":{"displayName":"이진규","userId":"11520813773494359482"}}},"outputs":[],"source":["data_test = GTSRB_test()"]},{"cell_type":"code","execution_count":58,"metadata":{"id":"VE9NTZrAFv7e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663469188244,"user_tz":-540,"elapsed":4,"user":{"displayName":"이진규","userId":"11520813773494359482"}},"outputId":"fccc5bdf-0e3c-40c4-9629-e8aadb65efa7"},"outputs":[{"output_type":"stream","name":"stdout","text":["(6180, 32, 32, 3)\n","(6180, 12)\n"]}],"source":["print(data_test.x_test.shape) # 0~255\n","print(data_test.y_test.shape) # 12개 원핫 인코딩"]},{"cell_type":"code","source":["print(np.min(data_test.x_test))\n","print(np.max(data_test.x_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"phupmxLufTsN","executionInfo":{"status":"ok","timestamp":1663469241973,"user_tz":-540,"elapsed":360,"user":{"displayName":"이진규","userId":"11520813773494359482"}},"outputId":"fc4da171-bbf8-4788-f605-396d8ed962ab"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","255\n"]}]},{"cell_type":"markdown","metadata":{"id":"XWfrLWt3EtSN"},"source":["# 분류기 : CNN"]},{"cell_type":"code","source":["print(np.min(data.x_train))\n","print(np.max(data.x_train))\n","print(np.min(data.x_test))\n","print(np.max(data.x_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-Ll78wYPewyM","executionInfo":{"status":"ok","timestamp":1663469422470,"user_tz":-540,"elapsed":298,"user":{"displayName":"이진규","userId":"11520813773494359482"}},"outputId":"3b88a5b4-582f-4ad2-b6f7-bc42134d0611"},"execution_count":65,"outputs":[{"output_type":"stream","name":"stdout","text":["0.0\n","1.0\n","0.0\n","1.0\n"]}]},{"cell_type":"code","execution_count":66,"metadata":{"id":"gI5nIfEQE0Dt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663469473323,"user_tz":-540,"elapsed":40693,"user":{"displayName":"이진규","userId":"11520813773494359482"}},"outputId":"6dc65f64-4647-42a9-b5db-ef5b455958ba"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_9 (Conv2D)           (None, 30, 30, 96)        2688      \n","                                                                 \n"," max_pooling2d_6 (MaxPooling  (None, 15, 15, 96)       0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_6 (Dropout)         (None, 15, 15, 96)        0         \n","                                                                 \n"," conv2d_10 (Conv2D)          (None, 13, 13, 192)       166080    \n","                                                                 \n"," max_pooling2d_7 (MaxPooling  (None, 6, 6, 192)        0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_7 (Dropout)         (None, 6, 6, 192)         0         \n","                                                                 \n"," conv2d_11 (Conv2D)          (None, 4, 4, 192)         331968    \n","                                                                 \n"," flatten_3 (Flatten)         (None, 3072)              0         \n","                                                                 \n"," dense_6 (Dense)             (None, 64)                196672    \n","                                                                 \n"," dense_7 (Dense)             (None, 12)                780       \n","                                                                 \n","=================================================================\n","Total params: 698,188\n","Trainable params: 698,188\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/30\n","60/60 [==============================] - 2s 23ms/step - loss: 0.3242 - accuracy: 0.1147 - val_loss: 0.2878 - val_accuracy: 0.2433\n","Epoch 2/30\n","60/60 [==============================] - 1s 24ms/step - loss: 0.1860 - accuracy: 0.5776 - val_loss: 0.0972 - val_accuracy: 0.8579\n","Epoch 3/30\n","60/60 [==============================] - 1s 24ms/step - loss: 0.0660 - accuracy: 0.9103 - val_loss: 0.0406 - val_accuracy: 0.9523\n","Epoch 4/30\n","60/60 [==============================] - 1s 24ms/step - loss: 0.0326 - accuracy: 0.9615 - val_loss: 0.0237 - val_accuracy: 0.9731\n","Epoch 5/30\n","60/60 [==============================] - 1s 19ms/step - loss: 0.0205 - accuracy: 0.9771 - val_loss: 0.0139 - val_accuracy: 0.9894\n","Epoch 6/30\n","60/60 [==============================] - 1s 19ms/step - loss: 0.0145 - accuracy: 0.9842 - val_loss: 0.0114 - val_accuracy: 0.9910\n","Epoch 7/30\n","60/60 [==============================] - 1s 19ms/step - loss: 0.0112 - accuracy: 0.9878 - val_loss: 0.0089 - val_accuracy: 0.9896\n","Epoch 8/30\n","60/60 [==============================] - 1s 19ms/step - loss: 0.0082 - accuracy: 0.9918 - val_loss: 0.0067 - val_accuracy: 0.9954\n","Epoch 9/30\n","60/60 [==============================] - 1s 24ms/step - loss: 0.0067 - accuracy: 0.9943 - val_loss: 0.0061 - val_accuracy: 0.9960\n","Epoch 10/30\n","60/60 [==============================] - 1s 24ms/step - loss: 0.0052 - accuracy: 0.9956 - val_loss: 0.0049 - val_accuracy: 0.9962\n","Epoch 11/30\n","60/60 [==============================] - 1s 19ms/step - loss: 0.0045 - accuracy: 0.9967 - val_loss: 0.0044 - val_accuracy: 0.9965\n","Epoch 12/30\n","60/60 [==============================] - 1s 24ms/step - loss: 0.0036 - accuracy: 0.9965 - val_loss: 0.0040 - val_accuracy: 0.9965\n","Epoch 13/30\n","60/60 [==============================] - 1s 19ms/step - loss: 0.0030 - accuracy: 0.9979 - val_loss: 0.0039 - val_accuracy: 0.9960\n","Epoch 14/30\n","60/60 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.9986 - val_loss: 0.0037 - val_accuracy: 0.9969\n","Epoch 15/30\n","60/60 [==============================] - 1s 19ms/step - loss: 0.0020 - accuracy: 0.9987 - val_loss: 0.0033 - val_accuracy: 0.9975\n","Epoch 16/30\n","60/60 [==============================] - 1s 19ms/step - loss: 0.0022 - accuracy: 0.9986 - val_loss: 0.0035 - val_accuracy: 0.9962\n","Epoch 17/30\n","60/60 [==============================] - 1s 24ms/step - loss: 0.0018 - accuracy: 0.9987 - val_loss: 0.0036 - val_accuracy: 0.9971\n","Epoch 18/30\n","60/60 [==============================] - 1s 19ms/step - loss: 0.0017 - accuracy: 0.9990 - val_loss: 0.0031 - val_accuracy: 0.9973\n","Epoch 19/30\n","60/60 [==============================] - 1s 24ms/step - loss: 0.0015 - accuracy: 0.9990 - val_loss: 0.0031 - val_accuracy: 0.9975\n","Epoch 20/30\n","60/60 [==============================] - 1s 24ms/step - loss: 0.0013 - accuracy: 0.9992 - val_loss: 0.0031 - val_accuracy: 0.9971\n","Epoch 21/30\n","60/60 [==============================] - 1s 19ms/step - loss: 9.5804e-04 - accuracy: 0.9997 - val_loss: 0.0041 - val_accuracy: 0.9965\n","Epoch 22/30\n","60/60 [==============================] - 1s 24ms/step - loss: 8.7626e-04 - accuracy: 0.9999 - val_loss: 0.0033 - val_accuracy: 0.9973\n","Epoch 23/30\n","60/60 [==============================] - 1s 24ms/step - loss: 7.2241e-04 - accuracy: 0.9999 - val_loss: 0.0031 - val_accuracy: 0.9975\n","Epoch 24/30\n","60/60 [==============================] - 1s 24ms/step - loss: 7.2839e-04 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 0.9967\n","Epoch 25/30\n","60/60 [==============================] - 1s 24ms/step - loss: 7.4552e-04 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9969\n","Epoch 26/30\n","60/60 [==============================] - 1s 19ms/step - loss: 8.2118e-04 - accuracy: 0.9996 - val_loss: 0.0042 - val_accuracy: 0.9962\n","Epoch 27/30\n","60/60 [==============================] - 1s 24ms/step - loss: 7.3108e-04 - accuracy: 0.9999 - val_loss: 0.0035 - val_accuracy: 0.9969\n","Epoch 28/30\n","60/60 [==============================] - 1s 19ms/step - loss: 8.9766e-04 - accuracy: 0.9996 - val_loss: 0.0054 - val_accuracy: 0.9944\n","Epoch 29/30\n","60/60 [==============================] - 1s 19ms/step - loss: 9.9903e-04 - accuracy: 0.9996 - val_loss: 0.0034 - val_accuracy: 0.9969\n","Epoch 30/30\n","60/60 [==============================] - 1s 24ms/step - loss: 6.3994e-04 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9971\n"]}],"source":["from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D,GlobalAveragePooling2D\n","from tensorflow.keras.optimizers import SGD\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","import tensorflow as tf\n","import os\n","\n","\n","def train(data, file_name, num_epochs=50, batch_size=128):\n","    \"\"\"\n","    Standard neural network training procedure.\n","    \"\"\"\n","    model = Sequential()\n","\n","    IMG_HEIGHT = 32\n","    IMG_WIDTH = 32\n","\n","    # 첫번째 Convolutional Layer : 입력 데이터로부터 특징을 추출\n","    model.add(Conv2D(filters=96, kernel_size=3, activation='relu', input_shape=data.x_train.shape[1:]))\n","    model.add(MaxPool2D(pool_size=(2, 2)))\n","    model.add(Dropout(rate=0.25))\n","\n","    # 두번째 Convolutional Layer\n","    model.add(Conv2D(filters=192, kernel_size=3, activation='relu'))\n","    model.add(MaxPool2D(pool_size=(2, 2)))\n","    model.add(Dropout(rate=0.25)) # 인풋데이터의 25%를 무작위로 0으로 만듦\n","\n","    # 세번째 Convolutional Layer\n","    model.add(Conv2D(filters=192, kernel_size=3, activation='relu')) # 특징을 추출하는 기능을 하는 필터, 비선형 값으로 바꿔주는 activation 함수->relu\n","    # model.add(GlobalAveragePooling2D())\n","    model.add(Flatten())\n","\n","    model.add(Dense(units=64, activation='relu'))\n","    model.add(Dense(12, activation='softmax'))\n","\n","\n","    # 모델 컴파일 하기\n","    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    model.summary()\n","\n","    # 모델 핏하기\n","    EPOCHS = num_epochs\n","    model.fit(data.x_train, data.y_train,\n","              validation_data = (data.x_test, data.y_test), \n","              epochs=EPOCHS, steps_per_epoch=60\n","              )\n","\n","    if file_name != None:\n","        model.save(file_name)\n","\n","    return model\n","\n","\n","if not os.path.isdir('models'):\n","    os.makedirs('models')\n","\n","model = train(data, \"models/gtsrb_classifier\", num_epochs=30)"]},{"cell_type":"code","execution_count":67,"metadata":{"id":"Ez-W2phKFLws","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663469480030,"user_tz":-540,"elapsed":1990,"user":{"displayName":"이진규","userId":"11520813773494359482"}},"outputId":"81db25b6-d61c-4191-cdc9-4cae04a9fe6c"},"outputs":[{"output_type":"stream","name":"stdout","text":["225/225 [==============================] - 1s 3ms/step - loss: 3.0757e-04 - accuracy: 0.9999\n","train set accuracy:  99.98611211776733\n","150/150 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 0.9971\n","valid set accuracy:  99.7083306312561\n"]}],"source":["loss, accuracy = model.evaluate(data.x_train, data.y_train)\n","\n","print('train set accuracy: ', accuracy * 100) #train 성능\n","\n","loss, accuracy = model.evaluate(data.x_test, data.y_test)\n","\n","print('valid set accuracy: ', accuracy * 100) #val 성능"]},{"cell_type":"code","execution_count":68,"metadata":{"id":"xbYmfSHYHOIa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663469499311,"user_tz":-540,"elapsed":1720,"user":{"displayName":"이진규","userId":"11520813773494359482"}},"outputId":"8e7e9742-cc15-48fa-c7d1-e3d234ecae49"},"outputs":[{"output_type":"stream","name":"stdout","text":["194/194 [==============================] - 1s 4ms/step - loss: 0.0281 - accuracy: 0.9757\n","test set accuracy with nomalization:  97.57281541824341\n"]}],"source":["loss, accuracy = model.evaluate(data_test.x_test/255, data_test.y_test)\n","\n","print('test set accuracy with nomalization: ', accuracy * 100) #찐 test"]},{"cell_type":"markdown","source":["# 공격 데이터셋 : FGSM & PGD"],"metadata":{"id":"QNRCIvO3-8lf"}},{"cell_type":"code","source":["def tf_preprocess(image):\n","  image = tf.cast(image, tf.float32)\n","  image = image/255\n","  image = tf.image.resize(image, (32, 32))\n","  image = image[None, ...]\n","  return image\n","\n","# 확률 벡터에서 레이블을 추출해주는 헬퍼 메서드\n","def get_tf_label(labels):\n","    label = tf.cast(labels, tf.int32)\n","    label = tf.reshape(label,[1,12])\n","    return label\n","\n","loss_object = tf.keras.losses.CategoricalCrossentropy()\n","\n","def create_adversarial_pattern(input_image, input_label):\n","  with tf.GradientTape() as tape:\n","    tape.watch(input_image)\n","    input_img = tf.reshape(input_image,[1,32,32,3])\n","    prediction = model(input_img)\n","    loss = loss_object(input_label, prediction)\n","\n","  # 입력 이미지에 대한 손실 함수의 기울기를 구합니다.\n","  gradient = tape.gradient(loss, input_image)\n","  # 왜곡을 생성하기 위해 그래디언트의 부호를 구합니다.\n","  signed_grad = tf.sign(gradient)\n","  return signed_grad"],"metadata":{"id":"Dn9x64obA9UB","executionInfo":{"status":"ok","timestamp":1663469628864,"user_tz":-540,"elapsed":294,"user":{"displayName":"이진규","userId":"11520813773494359482"}}},"execution_count":69,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4SUb6-MoJtay"},"source":["### FGSM & PGD define"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DGBdi7tWJT1K"},"outputs":[],"source":["def fgsm_attack(model,test_x,test_y,eps):\n","    \n","    correct = 0\n","    adv_examples = []\n","    save_adv_examples = [] # 공격받은 이미지들이 저장될 리스트\n","    save_original_output = [] # 공격받은 이미지들의 정답 라벨 값이 저장될 리스트\n","    \n","    for i in range(len(test_x)):\n","        # 1장의 이미지와 그 label\n","        data = test_x[i]\n","        target_onehot = test_y[i] # one-hot 형태\n","        target_label = int(np.argmax(target_onehot)) # label 형태\n","\n","        # model이 정상 데이터를 분류한 결과 (각각 one-hot 형태, int label 형태)\n","        result_onehot = model.predict(data.reshape(1,32,32,3) / 255) # one-hot 형태\n","        result_label = int(np.argmax(result_onehot))\n","\n","        # 모델이 정상 데이터인데도 잘못 분류했다면 사용하지 않는다 (아래 코드 실행하지 않고 다음 이미지로 넘어감)\n","        if target_label != result_label:\n","            continue\n","\n","        # 이미지 전처리\n","        img =  tf_preprocess(data) # 텐서플로 전처리\n","        label = get_tf_label(target_onehot) # 확률벡터에서 레이블 추출\n","        \n","        # FGSM 공격 수행\n","        perturbations = create_adversarial_pattern(img, label)\n","        adv_x = img + eps * perturbations\n","        adv_x = tf.clip_by_value(adv_x, 0, 1) # 공격받은 이미지\n","\n","        # 공격 이미지를 분류기에 넣은 결과; 잘못 분류되어야 할 것 \n","        atkresult_onehot = model.predict(adv_x) # one-hot 형태\n","        atkresult_label = int(np.argmax(atkresult_onehot)) # label 형태\n","\n","        # 만약 공격 받아도 제대로 분류된다면 correct로 count\n","        if atkresult_label == target_label:\n","            correct += 1\n","        # ####################################################################################\n","        # ################ 여기 코드는 필요 없지 않나?\n","        #     if (eps == 0) and (len(adv_examples) < 5):\n","        #         adv_ex = adv_x\n","        #         adv_examples.append((init_output,final_pred,adv_x))\n","        # else:\n","        #     if len(adv_examples) < 5:\n","        #         adv_ex = adv_x\n","        #         adv_examples.append((init_output,final_pred,adv_x))\n","        # ####################################################################################\n","        \n","        # 공격 적용된 이미지, 그 공격 받은 이미지의 원래 정답 label을 각각 리스트에 저장합니다\n","        save_adv_examples.append(tf.reshape(adv_x,[32,32,3]))\n","        save_original_output.append(atkresult_label)\n","\n","    # 해당 엡실론에서의 최종 정확도를 계산합니다\n","    final_acc = correct/float(len(test_x))\n","    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(eps, correct, len(test_x), final_acc))\n","\n","    # 정확도와 적대적 예제를 리턴합니다\n","    return final_acc, adv_examples, save_adv_examples, save_original_output"]},{"cell_type":"code","source":["def pgd_attack(model,test_x,test_y,eps,step_size=2,num_steps=7): \n","    \"\"\"\n","    FGSM 코드와 차이점\n","    - step_size, num_steps 파라미터 추가됨\n","    - unifrom distribution 코드 추가\n","    - FGSM 공격 수행 -> PGD 공격 수행\n","    ** 모든 return 형식은 동일함\n","    \n","    default 값\n","    - step_size = 2 (alpha 값)\n","    - num_steps = 7 (iterations 값)\n","\n","    \"\"\"\n","\n","    prog = 0 # 진행상황 확인용 변수\n","\n","    correct = 0\n","    adv_examples = []\n","    save_adv_examples = [] # 공격받은 이미지들이 저장될 리스트\n","    save_original_output = [] # 공격받은 이미지들의 정답 라벨 값이 저장될 리스트\n","    \n","    for i in range(len(test_x)):\n","        # 1장의 이미지와 그 label\n","        data = test_x[i]\n","        target_onehot = test_y[i] # one-hot 형태\n","        target_label = int(np.argmax(target_onehot)) # label 형태\n","\n","        # model이 정상 데이터를 분류한 결과 (각각 one-hot 형태, int label 형태)\n","        result_onehot = model.predict(data.reshape(1,32,32,3) / 255) # one-hot 형태\n","        result_label = int(np.argmax(result_onehot))\n","\n","        # 모델이 정상 데이터인데도 잘못 분류했다면 사용하지 않는다 (아래 코드 실행하지 않고 다음 이미지로 넘어감)\n","        if target_label != result_label:\n","            continue\n","\n","        # PGD uniform distribution 코드\n","        data = data + np.random.uniform(-eps,eps,data.shape)\n","        data = np.clip(data,0,255)\n","\n","        # 이미지 전처리\n","        img =  tf_preprocess(data) # 텐서플로 전처리 -> 0~1사이로 정규화 함.\n","        label = get_tf_label(target_onehot) # 확률벡터에서 레이블 추출\n","        \n","        # PGD 공격 수행\n","        adv_x = img # 공격받은 이미지 (for문으로 업데이트)\n","        for num_step in range(num_steps):\n","          perturbations = create_adversarial_pattern(adv_x,label) # signed_grad를 리턴한 값\n","          adv_x += step_size * perturbations\n","          adv_x = tf.clip_by_value(adv_x,img-eps,img+eps)\n","          adv_x = tf.clip_by_value(adv_x,0,1)\n","\n","        # 공격 이미지를 분류기에 넣은 결과; 잘못 분류되어야 할 것 \n","        atkresult_onehot = model.predict(adv_x) # one-hot 형태\n","        atkresult_label = int(np.argmax(atkresult_onehot)) # label 형태\n","\n","        # 만약 공격 받아도 제대로 분류된다면 correct로 count\n","        if atkresult_label == target_label:\n","            correct += 1\n","        # ####################################################################################\n","        # ################ 여기 코드는 필요 없지 않나?\n","        #     if (eps == 0) and (len(adv_examples) < 5):\n","        #         adv_ex = adv_x\n","        #         adv_examples.append((init_output,final_pred,adv_x))\n","        # else:\n","        #     if len(adv_examples) < 5:\n","        #         adv_ex = adv_x\n","        #         adv_examples.append((init_output,final_pred,adv_x))\n","        # ####################################################################################\n","        \n","        # 공격 적용된 이미지, 그 공격 받은 이미지의 원래 정답 label을 각각 리스트에 저장합니다\n","        save_adv_examples.append(tf.reshape(adv_x,[32,32,3]))\n","        save_original_output.append(atkresult_label)\n","\n","        prog += 1\n","\n","        if prog%500 == 0:\n","          print(\"prog :\", prog)\n","\n","    # 해당 엡실론에서의 최종 정확도를 계산합니다\n","    final_acc = correct/float(len(test_x))\n","    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(eps, correct, len(test_x), final_acc))\n","\n","    # 정확도와 적대적 예제를 리턴합니다\n","    return final_acc, adv_examples, save_adv_examples, save_original_output"],"metadata":{"id":"GmiLgFduVhR0","executionInfo":{"status":"ok","timestamp":1663470442272,"user_tz":-540,"elapsed":285,"user":{"displayName":"이진규","userId":"11520813773494359482"}}},"execution_count":82,"outputs":[]},{"cell_type":"markdown","source":["### Attack 수행 : 공격 데이터셋 만드는 코드\n","\n","**여기에서 [attack_type]과 [eps] 설정하면 됩니다!!!**\n","\n","* attack_type : FGSM, PGD\n","* eps = 0.02, 0.03, 8/255, 0.05, 0.08, 0.10\n","* 정상 이미지에 대한 분류기 정확도 -> 위에 있음 (분류기:CNN; 약 97%)"],"metadata":{"id":"AVs5AnagBdTK"}},{"cell_type":"code","source":["################################################################################\n","# 공격 데이터 설정 #################################################################\n","attack_type = \"PGD\" # FGSM, PGD\n","eps = 0.03 # 0.02, 0.03, 0.04, 0.05, 0.08, 0.10\n","################################################################################\n","################################################################################\n","\n","if attack_type == \"FGSM\":\n","  acc, ex, ad_examples, orig_labels = fgsm_attack(model, data_test.x_test, data_test.y_test, eps) #x 공격데이터 : 0~1 정규화 완료, y 데이터 : 12개 라벨\n","elif attack_type == \"PGD\":\n","  acc, ex, ad_examples, orig_labels = pgd_attack(model, data_test.x_test, data_test.y_test, eps) #x 공격데이터 : 0~1 정규화 완료, y 데이터 : 12개 라벨\n","\n","print(\"Attack Data 생성 완료\")"],"metadata":{"id":"ZE2wZtfAEOBh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663471400243,"user_tz":-540,"elapsed":953021,"user":{"displayName":"이진규","userId":"11520813773494359482"}},"outputId":"a93dab35-cd0c-4898-fd6d-f519b79e11eb"},"execution_count":83,"outputs":[{"output_type":"stream","name":"stdout","text":["prog : 500\n","prog : 1000\n","prog : 1500\n","prog : 2000\n","prog : 2500\n","prog : 3000\n","prog : 3500\n","prog : 4000\n","prog : 4500\n","prog : 5000\n","prog : 5500\n","prog : 6000\n","Epsilon: 0.03\tTest Accuracy = 2935 / 6180 = 0.4749190938511327\n","Attack Data 생성 완료\n"]}]},{"cell_type":"code","source":["print(orig_labels[0])\n","plt.figure()\n","plt.imshow(ad_examples[0])\n","plt.show();"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":284},"id":"Fjghmlv4kRKa","executionInfo":{"status":"ok","timestamp":1663471985009,"user_tz":-540,"elapsed":4,"user":{"displayName":"이진규","userId":"11520813773494359482"}},"outputId":"b9f7158a-ffa7-4584-af19-06fdf7e85910"},"execution_count":107,"outputs":[{"output_type":"stream","name":"stdout","text":["11\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["# 방어모델 : MagNet, Defense-GAN, PCA"],"metadata":{"id":"6DfDZcE5_GGB"}},{"cell_type":"markdown","source":["## MagNet"],"metadata":{"id":"Lb-doZmmIFqj"}},{"cell_type":"markdown","source":["### MagNet - def (utils, worker, Defensive Model)"],"metadata":{"id":"-Yc-yrW7ktMW"}},{"cell_type":"markdown","source":["#### MagNet - utils"],"metadata":{"id":"bt4nIJ5xg73T"}},{"cell_type":"code","source":["## utils.py -- utility functions\n","##\n","## Copyright (C) 2017, Dongyu Meng <zbshfmmm@gmail.com>.\n","##\n","## This program is licenced under the BSD 2-Clause licence,\n","## contained in the LICENCE file in this directory.\n","\n","import pickle\n","import os\n","import numpy as np\n","\n","\n","def prepare_data(dataset, idx):\n","    \"\"\"\n","    Extract data from index.\n","\n","    dataset: Full, working dataset. Such as MNIST().\n","    idx: Index of test examples that we care about.\n","    return: X, targets, Y\n","    \"\"\"\n","    return dataset.x_test[idx], dataset.y_test[idx], np.argmax(dataset.y_test[idx], axis=1)\n","\n","\n","def save_obj(obj, name, directory='./attack_data/'):\n","    with open(os.path.join(directory, name + '.pkl'), 'wb') as f:\n","        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n","\n","\n","def load_obj(name, directory='./attack_data/'):\n","    if name.endswith(\".pkl\"): name = name[:-4]\n","    with open(os.path.join(directory, name + '.pkl'), 'rb') as f:\n","        return pickle.load(f)"],"metadata":{"id":"hAvlahKmMFdO","executionInfo":{"status":"ok","timestamp":1663471997994,"user_tz":-540,"elapsed":289,"user":{"displayName":"이진규","userId":"11520813773494359482"}}},"execution_count":108,"outputs":[]},{"cell_type":"markdown","source":["#### MagNet - worker"],"metadata":{"id":"EhncucofhEvv"}},{"cell_type":"code","source":["## setup_mnist.py -- mnist data and model loading code\n","##\n","## Copyright (C) 2016, Nicholas Carlini <nicholas@carlini.com>.\n","##\n","## This program is licenced under the BSD 2-Clause licence,\n","## contained in the LICENCE file in this directory.\n","\n","## Modified for MagNet's use.\n","\n","## worker.py -- evaluation code\n","##\n","## Copyright (C) 2017, Dongyu Meng <zbshfmmm@gmail.com>.\n","##\n","## This program is licenced under the BSD 2-Clause licence,\n","## contained in the LICENCE file in this directory.\n","\n","import matplotlib\n","matplotlib.use('Agg')\n","from scipy.stats import entropy\n","from numpy.linalg import norm\n","from matplotlib.ticker import FuncFormatter\n","from keras.models import Sequential, load_model\n","from keras.activations import softmax\n","from keras.layers import Lambda\n","import numpy as np\n","import pylab\n","import os\n","import matplotlib.pyplot as plt\n","\n","\n","class AEDetector:\n","    def __init__(self, path, p=1):\n","        \"\"\"\n","        Error based detector.\n","        Marks examples for filtering decisions.\n","\n","        path: Path to the autoencoder used.\n","        p: Distance measure to use.\n","        \"\"\"\n","\n","        self.model = load_model(path)\n","        self.path = path\n","        self.p = p\n","\n","    def mark(self, X):\n","        diff = np.abs(X - self.model.predict(X)) # input X와 예측값 X'(autoencoder를 통해 노이즈가 더해진 값) 의 오차 값\n","        marks = np.mean(np.power(diff, self.p), axis=(1,2,3)) # 오차값의 분산\n","        return marks\n","\n","    def print(self):\n","        return \"AEDetector:\" + self.path.split(\"/\")[-1]\n","\n","\n","class IdReformer:\n","    def __init__(self, path=\"IdentityFunction\"):\n","        \"\"\"\n","        Identity reformer.\n","        Reforms an example to itself.\n","        \"\"\"\n","        self.path = path\n","        self.heal = lambda X: X\n","\n","    def print(self):\n","        return \"IdReformer:\" + self.path\n","\n","\n","class SimpleReformer:\n","    def __init__(self, path):\n","        \"\"\"\n","        Reformer.\n","        Reforms examples with autoencoder. Action of reforming is called heal.\n","\n","        path: Path to the autoencoder used.\n","        \"\"\"\n","        self.model = load_model(path)\n","        self.path = path\n","\n","    def heal(self, X):\n","        X = self.model.predict(X) # autoencoder로 X값 재구성\n","        return np.clip(X, 0.0, 1.0)\n","\n","    def print(self):\n","        return \"SimpleReformer:\" + self.path.split(\"/\")[-1]\n","\n","\n","def JSD(P, Q):\n","    _P = P / norm(P, ord=1)\n","    _Q = Q / norm(Q, ord=1)\n","    _M = 0.5 * (_P + _Q)\n","    return 0.5 * (entropy(_P, _M) + entropy(_Q, _M)) # Xp와 Xr의 분포의 entropy \n","    # KL divergence: Q(one autoencoder)를 기반으로 했을 때의 cross entropy와 P(magnet)를 기반으로 했을 때의 entropy의 차이\n","\n","\n","\n","class DBDetector:\n","    def __init__(self, reconstructor, prober, classifier, option=\"jsd\", T=1):\n","        \"\"\"\n","        Divergence-Based Detector.\n","\n","        reconstructor: One autoencoder.\n","        prober: Another autoencoder.\n","        classifier: Classifier object.\n","        option: Measure of distance, jsd as default.\n","        T: Temperature to soften the classification decision.\n","        \"\"\"\n","        self.prober = prober\n","        self.reconstructor = reconstructor\n","        self.classifier = classifier\n","        self.option = option\n","        self.T = T\n","\n","    def mark(self, X):\n","        return self.mark_jsd(X)\n","\n","    def mark_jsd(self, X):\n","        Xp = self.prober.heal(X) # 1번 autoencoder로 생성한 이미지 \n","        Xr = self.reconstructor.heal(X) #2번 autoencoder로 생성한 이미지 \n","        Pp = self.classifier.classify(Xp, option=\"prob\", T=self.T) # Xp의 확률\n","        Pr = self.classifier.classify(Xr, option=\"prob\", T=self.T) # Xr의 확률\n","\n","        marks = [(JSD(Pp[i], Pr[i])) for i in range(len(Pr))]\n","        return np.array(marks)\n","\n","    def print(self):\n","        return \"Divergence-Based Detector\"\n","\n","\n","class Classifier:\n","    def __init__(self, classifier_path):\n","        \"\"\"\n","        Keras classifier wrapper.\n","        Note that the wrapped classifier should spit logits as output.\n","\n","        classifier_path: Path to Keras classifier file.\n","        \"\"\"\n","        self.path = classifier_path\n","        self.model = load_model(classifier_path)\n","        self.softmax = Sequential()\n","        self.softmax.add(Lambda(lambda X: softmax(X, axis=1)))\n","\n","    def classify(self, X, option=\"logit\", T=1):\n","        if option == \"logit\":\n","            return self.model.predict(X)\n","        if option == \"prob\":\n","            logits = self.model.predict(X)/T\n","            return self.softmax.predict(logits)\n","\n","    def print(self):\n","        return \"Classifier:\"+self.path.split(\"/\")[-1]\n","\n","\n","class Operator:\n","    def __init__(self, data, classifier, det_dict, reformer):\n","        \"\"\"\n","        Operator.\n","        Describes the classification problem and defense.\n","\n","        data: Standard problem dataset. Including train, test, and validation.\n","        classifier: Target classifier.\n","        reformer: Reformer of defense.\n","        det_dict: Detector(s) of defense.\n","        \"\"\"\n","\n","        self.data = data\n","        self.classifier = classifier\n","        self.det_dict = det_dict \n","        self.reformer = reformer\n","        self.normal = self.operate(AttackData(data.x_train, np.argmax(data.y_train, axis=1), \"Normal\"))\n","        \n","\n","    def get_thrs(self, drop_rate):\n","        \"\"\"\n","        Get filtering threshold by marking validation set.\n","        \"\"\"\n","        thrs = dict()\n","        for name, detector in self.det_dict.items():\n","            num = int(len(data.x_test) * drop_rate[name])\n","            marks = detector.mark(data.x_test)\n","            marks = np.sort(marks)\n","            thrs[name] = marks[-num]\n","        return thrs\n","\n","    def operate(self, untrusted_obj):\n","        \"\"\"\n","        For untrusted input(normal or adversarial), classify original input and\n","        reformed input. Classifier is unaware of the source of input.\n","\n","        untrusted_obj: Input data.\n","        \"\"\"\n","\n","        X = untrusted_obj.data\n","        Y_true = untrusted_obj.labels\n","\n","\n","        X_prime = self.reformer.heal(X) # autoencoder 값으로 재구성\n","        Y = np.argmax(self.classifier.classify(X), axis=1) # 원본 input X 분류\n","        Y_judgement = (Y == Y_true[:len(X_prime)]) # 실제 label과 X 분류 label 비교\n","        Y_prime = np.argmax(self.classifier.classify(X_prime), axis=1)  # autoencoder로 재구성한 X' 분류\n","        Y_prime_judgement = (Y_prime == Y_true[:len(X_prime)])  # 실제 label과 X' 분류 label 비교\n","        return np.array(list(zip(Y_judgement, Y_prime_judgement)))\n","\n","    def filter(self, X, thrs):\n","        \"\"\"\n","        untrusted_obj: Untrusted input to test against.\n","        thrs: Thresholds.\n","\n","        return:\n","        all_pass: Index of examples that passed all detectors.\n","        collector: Number of examples that escaped each detector.\n","        \"\"\"\n","        collector = dict()\n","        all_pass = np.array(range(10000)) #Index\n","        for name, detector in self.det_dict.items():\n","            marks = detector.mark(X) #  KL divergnece: Xp와 Xr의 분포의 entropy \n","            idx_pass = np.argwhere(marks < thrs[name]) # KL divergnece가 thershold보다 작을 경우 pass, 클 경우 reject\n","            collector[name] = len(idx_pass) # pass가 된 수\n","            all_pass = np.intersect1d(all_pass, idx_pass) # 전체 index array와 pass된 array의 교집합\n","        return all_pass, collector\n","\n","    def print(self):\n","        components = [self.reformer, self.classifier]\n","        return \" \".join(map(lambda obj: getattr(obj, \"print\")(), components))\n","\n","\n","class AttackData:\n","    def __init__(self, examples, labels, name=\"\"):\n","        \"\"\"\n","        Input data wrapper. May be normal or adversarial.\n","\n","        examples: Path or object of input examples.\n","        labels: Ground truth labels.\n","        \"\"\"\n","        # if isinstance(examples, str): \n","        #   self.data = load_obj(examples)\n","        # else: \n","\n","        self.data = examples\n","        self.labels = labels\n","        self.name = name\n","\n","    def print(self):\n","        return \"Attack:\"+self.name\n","\n","\n","class Evaluator:\n","    def __init__(self, operator, untrusted_data, graph_dir=\"./graph\"):\n","        \"\"\"\n","        Evaluator.\n","        For strategy described by operator, conducts tests on untrusted input.\n","        Mainly stats and plotting code. Most methods omitted for clarity.\n","\n","        operator: Operator object.\n","        untrusted_data: Input data to test against.\n","        graph_dir: Where to spit the graphs.\n","        \"\"\"\n","        self.operator = operator\n","        self.untrusted_data = untrusted_data # attacked data\n","        self.graph_dir = graph_dir\n","        self.data_package = operator.operate(untrusted_data)\n","\n","    def bind_operator(self, operator):\n","        self.operator = operator\n","        self.data_package = operator.operate(self.untrusted_data)\n","\n","    def load_data(self, data):\n","        self.untrusted_data = data\n","        self.data_package = self.operator.operate(self.untrusted_data)\n","\n","    def get_normal_acc(self, normal_all_pass):\n","        \"\"\"\n","        traning data에 대한 정확도\n","\n","        Break down of who does what in defense. Accuracy of defense on normal\n","        input.\n","\n","        both: Both detectors and reformer take effect\n","        det_only: detector(s) take effect\n","        ref_only: Only reformer takes effect\n","        none: Attack effect with no defense\n","        \"\"\"\n","        normal_tups = self.operator.normal\n","        num_normal = len(normal_tups)\n","        filtered_normal_tups = normal_tups[normal_all_pass]\n","\n","        both_acc = sum(1 for _, XpC in filtered_normal_tups if XpC)/num_normal # detector and refomer\n","        det_only_acc = sum(1 for XC, XpC in filtered_normal_tups if XC)/num_normal # only detector\n","        ref_only_acc = sum([1 for _, XpC in normal_tups if XpC])/num_normal # only reformer\n","        none_acc = sum([1 for XC, _ in normal_tups if XC])/num_normal # no defense\n","\n","        return both_acc, det_only_acc, ref_only_acc, none_acc\n","\n","    def get_attack_acc(self, attack_pass):\n","        \"\"\"\n","        attacked data에 대한 정확도 \n","        \"\"\"\n","        attack_tups = self.data_package\n","        num_untrusted = len(attack_tups)\n","        filtered_attack_tups = attack_tups[attack_pass]\n","\n","\n","        both_acc = 1 - sum(1 for _, XpC in filtered_attack_tups if not XpC)/num_untrusted # detector and refomer\n","        det_only_acc = 1 - sum(1 for XC, XpC in filtered_attack_tups if not XC)/num_untrusted # only detector\n","        ref_only_acc = sum([1 for _, XpC in attack_tups if XpC])/num_untrusted # only reformer\n","        none_acc = sum([1 for XC, _ in attack_tups if XC])/num_untrusted # no defense\n","        \n","        return both_acc, det_only_acc, ref_only_acc, none_acc\n","\n","    def plot_various_confidences(self, graph_name, drop_rate,\n","                                 idx_file=\"example_idx\",\n","                                 confs=(0.0, 10.0),\n","                                 get_attack_data_name=lambda c: \"example_carlini_\"+str(c)):\n","        \"\"\"\n","        Test defense performance against Carlini L2 attack of various confidences.\n","\n","        graph_name: Name of graph file.\n","        drop_rate: How many normal examples should each detector drops?\n","        idx_file: Index of adversarial examples in standard test set.\n","        confs: A series of confidence to test against.\n","        get_attack_data_name: Function mapping confidence to corresponding file.\n","        \"\"\"\n","        pylab.rcParams['figure.figsize'] = 6, 4\n","        fig = plt.figure(1, (6, 4))\n","        ax = fig.add_subplot(1, 1, 1)\n","\n","        idx = orig_labels\n","        # idx = original_labels_list\n","        X, _, Y = prepare_data(self.operator.data, idx)\n","\n","\n","        det_only = []\n","        ref_only = []\n","        both = []\n","        none = []\n","\n","        print(\"\\n==========================================================\")\n","        print(\"Drop Rate:\", drop_rate)\n","        thrs = self.operator.get_thrs(drop_rate)\n","\n","        all_pass, _ = self.operator.filter(self.operator.data.x_train, thrs)\n","        all_on_acc, _, _, _ = self.get_normal_acc(all_pass)\n","\n","        print(\"Classification accuracy with all defense on:\", all_on_acc)\n","\n","        for confidence in confs:\n","            # f = get_attack_data_name(confidence)\n","            self.load_data(AttackData(ad_examples1, orig_labels, \"GTSRB FSGM\"))\n","\n","            print(\"----------------------------------------------------------\")\n","            print(\"Confidence:\", confidence)\n","            all_pass, detector_breakdown = self.operator.filter(self.untrusted_data.data, thrs)\n","            both_acc, det_only_acc, ref_only_acc, none_acc = self.get_attack_acc(all_pass)\n","            print(detector_breakdown)\n","            both.append(both_acc)\n","            det_only.append(det_only_acc)\n","            ref_only.append(ref_only_acc)\n","            none.append(none_acc)\n","\n","        size = 2.5\n","\n","        print(\"With detector & reformer: \", both_acc)\n","        print(\"With detector: \",det_only_acc)\n","        print(\"With reformer: \", ref_only_acc)\n","        print(\"No Defense: \",none_acc)\n","\n","        # print(\"With detector & reformer: \", both)\n","        # print(\"With detector: \",det_only)\n","        # print(\"With reformer: \", ref_only)\n","        # print(\"No Defense: \",none)\n","\n","        plt.plot(confs, none, c=\"green\", label=\"No Defense\", marker=\"x\", markersize=size,alpha=0.5)\n","        # plt.plot(confs, det_only, c=\"orange\", label=\"With detector\", marker=\"o\", markersize=size,alpha=0.5)\n","        # plt.plot(confs, ref_only, c=\"blue\", label=\"With reformer\", marker=\"^\", markersize=size,alpha=0.5)\n","        plt.plot(confs, both, c=\"red\", label=\"With detector & reformer\", marker=\"s\", markersize=size,alpha=0.5)\n","\n","        pylab.legend(loc='lower left', bbox_to_anchor=(0.02, 0.1), prop={'size':8})\n","        plt.grid(linestyle='dotted')\n","        plt.xlabel(r\"Confidence in Carlini $L^2$ attack\")\n","        plt.ylabel(\"Classification accuracy\")\n","        plt.xlim(min(confs)-1.0, max(confs)+1.0)\n","        plt.ylim(-0.05, 1.05)\n","        ax.yaxis.set_major_formatter(FuncFormatter('{0:.0%}'.format))\n","\n","        save_path = os.path.join(self.graph_dir, graph_name+\".pdf\")\n","        plt.savefig(save_path)\n","        plt.clf()\n","\n","    def print(self):\n","        return \" \".join([self.operator.print(), self.untrusted_data.print()])"],"metadata":{"id":"ZRv7EXuShHMK","executionInfo":{"status":"ok","timestamp":1663471999087,"user_tz":-540,"elapsed":2,"user":{"displayName":"이진규","userId":"11520813773494359482"}}},"execution_count":109,"outputs":[]},{"cell_type":"markdown","source":["#### MagNet - Defensive Model"],"metadata":{"id":"4e-GBUowhNUQ"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import os\n","import numpy as np\n","from keras.layers.core import Lambda\n","from keras.layers.merge import Average, add\n","from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, AveragePooling2D\n","from keras.models import Model\n","import keras.regularizers as regs\n","\n","\n","class DenoisingAutoEncoder:\n","    def __init__(self, image_shape,\n","                 structure,\n","                 v_noise=0.0,\n","                 activation=\"relu\",\n","                 model_dir=\"./defensive_models/\",\n","                 reg_strength=0.0):\n","        \"\"\"\n","        Denoising Autoencoder(DAE)\n","        training data에 nosie를 추가하여 인코더에 넣어서 학습된 결과가 \n","        noise를 붙이기 전 데이터와의 error을 최소화하는 목적을 가진 Autoencoder\n","\n","        image_shape: Shape of input image. e.g. 28, 28, 1.\n","        structure: Structure of autoencoder.\n","        v_noise: Volume of noise while training.\n","        activation: What activation function to use.\n","        model_dir: Where to save / load model from.\n","        reg_strength: Strength of L2 regularization.\n","        \"\"\"\n","        h, w, c = image_shape\n","        self.image_shape = image_shape # shape of input image (32,32,3)\n","        self.model_dir = model_dir \n","        self.v_noise = v_noise\n","\n","        input_img = Input(shape=self.image_shape)\n","        x = input_img\n","\n","        # encoder 정의 \n","        for layer in structure: \n","            if isinstance(layer, int):\n","                x = Conv2D(layer, (3, 3), activation=activation, padding=\"same\",\n","                           activity_regularizer=regs.l2(reg_strength))(x)\n","            elif layer == \"max\":\n","                x = MaxPooling2D((2, 2), padding=\"same\")(x)\n","            elif layer == \"average\":\n","                x = AveragePooling2D((2, 2), padding=\"same\")(x)\n","            else:\n","                print(layer, \"is not recognized!\")\n","                exit(0)\n","        \n","        for layer in reversed(structure):\n","            if isinstance(layer, int):\n","                x = Conv2D(layer, (3, 3), activation=activation, padding=\"same\",\n","                           activity_regularizer=regs.l2(reg_strength))(x)\n","            elif layer == \"max\" or layer == \"average\":\n","                x = UpSampling2D((2, 2))(x)\n","\n","        # decoder 정의 \n","        decoded = Conv2D(c, (3, 3), activation='sigmoid', padding='same',\n","                         activity_regularizer=regs.l2(reg_strength))(x)\n","\n","        self.model = Model(input_img, decoded) # autoencoder 모델\n","\n","    def train(self, data, archive_name, num_epochs=100, batch_size=32):\n","        self.model.compile(loss='mean_squared_error',\n","                           metrics=['mean_squared_error'],\n","                           optimizer='adam')\n","        \n","        noise = self.v_noise * np.random.normal(size=np.shape(data.x_train)) # 랜덤 노이즈 \n","        noisy_train_data = data.x_train + noise # Input Data에 랜덤 노이즈 추가 \n","        noisy_train_data = np.clip(noisy_train_data, 0.0, 1.0) # [0,1] 범위로 재구성\n","\n","        self.model.fit(noisy_train_data, data.x_train,\n","                       batch_size=batch_size,\n","                       validation_data=(data.x_test, data.x_test),\n","                       epochs=num_epochs,\n","                       shuffle=True)\n","\n","        print(os.path.join(self.model_dir, archive_name))        \n","        self.model.save(os.path.join(self.model_dir, archive_name))\n","\n","    def load(self, archive_name, model_dir=None):\n","        if model_dir is None: model_dir = self.model_dir\n","        self.model.load_weights(os.path.join(model_dir, archive_name))\n","\n","\n","class PackedAutoEncoder:\n","    def __init__(self, image_shape, structure, data,\n","                 v_noise=0.1, n_pack=2, pre_epochs=3, activation=\"relu\",\n","                 model_dir=\"./defensive_models/\"):\n","        \"\"\"\n","        Train different autoencoders.\n","        Demo code for graybox scenario.\n","\n","        pre_epochs: How many epochs do we train before fine-tuning.\n","        n_pack: Number of autoencoders we want to train at once.\n","        \"\"\"\n","        self.v_noise = v_noise\n","        self.n_pack = n_pack\n","        self.model_dir = model_dir\n","        pack = []\n","\n","\n","\n","        for i in range(n_pack):\n","            dae = DenoisingAutoEncoder(image_shape, structure, v_noise=v_noise,\n","                                       activation=activation, model_dir=model_dir)\n","            dae.train(data, \"\", num_epochs=pre_epochs)\n","            pack.append(dae.model)\n","\n","\n","        shared_input = Input(shape=image_shape, name=\"shared_input\")\n","        outputs = [dae(shared_input) for dae in pack]\n","        avg_output = Average()(outputs)\n","        delta_outputs = [add([avg_output, Lambda(lambda x: -x)(output)])\n","                         for output in outputs]\n","\n","        self.model = Model(inputs=shared_input, outputs=outputs+delta_outputs)\n","\n","    def train(self, data, archive_name, alpha, num_epochs=10, batch_size=32):\n","        noise = self.v_noise * np.random.normal(size=np.shape(data.x_train))\n","        noisy_train_data = data.x_train + noise\n","        noisy_train_data = np.clip(noisy_train_data, 0.0, 1.0)\n","\n","        train_zeros = [np.zeros_like(data.x_train)] * self.n_pack\n","        val_zeros = [np.zeros_like(data.x_test)] * self.n_pack\n","\n","        self.model.compile(loss=\"mean_squared_error\", optimizer=\"adam\",\n","                           loss_weights=[1.0]*self.n_pack + [-alpha]*self.n_pack)\n","\n","        self.model.fit(noisy_train_data,\n","                       [data.x_train]*self.n_pack + train_zeros,\n","                       batch_size=batch_size,\n","                       validation_data=(data.x_test,\n","                            [data.x_test]*self.n_pack+val_zeros),\n","                       epochs=num_epochs,\n","                       shuffle=True)\n","\n","        for i in range(self.n_pack):\n","            model = Model(self.model.input, self.model.outputs[i])\n","            self.model.save(\"\")\n","            print(os.path.join(self.model_dir, archive_name+\"_\"+str(i)))\n","            self.model.save(os.path.join(self.model_dir, archive_name+\"_\"+str(i)))\n","\n","    def load(self, archive_name, model_dir=None):\n","        if model_dir is None: model_dir = self.model_dir\n","        self.model.load_weights(os.path.join(model_dir, archive_name))"],"metadata":{"id":"HyIrYmBIhPRc","executionInfo":{"status":"ok","timestamp":1663472000540,"user_tz":-540,"elapsed":1,"user":{"displayName":"이진규","userId":"11520813773494359482"}}},"execution_count":110,"outputs":[]},{"cell_type":"markdown","source":["### MagNet - Train Defensive Model"],"metadata":{"id":"ukxjkHWahV8B"}},{"cell_type":"code","source":["DAE = DenoisingAutoEncoder\n","PAE = PackedAutoEncoder\n","\n","shape = [32, 32, 3]\n","combination_I = [3, \"average\", 3]\n","combination_II = [3]\n","activation = \"sigmoid\"\n","reg_strength = 1e-9\n","epochs = 350\n","\n","# data = GTSRB()\n","\n","# AE_II = PAE(shape, combination_II, data, v_noise=0.025, activation=activation, n_pack=8)\n","# AE_II.train(data, \"_8_PAE_GTSRB_II\", alpha=.2, num_epochs=epochs)\n","\n","# AE_II = PAE(shape, combination_II, data, v_noise=0.025, activation=activation)\n","# AE_II.train(data, \"_PAE_GTSRB_II\", alpha=.2, num_epochs=epochs)    \n","\n","# AE_II = PAE(shape, combination_II, data, v_noise=0.025, activation=activation, n_pack=32)\n","# AE_II.train(data, \"O32_PAE_GTSRB_II\", alpha=.2, num_epochs=epochs)  \n","\n","AE_I = DAE(shape, combination_I, v_noise=0.1, activation=activation, reg_strength=reg_strength)\n","AE_I.train(data, \"350_0918_DAE_GTSRB_I\", num_epochs=epochs)\n","\n","AE_II = DAE(shape, combination_II, v_noise=0.1, activation=activation,  reg_strength=reg_strength)\n","AE_II.train(data, \"350_0918_DAE_GTSRB_II\", num_epochs=epochs)"],"metadata":{"id":"C5S8s9wxhanJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663473154465,"user_tz":-540,"elapsed":1033163,"user":{"displayName":"이진규","userId":"11520813773494359482"}},"outputId":"ea74d42c-fef4-457e-af0d-17e287ad4d78"},"execution_count":111,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/350\n","225/225 [==============================] - 3s 7ms/step - loss: 0.0743 - mean_squared_error: 0.0743 - val_loss: 0.0606 - val_mean_squared_error: 0.0606\n","Epoch 2/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0343 - mean_squared_error: 0.0342 - val_loss: 0.0221 - val_mean_squared_error: 0.0221\n","Epoch 3/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0207 - mean_squared_error: 0.0207 - val_loss: 0.0185 - val_mean_squared_error: 0.0185\n","Epoch 4/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0173 - mean_squared_error: 0.0172 - val_loss: 0.0151 - val_mean_squared_error: 0.0151\n","Epoch 5/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0144 - mean_squared_error: 0.0144 - val_loss: 0.0127 - val_mean_squared_error: 0.0127\n","Epoch 6/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n","Epoch 7/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0101 - val_mean_squared_error: 0.0101\n","Epoch 8/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0094 - val_mean_squared_error: 0.0094\n","Epoch 9/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0090 - val_mean_squared_error: 0.0090\n","Epoch 10/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0086 - val_mean_squared_error: 0.0086\n","Epoch 11/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.0084 - val_mean_squared_error: 0.0084\n","Epoch 12/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.0082 - val_mean_squared_error: 0.0082\n","Epoch 13/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0081 - val_mean_squared_error: 0.0081\n","Epoch 14/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.0080 - val_mean_squared_error: 0.0080\n","Epoch 15/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.0079 - val_mean_squared_error: 0.0079\n","Epoch 16/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.0078 - val_mean_squared_error: 0.0078\n","Epoch 17/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0077 - val_mean_squared_error: 0.0077\n","Epoch 18/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0075 - val_mean_squared_error: 0.0075\n","Epoch 19/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.0075 - val_mean_squared_error: 0.0075\n","Epoch 20/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.0074 - val_mean_squared_error: 0.0074\n","Epoch 21/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0073 - val_mean_squared_error: 0.0073\n","Epoch 22/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0073 - val_mean_squared_error: 0.0073\n","Epoch 23/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n","Epoch 24/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0071 - val_mean_squared_error: 0.0071\n","Epoch 25/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0070 - val_mean_squared_error: 0.0070\n","Epoch 26/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0070 - val_mean_squared_error: 0.0070\n","Epoch 27/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0076 - mean_squared_error: 0.0075 - val_loss: 0.0069 - val_mean_squared_error: 0.0069\n","Epoch 28/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0069 - val_mean_squared_error: 0.0068\n","Epoch 29/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0068 - val_mean_squared_error: 0.0068\n","Epoch 30/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0067 - val_mean_squared_error: 0.0067\n","Epoch 31/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0067 - val_mean_squared_error: 0.0067\n","Epoch 32/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0066 - val_mean_squared_error: 0.0066\n","Epoch 33/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0066 - val_mean_squared_error: 0.0066\n","Epoch 34/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0066 - val_mean_squared_error: 0.0065\n","Epoch 35/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0072 - mean_squared_error: 0.0071 - val_loss: 0.0065 - val_mean_squared_error: 0.0065\n","Epoch 36/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0065 - val_mean_squared_error: 0.0065\n","Epoch 37/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0065 - val_mean_squared_error: 0.0065\n","Epoch 38/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0064 - val_mean_squared_error: 0.0064\n","Epoch 39/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0064 - val_mean_squared_error: 0.0064\n","Epoch 40/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0064 - val_mean_squared_error: 0.0064\n","Epoch 41/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n","Epoch 42/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n","Epoch 43/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n","Epoch 44/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n","Epoch 45/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n","Epoch 46/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n","Epoch 47/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n","Epoch 48/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n","Epoch 49/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n","Epoch 50/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n","Epoch 51/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n","Epoch 52/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n","Epoch 53/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n","Epoch 54/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n","Epoch 55/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n","Epoch 56/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n","Epoch 57/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n","Epoch 58/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n","Epoch 59/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n","Epoch 60/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n","Epoch 61/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n","Epoch 62/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n","Epoch 63/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n","Epoch 64/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n","Epoch 65/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n","Epoch 66/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n","Epoch 67/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n","Epoch 68/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n","Epoch 69/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n","Epoch 70/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n","Epoch 71/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n","Epoch 72/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n","Epoch 73/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n","Epoch 74/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n","Epoch 75/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n","Epoch 76/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n","Epoch 77/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n","Epoch 78/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n","Epoch 79/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n","Epoch 80/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n","Epoch 81/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n","Epoch 82/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n","Epoch 83/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 84/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n","Epoch 85/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n","Epoch 86/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0060 - val_mean_squared_error: 0.0059\n","Epoch 87/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 88/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n","Epoch 89/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 90/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 91/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 92/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 93/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 94/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 95/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 96/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 97/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 98/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 99/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 100/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 101/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 102/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 103/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 104/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 105/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 106/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 107/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 108/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 109/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 110/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 111/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 112/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 113/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 114/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 115/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 116/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 117/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 118/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 119/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0059 - val_mean_squared_error: 0.0058\n","Epoch 120/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 121/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 122/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 123/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 124/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 125/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 126/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0065 - mean_squared_error: 0.0064 - val_loss: 0.0059 - val_mean_squared_error: 0.0058\n","Epoch 127/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 128/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 129/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 130/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 131/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 132/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 133/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 134/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 135/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 136/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 137/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 138/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 139/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 140/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 141/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 142/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 143/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 144/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 145/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 146/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 147/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 148/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n","Epoch 149/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 150/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 151/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 152/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 153/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 154/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 155/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 156/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 157/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 158/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 159/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 160/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 161/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 162/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0059 - val_mean_squared_error: 0.0058\n","Epoch 163/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 164/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 165/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 166/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 167/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 168/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 169/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 170/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 171/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 172/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 173/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 174/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 175/350\n","225/225 [==============================] - 2s 10ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 176/350\n","225/225 [==============================] - 2s 8ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 177/350\n","225/225 [==============================] - 2s 8ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 178/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 179/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 180/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 181/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 182/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 183/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 184/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 185/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 186/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 187/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 188/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 189/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 190/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 191/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 192/350\n","225/225 [==============================] - 2s 8ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 193/350\n","225/225 [==============================] - 2s 10ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 194/350\n","225/225 [==============================] - 2s 9ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 195/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 196/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 197/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 198/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 199/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 200/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 201/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 202/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 203/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 204/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 205/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 206/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 207/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 208/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 209/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 210/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 211/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 212/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 213/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 214/350\n","225/225 [==============================] - 2s 9ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 215/350\n","225/225 [==============================] - 3s 12ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 216/350\n","225/225 [==============================] - 2s 8ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 217/350\n","225/225 [==============================] - 2s 10ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 218/350\n","225/225 [==============================] - 2s 9ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 219/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 220/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 221/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0064 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 222/350\n","225/225 [==============================] - 2s 10ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 223/350\n","225/225 [==============================] - 2s 10ms/step - loss: 0.0064 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 224/350\n","225/225 [==============================] - 2s 10ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 225/350\n","225/225 [==============================] - 2s 11ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 226/350\n","225/225 [==============================] - 3s 12ms/step - loss: 0.0064 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 227/350\n","225/225 [==============================] - 2s 9ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 228/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 229/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 230/350\n","225/225 [==============================] - 2s 8ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 231/350\n","225/225 [==============================] - 2s 11ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 232/350\n","225/225 [==============================] - 2s 11ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 233/350\n","225/225 [==============================] - 2s 9ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 234/350\n","225/225 [==============================] - 2s 10ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 235/350\n","225/225 [==============================] - 2s 10ms/step - loss: 0.0064 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 236/350\n","225/225 [==============================] - 3s 12ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 237/350\n","225/225 [==============================] - 2s 9ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 238/350\n","225/225 [==============================] - 2s 10ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 239/350\n","225/225 [==============================] - 3s 14ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 240/350\n","225/225 [==============================] - 2s 11ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 241/350\n","225/225 [==============================] - 2s 10ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 242/350\n","225/225 [==============================] - 2s 10ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 243/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 244/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 245/350\n","225/225 [==============================] - 2s 8ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 246/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 247/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 248/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 249/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 250/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 251/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 252/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 253/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 254/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 255/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 256/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0057\n","Epoch 257/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 258/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 259/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 260/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 261/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 262/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 263/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 264/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 265/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 266/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 267/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 268/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 269/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 270/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 271/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 272/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 273/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0057\n","Epoch 274/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 275/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 276/350\n","225/225 [==============================] - 3s 11ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 277/350\n","225/225 [==============================] - 2s 8ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 278/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 279/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n","Epoch 280/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 281/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 282/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 283/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 284/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0057\n","Epoch 285/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 286/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 287/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 288/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 289/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 290/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 291/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0057\n","Epoch 292/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 293/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 294/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 295/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 296/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 297/350\n","225/225 [==============================] - 2s 8ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 298/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 299/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 300/350\n","225/225 [==============================] - 2s 8ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 301/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 302/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 303/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 304/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 305/350\n","225/225 [==============================] - 2s 8ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 306/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 307/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 308/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0057\n","Epoch 309/350\n","225/225 [==============================] - 2s 8ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 310/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 311/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 312/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 313/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 314/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 315/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 316/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 317/350\n","225/225 [==============================] - 2s 8ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 318/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 319/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 320/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 321/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 322/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 323/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 324/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 325/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 326/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 327/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0063 - mean_squared_error: 0.0062 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 328/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 329/350\n","225/225 [==============================] - 2s 11ms/step - loss: 0.0063 - mean_squared_error: 0.0062 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 330/350\n","225/225 [==============================] - 3s 12ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 331/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 332/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 333/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 334/350\n","225/225 [==============================] - 2s 8ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0057 - val_mean_squared_error: 0.0056\n","Epoch 335/350\n","225/225 [==============================] - 2s 8ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n","Epoch 336/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 337/350\n","225/225 [==============================] - 2s 8ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 338/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 339/350\n","225/225 [==============================] - 2s 8ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n","Epoch 340/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 341/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n","Epoch 342/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 343/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n","Epoch 344/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n","Epoch 345/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n","Epoch 346/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n","Epoch 347/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n","Epoch 348/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n","Epoch 349/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n","Epoch 350/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n","./defensive_models/350_0918_DAE_GTSRB_I\n","Epoch 1/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0677 - mean_squared_error: 0.0677 - val_loss: 0.0465 - val_mean_squared_error: 0.0465\n","Epoch 2/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0367 - mean_squared_error: 0.0367 - val_loss: 0.0288 - val_mean_squared_error: 0.0288\n","Epoch 3/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0264 - mean_squared_error: 0.0264 - val_loss: 0.0231 - val_mean_squared_error: 0.0231\n","Epoch 4/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0220 - mean_squared_error: 0.0220 - val_loss: 0.0197 - val_mean_squared_error: 0.0197\n","Epoch 5/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0185 - mean_squared_error: 0.0185 - val_loss: 0.0155 - val_mean_squared_error: 0.0155\n","Epoch 6/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0131 - mean_squared_error: 0.0131 - val_loss: 0.0107 - val_mean_squared_error: 0.0107\n","Epoch 7/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0090 - val_mean_squared_error: 0.0089\n","Epoch 8/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.0069 - val_mean_squared_error: 0.0069\n","Epoch 9/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n","Epoch 10/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n","Epoch 11/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0044 - val_mean_squared_error: 0.0043\n","Epoch 12/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n","Epoch 13/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n","Epoch 14/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n","Epoch 15/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n","Epoch 16/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n","Epoch 17/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0034 - val_mean_squared_error: 0.0033\n","Epoch 18/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n","Epoch 19/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n","Epoch 20/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0032 - val_mean_squared_error: 0.0031\n","Epoch 21/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n","Epoch 22/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n","Epoch 23/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n","Epoch 24/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n","Epoch 25/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0038 - mean_squared_error: 0.0037 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n","Epoch 26/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n","Epoch 27/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n","Epoch 28/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n","Epoch 29/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n","Epoch 30/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n","Epoch 31/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n","Epoch 32/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n","Epoch 33/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n","Epoch 34/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n","Epoch 35/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n","Epoch 36/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0035 - mean_squared_error: 0.0034 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n","Epoch 37/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n","Epoch 38/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n","Epoch 39/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n","Epoch 40/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n","Epoch 41/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0034 - mean_squared_error: 0.0033 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n","Epoch 42/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n","Epoch 43/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n","Epoch 44/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n","Epoch 45/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n","Epoch 46/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n","Epoch 47/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0033 - mean_squared_error: 0.0032 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n","Epoch 48/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n","Epoch 49/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n","Epoch 50/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n","Epoch 51/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n","Epoch 52/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n","Epoch 53/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n","Epoch 54/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n","Epoch 55/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n","Epoch 56/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n","Epoch 57/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0032 - mean_squared_error: 0.0031 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n","Epoch 58/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n","Epoch 59/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n","Epoch 60/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n","Epoch 61/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n","Epoch 62/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n","Epoch 63/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n","Epoch 64/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n","Epoch 65/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n","Epoch 66/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n","Epoch 67/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n","Epoch 68/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n","Epoch 69/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n","Epoch 70/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n","Epoch 71/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n","Epoch 72/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n","Epoch 73/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n","Epoch 74/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n","Epoch 75/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n","Epoch 76/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0021 - val_mean_squared_error: 0.0020\n","Epoch 77/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n","Epoch 78/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n","Epoch 79/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n","Epoch 80/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n","Epoch 81/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n","Epoch 82/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n","Epoch 83/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n","Epoch 84/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n","Epoch 85/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n","Epoch 86/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n","Epoch 87/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n","Epoch 88/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n","Epoch 89/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0020 - val_mean_squared_error: 0.0019\n","Epoch 90/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n","Epoch 91/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n","Epoch 92/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n","Epoch 93/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n","Epoch 94/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n","Epoch 95/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n","Epoch 96/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n","Epoch 97/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n","Epoch 98/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n","Epoch 99/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n","Epoch 100/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n","Epoch 101/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n","Epoch 102/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n","Epoch 103/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n","Epoch 104/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n","Epoch 105/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n","Epoch 106/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0028 - mean_squared_error: 0.0027 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n","Epoch 107/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n","Epoch 108/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n","Epoch 109/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n","Epoch 110/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n","Epoch 111/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n","Epoch 112/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n","Epoch 113/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n","Epoch 114/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n","Epoch 115/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n","Epoch 116/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n","Epoch 117/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n","Epoch 118/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n","Epoch 119/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n","Epoch 120/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n","Epoch 121/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n","Epoch 122/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n","Epoch 123/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n","Epoch 124/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n","Epoch 125/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n","Epoch 126/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n","Epoch 127/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0016 - val_mean_squared_error: 0.0015\n","Epoch 128/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n","Epoch 129/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n","Epoch 130/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n","Epoch 131/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n","Epoch 132/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n","Epoch 133/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n","Epoch 134/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n","Epoch 135/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n","Epoch 136/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n","Epoch 137/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n","Epoch 138/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n","Epoch 139/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n","Epoch 140/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n","Epoch 141/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n","Epoch 142/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n","Epoch 143/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n","Epoch 144/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n","Epoch 145/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n","Epoch 146/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n","Epoch 147/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n","Epoch 148/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n","Epoch 149/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n","Epoch 150/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n","Epoch 151/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n","Epoch 152/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n","Epoch 153/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n","Epoch 154/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n","Epoch 155/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n","Epoch 156/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n","Epoch 157/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n","Epoch 158/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n","Epoch 159/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n","Epoch 160/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n","Epoch 161/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n","Epoch 162/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n","Epoch 163/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n","Epoch 164/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n","Epoch 165/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n","Epoch 166/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0024 - mean_squared_error: 0.0023 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n","Epoch 167/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n","Epoch 168/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0024 - mean_squared_error: 0.0023 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n","Epoch 169/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n","Epoch 170/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n","Epoch 171/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n","Epoch 172/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n","Epoch 173/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n","Epoch 174/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n","Epoch 175/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n","Epoch 176/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n","Epoch 177/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n","Epoch 178/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0014 - val_mean_squared_error: 0.0013\n","Epoch 179/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 180/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 181/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n","Epoch 182/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0014 - val_mean_squared_error: 0.0013\n","Epoch 183/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 184/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 185/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 186/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n","Epoch 187/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 188/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n","Epoch 189/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n","Epoch 190/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 191/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 192/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 193/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0014 - val_mean_squared_error: 0.0013\n","Epoch 194/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 195/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 196/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 197/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 198/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 199/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 200/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 201/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0014 - val_mean_squared_error: 0.0013\n","Epoch 202/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n","Epoch 203/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 204/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 205/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 206/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 207/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 208/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 209/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 210/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 211/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 212/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 213/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 214/350\n","225/225 [==============================] - 1s 5ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 215/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 216/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 217/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 218/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 219/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 220/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 221/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 222/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 223/350\n","225/225 [==============================] - 2s 10ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 224/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 225/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 226/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 227/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 228/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 229/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 230/350\n","225/225 [==============================] - 2s 9ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 231/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 232/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 233/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 234/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 235/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 236/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 237/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 238/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 239/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 240/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 241/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 242/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 243/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 244/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 245/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 246/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 247/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 248/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 249/350\n","225/225 [==============================] - 2s 8ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 250/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 251/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 252/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 253/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 254/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 255/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 256/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 257/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 258/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 259/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 260/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 261/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 262/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 263/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 264/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0012\n","Epoch 265/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 266/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 267/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 268/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 269/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 270/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 271/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 272/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 273/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 274/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 275/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 276/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 277/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 278/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 279/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 280/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 281/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 282/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 283/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 284/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 285/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 286/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 287/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 288/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0012\n","Epoch 289/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n","Epoch 290/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0012\n","Epoch 291/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 292/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 293/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 294/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 295/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0012\n","Epoch 296/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 297/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 298/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 299/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 300/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0012\n","Epoch 301/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n","Epoch 302/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0012\n","Epoch 303/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 304/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 305/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0022 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n","Epoch 306/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0022 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 307/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0023 - mean_squared_error: 0.0022 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 308/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 309/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 310/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0022 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 311/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0022 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n","Epoch 312/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0022 - val_loss: 0.0013 - val_mean_squared_error: 0.0012\n","Epoch 313/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0022 - val_loss: 0.0013 - val_mean_squared_error: 0.0012\n","Epoch 314/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 315/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 316/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0023 - mean_squared_error: 0.0022 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 317/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n","Epoch 318/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n","Epoch 319/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 320/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 321/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 322/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0013 - val_mean_squared_error: 0.0012\n","Epoch 323/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 324/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 325/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 326/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n","Epoch 327/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 328/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n","Epoch 329/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 330/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 331/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 332/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 333/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n","Epoch 334/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n","Epoch 335/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n","Epoch 336/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n","Epoch 337/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 338/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 339/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 340/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 341/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n","Epoch 342/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0013 - val_mean_squared_error: 0.0012\n","Epoch 343/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","Epoch 344/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n","Epoch 345/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n","Epoch 346/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0013 - val_mean_squared_error: 0.0012\n","Epoch 347/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n","Epoch 348/350\n","225/225 [==============================] - 2s 7ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n","Epoch 349/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0013 - val_mean_squared_error: 0.0012\n","Epoch 350/350\n","225/225 [==============================] - 1s 6ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n","./defensive_models/350_0918_DAE_GTSRB_II\n"]}]},{"cell_type":"markdown","source":["### MagNet - 1"],"metadata":{"id":"mzltzwx8he_N"}},{"cell_type":"code","source":["ad_examples1 = np.array(ad_examples)\n","orig_labels1 = to_categorical(orig_labels)"],"metadata":{"id":"BZXZc5yXGbHR","executionInfo":{"status":"ok","timestamp":1663473175562,"user_tz":-540,"elapsed":886,"user":{"displayName":"이진규","userId":"11520813773494359482"}}},"execution_count":112,"outputs":[]},{"cell_type":"code","source":["ad_examples1.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jNeNPwhcwXgR","executionInfo":{"status":"ok","timestamp":1663473657199,"user_tz":-540,"elapsed":307,"user":{"displayName":"이진규","userId":"11520813773494359482"}},"outputId":"3d2fcc10-2c1e-467a-ae00-a4fd713a29cc"},"execution_count":123,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(6030, 32, 32, 3)"]},"metadata":{},"execution_count":123}]},{"cell_type":"code","source":["print(np.min(ad_examples1[0]))\n","print(np.max(ad_examples1[0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n88gOua2r0cF","executionInfo":{"status":"ok","timestamp":1663473175563,"user_tz":-540,"elapsed":8,"user":{"displayName":"이진규","userId":"11520813773494359482"}},"outputId":"c174f504-6c37-4cc8-ed16-d76f8cb1e44c"},"execution_count":113,"outputs":[{"output_type":"stream","name":"stdout","text":["0.03658828\n","0.90831506\n"]}]},{"cell_type":"code","source":["orig_labels1[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S6TVgUZer8GA","executionInfo":{"status":"ok","timestamp":1663473175563,"user_tz":-540,"elapsed":6,"user":{"displayName":"이진규","userId":"11520813773494359482"}},"outputId":"4f05dfe8-aeed-4c92-9016-1ede241b8fde"},"execution_count":114,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"]},"metadata":{},"execution_count":114}]},{"cell_type":"code","source":[" data_test.y_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W0UMav8hwSJ0","executionInfo":{"status":"ok","timestamp":1663473626506,"user_tz":-540,"elapsed":368,"user":{"displayName":"이진규","userId":"11520813773494359482"}},"outputId":"5e89da7b-7a90-4249-bd9b-974d7d4b8087"},"execution_count":122,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 0., ..., 0., 0., 1.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 1.],\n","       ...,\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 1., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"]},"metadata":{},"execution_count":122}]},{"cell_type":"code","source":["# 원본 이미지\n","classifier = Classifier(\"./models/gtsrb_classifier\")\n","loss, accuracy = classifier.model.evaluate(data_test.x_test/255, data_test.y_test)\n","\n","print('test set accuracy (original) : ', accuracy * 100)"],"metadata":{"id":"0vMxKPzjhhAy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663473250352,"user_tz":-540,"elapsed":1881,"user":{"displayName":"이진규","userId":"11520813773494359482"}},"outputId":"4b784d75-3d32-410d-c00c-c4e280052ded"},"execution_count":116,"outputs":[{"output_type":"stream","name":"stdout","text":["194/194 [==============================] - 1s 4ms/step - loss: 0.0281 - accuracy: 0.9757\n","test set accuracy (original) :  97.57281541824341\n"]}]},{"cell_type":"code","source":["# 공격받은 이미지\n","classifier = Classifier(\"./models/gtsrb_classifier\")\n","loss, accuracy = classifier.model.evaluate(ad_examples1, orig_labels1)\n","\n","print('test set accuracy (attacked) : ', accuracy * 100)"],"metadata":{"id":"ca5TN0fGhrgk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663473284279,"user_tz":-540,"elapsed":2248,"user":{"displayName":"이진규","userId":"11520813773494359482"}},"outputId":"fa8a85bd-ecbb-49c7-d517-543585df0a07"},"execution_count":117,"outputs":[{"output_type":"stream","name":"stdout","text":["189/189 [==============================] - 1s 4ms/step - loss: 0.0433 - accuracy: 1.0000\n","test set accuracy (attacked) :  100.0\n"]}]},{"cell_type":"code","source":["DAE_detector_I = AEDetector(\"./defensive_models/350_0918_DAE_GTSRB_I\", p=2)\n","DAE_detector_II = AEDetector(\"./defensive_models/350_0918_DAE_GTSRB_II\", p=1)\n","DAE_reformer = SimpleReformer(\"./defensive_models/350_0918_DAE_GTSRB_I\")\n","\n","\n","DAE_id_reformer = IdReformer()\n","DAE_classifier = Classifier(\"./models/gtsrb_classifier\")"],"metadata":{"id":"L6gv49XOhtCl","executionInfo":{"status":"ok","timestamp":1663473771380,"user_tz":-540,"elapsed":2352,"user":{"displayName":"이진규","userId":"11520813773494359482"}}},"execution_count":124,"outputs":[]},{"cell_type":"code","source":["detector_JSD1 = DBDetector(DAE_id_reformer, DAE_reformer, DAE_classifier, T=10)\n","detector_JSD2 = DBDetector(DAE_id_reformer, DAE_reformer, DAE_classifier, T=40)\n","\n","\n","DAE_detector_dict = dict()\n","DAE_detector_dict[\"I\"] = DAE_detector_I\n","DAE_detector_dict[\"II\"] = DAE_detector_II\n","DAE_detector_dict[\"JSD1\"] = detector_JSD1\n","DAE_detector_dict[\"JSD2\"] = detector_JSD2"],"metadata":{"id":"qRcUtasdhuRN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["DAE_operator = Operator(data, DAE_classifier, DAE_detector_dict, DAE_reformer)\n","DAE_testAttack = AttackData(ad_examples1, orig_labels, \"GTSRB FSGM\")"],"metadata":{"id":"36Yx1eqahvso"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["DAE_evaluator = Evaluator(DAE_operator, DAE_testAttack)\n","DAE_evaluator.plot_various_confidences(\"defense_performance\", drop_rate={\"I\": 0.001, \"II\": 0.001,\"JSD1\": 0.001,\"JSD2\": 0.001})"],"metadata":{"id":"C3MbM1HDhwv0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('with reformer')\n","\n","predict = np.array((DAE_reformer.model.predict(ad_examples1))).reshape(-1,32,32,3)\n","predicted1 = np.argmax(classifier.model.predict(predict),axis=1)\n","\n","print(np.mean(predicted1[:len(orig_labels)] == orig_labels[:len(orig_labels)]))\n","# print(.sum(predicted==orig_labels))#,predicted)"],"metadata":{"id":"gBi_uO4Dhx6D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(type(data.x_train))\n","print(type(ad_examples))"],"metadata":{"id":"AmEhY0bFhzJd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Defense-GAN"],"metadata":{"id":"vIK9wb4vIIlv"}},{"cell_type":"markdown","metadata":{"id":"P9v5DhrcQTi_"},"source":["###  Defense Model 1 : DefenseGAN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1w18KhjvQaN-"},"outputs":[],"source":["import numpy as np\n","import os\n","import gzip\n","import urllib.request\n","\n","from keras.models import load_model\n","\n","def ordered_onehotencoding(labels):\n","    labels_ordered = []\n","    for i in range(len(labels)):\n","        if labels[i] == 3:\n","            labels_ordered.append(0)\n","        elif labels[i] == 7:\n","            labels_ordered.append(1)\n","        elif labels[i] == 9:\n","            labels_ordered.append(2)\n","        elif labels[i] == 10:\n","            labels_ordered.append(3)\n","        elif labels[i] == 11:\n","            labels_ordered.append(4)\n","        elif labels[i] == 12:\n","            labels_ordered.append(5)\n","        elif labels[i] == 13:\n","            labels_ordered.append(6)\n","        elif labels[i] == 17:\n","            labels_ordered.append(7)\n","        elif labels[i] == 18:\n","            labels_ordered.append(8)\n","        elif labels[i] == 25:\n","            labels_ordered.append(9)\n","        elif labels[i] == 35:\n","            labels_ordered.append(10)\n","        elif labels[i] == 38:\n","            labels_ordered.append(11)\n","    \n","    return np.array(labels_ordered)\n","\n","class GTSRB_defenseGAN:\n","    def __init__(self):\n","        imgs_path = \"Train\"\n","        data_list = []\n","        labels_list = []\n","\n","        result_class = [3,7, 9, 10, 11, 12, 13, 17, 18, 25, 35, 38]\n","\n","        for i in result_class:\n","            i_path = os.path.join(imgs_path, str(i)) # 3, 7, 9, 10, 11, 12,13, 17, 18, 25, 35, 38\n","            num = 0\n","            for img in os.listdir(i_path):\n","          \n","                im = Image.open(i_path +'/'+ img)\n","                im = im.resize((32,32))\n","                im = np.array(im)\n","\n","                data_list.append(im)\n","                labels_list.append(i)\n","                num = num + 1\n","                if num == 1000:\n","                    break;\n","\n","        data = np.array(data_list)\n","        labels = ordered_onehotencoding(labels_list)\n","\n","        labels = to_categorical(labels)\n","\n","        VALIDATION_SIZE = 5000\n","        \n","        data = (data.astype(np.float32) - 127.5) / 127.5 #모든 데이터 픽셀 값을 -1~1로 피팅 시킨다 (GAN 학습을 위함)\n","        \n","        self.x_train = np.array(data)\n","        self.y_train = labels\n","\n","    @staticmethod\n","    def print():\n","        return \"GTSRB_defenseGAN\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jFZPnqlWRPA7"},"outputs":[],"source":["data_train_GAN = GTSRB_defenseGAN()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a_zbYD_uRrNQ"},"outputs":[],"source":["print(data_train_GAN.x_train.shape)\n","print(data_train_GAN.y_train.shape)"]},{"cell_type":"markdown","metadata":{"id":"nZvOoqJqTtgW"},"source":["GAN 생성"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rOz8KOvWRqFq"},"outputs":[],"source":["import numpy as np \n","import matplotlib.pyplot as plt \n","\n","from keras.datasets import mnist\n","\n","from keras.models import Sequential, Model\n","\n","from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n","from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.layers.convolutional import UpSampling2D, Conv2D\n","\n","from tensorflow.keras.optimizers import Adam\n","\n","noise_data = np.random.normal(0, 1, (32, 100))\n","#generated_images = 0.5 * generator.predict(np.random.normal(0, 1, (32, 100))) + 0.5\n","\n","def show_images(generated_images, n=4, m=8, figsize=(9, 5)):\n","    f, axes = plt.subplots(n, m, figsize=figsize)\n","    #plt.subplots_adjust(top=1, bottom=0, hspace=0, wspace=0.05)\n","    for i in range(0, n):\n","        for j in range(0, m):\n","            ax = axes[i][j]\n","            ax.imshow(generated_images[i * m + j])\n","            ax.grid(False)\n","            ax.xaxis.set_ticks([])\n","            ax.yaxis.set_ticks([])\n","    plt.tight_layout()\n","    plt.savefig('20220729_basicgan.svg')\n","    plt.show()   \n","#show_images(0.5 * generator.predict(np.random.normal(0, 1, (32, 100))) + 0.5)\n","\n","\n","## create generator         \n","generator_ = Sequential([\n","    Dense(128 * 8 * 8, activation=\"relu\", input_shape=(100,)), \n","    Reshape((8, 8, 128)), \n","    \n","    BatchNormalization(momentum=0.8), # what is batch normalization?? \n","    UpSampling2D(), # what is upsampling?? \n","    Conv2D(128, kernel_size=3, padding=\"same\"),\n","    Activation(\"relu\"), \n","    \n","    BatchNormalization(momentum=0.8), \n","    UpSampling2D(), \n","    Conv2D(64, kernel_size=3, padding=\"same\"), \n","    Activation(\"relu\"), \n","    \n","    BatchNormalization(momentum=0.8), \n","    Conv2D(3, kernel_size=3, padding=\"same\"), \n","    Activation(\"tanh\"), \n","])\n","\n","noise_input = Input(shape=(100,), name=\"noise_input\")\n","generator_base = Model(noise_input, generator_(noise_input), name=\"generator\")\n","\n","generator_.summary()# summary가 매우 유용하군요. \n","\n","optimizer = Adam(0.0002, 0.5)\n","generator_base.compile(loss='binary_crossentropy', optimizer=optimizer)\n","\n","### create discriminator\n","discriminator_ = Sequential([\n","    Conv2D(32, kernel_size=3, strides=2, input_shape=(32, 32, 3), padding=\"same\"), \n","    LeakyReLU(alpha=0.2), \n","    Dropout(0.25), \n","    \n","    Conv2D(64, kernel_size=3, strides=2, padding=\"same\"), \n","    ZeroPadding2D(padding=((0,1),(0,1))), \n","    LeakyReLU(alpha=0.2), \n","    Dropout(0.25), \n","    BatchNormalization(momentum=0.8), \n","    \n","    Conv2D(128, kernel_size=3, strides=2, padding=\"same\"), \n","    LeakyReLU(alpha=0.2), \n","    Dropout(0.25), \n","    BatchNormalization(momentum=0.8), \n","    \n","    Conv2D(256, kernel_size=3, strides=1, padding=\"same\"), \n","    LeakyReLU(alpha=0.2), \n","    Dropout(0.25), \n","    Flatten(), \n","    Dense(1, activation='sigmoid'), \n","])\n","image_input = Input(shape=(32, 32, 3), name=\"image_input\")\n","\n","discriminator = Model(image_input, discriminator_(image_input), name=\"discriminator\")\n","discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","discriminator_.summary()\n","\n","### Combined Model\n","noise_input2 = Input(shape=(100,), name=\"noise_input2\")\n","\"\"\"\n","model과 sequential의 차이는?? \n","가설1: 레이어를 쌓는 것이 sequential 이라면, sequential을 쌓는 것이 model인가???\n","\n","1) 다음 모델의 경우는 랜덤으로 만든 이미지로부터 학습해서 새로운 이미지를 만들어내는 generator의 데이터를 \n","2) discriminator가 분류하는 형식으로 진행된다. \n","\"\"\"\n","combined = Model(noise_input2, discriminator(generator_base(noise_input2)))\n","combined.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7NWG3wxrSF4p"},"outputs":[],"source":["## training\n","\"\"\"\n","- 이 코드에서는 fit을 사용한 것이 아니라, train_on_batch를 사용했음. \n","- train_on_batch와의 차이점?을 구글에 검색해보니, 큰 차이가 없다고 하긴 하는데\n","    - train_on_batch의 경우, 넘겨 받은 데이터에 대해서 gradient vector를 계산해서 적용하고 끝내는 것이고(1epoch)\n","    - fit의 경우는 epoch과 batch_size를 한번에 모두 넘겨준다는 것 정도가 차이가 된다. \n","- GAN의 경우, discriminator의 학습시 마다 generator가 생성하는 데이터가 변화하게 된다. \n","    - 즉 처음부터 모든 데이터가 존재하고 이를 한번에 학습시키는 fit과는 다르게, 한번씩 업데이트를 할때마다 모델이 변화하므로, \n","    - train_on_batch를 사용하는 것이 매우 합당함.\n","\"\"\"\n","batch_size = 256\n","half_batch = batch_size // 2\n","\n","def train(epochs, print_step=10):\n","    history = []\n","    for epoch in range(epochs):\n","        # discriminator 트레이닝 단계\n","        #######################################################################3\n","        # 데이터 절반은 실제 이미지, 절반은 generator가 생성한 가짜 이미지\n","        # discriminator가 실제 이미지와 가짜 이미지를 구별하도록 discriminator를 트레이닝\n","        discriminator.trainable = True\n","        d_loss_real = discriminator.train_on_batch(data_train_GAN.x_train[np.random.randint(0, data_train_GAN.x_train.shape[0], half_batch)], \n","                                                   np.ones((half_batch, 1)))\n","        d_loss_fake = discriminator.train_on_batch(generator_base.predict(np.random.normal(0, 1, (half_batch, 100))), \n","                                                   np.zeros((half_batch, 1)))\n","        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","        # generator 트레이닝 단계\n","        #######################################################################3\n","        # 전부 generator가 생성한 가짜 이미지를 사용. \n","        # discriminator가 구별하지 못하도록 generator를 트레이닝\n","        \n","        \"\"\"\n","        generator를 트레이닝할 때는, 반드시 discriminator가 필요함. \n","        generator가 만든 image를 평가해야 하고, 그래야 feedback이 생겨서 generator가 학습됨. \n","        따라서, generator는 combined model을 통해 학습시키는데, 이때, discriminator도 함께 학습되면 안되기 때문에\n","        discriminator.trainable 을 False로 변경시켜 둔다. \n","        \"\"\"\n","        noise = np.random.normal(0, 1, (batch_size, 100))\n","        discriminator.trainable = False \n","        g_loss = combined.train_on_batch(noise, np.ones((batch_size, 1)))  #여기서는 왜 만들어준 fake img의 y 값을 1로 두는 걸까 ..\n","        # 기록\n","        record = (epoch, d_loss[0], 100 * d_loss[1], g_loss[0], 100 * g_loss[1])\n","        history.append(record)\n","        if epoch % print_step == 0:\n","            print(\"%5d [D loss: %.3f, acc.: %.2f%%] [G loss: %.3f, acc.: %.2f%%]\" % record)\n","            show_images(0.5 * generator_base.predict(noise_data) + 0.5)\n","    return history\n","#%%time, 은\n","history100 = train(20000, 500)\n","show_images(0.5 * generator_base.predict(noise_data) + 0.5)"]},{"cell_type":"code","source":["# GAN 모델 저장\n","from keras.models import load_model\n","\n","generator_base.save('baseGAN_Generator_attacked0.02.h5')"],"metadata":{"id":"dXXJ-Wgyu_bT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4BPL_wcJTvXO"},"source":["DefenseGAN 구현 - FGSM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h5JFZsEPTqeY"},"outputs":[],"source":["ad_example_data = ad_examples1 #/255로 이미 정규화가 된 이미지이다\n","orig_label_data = orig_labels1\n","\n","print(ad_example_data.shape)\n","print(orig_label_data.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LrHjDgblT_c1"},"outputs":[],"source":["def DefenseGAN(img_at,L,R):\n","    z_list = []\n","    img = img_at.reshape(32,32,3)\n","    img_st = (img - np.mean(img)) / np.std(img) \n","    img_var = tf.Variable(img_st,dtype = float)\n","    opt = tf.keras.optimizers.SGD(learning_rate=0.1,momentum = 0.7)\n","\n","    def compute():\n","        z_hats_recs = generator_base(z_var)\n","        z_hats_recs = tf.reshape(z_hats_recs, [32,32,3])\n","        num_dim = len(z_hats_recs.get_shape())\n","        axes = range(1, num_dim)\n","        image_rec_loss = tf.reduce_mean(tf.square(z_hats_recs - img_var),axis=axes)\n","        rec_loss = tf.reduce_sum(image_rec_loss)\n","        return rec_loss\n","\n","    for r in range(R):\n","        z = np.random.normal(0, 1, (1, 100))\n","        z_var = tf.Variable(z,dtype = float)\n","    \n","        for l in range(L):\n","            opt.minimize(compute,[z_var])\n","        z_list.append(z_var)\n","\n","    def compute_10(z):\n","        #generator_base.trainable = False #아직 더해야하는지 뺴야하는지 판단 x\n","        z_hats_recs = generator_base(z)\n","        z_hats_recs = tf.reshape(z_hats_recs, [32,32,3])\n","        num_dim = len(z_hats_recs.get_shape())\n","        axes = range(1, num_dim)\n","        image_rec_loss = tf.reduce_mean(tf.square(z_hats_recs - img_var),axis=axes)\n","        rec_loss = tf.reduce_sum(image_rec_loss)\n","        return rec_loss\n","    \n","\n","    loss_list = []\n","    \n","    for i in range(len(z_list)):\n","        loss = compute_10(z_list[i])\n","        loss_list.append(loss)\n","    \n","    index_min = np.argmin(loss_list)\n","\n","    z_min = np.array(z_list[index_min])\n","\n","    generated_images = 0.5 * generator_base.predict(z_min)+ 0.5\n","\n","    generated_images = generated_images.reshape(32,32,3)\n","\n","    return generated_images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9ks2QRZbUKO_"},"outputs":[],"source":["## predict_output에 한개씩 넣는 것부터 구현해야한다. (전체가 들어가는 것만 정상 작동함)\n","\n","def test(classifier, ad_example_data, orig_label_data):\n","\n","    # 정확도 카운터\n","    correct = 0\n","    defense_correct = 0\n","    df_examples = []\n","    # 테스트 셋의 모든 예제에 대해 루프를 돕니다\n","\n","    loss, accuracy = classifier.evaluate(ad_examples1, orig_labels1)\n","\n","    print('방어 전 모델 정확도 : ',accuracy * 100)\n","\n","    for i in range(len(ad_example_data)):\n","        data = ad_example_data[i].reshape(-1,32,32,3)\n","        target = orig_label_data[i]\n","        \n","        data_plot = data.reshape(32,32,3)\n","        print('원본 label : ',np.argmax(target))\n","        plt.imshow(data_plot)\n","        plt.show();\n","\n","        generated_img = DefenseGAN(data.reshape(32,32,3),200,10).reshape(-1,32,32,3)\n","\n","        generated_img_plot = generated_img.reshape(32,32,3)\n","\n","\n","        defense_output = classifier.predict(generated_img.reshape(1,32,32,3))\n","\n","        defense_pred= int(np.argmax(defense_output))\n","\n","        print('방어 라벨 : ',defense_pred)\n","        plt.imshow(generated_img_plot)\n","        plt.show();\n","\n","        if defense_pred == int(np.argmax(target)):\n","            defense_correct += 1\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","        else:\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","\n","        print('Working...!')\n","\n","\n","    defense_acc = defense_correct / float(len(ad_example_data))\n","    print(\"Defense Accuracy = {} / {} = {}\".format(defense_correct, len(ad_example_data), defense_acc))\n","    # 정확도와 적대적 예제를 리턴합니다\n","    return defense_acc, df_examples"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UmgqhBaWaqXz"},"outputs":[],"source":["accuracies_df = []\n","examples_df = []\n","\n","acc_df, ex_df = test(model, ad_example_data[:100], orig_label_data[:100])\n","\n","accuracies_df.append(acc_df)\n","examples_df.append(ex_df)"]},{"cell_type":"markdown","source":["### DefenseGAN 구현 - BIM\n","\n"],"metadata":{"id":"2TtBNBJxn2Db"}},{"cell_type":"code","source":["ad_examples_BIM = np.array(ad_examples) # 이미 정규화되어서 나온 값으로 추가적인 /255 정규화 필요 없음\n","orig_labels_BIM = to_categorical(orig_labels)\n","\n","print(ad_examples_BIM.shape)\n","print(orig_labels_BIM.shape)"],"metadata":{"id":"fhZ-PyFGn3lz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# GAN 모델 저장\n","from keras.models import load_model\n","\n","generator_base = load_model('baseGAN_Generator_attacked0.02.h5')"],"metadata":{"id":"lZngn6VduEUE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.imshow(generator_base.predict(np.random.normal(0, 1, (1, 100))).reshape(32,32,3))"],"metadata":{"id":"P4m8Jituudng"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def DefenseGAN(img_at,L,R):\n","    z_list = []\n","    img = img_at.reshape(32,32,3)\n","    img_st = (img - np.mean(img)) / np.std(img) \n","    img_var = tf.Variable(img_st,dtype = float)\n","    opt = tf.keras.optimizers.SGD(learning_rate=0.1,momentum = 0.7)\n","\n","    def compute():\n","        z_hats_recs = generator_base(z_var)\n","        z_hats_recs = tf.reshape(z_hats_recs, [32,32,3])\n","        num_dim = len(z_hats_recs.get_shape())\n","        axes = range(1, num_dim)\n","        image_rec_loss = tf.reduce_mean(tf.square(z_hats_recs - img_var),axis=axes)\n","        rec_loss = tf.reduce_sum(image_rec_loss)\n","        return rec_loss\n","\n","    for r in range(R):\n","        z = np.random.normal(0, 1, (1, 100))\n","        z_var = tf.Variable(z,dtype = float)\n","    \n","        for l in range(L):\n","            opt.minimize(compute,[z_var])\n","        z_list.append(z_var)\n","\n","    def compute_10(z):\n","        #generator_base.trainable = False #아직 더해야하는지 뺴야하는지 판단 x\n","        z_hats_recs = generator_base(z)\n","        z_hats_recs = tf.reshape(z_hats_recs, [32,32,3])\n","        num_dim = len(z_hats_recs.get_shape())\n","        axes = range(1, num_dim)\n","        image_rec_loss = tf.reduce_mean(tf.square(z_hats_recs - img_var),axis=axes)\n","        rec_loss = tf.reduce_sum(image_rec_loss)\n","        return rec_loss\n","    \n","\n","    loss_list = []\n","    \n","    for i in range(len(z_list)):\n","        loss = compute_10(z_list[i])\n","        loss_list.append(loss)\n","    \n","    index_min = np.argmin(loss_list)\n","\n","    z_min = np.array(z_list[index_min])\n","\n","    generated_images = 0.5 * generator_base.predict(z_min)+ 0.5\n","\n","    generated_images = generated_images.reshape(32,32,3)\n","\n","    return generated_images"],"metadata":{"id":"2Zppe2W6n3n9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## predict_output에 한개씩 넣는 것부터 구현해야한다. (전체가 들어가는 것만 정상 작동함)\n","\n","def test(classifier, ad_example_data, orig_label_data):\n","\n","    # 정확도 카운터\n","    correct = 0\n","    defense_correct = 0\n","    df_examples = []\n","    # 테스트 셋의 모든 예제에 대해 루프를 돕니다\n","\n","    loss, accuracy = classifier.evaluate(ad_example_data, orig_label_data)\n","\n","    print('방어 전 모델 정확도 : ',accuracy * 100)\n","\n","    for i in range(len(ad_example_data)):\n","        data = ad_example_data[i].reshape(-1,32,32,3)\n","        target = orig_label_data[i]\n","        \n","        data_plot = data.reshape(32,32,3)\n","        print('원본 label : ',np.argmax(target))\n","        plt.imshow(data_plot)\n","        plt.show();\n","\n","        generated_img = DefenseGAN(data.reshape(32,32,3),200,10).reshape(-1,32,32,3)\n","\n","        generated_img_plot = generated_img.reshape(32,32,3)\n","\n","\n","        defense_output = classifier.predict(generated_img.reshape(1,32,32,3))\n","\n","        defense_pred= int(np.argmax(defense_output))\n","\n","        print('방어 라벨 : ',defense_pred)\n","        plt.imshow(generated_img_plot)\n","        plt.show();\n","\n","        if defense_pred == int(np.argmax(target)):\n","            defense_correct += 1\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","        else:\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","\n","        print('Working...!')\n","\n","\n","    defense_acc = defense_correct / float(len(ad_example_data))\n","    print(\"Defense Accuracy = {} / {} = {}\".format(defense_correct, len(ad_example_data), defense_acc))\n","    # 정확도와 적대적 예제를 리턴합니다\n","    return defense_acc, df_examples"],"metadata":{"id":"HsGI-NY4n3qe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["accuracies_df = []\n","examples_df = []\n","\n","acc_df, ex_df = test(model, ad_examples_BIM[:100], orig_labels_BIM[:100])\n","\n","accuracies_df.append(acc_df)\n","examples_df.append(ex_df)"],"metadata":{"id":"qnYmHP5Bn3tC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## PCA"],"metadata":{"id":"63SBpYd-IL2u"}},{"cell_type":"markdown","metadata":{"id":"1ywsHS3sfPxD"},"source":["### Defense 2 : PCA (Components = 5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KuoOeVKxsyvD"},"outputs":[],"source":["ad_example_data = ad_examples1 #/255로 이미 정규화가 된 이미지이다\n","orig_label_data = orig_labels1\n","\n","print(ad_example_data.shape)\n","print(orig_label_data.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rAB3avuSbB3q"},"outputs":[],"source":["from sklearn.decomposition import PCA\n","\n","# data shape이 32,32,3이어야한다.\n","def defense_PCA(data,component):\n","    #r,g,b를 각각 나눠준다\n","    data = data.reshape(32,32,3)\n","    r = data[:,:,0]\n","    g = data[:,:,1]\n","    b = data[:,:,2]\n","\n","    pca_r = PCA(n_components=component)\n","    pca_r_trans = pca_r.fit_transform(r)\n","\n","    pca_g = PCA(n_components=component)\n","    pca_g_trans = pca_g.fit_transform(g)\n","\n","    pca_b = PCA(n_components=component)\n","    pca_b_trans = pca_b.fit_transform(b)\n","\n","    pca_r_org = pca_r.inverse_transform(pca_r_trans)\n","    pca_g_org = pca_g.inverse_transform(pca_g_trans)\n","    pca_b_org = pca_b.inverse_transform(pca_b_trans)\n","\n","    img_compressed = np.stack((pca_r_org, pca_g_org, pca_b_org),axis = 2)\n","\n","    return img_compressed.reshape((-1,32,32,3))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j2uWTxjIf-a-"},"outputs":[],"source":["## predict_output에 한개씩 넣는 것부터 구현해야한다. (전체가 들어가는 것만 정상 작동함)\n","\n","def test(classifier, ad_example_data, orig_label_data):\n","\n","    # 정확도 카운터\n","    correct = 0\n","    defense_correct = 0\n","    df_examples = []\n","    # 테스트 셋의 모든 예제에 대해 루프를 돕니다\n","\n","    loss, accuracy = classifier.evaluate(ad_examples1, orig_labels1)\n","\n","    print('방어 전 모델 정확도 : ',accuracy * 100)\n","\n","    for i in range(len(ad_example_data)):\n","        data = ad_example_data[i].reshape(-1,32,32,3)\n","        target = orig_label_data[i]\n","        \n","        data_plot = data.reshape(32,32,3)\n","        print('원본 label : ',np.argmax(target))\n","        plt.imshow(data_plot)\n","        plt.show();\n","\n","        generated_img = defense_PCA(data,5)\n","\n","        generated_img_plot = generated_img.reshape(32,32,3)\n","\n","        defense_output = classifier.predict(generated_img.reshape(1,32,32,3))\n","\n","        defense_pred= int(np.argmax(defense_output))\n","\n","        print('방어 라벨 : ',defense_pred)\n","        plt.imshow(generated_img_plot)\n","        plt.show();\n","\n","        if defense_pred == int(np.argmax(target)):\n","            defense_correct += 1\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","        else:\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","\n","        print('Working...!')\n","\n","\n","    defense_acc = defense_correct / float(len(ad_example_data))\n","    print(\"Defense Accuracy = {} / {} = {}\".format(defense_correct, len(ad_example_data), defense_acc))\n","    # 정확도와 적대적 예제를 리턴합니다\n","    return defense_acc, df_examples"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TGm6ObXDhR2V"},"outputs":[],"source":["accuracies_df = []\n","examples_df = []\n","\n","acc_df, ex_df = test(model, ad_example_data, orig_label_data)\n","\n","accuracies_df.append(acc_df)\n","examples_df.append(ex_df)"]},{"cell_type":"markdown","metadata":{"id":"9Y_-9xiJiAeC"},"source":["### Defense 2 : PCA (Components = 10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZOiE-bIgsz6w"},"outputs":[],"source":["ad_example_data = ad_examples1 #/255로 이미 정규화가 된 이미지이다\n","orig_label_data = orig_labels1\n","\n","print(ad_example_data.shape)\n","print(orig_label_data.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EyLQ-kGQwqEZ"},"outputs":[],"source":["from sklearn.decomposition import PCA\n","\n","# data shape이 32,32,3이어야한다.\n","def defense_PCA(data,component):\n","    #r,g,b를 각각 나눠준다\n","    data = data.reshape(32,32,3)\n","    r = data[:,:,0]\n","    g = data[:,:,1]\n","    b = data[:,:,2]\n","\n","    pca_r = PCA(n_components=component)\n","    pca_r_trans = pca_r.fit_transform(r)\n","\n","    pca_g = PCA(n_components=component)\n","    pca_g_trans = pca_g.fit_transform(g)\n","\n","    pca_b = PCA(n_components=component)\n","    pca_b_trans = pca_b.fit_transform(b)\n","\n","    pca_r_org = pca_r.inverse_transform(pca_r_trans)\n","    pca_g_org = pca_g.inverse_transform(pca_g_trans)\n","    pca_b_org = pca_b.inverse_transform(pca_b_trans)\n","\n","    img_compressed = np.stack((pca_r_org, pca_g_org, pca_b_org),axis = 2)\n","\n","    return img_compressed.reshape((-1,32,32,3))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lWXuP7V4iPO0"},"outputs":[],"source":["## predict_output에 한개씩 넣는 것부터 구현해야한다. (전체가 들어가는 것만 정상 작동함)\n","\n","def test(classifier, ad_example_data, orig_label_data):\n","\n","    # 정확도 카운터\n","    correct = 0\n","    defense_correct = 0\n","    df_examples = []\n","    # 테스트 셋의 모든 예제에 대해 루프를 돕니다\n","\n","    loss, accuracy = classifier.evaluate(ad_examples1, orig_labels1)\n","\n","    print('방어 전 모델 정확도 : ',accuracy * 100)\n","\n","    for i in range(len(ad_example_data)):\n","        data = ad_example_data[i].reshape(-1,32,32,3)\n","        target = orig_label_data[i]\n","        \n","        data_plot = data.reshape(32,32,3)\n","        print('원본 label : ',np.argmax(target))\n","        plt.imshow(data_plot)\n","        plt.show();\n","\n","        generated_img = defense_PCA(data,10)\n","\n","        generated_img_plot = generated_img.reshape(32,32,3)\n","\n","        defense_output = classifier.predict(generated_img.reshape(1,32,32,3))\n","\n","        defense_pred= int(np.argmax(defense_output))\n","\n","        print('방어 라벨 : ',defense_pred)\n","        plt.imshow(generated_img_plot)\n","        plt.show();\n","\n","        if defense_pred == int(np.argmax(target)):\n","            defense_correct += 1\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","        else:\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","\n","        print('Working...!')\n","\n","\n","    defense_acc = defense_correct / float(len(ad_example_data))\n","    print(\"Defense Accuracy = {} / {} = {}\".format(defense_correct, len(ad_example_data), defense_acc))\n","    # 정확도와 적대적 예제를 리턴합니다\n","    return defense_acc, df_examples"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HP7_KoXqiWhf"},"outputs":[],"source":["accuracies_df = []\n","examples_df = []\n","\n","acc_df, ex_df = test(model, ad_example_data, orig_label_data)\n","\n","accuracies_df.append(acc_df)\n","examples_df.append(ex_df)"]},{"cell_type":"markdown","source":["### Defense 2 : PCA (Components = 5)"],"metadata":{"id":"hGoEmuWF4S1T"}},{"cell_type":"code","source":["ad_examples_BIM = np.array(ad_examples) # 이미 정규화되어서 나온 값으로 추가적인 /255 정규화 필요 없음\n","orig_labels_BIM = to_categorical(orig_labels)\n","\n","print(ad_examples_BIM.shape)\n","print(orig_labels_BIM.shape)\n","\n","from sklearn.decomposition import PCA\n","\n","# data shape이 32,32,3이어야한다.\n","def defense_PCA(data,component):\n","    #r,g,b를 각각 나눠준다\n","    data = data.reshape(32,32,3)\n","    r = data[:,:,0]\n","    g = data[:,:,1]\n","    b = data[:,:,2]\n","\n","    pca_r = PCA(n_components=component)\n","    pca_r_trans = pca_r.fit_transform(r)\n","\n","    pca_g = PCA(n_components=component)\n","    pca_g_trans = pca_g.fit_transform(g)\n","\n","    pca_b = PCA(n_components=component)\n","    pca_b_trans = pca_b.fit_transform(b)\n","\n","    pca_r_org = pca_r.inverse_transform(pca_r_trans)\n","    pca_g_org = pca_g.inverse_transform(pca_g_trans)\n","    pca_b_org = pca_b.inverse_transform(pca_b_trans)\n","\n","    img_compressed = np.stack((pca_r_org, pca_g_org, pca_b_org),axis = 2)\n","\n","    return img_compressed.reshape((-1,32,32,3))\n","\n","## predict_output에 한개씩 넣는 것부터 구현해야한다. (전체가 들어가는 것만 정상 작동함)\n","\n","def test(classifier, ad_example_data, orig_label_data):\n","\n","    # 정확도 카운터\n","    correct = 0\n","    defense_correct = 0\n","    df_examples = []\n","    # 테스트 셋의 모든 예제에 대해 루프를 돕니다\n","\n","    loss, accuracy = classifier.evaluate(ad_examples_BIM, orig_labels_BIM)\n","\n","    print('방어 전 모델 정확도 : ',accuracy * 100)\n","\n","    for i in range(len(ad_example_data)):\n","        data = ad_example_data[i].reshape(-1,32,32,3)\n","        target = orig_label_data[i]\n","        \n","        data_plot = data.reshape(32,32,3)\n","        print('원본 label : ',np.argmax(target))\n","        plt.imshow(data_plot)\n","        plt.show();\n","\n","        generated_img = defense_PCA(data,5)\n","\n","        generated_img_plot = generated_img.reshape(32,32,3)\n","\n","        defense_output = classifier.predict(generated_img.reshape(1,32,32,3))\n","\n","        defense_pred= int(np.argmax(defense_output))\n","\n","        print('방어 라벨 : ',defense_pred)\n","        plt.imshow(generated_img_plot)\n","        plt.show();\n","\n","        if defense_pred == int(np.argmax(target)):\n","            defense_correct += 1\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","        else:\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","\n","        print('Working...!')\n","\n","\n","    defense_acc = defense_correct / float(len(ad_example_data))\n","    print(\"Defense Accuracy = {} / {} = {}\".format(defense_correct, len(ad_example_data), defense_acc))\n","    # 정확도와 적대적 예제를 리턴합니다\n","    return defense_acc, df_examples"],"metadata":{"id":"sP6AyMGH4bkk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["accuracies_df = []\n","examples_df = []\n","\n","acc_df, ex_df = test(model, ad_examples_BIM[:1000], orig_labels_BIM[:1000])\n","\n","accuracies_df.append(acc_df)\n","examples_df.append(ex_df)"],"metadata":{"id":"pJv8QiS94bm8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Defense 2 : PCA (Components = 10)"],"metadata":{"id":"7rWZ6_Kf48hG"}},{"cell_type":"code","source":["ad_examples_BIM = np.array(ad_examples) # 이미 정규화되어서 나온 값으로 추가적인 /255 정규화 필요 없음\n","orig_labels_BIM = to_categorical(orig_labels)\n","\n","print(ad_examples_BIM.shape)\n","print(orig_labels_BIM.shape)\n","\n","from sklearn.decomposition import PCA\n","\n","# data shape이 32,32,3이어야한다.\n","def defense_PCA(data,component):\n","    #r,g,b를 각각 나눠준다\n","    data = data.reshape(32,32,3)\n","    r = data[:,:,0]\n","    g = data[:,:,1]\n","    b = data[:,:,2]\n","\n","    pca_r = PCA(n_components=component)\n","    pca_r_trans = pca_r.fit_transform(r)\n","\n","    pca_g = PCA(n_components=component)\n","    pca_g_trans = pca_g.fit_transform(g)\n","\n","    pca_b = PCA(n_components=component)\n","    pca_b_trans = pca_b.fit_transform(b)\n","\n","    pca_r_org = pca_r.inverse_transform(pca_r_trans)\n","    pca_g_org = pca_g.inverse_transform(pca_g_trans)\n","    pca_b_org = pca_b.inverse_transform(pca_b_trans)\n","\n","    img_compressed = np.stack((pca_r_org, pca_g_org, pca_b_org),axis = 2)\n","\n","    return img_compressed.reshape((-1,32,32,3))\n","\n","## predict_output에 한개씩 넣는 것부터 구현해야한다. (전체가 들어가는 것만 정상 작동함)\n","\n","def test(classifier, ad_example_data, orig_label_data):\n","\n","    # 정확도 카운터\n","    correct = 0\n","    defense_correct = 0\n","    df_examples = []\n","    # 테스트 셋의 모든 예제에 대해 루프를 돕니다\n","\n","    loss, accuracy = classifier.evaluate(ad_examples_BIM, orig_labels_BIM)\n","\n","    print('방어 전 모델 정확도 : ',accuracy * 100)\n","\n","    for i in range(len(ad_example_data)):\n","        data = ad_example_data[i].reshape(-1,32,32,3)\n","        target = orig_label_data[i]\n","        \n","        data_plot = data.reshape(32,32,3)\n","        print('원본 label : ',np.argmax(target))\n","        plt.imshow(data_plot)\n","        plt.show();\n","\n","        generated_img = defense_PCA(data,10)\n","\n","        generated_img_plot = generated_img.reshape(32,32,3)\n","\n","        defense_output = classifier.predict(generated_img.reshape(1,32,32,3))\n","\n","        defense_pred= int(np.argmax(defense_output))\n","\n","        print('방어 라벨 : ',defense_pred)\n","        plt.imshow(generated_img_plot)\n","        plt.show();\n","\n","        if defense_pred == int(np.argmax(target)):\n","            defense_correct += 1\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","        else:\n","            df_ex = generated_img\n","            df_examples.append((np.argmax(target),defense_pred,generated_img))\n","\n","        print('Working...!')\n","\n","\n","    defense_acc = defense_correct / float(len(ad_example_data))\n","    print(\"Defense Accuracy = {} / {} = {}\".format(defense_correct, len(ad_example_data), defense_acc))\n","    # 정확도와 적대적 예제를 리턴합니다\n","    return defense_acc, df_examples"],"metadata":{"id":"fpPzHByO4bpO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["accuracies_df = []\n","examples_df = []\n","\n","acc_df, ex_df = test(model, ad_examples_BIM[:1000], orig_labels_BIM[:1000])\n","\n","accuracies_df.append(acc_df)\n","examples_df.append(ex_df)"],"metadata":{"id":"aCH5IdKe4br4"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"collapsed_sections":["vIK9wb4vIIlv","P9v5DhrcQTi_","2TtBNBJxn2Db","63SBpYd-IL2u","1ywsHS3sfPxD","9Y_-9xiJiAeC","hGoEmuWF4S1T","7rWZ6_Kf48hG"],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}