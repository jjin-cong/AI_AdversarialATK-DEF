{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"20220605_FGSM_GCIFAR10.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"f3e0CYtfN3GU"},"outputs":[],"source":["import numpy as np\n","from sklearn.preprocessing import OneHotEncoder\n","import tensorflow as tf\n","from tensorflow import keras\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import cv2\n","from keras.datasets import cifar10\n","\n","\n","class ANN:\n","    def __init__(self, layers_size):\n","        self.layers_size = layers_size\n","        self.parameters = {}\n","        self.L = len(self.layers_size)\n","        self.n = 0\n","        self.costs = []\n","    \n","    def sigmoid(self, Z):\n","        return 1 / (1 + np.exp(-Z))\n","\n","    def softmax(self, Z):\n","        expZ = np.exp(Z - np.max(Z))\n","        return expZ / expZ.sum(axis=0, keepdims=True)\n","    \n","    def initialize_parameters(self):\n","        for l in range(1, len(self.layers_size)):\n","            self.parameters[\"W\" + str(l)] = np.random.randn(self.layers_size[l], self.layers_size[l - 1]) / np.sqrt(self.layers_size[l - 1])\n","            self.parameters[\"b\" + str(l)] = np.zeros((self.layers_size[l], 1))\n","    \n","    def forward(self, X):\n","        store = {}\n"," \n","        A = X.T\n","        for l in range(self.L - 1):\n","            Z = self.parameters[\"W\" + str(l + 1)].dot(A) + self.parameters[\"b\" + str(l + 1)]\n","            A = self.sigmoid(Z)\n","            store[\"A\" + str(l + 1)] = A\n","            store[\"W\" + str(l + 1)] = self.parameters[\"W\" + str(l + 1)]\n","            store[\"Z\" + str(l + 1)] = Z\n"," \n","        Z = self.parameters[\"W\" + str(self.L)].dot(A) + self.parameters[\"b\" + str(self.L)]\n","        A = self.softmax(Z)\n","        store[\"A\" + str(self.L)] = A\n","        store[\"W\" + str(self.L)] = self.parameters[\"W\" + str(self.L)]\n","        store[\"Z\" + str(self.L)] = Z\n"," \n","        return A, store\n"," \n","    def sigmoid_derivative(self, Z):\n","        s = 1 / (1 + np.exp(-Z))\n","        return s * (1 - s)\n","\n","    def backward(self,X,Y,store):\n","\n","        derivatives = {}\n","\n","        store['A0'] = X.T\n","\n","        A = store['A' + str(self.L)]\n","        dZ = A - Y.T\n","\n","        dW = dZ.dot(store['A' + str(self.L - 1)].T) / self.n\n","        db = np.sum(dZ, axis = 1, keepdims = True) / self.n\n","        dAPrev = store['W' + str(self.L)].T.dot(dZ)\n","\n","        derivatives['dW' + str(self.L)] = dW\n","        derivatives['db' + str(self.L)] = db\n","\n","        for l in range(self.L - 1,0,-1):\n","            dZ = dAPrev * self.sigmoid_derivative(store['Z' + str(l)])\n","            dW = dZ.dot(store['A' + str(l-1)].T) / self.n\n","            db = np.sum(dZ, axis = 1, keepdims = True) / self.n\n","            if l > 1:\n","                dAPrev = store['W' + str(l)].T.dot(dZ)\n","            derivatives[\"dW\" + str(l)] = dW\n","            derivatives[\"db\" + str(l)] = db\n","\n","        return derivatives\n","    \n","    def backward_ad(self,X,Y,store):\n","\n","        derivatives = {}\n","\n","        store['A0'] = X.T\n","\n","        A = store['A' + str(self.L)]\n","        dZ = A - Y.T\n","\n","        dW = dZ.dot(store['A' + str(self.L - 1)].T) / self.n\n","        db = np.sum(dZ, axis = 1, keepdims = True) / self.n\n","        dAPrev = store['W' + str(self.L)].T.dot(dZ)\n","\n","        derivatives['dW' + str(self.L)] = dW\n","        derivatives['db' + str(self.L)] = db\n","\n","        for l in range(self.L - 1,0,-1):\n","            dZ = dAPrev * self.sigmoid_derivative(store['Z' + str(l)])\n","            dW = dZ.dot(store['A' + str(l-1)].T) / self.n\n","            db = np.sum(dZ, axis = 1, keepdims = True) / self.n\n","            if l > 1:\n","                dAPrev = store['W' + str(l)].T.dot(dZ)\n","            derivatives[\"dW\" + str(l)] = dW\n","            derivatives[\"db\" + str(l)] = db\n","            dAPrev_0 = store['W' + str(l)].T.dot(dZ)\n","\n","        return dAPrev_0\n","\n","    def fit(self, X, Y, learning_rate=0.01, n_iterations=300):\n","        self.n = X.shape[0]\n"," \n","        self.layers_size.insert(0, X.shape[1])\n"," \n","        self.initialize_parameters()\n","        for loop in range(n_iterations):\n","            A, store = self.forward(X)\n","            cost = -np.mean(Y * np.log(A.T+ 1e-8))\n","            derivatives = self.backward(X, Y, store)\n"," \n","            for l in range(1, self.L + 1):\n","                self.parameters[\"W\" + str(l)] = self.parameters[\"W\" + str(l)] - learning_rate * derivatives[\"dW\" + str(l)]\n","                self.parameters[\"b\" + str(l)] = self.parameters[\"b\" + str(l)] - learning_rate * derivatives[\"db\" + str(l)]\n"," \n","            if loop % 100 == 0:\n","                print(\"Cost: \", cost, \"Train Accuracy:\", self.predict(X, Y))\n"," \n","            if loop % 10 == 0:\n","                self.costs.append(cost)\n","\n","    def predict(self, X, Y):\n","        A, cache = self.forward(X)\n","        y_hat = np.argmax(A, axis=0)\n","        Y = np.argmax(Y, axis=1)\n","        accuracy = (y_hat == Y).mean()\n","        return accuracy * 100\n","    \n","    def predict_output(self, X):\n","        A, cache = self.forward(X)\n","        y_hat = np.argmax(A, axis=0)\n","        return y_hat\n","\n","    def plot_cost(self):\n","        plt.figure()\n","        plt.plot(np.arange(len(self.costs)), self.costs)\n","        plt.xlabel(\"epochs\")\n","        plt.ylabel(\"cost\")\n","        plt.show()\n","\n","def pre_process_data(train_x, train_y, test_x, test_y):\n","    # Normalize\n","    train_x = train_x / 255.\n","    test_x = test_x / 255.\n"," \n","    enc = OneHotEncoder(sparse=False, categories='auto')\n","    train_y = enc.fit_transform(train_y.reshape(len(train_y), -1))\n"," \n","    test_y = enc.transform(test_y.reshape(len(test_y), -1))\n","    \n","    train_x_flatten = train_x.reshape(train_x.shape[0],-1)\n","    test_x_flatten = test_x.reshape(test_x.shape[0],-1)\n","    \n","    return train_x_flatten, train_y, test_x_flatten, test_y\n","\n","if __name__ == '__main__':\n","    \n","    (train_x, train_y), (test_x, test_y) = cifar10.load_data()\n","\n","    train_x = np.array([cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) for image in train_x])\n","    test_x = np.array([cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) for image in test_x])\n","\n"," \n","    train_x, train_y, test_x, test_y = pre_process_data(train_x, train_y, test_x, test_y)\n"," \n","    print(\"train_x's shape: \" + str(train_x.shape))\n","    print(\"test_x's shape: \" + str(test_x.shape))\n","    print(\"train_y's shape: \" + str(train_y.shape))\n","    print(\"test_y's shape: \" + str(test_y.shape))\n"," \n"," \n","    layers_dims = [40,50,30,10]\n"," \n","    ann = ANN(layers_dims)\n","    ann.fit(train_x, train_y, learning_rate=0.1, n_iterations=3000)\n","    print(\"Train Accuracy:\", ann.predict(train_x, train_y))\n","    print(\"Test Accuracy:\", ann.predict(test_x, test_y))\n","    ann.plot_cost()"]},{"cell_type":"code","source":["ann"],"metadata":{"id":"c2x-OtWBOoLg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["FGSM 구현"],"metadata":{"id":"SMh9I7xIPxDg"}},{"cell_type":"code","source":["epsilons = [0, .05, .1, .15, .2, .25, .3]\n","epsilon = 0.05"],"metadata":{"id":"AhIk3JDUPxjN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# FGSM 공격 코드\n","def fgsm_attack(image, epsilon, data_grad):\n","    # data_grad 의 요소별 부호 값을 얻어옵니다\n","    sign_data_grad = np.sign(data_grad)\n","    perturbed_image = image + epsilon*sign_data_grad.T\n","    # 값 범위를 [0,1]로 유지하기 위해 자르기(clipping)를 추가합니다\n","    perturbed_image = np.clip(perturbed_image, 0, 1)\n","    # 작은 변화가 적용된 이미지를 리턴합니다\n","    return perturbed_image"],"metadata":{"id":"jmwEMbN9Pzx3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## predict_output에 한개씩 넣는 것부터 구현해야한다. (전체가 들어가는 것만 정상 작동함)\n","\n","def test(model, test_x, test_y, epsilon, layers_dims):\n","\n","    # 정확도 카운터\n","    correct = 0\n","    adv_examples = []\n","\n","    # 테스트 셋의 모든 예제에 대해 루프를 돕니다\n","    \n","    for i in range(len(test_x)):\n","        data = test_x[i].reshape(1,784)\n","        target = test_y[i].reshape(1,10)\n","        \n","        A,store = model.forward(data)\n","        output = model.predict_output(data)\n","        init_output = int(output)\n","        \n","        if init_output != int(np.argmax(target,axis = 1)):\n","            continue\n","\n","        data_grad = model.backward_ad(data,target,store)\n","        \n","        perturbed_data = fgsm_attack(data, epsilon, data_grad)\n","\n","        output = model.predict_output(perturbed_data)\n","\n","        final_pred = int(output)\n","\n","        if final_pred == int(np.argmax(target,axis = 1)):\n","            correct += 1\n","            if (epsilon == 0) and (len(adv_examples) < 5):\n","                adv_ex = perturbed_data\n","                adv_examples.append((init_output,final_pred,perturbed_data))\n","        else:\n","            if len(adv_examples) < 5:\n","                adv_ex = perturbed_data\n","                adv_examples.append((init_output,final_pred,perturbed_data))\n","\n","    # 해당 엡실론에서의 최종 정확도를 계산합니다\n","    final_acc = correct/float(len(test_x))\n","    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(test_x), final_acc))\n","\n","    # 정확도와 적대적 예제를 리턴합니다\n","    return final_acc, adv_examples"],"metadata":{"id":"5NKKuRXqP07r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["accuracies = []\n","examples = []\n","\n","# 각 엡실론에 대해 테스트 함수를 실행합니다\n","for eps in epsilons:\n","    acc, ex = test(ann, test_x, test_y, eps, layers_dims)\n","    accuracies.append(acc)\n","    examples.append(ex)"],"metadata":{"id":"XGbtvJ0yP2NX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(5,5))\n","plt.plot(epsilons, accuracies, \"*-\")\n","plt.yticks(np.arange(0, 1.1, step=0.1))\n","plt.xticks(np.arange(0, .35, step=0.05))\n","plt.title(\"Accuracy vs Epsilon\")\n","plt.xlabel(\"Epsilon\")\n","plt.ylabel(\"Accuracy\")\n","plt.show()"],"metadata":{"id":"MSZGonT-P34J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 각 엡실론에서 적대적 샘플의 몇 가지 예를 도식화합니다\n","cnt = 0\n","plt.figure(figsize=(8,10))\n","for i in range(len(epsilons)):\n","    for j in range(len(examples[i])):\n","        cnt += 1\n","        plt.subplot(len(epsilons),len(examples[0]),cnt)\n","        plt.xticks([], [])\n","        plt.yticks([], [])\n","        if j == 0:\n","            plt.ylabel(\"Eps: {}\".format(epsilons[i]), fontsize=14)\n","        orig,adv,ex = examples[i][j]\n","        plt.title(\"{} -> {}\".format(orig, adv))\n","        plt.imshow(ex.reshape((28,28)), cmap=\"gray\")\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"O73Ew12ZP48t"},"execution_count":null,"outputs":[]}]}