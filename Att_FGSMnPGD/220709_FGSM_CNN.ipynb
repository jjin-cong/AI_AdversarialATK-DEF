{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"R06urpTR_Haj"},"outputs":[],"source":["import os\n","from PIL import Image\n","import numpy as np\n","import csv\n","import pandas as pd\n","import natsort\n","import pickle\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25061,"status":"ok","timestamp":1658021381981,"user":{"displayName":"이진규","userId":"11520813773494359482"},"user_tz":-540},"id":"_O-uQmt43mbi","outputId":"dcd6eb4b-1ceb-46da-e895-be860a01fb29"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":834,"status":"ok","timestamp":1658020531441,"user":{"displayName":"김채현","userId":"06024775478798789360"},"user_tz":-540},"id":"HGk_EL9a70_Q","outputId":"b893e668-038c-49fc-f97d-6141dec84962"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/[한이음] 적대적 AI 공격에 대한 인공지능 보안기술 연구/3. 소스코드/GTSRB\n"]}],"source":["cd drive/MyDrive/[한이음] 적대적 AI 공격에 대한 인공지능 보안기술 연구/3. 소스코드/GTSRB/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ibaUfdhc8kif"},"outputs":[],"source":["classes = { 0:'Speed limit (20km/h)',\n","            1:'Speed limit (30km/h)', \n","            2:'Speed limit (50km/h)', \n","            3:'Speed limit (60km/h)', \n","            4:'Speed limit (70km/h)', \n","            5:'Speed limit (80km/h)', \n","            6:'End of speed limit (80km/h)', \n","            7:'Speed limit (100km/h)', \n","            8:'Speed limit (120km/h)', \n","            9:'No passing', \n","            10:'No passing veh over 3.5 tons', \n","            11:'Right-of-way at intersection', \n","            12:'Priority road', \n","            13:'Yield', \n","            14:'Stop', \n","            15:'No vehicles', \n","            16:'Veh > 3.5 tons prohibited', \n","            17:'No entry', \n","            18:'General caution', \n","            19:'Dangerous curve left', \n","            20:'Dangerous curve right', \n","            21:'Double curve', \n","            22:'Bumpy road', \n","            23:'Slippery road', \n","            24:'Road narrows on the right', \n","            25:'Road work', \n","            26:'Traffic signals', \n","            27:'Pedestrians', \n","            28:'Children crossing', \n","            29:'Bicycles crossing', \n","            30:'Beware of ice/snow',\n","            31:'Wild animals crossing', \n","            32:'End speed + passing limits', \n","            33:'Turn right ahead', \n","            34:'Turn left ahead', \n","            35:'Ahead only', \n","            36:'Go straight or right', \n","            37:'Go straight or left', \n","            38:'Keep right', \n","            39:'Keep left', \n","            40:'Roundabout mandatory', \n","            41:'End of no passing', \n","            42:'End no passing veh > 3.5 tons' }"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"ab_qHCAZ9ODw","executionInfo":{"status":"error","timestamp":1658021059806,"user_tz":-540,"elapsed":54325,"user":{"displayName":"김채현","userId":"06024775478798789360"}},"outputId":"f543e48e-ad50-4c96-ac70-1e2728d63c2c"},"outputs":[{"output_type":"stream","name":"stdout","text":["train_0_0.png\n","train_0_1.png\n","train_0_2.png\n","train_0_3.png\n","train_0_4.png\n","train_0_5.png\n","train_0_6.png\n","train_0_7.png\n","train_0_8.png\n","train_0_9.png\n","train_0_10.png\n","train_0_11.png\n","train_0_12.png\n","train_0_13.png\n","train_0_14.png\n","train_0_15.png\n","train_0_16.png\n","train_0_17.png\n","train_0_18.png\n","train_0_19.png\n","train_0_20.png\n","train_0_21.png\n","train_0_22.png\n","train_0_23.png\n","train_0_24.png\n","train_0_25.png\n","train_0_26.png\n","train_0_27.png\n","train_0_28.png\n","train_0_29.png\n","train_0_30.png\n","train_0_31.png\n","train_0_32.png\n","train_0_33.png\n","train_0_34.png\n","train_0_35.png\n","train_0_36.png\n","train_0_37.png\n","train_0_38.png\n","train_0_39.png\n","train_0_40.png\n","train_0_41.png\n","train_0_42.png\n","train_0_43.png\n","train_0_44.png\n","train_0_45.png\n","train_0_46.png\n","train_0_47.png\n","train_0_48.png\n","train_0_49.png\n","train_0_50.png\n","train_0_51.png\n","train_0_52.png\n","train_0_53.png\n","train_0_54.png\n","train_0_55.png\n","train_0_56.png\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-610974fc396e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnatsort\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnatsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2850\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2852\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Train & Test & X & y load\n","\n","# Train\n","trainpath = \"Train_preprocessed\"\n","X_train = []\n","for img in natsort.natsorted(os.listdir(trainpath)):\n","  image = Image.open(trainpath+\"/\"+img)\n","  image = image.resize((32,32))\n","  image = np.array(image)\n","  image = image.transpose(2,0,1)\n","  X_train.append(image)\n","  print(img)\n","X_train = np.array(X_train)\n","print(\"Train:done\")\n","\n","df = pd.read_csv(\"./Train.csv\")\n","df = np.array(df)\n","y_train = df[:,6]\n","\n","# Test\n","testpath = \"Test_preprocessed\"\n","X_test = []\n","for img in natsort.natsorted(os.listdir(testpath)):\n","  image = Image.open(testpath+\"/\"+img)\n","  image = image.resize((32,32))\n","  image = np.array(image)\n","  image = image.transpose(2,0,1)\n","  X_test.append(image)\n","  print(img)\n","X_test = np.array(X_test)\n","print(\"Test:done\")\n","\n","df = pd.read_csv(\"./Test.csv\")\n","df = np.array(df)\n","y_test = df[:,6]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"8Ir-4SbaKFMQ"},"outputs":[],"source":["# 교재 코드에서 이미지지-채널-shape 순으로 둬서 그걸 tranpose 해줘야 \n","print(X_train.shape)"]},{"cell_type":"markdown","metadata":{"id":"S_a66AzF-Tha"},"source":["# CNN"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"4QHxnHLKMd8H"},"outputs":[],"source":["from collections import OrderedDict"]},{"cell_type":"markdown","metadata":{"id":"CaqQt66iPKC3"},"source":["# im2col col2im"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"mMp_lb66NNTs"},"outputs":[],"source":["def im2col(input_data, filter_h, filter_w, stride=1, pad=0):\n","    \"\"\"다수의 이미지를 입력받아 2차원 배열로 변환한다(평탄화).\n","    \n","    Parameters\n","    ----------\n","    input_data : 4차원 배열 형태의 입력 데이터(이미지 수, 채널 수, 높이, 너비)\n","    filter_h : 필터의 높이\n","    filter_w : 필터의 너비\n","    stride : 스트라이드\n","    pad : 패딩\n","    \n","    Returns\n","    -------\n","    col : 2차원 배열\n","    \"\"\"\n","    N, C, H, W = input_data.shape\n","    out_h = (H + 2*pad - filter_h)//stride + 1\n","    out_w = (W + 2*pad - filter_w)//stride + 1\n","\n","    img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')\n","    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\n","\n","    for y in range(filter_h):\n","        y_max = y + stride*out_h\n","        for x in range(filter_w):\n","            x_max = x + stride*out_w\n","            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]\n","\n","    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)\n","    return col\n","\n","\n","def col2im(col, input_shape, filter_h, filter_w, stride=1, pad=0):\n","    \"\"\"(im2col과 반대) 2차원 배열을 입력받아 다수의 이미지 묶음으로 변환한다.\n","    \n","    Parameters\n","    ----------\n","    col : 2차원 배열(입력 데이터)\n","    input_shape : 원래 이미지 데이터의 형상（예：(10, 1, 28, 28)）\n","    filter_h : 필터의 높이\n","    filter_w : 필터의 너비\n","    stride : 스트라이드\n","    pad : 패딩\n","    \n","    Returns\n","    -------\n","    img : 변환된 이미지들\n","    \"\"\"\n","    N, C, H, W = input_shape\n","    out_h = (H + 2*pad - filter_h)//stride + 1\n","    out_w = (W + 2*pad - filter_w)//stride + 1\n","    col = col.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(0, 3, 4, 5, 1, 2)\n","\n","    img = np.zeros((N, C, H + 2*pad + stride - 1, W + 2*pad + stride - 1))\n","    for y in range(filter_h):\n","        y_max = y + stride*out_h\n","        for x in range(filter_w):\n","            x_max = x + stride*out_w\n","            img[:, :, y:y_max:stride, x:x_max:stride] += col[:, :, y, x, :, :]\n","\n","    return img[:, :, pad:H + pad, pad:W + pad]"]},{"cell_type":"markdown","metadata":{"id":"l4mkt58MO3hK"},"source":["# class Convolution"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"6cX88i6XM70C"},"outputs":[],"source":["class Convolution:\n","    def __init__(self, W, b, stride=1, pad=0):\n","        self.W = W\n","        self.b = b\n","        self.stride = stride\n","        self.pad = pad\n","        \n","        # 중간 데이터（backward 시 사용）\n","        self.x = None   \n","        self.col = None\n","        self.col_W = None\n","        \n","        # 가중치와 편향 매개변수의 기울기\n","        self.dW = None\n","        self.db = None\n","\n","    def forward(self, x):\n","        FN, C, FH, FW = self.W.shape\n","        N, C, H, W = x.shape\n","        out_h = 1 + int((H + 2*self.pad - FH) / self.stride)\n","        out_w = 1 + int((W + 2*self.pad - FW) / self.stride)\n","\n","        col = im2col(x, FH, FW, self.stride, self.pad)\n","        col_W = self.W.reshape(FN, -1).T\n","\n","        out = np.dot(col, col_W) + self.b\n","        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n","\n","        self.x = x\n","        self.col = col\n","        self.col_W = col_W\n","\n","        return out\n","\n","    def backward(self, dout):\n","        FN, C, FH, FW = self.W.shape\n","        dout = dout.transpose(0,2,3,1).reshape(-1, FN)\n","\n","        self.db = np.sum(dout, axis=0)\n","        self.dW = np.dot(self.col.T, dout)\n","        self.dW = self.dW.transpose(1, 0).reshape(FN, C, FH, FW)\n","\n","        dcol = np.dot(dout, self.col_W.T)\n","        dx = col2im(dcol, self.x.shape, FH, FW, self.stride, self.pad)\n","\n","        return dx"]},{"cell_type":"markdown","metadata":{"id":"trgBAc8JO8TJ"},"source":["# class Pooling"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"3LjufTtaO2Mn"},"outputs":[],"source":["class Pooling:\n","    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n","        self.pool_h = pool_h\n","        self.pool_w = pool_w\n","        self.stride = stride\n","        self.pad = pad\n","        \n","        self.x = None\n","        self.arg_max = None\n","\n","    def forward(self, x):\n","        N, C, H, W = x.shape\n","        out_h = int(1 + (H - self.pool_h) / self.stride)\n","        out_w = int(1 + (W - self.pool_w) / self.stride)\n","\n","        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n","        col = col.reshape(-1, self.pool_h*self.pool_w)\n","\n","        arg_max = np.argmax(col, axis=1)\n","        out = np.max(col, axis=1)\n","        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n","\n","        self.x = x\n","        self.arg_max = arg_max\n","\n","        return out\n","\n","    def backward(self, dout):\n","        dout = dout.transpose(0, 2, 3, 1)\n","        \n","        pool_size = self.pool_h * self.pool_w\n","        dmax = np.zeros((dout.size, pool_size))\n","        dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = dout.flatten()\n","        dmax = dmax.reshape(dout.shape + (pool_size,)) \n","        \n","        dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1)\n","        dx = col2im(dcol, self.x.shape, self.pool_h, self.pool_w, self.stride, self.pad)\n","        \n","        return dx"]},{"cell_type":"markdown","metadata":{"id":"zm7k0T_jPR23"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"GsRyXrkiPRqG"},"outputs":[],"source":["class Relu:\n","    def __init__(self):\n","        self.mask = None\n","\n","    def forward(self, x):\n","        self.mask = (x <= 0)\n","        out = x.copy()\n","        out[self.mask] = 0\n","\n","        return out\n","\n","    def backward(self, dout):\n","        dout[self.mask] = 0\n","        dx = dout\n","\n","        return dx"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"6dLV5gIBPg-I"},"outputs":[],"source":["class Affine:\n","    def __init__(self, W, b):\n","        self.W = W\n","        self.b = b\n","        \n","        self.x = None\n","        self.original_x_shape = None\n","        # 가중치와 편향 매개변수의 미분\n","        self.dW = None\n","        self.db = None\n","\n","    def forward(self, x):\n","        # 텐서 대응\n","        self.original_x_shape = x.shape\n","        x = x.reshape(x.shape[0], -1)\n","        self.x = x\n","\n","        out = np.dot(self.x, self.W) + self.b\n","\n","        return out\n","\n","    def backward(self, dout):\n","        dx = np.dot(dout, self.W.T)\n","        self.dW = np.dot(self.x.T, dout)\n","        self.db = np.sum(dout, axis=0)\n","        \n","        dx = dx.reshape(*self.original_x_shape)  # 입력 데이터 모양 변경(텐서 대응)\n","        return dx"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"IYhyhaY1Px4q"},"outputs":[],"source":["def softmax(x):\n","    if x.ndim == 2:\n","        x = x.T\n","        x = x - np.max(x, axis=0)\n","        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n","        return y.T \n","\n","    x = x - np.max(x) # 오버플로 대책\n","    return np.exp(x) / np.sum(np.exp(x))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Gyu2_r1VPq4y"},"outputs":[],"source":["def cross_entropy_error(y, t):\n","    if y.ndim == 1:\n","        t = t.reshape(1, t.size)\n","        y = y.reshape(1, y.size)\n","        \n","    # 훈련 데이터가 원-핫 벡터라면 정답 레이블의 인덱스로 반환\n","    if t.size == y.size:\n","        t = t.argmax(axis=1)\n","             \n","    batch_size = y.shape[0]\n","    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"BatMCqzVPitj"},"outputs":[],"source":["class SoftmaxWithLoss:\n","    def __init__(self):\n","        self.loss = None # 손실함수\n","        self.y = None    # softmax의 출력\n","        self.t = None    # 정답 레이블(원-핫 인코딩 형태)\n","        \n","    def forward(self, x, t):\n","        self.t = t\n","        self.y = softmax(x)\n","        self.loss = cross_entropy_error(self.y, self.t)\n","        \n","        return self.loss\n","\n","    def backward(self, dout=1):\n","        batch_size = self.t.shape[0]\n","        if self.t.size == self.y.size: # 정답 레이블이 원-핫 인코딩 형태일 때\n","            dx = (self.y - self.t) / batch_size\n","        else:\n","            dx = self.y.copy()\n","            dx[np.arange(batch_size), self.t] -= 1\n","            dx = dx / batch_size\n","        \n","        return dx"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"1eO4MHAmQGgz"},"outputs":[],"source":["def numerical_gradient(f, x):\n","    h = 1e-4 # 0.0001\n","    grad = np.zeros_like(x)\n","    \n","    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n","    while not it.finished:\n","        idx = it.multi_index\n","        tmp_val = x[idx]\n","        x[idx] = float(tmp_val) + h\n","        fxh1 = f(x) # f(x+h)\n","        \n","        x[idx] = tmp_val - h \n","        fxh2 = f(x) # f(x-h)\n","        grad[idx] = (fxh1 - fxh2) / (2*h)\n","        \n","        x[idx] = tmp_val # 값 복원\n","        it.iternext()   \n","        \n","    return grad"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"O61M38H02dU4"},"outputs":[],"source":["class SimpleConvNet:\n","  def __init__(self, input_dim=(3,32,32), \n","             conv_param={'filter_num':30,'filter_size':5, 'pad':0, 'stride':1}, \n","             hidden_size=100, output_size=10, weight_init_std=0.01):\n","    filter_num = conv_param['filter_num']\n","    filter_size = conv_param['filter_size']\n","    filter_pad = conv_param['pad']\n","    filter_stride = conv_param['stride']\n","    input_size = input_dim[1]\n","    conv_output_size = (input_size-filter_size+2*filter_pad)/filter_stride+1\n","    pool_output_size = int(filter_num*(conv_output_size/2)*(conv_output_size/2))\n","\n","    # 가중치 매개변수 초기화\n","    self.params = {}\n","    self.params['W1'] = weight_init_std * np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n","    self.params['b1'] = np.zeros(filter_num)\n","    self.params['W2'] = weight_init_std * np.random.randn(pool_output_size, hidden_size)\n","    self.params['b2'] = np.zeros(hidden_size)\n","    self.params['W3'] = weight_init_std * np.random.randn(hidden_size, output_size)\n","    self.params['b3'] = np.zeros(output_size)\n","    \n","    # 계층 생성\n","    self.layers = OrderedDict()\n","    self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'],conv_param['stride'], conv_param['pad'])\n","    self.layers['Relu1'] = Relu()\n","    self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n","    self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n","    self.layers['Relu2'] = Relu()\n","    self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n","    self.last_layer = SoftmaxWithLoss()\n","  \n","  def predict(self, x):\n","    for layer in self.layers.values():\n","      x = layer.forward(x)\n","      return x\n","\n","  def loss(self, x, t):\n","      \"\"\"손실 함수를 구한다.\n","      Parameters\n","      ----------\n","      x : 입력 데이터\n","      t : 정답 레이블\n","      \"\"\"\n","      y = self.predict(x)\n","      return self.last_layer.forward(y, t)\n","\n","  def accuracy(self, x, t, batch_size=100):\n","      if t.ndim != 1 : t = np.argmax(t, axis=1)\n","      \n","      acc = 0.0\n","        \n","      for i in range(int(x.shape[0] / batch_size)):\n","          tx = x[i*batch_size:(i+1)*batch_size]\n","          tt = t[i*batch_size:(i+1)*batch_size]\n","          y = self.predict(tx)\n","          y = np.argmax(y, axis=1)\n","          acc += np.sum(y == tt) \n","        \n","      return acc / x.shape[0]\n","\n","  def numerical_gradient(self, x, t):\n","      \"\"\"기울기를 구한다（수치미분）.\n","      Parameters\n","      ----------\n","      x : 입력 데이터\n","      t : 정답 레이블\n","      Returns\n","      -------\n","      각 층의 기울기를 담은 사전(dictionary) 변수\n","          grads['W1']、grads['W2']、... 각 층의 가중치\n","          grads['b1']、grads['b2']、... 각 층의 편향\n","      \"\"\"\n","      loss_w = lambda w: self.loss(x, t)\n","\n","      grads = {}\n","      for idx in (1, 2, 3):\n","          grads['W' + str(idx)] = numerical_gradient(loss_w, self.params['W' + str(idx)])\n","          grads['b' + str(idx)] = numerical_gradient(loss_w, self.params['b' + str(idx)])\n","\n","      return grads\n","\n","  def gradient(self, x, t):\n","      \"\"\"기울기를 구한다(오차역전파법).\n","      Parameters\n","      ----------\n","      x : 입력 데이터\n","      t : 정답 레이블\n","      Returns\n","      -------\n","      각 층의 기울기를 담은 사전(dictionary) 변수\n","          grads['W1']、grads['W2']、... 각 층의 가중치\n","          grads['b1']、grads['b2']、... 각 층의 편향\n","      \"\"\"\n","      # forward\n","      self.loss(x, t)\n","\n","      # backward\n","      dout = 1\n","      dout = self.last_layer.backward(dout)\n","\n","      layers = list(self.layers.values())\n","      layers.reverse()\n","      for layer in layers:\n","          dout = layer.backward(dout)\n","\n","      # 결과 저장\n","      grads = {}\n","      grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db\n","      grads['W2'], grads['b2'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n","      grads['W3'], grads['b3'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n","\n","      return grads\n","      \n","  def save_params(self, file_name=\"params.pkl\"):\n","      params = {}\n","      for key, val in self.params.items():\n","          params[key] = val\n","      with open(file_name, 'wb') as f:\n","          pickle.dump(params, f)\n","\n","  def load_params(self, file_name=\"params.pkl\"):\n","      with open(file_name, 'rb') as f:\n","          params = pickle.load(f)\n","      for key, val in params.items():\n","          self.params[key] = val\n","\n","      for i, key in enumerate(['Conv1', 'Affine1', 'Affine2']):\n","          self.layers[key].W = self.params['W' + str(i+1)]\n","          self.layers[key].b = self.params['b' + str(i+1)]"]},{"cell_type":"markdown","metadata":{"id":"Q7OXXkcoTZdq"},"source":["# Trainer"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"TXo2hhESQsrm"},"outputs":[],"source":["import sys, os\n","sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n","import numpy as np\n","\n","class Trainer:\n","    \"\"\"신경망 훈련을 대신 해주는 클래스\n","    \"\"\"\n","    def __init__(self, network, x_train, t_train, x_test, t_test,\n","                 epochs=20, mini_batch_size=100,\n","                 optimizer='SGD', optimizer_param={'lr':0.01}, \n","                 evaluate_sample_num_per_epoch=None, verbose=True):\n","        self.network = network\n","        self.verbose = verbose\n","        self.x_train = x_train\n","        self.t_train = t_train\n","        self.x_test = x_test\n","        self.t_test = t_test\n","        self.epochs = epochs\n","        self.batch_size = mini_batch_size\n","        self.evaluate_sample_num_per_epoch = evaluate_sample_num_per_epoch\n","\n","        # optimzer\n","        optimizer_class_dict = {'sgd':SGD, 'momentum':Momentum, 'nesterov':Nesterov,\n","                                'adagrad':AdaGrad, 'rmsprpo':RMSprop, 'adam':Adam}\n","        self.optimizer = optimizer_class_dict[optimizer.lower()](**optimizer_param)\n","        \n","        self.train_size = x_train.shape[0]\n","        self.iter_per_epoch = max(self.train_size / mini_batch_size, 1)\n","        self.max_iter = int(epochs * self.iter_per_epoch)\n","        self.current_iter = 0\n","        self.current_epoch = 0\n","        \n","        self.train_loss_list = []\n","        self.train_acc_list = []\n","        self.test_acc_list = []\n","\n","    def train_step(self):\n","        batch_mask = np.random.choice(self.train_size, self.batch_size)\n","        x_batch = self.x_train[batch_mask]\n","        t_batch = self.t_train[batch_mask]\n","        \n","        grads = self.network.gradient(x_batch, t_batch)\n","        self.optimizer.update(self.network.params, grads)\n","        \n","        loss = self.network.loss(x_batch, t_batch)\n","        self.train_loss_list.append(loss)\n","        if self.verbose: print(\"train loss:\" + str(loss))\n","        \n","        if self.current_iter % self.iter_per_epoch == 0:\n","            self.current_epoch += 1\n","            \n","            x_train_sample, t_train_sample = self.x_train, self.t_train\n","            x_test_sample, t_test_sample = self.x_test, self.t_test\n","            if not self.evaluate_sample_num_per_epoch is None:\n","                t = self.evaluate_sample_num_per_epoch\n","                x_train_sample, t_train_sample = self.x_train[:t], self.t_train[:t]\n","                x_test_sample, t_test_sample = self.x_test[:t], self.t_test[:t]\n","                \n","            train_acc = self.network.accuracy(x_train_sample, t_train_sample)\n","            test_acc = self.network.accuracy(x_test_sample, t_test_sample)\n","            self.train_acc_list.append(train_acc)\n","            self.test_acc_list.append(test_acc)\n","\n","            if self.verbose: print(\"=== epoch:\" + str(self.current_epoch) + \", train acc:\" + str(train_acc) + \", test acc:\" + str(test_acc) + \" ===\")\n","        self.current_iter += 1\n","\n","    def train(self):\n","        for i in range(self.max_iter):\n","            self.train_step()\n","\n","        test_acc = self.network.accuracy(self.x_test, self.t_test)\n","\n","        if self.verbose:\n","            print(\"=============== Final Test Accuracy ===============\")\n","            print(\"test acc:\" + str(test_acc))"]},{"cell_type":"markdown","metadata":{"id":"Jv1kM7A4TnTZ"},"source":["# Optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"yBbRkDRTToIe"},"outputs":[],"source":["import numpy as np\n","\n","class SGD:\n","\n","    \"\"\"확률적 경사 하강법（Stochastic Gradient Descent）\"\"\"\n","\n","    def __init__(self, lr=0.01):\n","        self.lr = lr\n","        \n","    def update(self, params, grads):\n","        for key in params.keys():\n","            params[key] -= self.lr * grads[key] \n","\n","\n","class Momentum:\n","\n","    \"\"\"모멘텀 SGD\"\"\"\n","\n","    def __init__(self, lr=0.01, momentum=0.9):\n","        self.lr = lr\n","        self.momentum = momentum\n","        self.v = None\n","        \n","    def update(self, params, grads):\n","        if self.v is None:\n","            self.v = {}\n","            for key, val in params.items():                                \n","                self.v[key] = np.zeros_like(val)\n","                \n","        for key in params.keys():\n","            self.v[key] = self.momentum*self.v[key] - self.lr*grads[key] \n","            params[key] += self.v[key]\n","\n","\n","class Nesterov:\n","\n","    \"\"\"Nesterov's Accelerated Gradient (http://arxiv.org/abs/1212.0901)\"\"\"\n","    # NAG는 모멘텀에서 한 단계 발전한 방법이다. (http://newsight.tistory.com/224)\n","    \n","    def __init__(self, lr=0.01, momentum=0.9):\n","        self.lr = lr\n","        self.momentum = momentum\n","        self.v = None\n","        \n","    def update(self, params, grads):\n","        if self.v is None:\n","            self.v = {}\n","            for key, val in params.items():\n","                self.v[key] = np.zeros_like(val)\n","            \n","        for key in params.keys():\n","            self.v[key] *= self.momentum\n","            self.v[key] -= self.lr * grads[key]\n","            params[key] += self.momentum * self.momentum * self.v[key]\n","            params[key] -= (1 + self.momentum) * self.lr * grads[key]\n","\n","\n","class AdaGrad:\n","\n","    \"\"\"AdaGrad\"\"\"\n","\n","    def __init__(self, lr=0.01):\n","        self.lr = lr\n","        self.h = None\n","        \n","    def update(self, params, grads):\n","        if self.h is None:\n","            self.h = {}\n","            for key, val in params.items():\n","                self.h[key] = np.zeros_like(val)\n","            \n","        for key in params.keys():\n","            self.h[key] += grads[key] * grads[key]\n","            params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7)\n","\n","\n","class RMSprop:\n","\n","    \"\"\"RMSprop\"\"\"\n","\n","    def __init__(self, lr=0.01, decay_rate = 0.99):\n","        self.lr = lr\n","        self.decay_rate = decay_rate\n","        self.h = None\n","        \n","    def update(self, params, grads):\n","        if self.h is None:\n","            self.h = {}\n","            for key, val in params.items():\n","                self.h[key] = np.zeros_like(val)\n","            \n","        for key in params.keys():\n","            self.h[key] *= self.decay_rate\n","            self.h[key] += (1 - self.decay_rate) * grads[key] * grads[key]\n","            params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7)\n","\n","\n","class Adam:\n","\n","    \"\"\"Adam (http://arxiv.org/abs/1412.6980v8)\"\"\"\n","\n","    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):\n","        self.lr = lr\n","        self.beta1 = beta1\n","        self.beta2 = beta2\n","        self.iter = 0\n","        self.m = None\n","        self.v = None\n","        \n","    def update(self, params, grads):\n","        if self.m is None:\n","            self.m, self.v = {}, {}\n","            for key, val in params.items():\n","                self.m[key] = np.zeros_like(val)\n","                self.v[key] = np.zeros_like(val)\n","        \n","        self.iter += 1\n","        lr_t  = self.lr * np.sqrt(1.0 - self.beta2**self.iter) / (1.0 - self.beta1**self.iter)         \n","        \n","        for key in params.keys():\n","            #self.m[key] = self.beta1*self.m[key] + (1-self.beta1)*grads[key]\n","            #self.v[key] = self.beta2*self.v[key] + (1-self.beta2)*(grads[key]**2)\n","            self.m[key] += (1 - self.beta1) * (grads[key] - self.m[key])\n","            self.v[key] += (1 - self.beta2) * (grads[key]**2 - self.v[key])\n","            \n","            params[key] -= lr_t * self.m[key] / (np.sqrt(self.v[key]) + 1e-7)\n","            \n","            #unbias_m += (1 - self.beta1) * (grads[key] - self.m[key]) # correct bias\n","            #unbisa_b += (1 - self.beta2) * (grads[key]*grads[key] - self.v[key]) # correct bias\n","            #params[key] += self.lr * unbias_m / (np.sqrt(unbisa_b) + 1e-7)"]},{"cell_type":"markdown","metadata":{"id":"wmDDuldYT1re"},"source":["# Train Convnet"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"oXw0UMGbT3MT"},"outputs":[],"source":["max_epochs = 20\n","\n","network = SimpleConvNet(input_dim=(3,32,32), conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},hidden_size=100, output_size=10, weight_init_std=0.01)\n","                        \n","trainer = Trainer(network, X_train, y_train, X_test, y_test,\n","                  epochs=max_epochs, mini_batch_size=100,\n","                  optimizer='Adam', optimizer_param={'lr': 0.001},\n","                  evaluate_sample_num_per_epoch=1000)\n","trainer.train()\n","\n","# 매개변수 보존\n","network.save_params(\"params.pkl\")\n","print(\"Saved Network Parameters!\")\n","\n","# 그래프 그리기\n","markers = {'train': 'o', 'test': 's'}\n","x = np.arange(max_epochs)\n","plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n","plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n","plt.xlabel(\"epochs\")\n","plt.ylabel(\"accuracy\")\n","plt.ylim(0, 1.0)\n","plt.legend(loc='lower right')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"nOs_dDaEUDYb"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":["Q7OXXkcoTZdq"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}