{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"220605_FGSM_MNIST.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"eViqOeBwm2Pd"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","\n","import numpy as np \n","\n","print(tf.__version__)   # Tensorflow의 버전을 출력\n","\n","mnist = keras.datasets.mnist\n","\n","# MNIST 데이터를 로드. 다운로드하지 않았다면 다운로드까지 자동으로 진행됩니다. \n","(x_train, y_train), (x_test, y_test) = mnist.load_data()   "]},{"cell_type":"code","source":["import copy"],"metadata":{"id":"Qyna9Wn3RCk7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.imshow(x_train[0],cmap=plt.cm.binary) #[1]은 x_train의 2번째 이미지 \n","plt.show()\n","print('target_label is :',y_train[0])"],"metadata":{"id":"C1Gi36G7s5yr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["MNIST 데이터 셋 확인\n","\n","데이터의 Shape, type, 차원 등 정보를 확인하겠다"],"metadata":{"id":"iCB2-k-Dtxvq"}},{"cell_type":"code","source":["print('학습 손글씨 데이터 개수 :',len(x_train))\n","print('학습 손글씨 데이터 개수 :',len(y_train))\n","print('테스트 손글씨 데이터 개수 :',len(x_test))\n","print('테스트 손글씨 데이터 개수 :',len(y_test))"],"metadata":{"id":"_uh2mS0Zt7Hz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train[0]"],"metadata":{"id":"_QtvFSQcuZs8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train[0].shape"],"metadata":{"id":"7LCRxxxduh_y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_train.shape"],"metadata":{"id":"pquag0jBbyYE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_train"],"metadata":{"id":"9iCnbEPxb0sZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_train_reshape = y_train.reshape((60000,-1))\n","y_test_reshape = y_test.reshape((10000,-1))"],"metadata":{"id":"GbKQN5KBAyyl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_train_reshape.shape"],"metadata":{"id":"8cGoDmDoA6R6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_test_reshape.shape"],"metadata":{"id":"XvPvbfUlGpwc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_train_reshape"],"metadata":{"id":"KDTOuopnb3oU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_test_reshape"],"metadata":{"id":"VQk1k_ejb9ng"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["target label one-hot encoding\n","\n","0~9까지 인식되는 타겟 데이터를 원 핫 인코딩 시키겠다 --> softmax에 넣기 위함"],"metadata":{"id":"n-8yqeCvmeQ0"}},{"cell_type":"code","source":["from sklearn.preprocessing import OneHotEncoder\n","\n","one_hot_encoder = OneHotEncoder(sparse = False)\n","y_train_reshape_onehot = one_hot_encoder.fit_transform(y_train_reshape)\n","y_train_reshape_onehot"],"metadata":{"id":"8OH2raSEoDbW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import OneHotEncoder\n","\n","one_hot_encoder = OneHotEncoder(sparse = False)\n","y_test_reshape_onehot = one_hot_encoder.fit_transform(y_test_reshape)\n","y_test_reshape_onehot"],"metadata":{"id":"Q4cMqgktmtvi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_train_reshape_onehot.shape"],"metadata":{"id":"sNqdqqQmoKly"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_test_reshape_onehot.shape"],"metadata":{"id":"v_qaK-fin_HT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_test_reshape"],"metadata":{"id":"pa7R9rgTnXVr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["28 x 28 데이터가 60000장 있는 것이다.\n","이를 input으로 넣어주어야한다.\n","\n","- RGB가 아닌 Gray Scale이므로 Flatten은 불필요\n","- 255로 normalization 진행"],"metadata":{"id":"edcp5tjSvi0w"}},{"cell_type":"code","source":["x_train_flatten = x_train.reshape(x_train.shape[0],-1)\n","x_test_flatten = x_test.reshape(x_test.shape[0],-1)"],"metadata":{"id":"v5fa-12Fw3i1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train_flatten.shape"],"metadata":{"id":"VzcM1f5K0YeP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_test_flatten.shape"],"metadata":{"id":"L3Wud02a3cQ4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train_flatten_normalize = x_train_flatten/255.\n","x_test_flatten_normalize = x_test_flatten/255."],"metadata":{"id":"gnJLybZ23HNf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["모델링\n","\n","- 기울기 계산을 통한 순전파, 역전파로 모델을 학습하겠다."],"metadata":{"id":"jkz8ubJA4F3a"}},{"cell_type":"code","source":["def softmax(self, Z):\n","    expZ = np.exp(Z - np.max(Z))\n","    return expZ / expZ.sum(axis = 0, keepdims = True)"],"metadata":{"id":"1c1G2tt9uTKn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def forward(self.X):\n","    store = {}\n","\n","    A = X.T\n","    for l in range(self.L - 1):\n","        Z = self.parameters['W' + str(l+1)].dot(A) + self.parameters['b' + str(l+1)]\n","        A = self.sigmoid(Z)\n","        store['A' + str(l+1)] = A\n","        store['W' + str(l+1)] = self.parameters['W' + str(l+1)]\n","        store['Z' + str(l+1)] = Z\n","    \n","    Z = self.parameters['W' + str(self.L)].dot(A) + self.parameters['b' + str(L)]\n","    A = self.softmax(Z)\n","    store['A' + str(L)] = A\n","    store['W' + str(L)] = self.parameters['W' + str(L)]\n","    store['Z' + str(L)] = Z\n","\n","    return A, store"],"metadata":{"id":"L2AazB0-uwLq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cost = -np.mean(Y * np.log(A.T + 1e-8))"],"metadata":{"id":"WnlIJGPkv9Ry"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def backward(self,X,Y,store):\n","\n","    derivatives = {}\n","\n","    store['A0'] = X.T\n","\n","    A = store['A' + str(self.L)]\n","    dZ = A - Y.T\n","\n","    dW = dZ.dot(store['A' + str(self.L - 1)].T) / self.n\n","    db = np.sum(dZ, axis = 1, keepdims = True) / self.n\n","    dAPrev = store['W' + str(self.L)].T.dot(dZ)\n","\n","    derivatives['dW' + str(self.L)] = dW\n","    derivatives['db' + str(self.L)] = db\n","\n","    for l in range(self.L - 1,0,-1):\n","        dZ = dAPrev * self.sigmoid_derivative(store['Z' + str(l)])\n","        dW = dZ.dot(store['A' + str(l-1)].T) / self.n\n","        db = np.sum(dZ, axis = 1, keepdims = True) / self.n\n","        if l > 1:\n","            dAPrev = store['W' + str(l)].T.dot(dZ)\n","\n","        derivatives[\"dW\" + str(l)] = dW\n","\t\tderivatives[\"db\" + str(l)] = db\n","\n","    return derivatives"],"metadata":{"id":"oIRpOIDrwYih"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def pre_process_data(train_x, train_y, test_x, test_y):\n","    train_x = train_x / 255.\n","    test_x = test_x / 255.\n"," \n","    enc = OneHotEncoder(sparse=False, categories='auto')\n","    train_y = enc.fit_transform(train_y.reshape(len(train_y), -1))\n"," \n","    test_y = enc.transform(test_y.reshape(len(test_y), -1))\n"," \n","    return train_x, train_y, test_x, test_y"],"metadata":{"id":"5n5mzuM60wTb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def predict(self, X, Y):\n","\tA, cache = self.forward(X)\n","\ty_hat = np.argmax(A, axis=0)\n","\tY = np.argmax(Y, axis=1)\n","\taccuracy = (y_hat == Y).mean()\n","\treturn accuracy * 100"],"metadata":{"id":"a-cge_gC4BS4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.preprocessing import OneHotEncoder\n","import tensorflow as tf\n","from tensorflow import keras\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","\n","mnist = keras.datasets.mnist\n","\n","class ANN:\n","    def __init__(self, layers_size):\n","        self.layers_size = layers_size\n","        self.parameters = {}\n","        self.L = len(self.layers_size)\n","        self.n = 0\n","        self.costs = []\n","    \n","    def sigmoid(self, Z):\n","        return 1 / (1 + np.exp(-Z))\n","\n","    def softmax(self, Z):\n","        expZ = np.exp(Z - np.max(Z))\n","        return expZ / expZ.sum(axis=0, keepdims=True)\n","    \n","    def initialize_parameters(self):\n","        for l in range(1, len(self.layers_size)):\n","            self.parameters[\"W\" + str(l)] = np.random.randn(self.layers_size[l], self.layers_size[l - 1]) / np.sqrt(self.layers_size[l - 1])\n","            self.parameters[\"b\" + str(l)] = np.zeros((self.layers_size[l], 1))\n","    \n","    def forward(self, X):\n","        store = {}\n"," \n","        A = X.T\n","        for l in range(self.L - 1):\n","            Z = self.parameters[\"W\" + str(l + 1)].dot(A) + self.parameters[\"b\" + str(l + 1)]\n","            A = self.sigmoid(Z)\n","            store[\"A\" + str(l + 1)] = A\n","            store[\"W\" + str(l + 1)] = self.parameters[\"W\" + str(l + 1)]\n","            store[\"Z\" + str(l + 1)] = Z\n"," \n","        Z = self.parameters[\"W\" + str(self.L)].dot(A) + self.parameters[\"b\" + str(self.L)]\n","        A = self.softmax(Z)\n","        store[\"A\" + str(self.L)] = A\n","        store[\"W\" + str(self.L)] = self.parameters[\"W\" + str(self.L)]\n","        store[\"Z\" + str(self.L)] = Z\n"," \n","        return A, store\n"," \n","    def sigmoid_derivative(self, Z):\n","        s = 1 / (1 + np.exp(-Z))\n","        return s * (1 - s)\n","\n","    def backward(self,X,Y,store):\n","\n","        derivatives = {}\n","\n","        store['A0'] = X.T\n","\n","        A = store['A' + str(self.L)]\n","        dZ = A - Y.T\n","\n","        dW = dZ.dot(store['A' + str(self.L - 1)].T) / self.n\n","        db = np.sum(dZ, axis = 1, keepdims = True) / self.n\n","        dAPrev = store['W' + str(self.L)].T.dot(dZ)\n","\n","        derivatives['dW' + str(self.L)] = dW\n","        derivatives['db' + str(self.L)] = db\n","\n","        for l in range(self.L - 1,0,-1):\n","            dZ = dAPrev * self.sigmoid_derivative(store['Z' + str(l)])\n","            dW = dZ.dot(store['A' + str(l-1)].T) / self.n\n","            db = np.sum(dZ, axis = 1, keepdims = True) / self.n\n","            if l > 1:\n","                dAPrev = store['W' + str(l)].T.dot(dZ)\n","            derivatives[\"dW\" + str(l)] = dW\n","            derivatives[\"db\" + str(l)] = db\n","\n","        return derivatives\n","\n","    def fit(self, X, Y, learning_rate=0.01, n_iterations=300):\n","        self.n = X.shape[0]\n"," \n","        self.layers_size.insert(0, X.shape[1])\n"," \n","        self.initialize_parameters()\n","        for loop in range(n_iterations):\n","            A, store = self.forward(X)\n","            cost = -np.mean(Y * np.log(A.T+ 1e-8))\n","            derivatives = self.backward(X, Y, store)\n"," \n","            for l in range(1, self.L + 1):\n","                self.parameters[\"W\" + str(l)] = self.parameters[\"W\" + str(l)] - learning_rate * derivatives[\"dW\" + str(l)]\n","                self.parameters[\"b\" + str(l)] = self.parameters[\"b\" + str(l)] - learning_rate * derivatives[\"db\" + str(l)]\n"," \n","            if loop % 100 == 0:\n","                print(\"Cost: \", cost, \"Train Accuracy:\", self.predict(X, Y))\n"," \n","            if loop % 10 == 0:\n","                self.costs.append(cost)\n","\n","    def predict(self, X, Y):\n","        A, cache = self.forward(X)\n","        y_hat = np.argmax(A, axis=0)\n","        Y = np.argmax(Y, axis=1)\n","        accuracy = (y_hat == Y).mean()\n","        return accuracy * 100\n","    \n","    def predict_output(self, X):\n","        A, cache = self.forward(X)\n","        y_hat = np.argmax(A, axis=0)\n","        return y_hat\n","\n","    def plot_cost(self):\n","        plt.figure()\n","        plt.plot(np.arange(len(self.costs)), self.costs)\n","        plt.xlabel(\"epochs\")\n","        plt.ylabel(\"cost\")\n","        plt.show()\n","\n","def pre_process_data(train_x, train_y, test_x, test_y):\n","    # Normalize\n","    train_x = train_x / 255.\n","    test_x = test_x / 255.\n"," \n","    enc = OneHotEncoder(sparse=False, categories='auto')\n","    train_y = enc.fit_transform(train_y.reshape(len(train_y), -1))\n"," \n","    test_y = enc.transform(test_y.reshape(len(test_y), -1))\n","    \n","    train_x_flatten = train_x.reshape(train_x.shape[0],-1)\n","    test_x_flatten = test_x.reshape(test_x.shape[0],-1)\n","    \n","    return train_x_flatten, train_y, test_x_flatten, test_y\n","\n","if __name__ == '__main__':\n","    (train_x, train_y), (test_x, test_y) = mnist.load_data()\n"," \n","    train_x, train_y, test_x, test_y = pre_process_data(train_x, train_y, test_x, test_y)\n"," \n","    print(\"train_x's shape: \" + str(train_x.shape))\n","    print(\"test_x's shape: \" + str(test_x.shape))\n","    print(\"train_y's shape: \" + str(train_y.shape))\n","    print(\"test_y's shape: \" + str(test_y.shape))\n"," \n"," \n","    layers_dims = [50, 10]\n"," \n","    ann = ANN(layers_dims)\n","    ann.fit(train_x, train_y, learning_rate=0.1, n_iterations=300)\n","    print(\"Train Accuracy:\", ann.predict(train_x, train_y))\n","    print(\"Test Accuracy:\", ann.predict(test_x, test_y))\n","    ann.plot_cost()    "],"metadata":{"id":"DHkIU1z04D0l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ann"],"metadata":{"id":"uCOR3HHImLMn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["FGSM 구현"],"metadata":{"id":"uL7NXHWqhvLc"}},{"cell_type":"code","source":["epsilons = [0, .05, .1, .15, .2, .25, .3]"],"metadata":{"id":"BvMnEzvS-_1-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# FGSM 공격 코드\n","def fgsm_attack(image, epsilon, data_grad):\n","    # data_grad 의 요소별 부호 값을 얻어옵니다\n","    sign_data_grad = np.sign(data_grad)\n","    # 입력 이미지의 각 픽셀에 sign_data_grad 를 적용해 작은 변화가 적용된 이미지를 생성합니다\n","    perturbed_image = image + epsilon*sign_data_grad\n","    # 값 범위를 [0,1]로 유지하기 위해 자르기(clipping)를 추가합니다\n","# perturbed_image = torch.clamp(perturbed_image, 0, 1)\n","    # 작은 변화가 적용된 이미지를 리턴합니다\n","    return perturbed_image"],"metadata":{"id":"imCYUyMdfBIe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## predict_output에 한개씩 넣는 것부터 구현해야한다. (전체가 들어가는 것만 정상 작동함)\n","\n","def test(model, test_x, test_y, epsilon, layers_dims):\n","\n","    # 정확도 카운터\n","    correct = 0\n","    adv_examples = []\n","\n","    # 테스트 셋의 모든 예제에 대해 루프를 돕니다\n","    \n","    for i in range(len(test_x)):\n","        data = test_x[i].reshape(1,784)\n","        target = test_y[i].reshape(1,10)\n","        \n","        A,store = model.forward(data)\n","        output = model.predict_output(data)\n","        \n","        #if output != np.argmax(target,axis = 1):\n","            #continue\n","\n","        data_grad = model.backward(data,target,store)\n","        print(data_grad)\n","\n","        #perturbed_data = fgsm_attack(data, epsilon, data_grad)\n","\n","        #print(perturbed_data)"],"metadata":{"id":"ffh28GpmkxTD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## predict_output에 한개씩 넣는 것부터 구현해야한다. (전체가 들어가는 것만 정상 작동함)\n","\n","def test(model, test_x, test_y, epsilon, layers_dims):\n","\n","\n","    data = test_x[0].reshape(1,784)\n","    target = test_y[0].reshape(1,10)\n","        \n","    A,store = model.forward(data)\n","    output = model.predict_output(data)\n","        \n","        #if output != np.argmax(target,axis = 1):\n","            #continue\n","\n","    data_grad = model.backward(data,target,store)\n","\n","    for data_grad.items():\n","        \n","\n","    print(data_grad_array.shape)\n","    #perturbed_data = fgsm_attack(data, epsilon, data_grad)\n","\n","    #print(perturbed_data)"],"metadata":{"id":"LFqthe5LlbBO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test(ann, test_x, test_y, epsilons, layers_dims)"],"metadata":{"id":"EyYqCyEwmOlJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["A = ann.predict_output(test_x0)\n","A"],"metadata":{"id":"chzEPjLRfd2W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.sum(A)"],"metadata":{"id":"WWXRPDq3g2B2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_x0 = test_x[0].reshape(1,784)"],"metadata":{"id":"z8TOFtutf2ej"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_x0.shape"],"metadata":{"id":"ONZYf9Pbgw_N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def test(model, test_x, test_y, epsilon, layers_dims):\n","\n","    # 정확도 카운터\n","    correct = 0\n","    adv_examples = []\n","\n","    # 테스트 셋의 모든 예제에 대해 루프를 돕니다\n","    for data, target in test_x, test_y:\n","\n","        # 데이터를 모델에 통과시킵니다\n","        output = model.predict_output(data)\n","        print(output)\n","        init_pred = output.max(1, keepdim=True)[1] # 로그 확률의 최대값을 가지는 인덱스를 얻습니다\n","\n","        # 만약 초기 예측이 틀리면, 공격하지 않도록 하고 계속 진행합니다\n","        if init_pred.item() != target.item():\n","            continue\n","\n","        # 손실을 계산합니다\n","        loss = F.nll_loss(output, target)\n","\n","        # 모델의 변화도들을 전부 0으로 설정합니다\n","        model.zero_grad()\n","\n","        # 후방 전달을 통해 모델의 변화도를 계산합니다\n","        loss.backward()\n","\n","        # 변화도 값을 모읍니다\n","        data_grad = data.grad.data\n","\n","        # FGSM 공격을 호출합니다\n","        perturbed_data = fgsm_attack(data, epsilon, data_grad)\n","\n","        # 작은 변화가 적용된 이미지에 대해 재분류합니다\n","        output = model(perturbed_data)\n","\n","        # 올바른지 확인합니다\n","        final_pred = output.max(1, keepdim=True)[1] # 로그 확률의 최대값을 가지는 인덱스를 얻습니다\n","        if final_pred.item() == target.item():\n","            correct += 1\n","            # 0 엡실론 예제에 대해서 저장합니다\n","            if (epsilon == 0) and (len(adv_examples) < 5):\n","                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n","                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n","        else:\n","            # 추후 시각화를 위하 다른 예제들을 저장합니다\n","            if len(adv_examples) < 5:\n","                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n","                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n","\n","    # 해당 엡실론에서의 최종 정확도를 계산합니다\n","    final_acc = correct/float(len(test_loader))\n","    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(test_loader), final_acc))\n","\n","    # 정확도와 적대적 예제를 리턴합니다\n","    return final_acc, adv_examples"],"metadata":{"id":"0WG6IxGjikNa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"f5S6Ny4ZjXeE"},"execution_count":null,"outputs":[]}]}